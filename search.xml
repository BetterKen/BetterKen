<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>16.ES读性能优化</title>
      <link href="/2020/03/05/16-ES%E8%AF%BB%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"/>
      <url>/2020/03/05/16-ES%E8%AF%BB%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/</url>
      
        <content type="html"><![CDATA[<ul><li><strong>加大filesystem cache，写入 es 的数据最好小于等于，或者是略微大于 es 的 filesystem cache 的内存容量。</strong>然后你从 es 检索可能就花费 20ms，然后再根据 es 返回的 id 去 hbase 里查询，查 20 条数据，可能也就耗费个 30ms</li><li><strong>数据预热</strong></li><li><strong>冷热分离</strong>,最好是将冷数据写入一个索引中，然后热数据写入另外一个索引中，这样可以确保热数据在被预热之后，尽量都让他们留在 filesystem os cache 里，别让冷数据给冲刷掉。</li><li><strong>不允许深度分页</strong></li><li><strong>尽量使用 Filter Context，利用缓存机制，减少不必要的算分</strong></li><li><strong>反范式化数据,尽量不要父子文档和nested类型数据</strong></li><li><strong>严禁使用 * 开头通配符 Terms 查询与正则查询</strong></li><li><strong>避免查询是使用脚本,可以在 Index 文档时，使用 Ingest Pipeline，计算并写 入某个字段</strong></li><li><strong>聚合查询会消耗内存，特别是针对很大的数据集进行聚合运算</strong></li><li><strong>避免过度分片,控制单分片尺寸:</strong><ul><li><strong>search类20GB</strong></li><li><strong>Logging类40GB</strong></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Elaticsearch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elaticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>15.ES写性能优化</title>
      <link href="/2020/03/05/15-ES%E5%86%99%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"/>
      <url>/2020/03/05/15-ES%E5%86%99%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/</url>
      
        <content type="html"><![CDATA[<ul><li><strong>增大写吞吐量（Events Per Second），越高越好</strong></li><li><strong>客户端:多线程,批量写</strong></li><li><strong>建立高质量的数据建模,反范式化</strong></li><li><strong>关闭无关的功能:</strong><ul><li><strong>只需要聚合不需要搜索，Index 设置成 false</strong> </li><li><strong>不需要算分，Norms 设置成 false</strong> </li><li><strong>不要对字符串使用默认的 dynamic mapping。字段 数量过多，会对性能产生比较大的影响</strong> </li><li><strong>Index_options 控制在创建倒排索引时，哪些内容 会被添加到倒排索引中。优化这些设置，一定程度 可以节约 CPU</strong> </li><li><strong>指标型数据关闭 _source，减少 IO 操作</strong></li></ul></li><li><strong>降低refresh频率</strong></li><li><strong>降低translog频率</strong></li><li><strong>副本数可以在写入时设置为0,完成后再增加</strong></li></ul>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Elaticsearch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elaticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>14.ES的并发控制</title>
      <link href="/2020/03/04/14-ES%E7%9A%84%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6/"/>
      <url>/2020/03/04/14-ES%E7%9A%84%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<p>两个 Web 程序同时更新某个⽂档，如果缺乏有效的并发，会导致更改的数据丢失</p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/eslock.png" alt=""></p><h2 id="14-1-锁的选择"><a href="#14-1-锁的选择" class="headerlink" title="14.1 锁的选择"></a>14.1 锁的选择</h2><p>ES采用乐观锁实现并发控制</p><h2 id="14-2-具体实现"><a href="#14-2-具体实现" class="headerlink" title="14.2 具体实现"></a>14.2 具体实现</h2><p>ES 中的⽂档是不可变更的。如果你更新⼀个⽂档，会将就⽂档标记为删除，同时增加⼀个全新的⽂档。同时⽂档的 version 字段加 1</p><p>ES实现用两种方式实现乐观锁的CAS机制:</p><ul><li><strong>内部版本控制</strong>:version</li><li><strong>使⽤外部版本(使⽤其他数据库作为主要数据存储)</strong> :version + version_type=external</li></ul><h3 id="14-2-1-内部版本控制"><a href="#14-2-1-内部版本控制" class="headerlink" title="14.2.1 内部版本控制"></a>14.2.1 内部版本控制</h3><pre><code class="json">GET staffs/base/1#获取结果{  &quot;_index&quot;: &quot;staffs&quot;,  &quot;_type&quot;: &quot;base&quot;,  &quot;_id&quot;: &quot;1&quot;,  &quot;_version&quot;: 7,  &quot;found&quot;: true,  &quot;_source&quot;: {    &quot;firstName&quot;: &quot;Song&quot;,    &quot;lastName&quot;: &quot;Gao&quot;,    &quot;age&quot;: 11,    &quot;mobile&quot;: &quot;13888888888&quot;,    &quot;birthday&quot;: &quot;1999-01-01&quot;,    &quot;died&quot;: false,    &quot;province&quot;: &quot;tj&quot;,    &quot;address&quot;: &quot;tj tanggu daliangzi&quot;,    &quot;tags&quot;: [      &quot;yellow&quot;,      &quot;blue&quot;    ],    &quot;tagsCount&quot;: 2  }}# 根据version值进行更新PUT staffs/base/1?version=7{  &quot;firstName&quot;: &quot;Song&quot;,  &quot;lastName&quot;: &quot;Gao&quot;,  &quot;age&quot;: 11,  &quot;mobile&quot;: &quot;13888888888&quot;,  &quot;birthday&quot;: &quot;1999-01-01&quot;,  &quot;died&quot;: false,  &quot;province&quot;: &quot;tj&quot;,  &quot;address&quot;: &quot;tj tanggu daliangzi&quot;,  &quot;tags&quot;: [    &quot;yellow&quot;,    &quot;blue&quot;  ],  &quot;tagsCount&quot;: 2}#获得结果{  &quot;_index&quot;: &quot;staffs&quot;,  &quot;_type&quot;: &quot;base&quot;,  &quot;_id&quot;: &quot;1&quot;,  &quot;_version&quot;: 8,  &quot;result&quot;: &quot;updated&quot;,  &quot;_shards&quot;: {    &quot;total&quot;: 2,    &quot;successful&quot;: 2,    &quot;failed&quot;: 0  },  &quot;_seq_no&quot;: 10,  &quot;_primary_term&quot;: 1}#同版本再次更新PUT staffs/base/1?version=7{  &quot;firstName&quot;: &quot;Song&quot;,  &quot;lastName&quot;: &quot;Gao&quot;,  &quot;age&quot;: 11,  &quot;mobile&quot;: &quot;13888888888&quot;,  &quot;birthday&quot;: &quot;1999-01-01&quot;,  &quot;died&quot;: false,  &quot;province&quot;: &quot;tj&quot;,  &quot;address&quot;: &quot;tj tanggu daliangzi&quot;,  &quot;tags&quot;: [    &quot;yellow&quot;,    &quot;blue&quot;  ],  &quot;tagsCount&quot;: 2}#获得结果{  &quot;error&quot;: {    &quot;root_cause&quot;: [      {        &quot;type&quot;: &quot;version_conflict_engine_exception&quot;,        &quot;reason&quot;: &quot;[base][1]: version conflict, current version [8] is different than the one provided [7]&quot;,        &quot;index_uuid&quot;: &quot;R3L64DNzQjWcdoUo8mLJNw&quot;,        &quot;shard&quot;: &quot;3&quot;,        &quot;index&quot;: &quot;staffs&quot;      }    ],    &quot;type&quot;: &quot;version_conflict_engine_exception&quot;,    &quot;reason&quot;: &quot;[base][1]: version conflict, current version [8] is different than the one provided [7]&quot;,    &quot;index_uuid&quot;: &quot;R3L64DNzQjWcdoUo8mLJNw&quot;,    &quot;shard&quot;: &quot;3&quot;,    &quot;index&quot;: &quot;staffs&quot;  },  &quot;status&quot;: 409}</code></pre><h3 id="14-2-2-外部版本控制"><a href="#14-2-2-外部版本控制" class="headerlink" title="14.2.2 外部版本控制"></a>14.2.2 外部版本控制</h3><ul><li><strong>GET传参多加入version_type=external参数</strong></li><li><strong>此时的version等于外部的版本号</strong></li></ul><pre><code class="json">PUT staffs/base/1?version=3000&amp;version_type=external{  &quot;firstName&quot;: &quot;Song&quot;,  &quot;lastName&quot;: &quot;Gao&quot;,  &quot;age&quot;: 11,  &quot;mobile&quot;: &quot;13888888888&quot;,  &quot;birthday&quot;: &quot;1999-01-01&quot;,  &quot;died&quot;: false,  &quot;province&quot;: &quot;tj&quot;,  &quot;address&quot;: &quot;tj tanggu daliangzi&quot;,  &quot;tags&quot;: [    &quot;yellow&quot;,    &quot;blue&quot;  ],  &quot;tagsCount&quot;: 2}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Elaticsearch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elaticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>13.ES分布式查询及相关性算分</title>
      <link href="/2020/03/04/13-ES%E5%88%86%E5%B8%83%E5%BC%8F%E6%9F%A5%E8%AF%A2%E5%8F%8A%E7%9B%B8%E5%85%B3%E6%80%A7%E7%AE%97%E5%88%86/"/>
      <url>/2020/03/04/13-ES%E5%88%86%E5%B8%83%E5%BC%8F%E6%9F%A5%E8%AF%A2%E5%8F%8A%E7%9B%B8%E5%85%B3%E6%80%A7%E7%AE%97%E5%88%86/</url>
      
        <content type="html"><![CDATA[<h2 id="13-1-分布式搜索的运行机制"><a href="#13-1-分布式搜索的运行机制" class="headerlink" title="13.1 分布式搜索的运行机制"></a>13.1 分布式搜索的运行机制</h2><p>ES的搜索会分两个阶段进行:</p><ul><li>第一阶段－－Query</li><li>第二阶段－－Fetch</li></ul><p>因此我们称ES的搜索运行机制为 <strong>Query-Then-Fetch</strong></p><h2 id="13-2-Query阶段"><a href="#13-2-Query阶段" class="headerlink" title="13.2 Query阶段"></a>13.2 Query阶段</h2><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/esquery.png" alt=""></p><h2 id="13-3-Fetch阶段"><a href="#13-3-Fetch阶段" class="headerlink" title="13.3  Fetch阶段"></a>13.3  Fetch阶段</h2><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/esfetch.png" alt=""></p><h2 id="13-4-Query-Then-Fetch-潜在的问题"><a href="#13-4-Query-Then-Fetch-潜在的问题" class="headerlink" title="13.4 Query Then Fetch 潜在的问题"></a>13.4 Query Then Fetch 潜在的问题</h2><h3 id="13-4-1-深度分页"><a href="#13-4-1-深度分页" class="headerlink" title="13.4.1 深度分页"></a>13.4.1 深度分页</h3><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/esfromsize.png" alt=""></p><ul><li><strong>每个分片上需要查的文档个数=from + size</strong></li><li><strong>最终协调节点需要处理：number_of_shard * ( from+size )</strong></li><li><strong>导致深度分页</strong></li></ul><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/esdeep.png" alt=""></p><h3 id="13-4-2-相关性算分"><a href="#13-4-2-相关性算分" class="headerlink" title="13.4.2 相关性算分"></a>13.4.2 相关性算分</h3><p><strong>每个分片都基于自己的分片上的数据进行相关度计算</strong>。</p><p>这会导致打分偏离的情况，特别是数据量很少时。相关性算分在分片之间是相互独立。当文档总数很少的情况下，如果主分片大于1,主分片数越多，相关性算分会越不准</p><h2 id="13-5-解决问题"><a href="#13-5-解决问题" class="headerlink" title="13.5 解决问题"></a>13.5 解决问题</h2><h3 id="13-4-1-深度分页-1"><a href="#13-4-1-深度分页-1" class="headerlink" title="13.4.1 深度分页"></a>13.4.1 深度分页</h3><p>使用search_after或scroll api来避免深度分页问题</p><p>思想都是:</p><ul><li><strong>可以实时获取下⼀⻚⽂档信息</strong></li><li><strong>不⽀持指定⻚数（From）</strong></li><li><strong>只能往下翻</strong></li></ul><h4 id="13-4-1-1-search-after"><a href="#13-4-1-1-search-after" class="headerlink" title="13.4.1.1 search after"></a>13.4.1.1 search after</h4><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/essearchafter.png" alt=""></p><pre><code class="json">#第一次取GET staffs/base/_search{  &quot;query&quot;: {      &quot;match_all&quot;: {}  },  &quot;size&quot;: 1,  &quot;sort&quot;: [    {      &quot;age&quot;: {        &quot;order&quot;: &quot;desc&quot;      },      &quot;_id&quot;:{        &quot;order&quot;: &quot;desc&quot;      }    }  ]}## 获取到sort数组{  &quot;took&quot;: 3,  &quot;timed_out&quot;: false,  &quot;_shards&quot;: {    &quot;total&quot;: 5,    &quot;successful&quot;: 5,    &quot;skipped&quot;: 0,    &quot;failed&quot;: 0  },  &quot;hits&quot;: {    &quot;total&quot;: 8,    &quot;max_score&quot;: null,    &quot;hits&quot;: [      {        &quot;_index&quot;: &quot;staffs&quot;,        &quot;_type&quot;: &quot;base&quot;,        &quot;_id&quot;: &quot;6&quot;,        &quot;_score&quot;: null,        &quot;_source&quot;: {          &quot;firstName&quot;: &quot;MML&quot;,          &quot;lastName&quot;: &quot;ZLA&quot;,          &quot;age&quot;: 88,          &quot;mobile&quot;: &quot;23688885589&quot;,          &quot;birthday&quot;: &quot;1944-01-02&quot;,          &quot;died&quot;: false,          &quot;province&quot;: &quot;sh&quot;,          &quot;address&quot;: &quot;zn minghanglu  aaa  daliangzi&quot;        },        &quot;sort&quot;: [          88,          &quot;6&quot;        ]      }    ]  }}## 根据sort数组里面的值　使用search after查询GET staffs/base/_search{  &quot;query&quot;: {      &quot;match_all&quot;: {}  },  &quot;size&quot;: 1,  &quot;search_after&quot;:[88,&quot;6&quot;],  &quot;sort&quot;: [    {      &quot;age&quot;: {        &quot;order&quot;: &quot;desc&quot;      },      &quot;_id&quot;:{        &quot;order&quot;: &quot;desc&quot;      }    }  ]}</code></pre><h4 id="13-4-1-2-scroll-API"><a href="#13-4-1-2-scroll-API" class="headerlink" title="13.4.1.2 scroll API"></a>13.4.1.2 scroll API</h4><ul><li><strong>创建一个快照，有新的数据写入以后，无法被查到</strong></li><li>每次查询后，输入上一次的Scroll Id</li></ul><pre><code class="json">#先获取到scroll_id#scroll=5m含义:将快照保留5minGET staffs/base/_search?scroll=5m{  &quot;size&quot;: 2,  &quot;query&quot;: {    &quot;match_all&quot;: {}  }}#根据scroll_id获取信息#注意每次返回的size等于第一次查询的时候指定的size#scroll:1m 表明快照再延续保留1minGET _search/scroll{  &quot;scroll&quot;:&quot;1m&quot;,  &quot;scroll_id&quot;: &quot;DnF1ZXJ5VGhlbkZldGNoBQAAAAAAAKo3Fk1mWktWa0ViVHh1OEcyZTE1eVF2MUEAAAAAAACqNhZNZlpLVmtFYlR4dThHMmUxNXlRdjFBAAAAAAAAqjkWTWZaS1ZrRWJUeHU4RzJlMTV5UXYxQQAAAAAAAKo4Fk1mWktWa0ViVHh1OEcyZTE1eVF2MUEAAAAAAACqOhZNZlpLVmtFYlR4dThHMmUxNXlRdjFB&quot;}</code></pre><h4 id="13-4-1-3-scroll-api和search-after的区别"><a href="#13-4-1-3-scroll-api和search-after的区别" class="headerlink" title="13.4.1.3 scroll api和search after的区别"></a>13.4.1.3 scroll api和search after的区别</h4><ul><li><strong>search after可以实时获取下一页文档信息</strong></li><li><strong>scroll 是从快照信息中获取数据</strong></li></ul><h3 id="13-4-2-相关性算分-1"><a href="#13-4-2-相关性算分-1" class="headerlink" title="13.4.2 相关性算分"></a>13.4.2 相关性算分</h3><ul><li>数据量不⼤的时候，可以将<strong>主分⽚数设置为 1</strong> </li><li>当数据量⾜够⼤时候，<strong>只要保证⽂档均匀分散在各个分⽚上</strong>，结果⼀般就不会出现偏差</li></ul>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Elaticsearch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elaticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>12.ES查询</title>
      <link href="/2020/03/04/12-ES%E5%9F%BA%E6%9C%AC%E6%A3%80%E7%B4%A2%E7%B1%BB%E5%9E%8B/"/>
      <url>/2020/03/04/12-ES%E5%9F%BA%E6%9C%AC%E6%A3%80%E7%B4%A2%E7%B1%BB%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<h2 id="12-1-检索和过滤"><a href="#12-1-检索和过滤" class="headerlink" title="12.1 检索和过滤"></a>12.1 检索和过滤</h2><h3 id="12-1-1-检索和过滤的区别"><a href="#12-1-1-检索和过滤的区别" class="headerlink" title="12.1.1 检索和过滤的区别"></a>12.1.1 检索和过滤的区别</h3><ul><li><strong>query</strong>：查询操作不仅仅会进行查询，还会计算分值，用于确定相关度；</li><li><strong>filter</strong>：查询操作仅判断是否满足查询条件，不会计算得分，查询的结果可以被缓存。</li></ul><h3 id="12-1-2-检索和过滤的适用场景"><a href="#12-1-2-检索和过滤的适用场景" class="headerlink" title="12.1.2 检索和过滤的适用场景"></a>12.1.2 检索和过滤的适用场景</h3><ul><li>全文检索以及任何使用相关性评分的场景使用query检索。</li><li>除此之外的其他使用filter过滤器过滤。</li></ul><h2 id="12-2-结构化检索"><a href="#12-2-结构化检索" class="headerlink" title="12.2 结构化检索"></a>12.2 结构化检索</h2><h3 id="12-2-1-精确匹配检索"><a href="#12-2-1-精确匹配检索" class="headerlink" title="12.2.1 精确匹配检索"></a>12.2.1 精确匹配检索</h3><ul><li><strong>term 单值精确匹配</strong></li><li><strong>terms多值精确匹配</strong></li></ul><p>Term 查询，对输⼊不做分词。会将输⼊作为⼀个整体，在倒排索引中查找准确的词项，并且使⽤相关度算分公式为<strong>每个包含该词项的⽂档</strong>进⾏相关度算分</p><pre><code class="json">#search address contains &quot;zn&quot;GET staffs/base/_search{  &quot;query&quot;: {    &quot;term&quot;: {      &quot;address&quot;: {        &quot;value&quot;: &quot;zn&quot;      }    }  }}#search tags contains &quot;yellow&quot; or &quot;red&quot;GET staffs/base/_search{  &quot;query&quot;: {    &quot;constant_score&quot;: {      &quot;filter&quot;: {        &quot;terms&quot;: {          &quot;tags&quot;: [            &quot;yellow&quot;,            &quot;red&quot;          ]        }      }    }  }}</code></pre><h3 id="12-2-2-范围检索"><a href="#12-2-2-范围检索" class="headerlink" title="12.2.2 范围检索"></a>12.2.2 范围检索</h3><ul><li><strong>关键字 range</strong></li><li>gt大于,lt小于,gte大于等于,Ite小于等于</li></ul><pre><code class="json">GET  staffs/base/_search{  &quot;query&quot;: {    &quot;constant_score&quot;: {      &quot;filter&quot;: {        &quot;range&quot;: {          &quot;age&quot;: {            &quot;gte&quot;: 10,            &quot;lte&quot;: 20          }        }      }    }  }}</code></pre><h3 id="12-2-3-存在与否检索"><a href="#12-2-3-存在与否检索" class="headerlink" title="12.2.3 存在与否检索"></a>12.2.3 存在与否检索</h3><ul><li><strong>关键字 exist</strong></li></ul><pre><code class="json"># existGET staffs/base/_search{  &quot;query&quot;: {    &quot;constant_score&quot;: {      &quot;filter&quot;: {        &quot;exists&quot;: {          &quot;field&quot;: &quot;mobile&quot;        }      }    }  }}# not exist#注意是返回mobile字段不存在的doc#不包含doc中mobile为空的GET staffs/base/_search{  &quot;query&quot;: {    &quot;constant_score&quot;: {      &quot;filter&quot;: {        &quot;bool&quot;: {          &quot;must_not&quot;:{            &quot;exists&quot;:{              &quot;field&quot;:&quot;mobile&quot;            }          }        }      }    }  }}</code></pre><h3 id="12-2-4-前缀检索"><a href="#12-2-4-前缀检索" class="headerlink" title="12.2.4 前缀检索"></a>12.2.4 前缀检索</h3><ul><li><strong>关键字prefix</strong></li></ul><pre><code class="json">#查询address以zn开头的数据GET staffs/base/_search{  &quot;query&quot;: {    &quot;prefix&quot;: {      &quot;address&quot;: {        &quot;value&quot;: &quot;zn&quot;      }    }  }}</code></pre><h3 id="12-2-5-通配符模糊检索"><a href="#12-2-5-通配符模糊检索" class="headerlink" title="12.2.5 通配符模糊检索"></a>12.2.5 通配符模糊检索</h3><ul><li><strong>关键字wildcard</strong></li><li>通配符*匹配任意字符（包含空字符）,通配符？匹配任何单个字符。</li><li><strong>注意这个査询可能会比较缓慢，需要在许多索引词上面重复执行。为了避免极端缓慢的通配符査询，通配符索引词不应该以一个通配符开头</strong></li></ul><pre><code class="json">GET staffs/base/_search{  &quot;query&quot;: {    &quot;wildcard&quot;: {      &quot;mobile&quot;: {        &quot;value&quot;: &quot;138*8&quot;      }    }  }}</code></pre><h3 id="12-2-6-正则检索"><a href="#12-2-6-正则检索" class="headerlink" title="12.2.6 正则检索"></a>12.2.6 正则检索</h3><ul><li><strong>关键字regexp</strong></li></ul><pre><code class="json">GET staffs/base/_search{  &quot;query&quot;: {    &quot;regexp&quot;:{      &quot;mobile&quot;:&quot;13[0-9]{9}&quot;    }  }}</code></pre><h3 id="12-2-7-模糊检索"><a href="#12-2-7-模糊检索" class="headerlink" title="12.2.7 模糊检索"></a>12.2.7 模糊检索</h3><ul><li><strong>关键字fuzzy</strong></li></ul><pre><code class="jso">GET staffs/base/_search{  &quot;query&quot;: {    &quot;fuzzy&quot;: {      &quot;address&quot;: {        &quot;value&quot;: &quot;aaa&quot;,        &quot;fuzziness&quot;: 0.5,        &quot;prefix_length&quot;: 0,        &quot;max_expansions&quot;:10      }    }  }}</code></pre><h3 id="12-2-8-主键检索"><a href="#12-2-8-主键检索" class="headerlink" title="12.2.8 主键检索"></a>12.2.8 主键检索</h3><ul><li><strong>关键字ids</strong></li></ul><pre><code class="json">GET staffs/base/_search{  &quot;query&quot;: {    &quot;ids&quot;:{      &quot;values&quot;:[&quot;1&quot;,&quot;2&quot;]    }  }}</code></pre><h2 id="12-3-全文检索"><a href="#12-3-全文检索" class="headerlink" title="12.3 全文检索"></a>12.3 全文检索</h2><h3 id="12-3-1-分词全文检索"><a href="#12-3-1-分词全文检索" class="headerlink" title="12.3.1 分词全文检索"></a>12.3.1 分词全文检索</h3><ul><li><strong>关键字match</strong></li><li>会将query里面的单词进行分词,然后默认or操作搜索</li></ul><pre><code class="json">GET staffs/base/_search{  &quot;query&quot;: {    &quot;match&quot;: {      &quot;address&quot;: {        &quot;query&quot;: &quot;zn daliangzi aaa&quot;      }    }  }}#address中最少应该包含&quot;zn&quot;,&quot;daliangzi&quot;,&quot;aaa&quot;中的两个GET staffs/base/_search{  &quot;query&quot;: {    &quot;match&quot;: {      &quot;address&quot;: {        &quot;query&quot;: &quot;zn daliangzi aaa&quot;,        &quot;minimum_should_match&quot;:2      }    }  }}#change match query operator to andGET staffs/base/_search{  &quot;query&quot;: {    &quot;match&quot;: {      &quot;address&quot;:{         &quot;query&quot;: &quot;zn daliangzi&quot;,        &quot;operator&quot;: &quot;AND&quot;      }    }  }}</code></pre><h3 id="12-3-2-短语检索"><a href="#12-3-2-短语检索" class="headerlink" title="12.3.2 短语检索"></a>12.3.2 短语检索</h3><ul><li><strong>关键字match_phrase</strong></li><li>不将query中的单词进行分词,按照一个整体进行搜索</li><li><strong>slop</strong> 搜索的单词之间最多可以隔几个单词</li></ul><pre><code class="json">GET staffs/base/_search{  &quot;query&quot;: {    &quot;match_phrase&quot;: {      &quot;address&quot;:{        &quot;query&quot;: &quot;zn aaa&quot;      }    }  }}GET staffs/base/_search{  &quot;query&quot;: {    &quot;match_phrase&quot;: {      &quot;address&quot;:{        &quot;query&quot;: &quot;zn aaa&quot;,        &quot;slop&quot;:1      }    }  }}</code></pre><h3 id="12-3-3-短语前缀检索"><a href="#12-3-3-短语前缀检索" class="headerlink" title="12.3.3 短语前缀检索"></a>12.3.3 短语前缀检索</h3><ul><li><strong>关键字match_phrase_prefix</strong></li></ul><pre><code class="json"># 可以匹配:# zn minaaa# zn minbbb# zn mincccGET staffs/base/_search{  &quot;query&quot;: {    &quot;match_phrase_prefix&quot;: {      &quot;address&quot;: &quot;zn min&quot;    }  }}</code></pre><h3 id="12-3-4-多字段匹配检索"><a href="#12-3-4-多字段匹配检索" class="headerlink" title="12.3.4 多字段匹配检索"></a>12.3.4 多字段匹配检索</h3><ul><li><strong>关键字multi_match</strong></li></ul><h4 id="12-3-4-1-三种场景"><a href="#12-3-4-1-三种场景" class="headerlink" title="12.3.4.1 三种场景"></a>12.3.4.1 三种场景</h4><ol><li><strong>最佳字段(Best Fields)</strong>:当字段之间相互竞争，又相互关联。例如title和body这样的字段。评分来自最匹配字段</li><li><strong>多数字段(Most Fields)</strong>:处理英文内容时：一种常见的手段是，在主字English Analyzer),抽取词干，加入同义词，以匹配更多的文档。相同的文本，加入子字段(Standard Analyzer),以提供更加精确的匹配。其他字段作为匹配文档提高相关度的信号。匹配字段越多则越好</li><li><strong>混合字段(Cross Field)</strong>:对于某些实体，例如人名，地址，图书信息。需要在多个字段中确定信息，单个字段只能作为整体的一部分。希望在任何这些列出的字段中找到尽可能多的词</li></ol><h4 id="12-3-4-2-demo"><a href="#12-3-4-2-demo" class="headerlink" title="12.3.4.2 demo"></a>12.3.4.2 demo</h4><pre><code class="json">//adress或者province里包含zn 按照这两个字段中分数高的一个字段排序GET staffs/base/_search{  &quot;query&quot;: {    &quot;multi_match&quot;: {      &quot;query&quot;: &quot;zn&quot;,      &quot;fields&quot;: [&quot;address&quot;,&quot;province&quot;],      &quot;type&quot;:&quot;best_fields&quot;    }  }}//adress或者province里包含zn或sh 按照这两个字段的分数和排序GET staffs/base/_search{  &quot;query&quot;: {    &quot;multi_match&quot;: {      &quot;query&quot;: &quot;zn sh&quot;,      &quot;fields&quot;: [&quot;address&quot;,&quot;province&quot;],      &quot;type&quot;:&quot;most_fields&quot;    }  }}//adress和province里　总共包含zn和sh//按照这两个字段的分数和排序GET staffs/base/_search{  &quot;query&quot;: {    &quot;multi_match&quot;: {      &quot;query&quot;: &quot;zn sh&quot;,      &quot;fields&quot;: [&quot;address&quot;,&quot;province&quot;],      &quot;type&quot;:&quot;cross_fields&quot;,      &quot;operator&quot;:&quot;AND&quot;    }  }}</code></pre><h3 id="12-3-5-支持与或非字符串检索"><a href="#12-3-5-支持与或非字符串检索" class="headerlink" title="12.3.5 支持与或非字符串检索"></a>12.3.5 支持与或非字符串检索</h3><ul><li><strong>关键字query string</strong></li><li>可以添加 AND/OR查询条件</li><li>支持多字段查询</li></ul><pre><code class="json">GET staffs/base/_search{  &quot;query&quot;: {    &quot;query_string&quot;: {      &quot;query&quot;: &quot;MML OR Song&quot;,      &quot;fields&quot;: [&quot;firstName&quot;,&quot;lastName&quot;]    }  }}</code></pre><h3 id="12-3-6-简化的字符串检索"><a href="#12-3-6-简化的字符串检索" class="headerlink" title="12.3.6 简化的字符串检索"></a>12.3.6 简化的字符串检索</h3><ul><li><strong>关键字simple_query_string</strong></li><li>类似 Query String , 但是会忽略错误的语法同时只支持部分查询语句</li><li>不支持 AND OR NOT , 但会当作字符串处理</li><li>Term 之间默认的关系是 OR, 可以指定 default_operator</li></ul><pre><code class="json">GET staffs/base/_search{  &quot;query&quot;: {    &quot;simple_query_string&quot;: {      &quot;query&quot;: &quot;MML Song&quot;,      &quot;default_operator&quot;: &quot;AND&quot;,       &quot;fields&quot;: [&quot;firstName&quot;,&quot;lastName&quot;]    }  }}</code></pre><h2 id="12-4-复合检索"><a href="#12-4-复合检索" class="headerlink" title="12.4 复合检索"></a>12.4 复合检索</h2><h3 id="12-4-1-固定得分检索"><a href="#12-4-1-固定得分检索" class="headerlink" title="12.4.1 固定得分检索"></a>12.4.1 固定得分检索</h3><ul><li><strong>关键字constant_score</strong> </li><li>Wraps a filter query and returns every matching document with a relevance score equal to the boost parameter value.</li></ul><pre><code class="json">GET /_search{    &quot;query&quot;: {        &quot;constant_score&quot; : {            &quot;filter&quot; : {                &quot;term&quot; : { &quot;user&quot; : &quot;kimchy&quot;}            },            &quot;boost&quot; : 1.2        }    }}</code></pre><h3 id="12-4-2-bool组合检索"><a href="#12-4-2-bool组合检索" class="headerlink" title="12.4.2 bool组合检索"></a>12.4.2 bool组合检索</h3><p>一个bool查询，是一个或者多个查询子句的组合,总共包括4种子句</p><ul><li><strong>must</strong>:必须匹配。贡献算</li><li><strong>should</strong>:选择性匹配。贡献算分</li><li><strong>must_not</strong>:Filter Context 查询字句，必须不能匹配</li><li><strong>filter</strong>:Filter Context 必须匹配，但是不贡献算分</li></ul><pre><code class="json">GET staffs/base/_search{  &quot;query&quot;: {    &quot;bool&quot;: {      &quot;should&quot;: [        {&quot;term&quot;:{&quot;age&quot;: {&quot;value&quot;: &quot;18&quot;}}},        {&quot;term&quot;: {&quot;age&quot;: {&quot;value&quot;: &quot;88&quot;}}}      ],      &quot;must&quot;: [        {&quot;term&quot;: {&quot;tags&quot;: &quot;yellow&quot;}},        {&quot;term&quot;: {&quot;tagsCount&quot;:1}}      ]    }  }}GET staffs/base/_search{    &quot;query&quot;: {    &quot;bool&quot;: {      &quot;should&quot;: [        {&quot;term&quot;:{&quot;age&quot;: {&quot;value&quot;: &quot;18&quot;}}},        {&quot;term&quot;: {&quot;age&quot;: {&quot;value&quot;: &quot;88&quot;}}}      ],      &quot;must_not&quot;: [        {&quot;term&quot;: {&quot;tags&quot;: &quot;yellow&quot;}},        {&quot;term&quot;: {&quot;tagsCount&quot;:2}}      ],      &quot;filter&quot;: {        &quot;term&quot;: {          &quot;province&quot;: &quot;sh&quot;        }      }    }  }}GET staffs/base/_search{  &quot;query&quot;: {    &quot;bool&quot;: {      &quot;should&quot;: [        {&quot;term&quot;: {          &quot;province&quot;: {            &quot;value&quot;: &quot;zn&quot;          }        }},        {          &quot;term&quot;: {            &quot;address&quot;: {              &quot;value&quot;: &quot;zn&quot;            }          }        }      ]    }  }}#将评分最⾼的字段评分作为结果返回，满⾜两个字段是竞争关系的场景GET staffs/base/_search{  &quot;query&quot;: {    &quot;dis_max&quot;: {      &quot;queries&quot;: [        {&quot;match&quot;: {&quot;province&quot;: &quot;zn&quot;}},        {&quot;match&quot;: {&quot;address&quot;: &quot;zn&quot;}}      ],      &quot;tie_breaker&quot;: 0.2    }  }}</code></pre><h3 id="12-4-3-改变评分检索"><a href="#12-4-3-改变评分检索" class="headerlink" title="12.4.3 改变评分检索"></a>12.4.3 改变评分检索</h3><h4 id="12-4-3-1-boosting-query"><a href="#12-4-3-1-boosting-query" class="headerlink" title="12.4.3.1 boosting query"></a>12.4.3.1 boosting query</h4><ul><li><p><strong>关键字boosting</strong></p></li><li><p><strong>positive</strong>:(Required, query object) Query you wish to run. Any returned documents must match this query.</p></li><li><p><strong>negative</strong>:(Required, query object) Query used to decrease the relevance score of matching documents.If a returned document matches the positive query and this query, the boosting query calculates the final relevance score for the document as follows:</p><ul><li><p>Take the original relevance score from the positive query.</p></li><li><p>Multiply the score by the negative_boost value.</p></li></ul></li><li><p><strong>negative_boost</strong>:(Required, float) Floating point number between 0 and 1.0 used to decrease the relevance scores of documents matching the negative query.</p></li></ul><pre><code class="demo">GET /_search{    &quot;query&quot;: {        &quot;boosting&quot; : {            &quot;positive&quot; : {                &quot;term&quot; : {                    &quot;text&quot; : &quot;apple&quot;                }            },            &quot;negative&quot; : {                 &quot;term&quot; : {                     &quot;text&quot; : &quot;pie tart fruit crumble tree&quot;                }            },            &quot;negative_boost&quot; : 0.5        }    }}</code></pre><h4 id="12-4-3-2-dis-max-query"><a href="#12-4-3-2-dis-max-query" class="headerlink" title="12.4.3.2 dis max query"></a>12.4.3.2 dis max query</h4><ul><li><strong>关键字dis_max</strong></li><li>获得<strong>最佳匹配语句的评分</strong></li><li>将<strong>其他匹配语句的评分与tie_breaker相乘</strong></li><li>对以上评分<strong>求和</strong></li></ul><pre><code class="json">GET staffs/base/_search{  &quot;query&quot;: {    &quot;dis_max&quot;: {      &quot;tie_breaker&quot;: 0.7,      &quot;boost&quot;: 1.2,      &quot;queries&quot;: [        {&quot;match&quot;: {&quot;address&quot;: &quot;zn&quot;}},        {&quot;match&quot;: {&quot;province&quot;: &quot;zn&quot;}}      ]    }  }}</code></pre><h4 id="12-4-3-3-function-scoring-query"><a href="#12-4-3-3-function-scoring-query" class="headerlink" title="12.4.3.3 function scoring query"></a>12.4.3.3 function scoring query</h4><ul><li><strong>Function Score Query</strong>:可以在查询结束后，对每⼀个匹配的⽂档进⾏⼀系列的重新算分，根据新⽣成的分数进⾏排序。</li><li>提供了⼏种默认的计算分值的函<ul><li>Weight ：为每⼀个⽂档设置⼀个简单⽽不被规范化的权重</li><li>Field Value Factor：使⽤该数值来修改 _score，例如将 “热度”和“点赞数”作为算分的参考因素</li><li>Random Score：为每⼀个⽤户使⽤⼀个不同的，随机算分结果</li><li>衰减函数： 以某个字段的值为标准，距离某个值越近，得分越⾼</li><li>Script Score：⾃定义脚本完全控制所需逻辑</li></ul></li></ul><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/essearch1.png" alt=""><br><img src="http://dist415.oss-cn-beijing.aliyuncs.com/essearch2.png" alt=""><br><img src="http://dist415.oss-cn-beijing.aliyuncs.com/essearch3.png" alt=""><br><img src="http://dist415.oss-cn-beijing.aliyuncs.com/essearch4.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Elaticsearch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elaticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>11.ES集群规划</title>
      <link href="/2020/03/04/11-ES%E9%9B%86%E7%BE%A4%E8%A7%84%E5%88%92/"/>
      <url>/2020/03/04/11-ES%E9%9B%86%E7%BE%A4%E8%A7%84%E5%88%92/</url>
      
        <content type="html"><![CDATA[<h2 id="11-1-分片"><a href="#11-1-分片" class="headerlink" title="11.1 分片"></a>11.1 分片</h2><h3 id="11-1-1-如何确定主分片数"><a href="#11-1-1-如何确定主分片数" class="headerlink" title="11.1.1 如何确定主分片数"></a>11.1.1 如何确定主分片数</h3><ul><li><p>从存储的物理角度看</p><ul><li><p>日志类应用，单个分片不要大于50 GB</p></li><li><p>搜索类应用，单个分片不要超过20 GB</p></li></ul></li><li><p>为什么要控制分片存储大小</p><ul><li>提高Update的性能</li><li>Merge时，减少所需的资源</li><li>丢失节点后，具备更快的恢复速度/便于分片在集群内Rebalancing</li></ul></li></ul><h3 id="11-1-2-如何确定副本分片数"><a href="#11-1-2-如何确定副本分片数" class="headerlink" title="11.1.2 如何确定副本分片数"></a>11.1.2 如何确定副本分片数</h3><ul><li><p>副本是主分片的拷贝</p><ul><li><p>提高系统可用性：相应査询请求，防止数据丢失</p></li><li><p>需要占用和主分片一样的资源</p></li></ul></li><li><p>对性能的影响</p><ul><li>副本会降低数据的索引速度：有几份副本就会有几倍的CPU资源消耗在索引上</li><li>会减缓对主分片的査询压力，但是会消耗同样的内存资源<ul><li>如果机器资源充分，提高副本数，可以提高整体的査询QPS</li></ul></li></ul></li></ul><h2 id="11-2-硬件配置"><a href="#11-2-硬件配置" class="headerlink" title="11.2 硬件配置"></a>11.2 硬件配置</h2><ul><li><p>选择合理的硬件，数据节点尽可能使用SSD</p></li><li><p>搜索等性能要求高的场景，建议SSD</p><ul><li><strong>按照1 ： 10的比例配置内存和硬盘</strong></li></ul></li><li><p>日志类和查询并发低的场景，可以考虑使用机械硬盘存储</p><ul><li><strong>按照1： 50的比例配置内存和硬盘</strong></li></ul></li><li><p>单节点数据建议控制在2TB以内，最大不建议超过5TB</p></li><li><p>JVM配置机器内存的一半，JVM内存配置不建议超过32G</p></li></ul><h2 id="11-3-部署方式"><a href="#11-3-部署方式" class="headerlink" title="11.3 部署方式"></a>11.3 部署方式</h2><ul><li>按需选择合理的部署方式，线上定要选择集群模式</li><li>如果需要考虑可靠性高可用，建议<strong>部署3台以上的dedicated的Master节点</strong></li><li>如果有复杂的查询和聚合，建议设置Coordinating节点</li></ul><h2 id="11-4-JVM设定"><a href="#11-4-JVM设定" class="headerlink" title="11.4 JVM设定"></a>11.4 JVM设定</h2><ul><li><p>从ES 6开始，只支持64位的JVM</p><ul><li>配置 config / jvm. options</li></ul></li><li><p>避免修改默认配置</p><ul><li>将内存Xms和Xmx设置成一样，避免heap resize时引发停顿</li><li>Xmx设置不要超过物理内存的50%；单个节点上，最大内存建议不要超过32 G内存</li><li>生产环境，JVM必须使用Server模式</li><li>关闭 JVM Swapping</li></ul></li></ul><h2 id="11-5-内存设定计算实例"><a href="#11-5-内存设定计算实例" class="headerlink" title="11.5 内存设定计算实例"></a>11.5 内存设定计算实例</h2><ul><li><p>内存大小要根据 Node 需要存储的数据来进行估算  </p><ul><li><p>搜索类的比例建议：1:16 </p></li><li><p>日志类： 1:48 - 1:96 之间 </p></li></ul></li><li><p>总数据量 1T， 设置一个副本 = 2T 总数据量 </p><ul><li>一台机器假设总内存为32G,可用内存为31G</li><li>如果搜索类的项目，每个节点 <code>31 *16 = 496G</code>，加上预留空间。所以每个节点最多 400 G 数据，至少需 要 5 个数据节点 </li><li>如果是日志类项目，每个节点 <code>31*50 = 1550GB</code>，2 个数据节点 即可</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Elaticsearch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elaticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>10.ES集群再进阶</title>
      <link href="/2020/03/04/10-ES%E9%9B%86%E7%BE%A4%E5%86%8D%E8%BF%9B%E9%98%B6/"/>
      <url>/2020/03/04/10-ES%E9%9B%86%E7%BE%A4%E5%86%8D%E8%BF%9B%E9%98%B6/</url>
      
        <content type="html"><![CDATA[<h2 id="10-1-Hot-amp-Warm-Architecture"><a href="#10-1-Hot-amp-Warm-Architecture" class="headerlink" title="10.1 Hot &amp; Warm Architecture"></a>10.1 Hot &amp; Warm Architecture</h2><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/eshotwarm.png" alt=""></p><h3 id="10-1-1-什么是-Hot-amp-Warm-Architecture"><a href="#10-1-1-什么是-Hot-amp-Warm-Architecture" class="headerlink" title="10.1.1 什么是 Hot &amp; Warm Architecture"></a>10.1.1 什么是 Hot &amp; Warm Architecture</h3><p>传统的Elasticsearch集群中所有节点均采用相同的配置，然而Elasticsearch并没有对节点的规格一致性做要求，换而言之就是每个节点可以是任意规格，当然这样做会导致集群各节点性能不一致，影响集群稳定性。但是如果有规则的将集群的节点分成不同类型，部分是高性能的节点用于存储热点数据，部分是性能相对差些的大容量节点用于存储冷数据，却可以一方面保证热数据的性能，另一方面保证冷数据的存储，降低存储成本，这也是Elasticsearch冷热分离架构的基本思想</p><h2 id="10-1-2-Node分类"><a href="#10-1-2-Node分类" class="headerlink" title="10.1.2 Node分类"></a>10.1.2 Node分类</h2><ul><li><strong>Hot节点</strong>（通常使用SSD）:索引有不断有新文档写入。通常使用SSD</li><li><strong>Wann节点</strong>（通常使用HDD）:索引不存在新数据的写入；同时也不存在大量的数据査询</li></ul><h3 id="10-1-3-配置"><a href="#10-1-3-配置" class="headerlink" title="10.1.3 配置"></a>10.1.3 配置</h3><p><strong>使用Shard Filtering</strong>,步骤分为以下几步</p><ol><li>标记节点（Tagging）</li><li>配置索引到Hot Node</li><li>配置索引到Warm节点</li></ol><h4 id="10-1-3-1-标记节点"><a href="#10-1-3-1-标记节点" class="headerlink" title="10.1.3.1 标记节点"></a>10.1.3.1 标记节点</h4><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/essign.png" alt=""></p><h4 id="10-1-3-2-配置索引到Hot-Node"><a href="#10-1-3-2-配置索引到Hot-Node" class="headerlink" title="10.1.3.2 配置索引到Hot Node"></a>10.1.3.2 配置索引到Hot Node</h4><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/essignhot.png" alt=""></p><h4 id="10-1-3-3-配置索引到Warm节点"><a href="#10-1-3-3-配置索引到Warm节点" class="headerlink" title="10.1.3.3 配置索引到Warm节点"></a>10.1.3.3 配置索引到Warm节点</h4><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/essignwarm.png" alt=""></p><h2 id="10-2-Rack-Awareness"><a href="#10-2-Rack-Awareness" class="headerlink" title="10.2 Rack Awareness"></a>10.2 Rack Awareness</h2><ul><li>ES的节点可能分布在不同的机架</li><li>当一个机架断电，可能会同时丢失几个节点</li><li>如果一个索引相同的主分片和副本分片，同时在这个机架上，就有可能导致数据的丢失</li><li>通过Rack Awareness的机制，就可以尽可能避免将同一个索引的主副分片同时分配在一个机架的节点上</li></ul><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/esrock.png" alt=""></p><h3 id="10-2-1标记-Rack-节点-配置集群"><a href="#10-2-1标记-Rack-节点-配置集群" class="headerlink" title="10.2.1标记 Rack 节点 + 配置集群"></a>10.2.1标记 Rack 节点 + 配置集群</h3><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/esrocksign.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Elaticsearch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elaticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>9.ES集群进阶</title>
      <link href="/2020/03/04/9-ES%E9%9B%86%E7%BE%A4%E8%BF%9B%E9%98%B6/"/>
      <url>/2020/03/04/9-ES%E9%9B%86%E7%BE%A4%E8%BF%9B%E9%98%B6/</url>
      
        <content type="html"><![CDATA[<h2 id="9-1-设置单一职责节点"><a href="#9-1-设置单一职责节点" class="headerlink" title="9.1 设置单一职责节点"></a>9.1 设置单一职责节点</h2><p>一个节点只承担一个角色</p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/esclusterdy.png" alt=""></p><p>好处可以使用不同的配置:</p><ul><li>Dedicated master eligible nodes：负责集群状态(cluster state)的管理<ul><li>使用低配置的CPU, RAM和磁盘</li></ul></li><li>Dedicated data nodes：负责数据存储及处理客户端请求<ul><li>使用高配置的CPU, RAM和磁盘</li></ul></li><li>Dedicated ingest nodes：负责数据处理<ul><li>使用高配置CPU；中等配置的RAM；低配置的磁盘</li></ul></li><li>Dedicate Coordinating Only Node (Client Node)<ul><li>配置：将 Master, Data, Ingest 都配置成 False</li><li>Medium/High CUP； Medium/High RAM； Low Disk</li></ul></li></ul><h2 id="9-2-Coordinating-Only-Nodes"><a href="#9-2-Coordinating-Only-Nodes" class="headerlink" title="9.2 Coordinating Only Nodes"></a>9.2 Coordinating Only Nodes</h2><ul><li>扮演 Load Balancers。降低 Master 和 Data Nodes 的负载</li><li>负责搜索结果的 Gather/Reduce </li><li>有时候无法预知客户端会发送怎么样的请求 <ul><li>大量占用内存的结合操作，一个深度聚合可能会引发 OOM</li></ul></li></ul><h2 id="9-3-Dedicate-Master-Node"><a href="#9-3-Dedicate-Master-Node" class="headerlink" title="9.3 Dedicate Master Node"></a>9.3 Dedicate Master Node</h2><ul><li>从高可用&amp;避免脑裂的角度出发</li><li>一般在生产环境中配置3台</li><li>一个集群只有1台活跃的主节点<ul><li>负责分片管理，索引创建，集群管理等操作</li></ul></li><li>如果和数据节点或者Coordinate节点混合部署<ul><li>数据节点相对有比较大的内存占用</li><li>Coordinate节点有时候可能会有开销很高的査询，导致OOM</li><li>这些都有可能影响Master节点，导致集群的不稳定</li></ul></li></ul><h2 id="9-4-基本部署"><a href="#9-4-基本部署" class="headerlink" title="9.4 基本部署"></a>9.4 基本部署</h2><p>当磁盘容量无法满足需求时，可以增加数据节点；</p><p>磁盘读写压力大时，增加数据节点</p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/esclusterbase.png" alt=""></p><h2 id="9-5-水平扩展"><a href="#9-5-水平扩展" class="headerlink" title="9.5 水平扩展"></a>9.5 水平扩展</h2><p>当系统中有大量的复杂查询及聚合时候，增加 Coordinating 节点，增加查询的性能</p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/esclustersp.png" alt=""></p><h2 id="9-6-读写分离"><a href="#9-6-读写分离" class="headerlink" title="9.6 读写分离"></a>9.6 读写分离</h2><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/esclusterrw.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Elaticsearch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elaticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>8.ES集群分片与文档存储</title>
      <link href="/2020/03/03/8-ES%E9%9B%86%E7%BE%A4%E5%88%86%E7%89%87%E4%B8%8E%E6%96%87%E6%A1%A3%E5%AD%98%E5%82%A8/"/>
      <url>/2020/03/03/8-ES%E9%9B%86%E7%BE%A4%E5%88%86%E7%89%87%E4%B8%8E%E6%96%87%E6%A1%A3%E5%AD%98%E5%82%A8/</url>
      
        <content type="html"><![CDATA[<h2 id="8-1-分片类型"><a href="#8-1-分片类型" class="headerlink" title="8.1 分片类型"></a>8.1 分片类型</h2><ul><li>主分片</li><li>副本分片</li></ul><h3 id="8-1-1-Primary-Shard"><a href="#8-1-1-Primary-Shard" class="headerlink" title="8.1.1 Primary Shard"></a>8.1.1 Primary Shard</h3><ul><li>通过主分⽚，将数据分布在所有节点上,<strong>用来提升系统存储容量</strong></li><li>可以将⼀份索引的数据，分散在多个 Data Node 上，<strong>实现存储的⽔平扩展</strong></li><li>主分⽚(Primary Shard)数在索引<strong>创建时候指定，后续默认不能修改，如要修改，需重建索引</strong></li></ul><h3 id="8-1-2-Replica-Shard"><a href="#8-1-2-Replica-Shard" class="headerlink" title="8.1.2 Replica Shard"></a>8.1.2 Replica Shard</h3><ul><li>通过引⼊副本分⽚ (Replica Shard) <strong>提⾼数据的可⽤性</strong>。⼀旦主分⽚丢失，副本分⽚可以 Promote 成主分⽚。副本分⽚数可以动态调整。每个节点上都有完备的数据。如果不设置副本分⽚，⼀旦出现节点硬件故障，就有可能造成数据丢失提升系统的读取性能</li><li>副本分⽚由主分⽚(Primary Shard)同步。通过⽀持增加 Replica 个数，⼀定程度可以<strong>提⾼读取的吞吐量</strong></li></ul><h2 id="8-2-分片数设定"><a href="#8-2-分片数设定" class="headerlink" title="8.2 分片数设定"></a>8.2 分片数设定</h2><ul><li>主分⽚数过⼩：例如创建了 1 个 Primary Shard 的 Index</li><li>如果该索引增⻓很快，集群⽆法通过增加节点实现对这个索引的数据扩展</li><li>主分⽚数设置过⼤：导致单个 Shard 容量很⼩，引发⼀个节点上有过多分⽚，影响性能</li><li>副本分⽚数设置过多，会降低集群整体的写⼊性能</li></ul><p><strong>总结</strong>: 实在有太多相关的因素了：你使用的硬件、文档的大小和复杂度、文档的索引分析方式、运行的查询类型、执行的聚合以及你的数据模型等等。<br><strong>建议设置Primary Shard数量为master node的数量的倍数,Primary Shard数量不能为0</strong></p><h2 id="8-3-新增节点分片转移过程"><a href="#8-3-新增节点分片转移过程" class="headerlink" title="8.3 新增节点分片转移过程"></a>8.3 新增节点分片转移过程</h2><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/esshardzy.png" alt=""></p><h2 id="8-5-故障转移"><a href="#8-5-故障转移" class="headerlink" title="8.5 故障转移"></a>8.5 故障转移</h2><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/esfailover.png" alt=""></p><h2 id="8-6-文档分布式储存"><a href="#8-6-文档分布式储存" class="headerlink" title="8.6 文档分布式储存"></a>8.6 文档分布式储存</h2><p><strong>⽂档会存储在具体的某个主分⽚和副本分⽚上：例如 ⽂档 1， 会存储在 P0 和 R0 分⽚上</strong></p><p>每个shard都是一个最小工作单元，承载部分数据，lucene实例，完整的建立索引和处理请求的能力</p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/esfenpian.png" alt=""></p><h2 id="8-7-⽂档到分⽚的路由算法"><a href="#8-7-⽂档到分⽚的路由算法" class="headerlink" title="8.7 ⽂档到分⽚的路由算法"></a>8.7 ⽂档到分⽚的路由算法</h2><blockquote><p>shard = hash(_routing) % number_of_primary_shards</p></blockquote><ul><li>Hash 算法确保⽂档均匀分散到分⽚中</li><li>默认的 _routing 值是⽂档 id</li><li>可以⾃⾏制定 routing数值，例如⽤相同国家的商品，都分配到指定的shard</li></ul><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/eshashrouting.png" alt=""></p><ul><li>设置 Index Settings 后， <strong>Primary 数不能随意修改的根本原因</strong></li></ul><h2 id="8-8-更新一个文档"><a href="#8-8-更新一个文档" class="headerlink" title="8.8 更新一个文档"></a>8.8 更新一个文档</h2><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/esdocupdate.png" alt=""></p><ol><li>打到一台Coordinating node节点</li><li>根据路由算法找到存储文档的Primary shard</li><li>路由到指定shard</li><li>删除文档</li><li>新建文档</li><li>同步到replica shard成功</li><li>返回</li></ol><h2 id="8-9-删除一个文档"><a href="#8-9-删除一个文档" class="headerlink" title="8.9 删除一个文档"></a>8.9 删除一个文档</h2><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/esdocdel.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Elaticsearch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elaticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>7.ES分布式集群</title>
      <link href="/2020/03/03/7-ES%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4/"/>
      <url>/2020/03/03/7-ES%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4/</url>
      
        <content type="html"><![CDATA[<h2 id="7-1-分布式特性"><a href="#7-1-分布式特性" class="headerlink" title="7.1 分布式特性"></a>7.1 分布式特性</h2><p>Elasticsearch 的分布式架构带来的好处:</p><ul><li>存储的⽔平扩容，⽀持 PB 级数据</li><li>提⾼系统的可⽤性，部分节点停⽌服务，整个集群的服务不受影响</li></ul><h2 id="7-2-集群节点类型"><a href="#7-2-集群节点类型" class="headerlink" title="7.2 集群节点类型"></a>7.2 集群节点类型</h2><ul><li><p><strong>Master Eligible Node</strong>:可以被选为主节点的节点</p></li><li><p><strong>Voting-only master-eligible node</strong>:只能投票选择主节点的节点</p></li><li><p><strong>Data nodes:</strong>数据节点</p></li><li><p><strong>Coordinating node</strong>:协调调度节点</p></li><li><p><strong>Ingest nodes</strong>: 流水线节点</p></li><li><p><strong>Machine learning node</strong>:机器学习节点</p></li></ul><h3 id="7-2-1-Master-Node"><a href="#7-2-1-Master-Node" class="headerlink" title="7.2.1 Master Node"></a>7.2.1 Master Node</h3><ul><li>Master Node 的职责:<ul><li><strong>处理创建，删除索引等请求 /决定分⽚被分配到哪个节点 / 负责索引的创建与删除</strong></li><li><strong>维护并且更新 Cluster State</strong></li></ul></li></ul><ul><li>Master Node 的最佳实践:<ul><li>Master 节点⾮常重要，在部署上需要考虑解决单点的问题</li><li>为⼀个集群设置多个 Master 节点 / 每个节点只承担 Master 的单⼀⻆⾊</li></ul></li></ul><h3 id="7-2-2-Master-Eligible-Nodes"><a href="#7-2-2-Master-Eligible-Nodes" class="headerlink" title="7.2.2 Master Eligible Nodes"></a>7.2.2 Master Eligible Nodes</h3><ul><li>⼀个集群，⽀持配置多个 Master Eligible 节点。这些节点可以在必要时(如 Master 节点出</li></ul><p>现故障，⽹络故障时)参与选主流程，成为 Master 节点</p><ul><li>每个节点启动后，默认就是⼀个 Master eligible 节点<ul><li>可以设置 node.master: false 禁⽌</li></ul></li><li>当集群内第⼀个 Master eligible 节点启动时候，它会将⾃⼰选举成 Master 节点</li></ul><h3 id="7-2-3-Data-Node"><a href="#7-2-3-Data-Node" class="headerlink" title="7.2.3 Data Node"></a>7.2.3 Data Node</h3><ul><li>可以保存数据的节点，叫做 Data Node,节点启动后，默认就是数据节点。可以设置 node.data: false 禁⽌</li><li>Data Node的职责:保存分⽚数据。在数据扩展上起到了⾄关重要的作⽤（由 Master Node 决定如何把分⽚分发到数据节点上）</li><li>通过增加数据节点可以解决数据⽔平扩展和解决数据单点问题</li></ul><h2 id="7-3-集群架构图"><a href="#7-3-集群架构图" class="headerlink" title="7.3 集群架构图"></a>7.3 集群架构图</h2><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/escluster.png" alt=""></p><h2 id="7-4-集群健康状态"><a href="#7-4-集群健康状态" class="headerlink" title="7.4 集群健康状态"></a>7.4 集群健康状态</h2><p>健康状态针对一个索引，Elasticsearch 中其实有专门的衡量索引健康状况的标志，分为三个等级：</p><ul><li><strong>green，绿色</strong>。<strong>这代表所有的主分片和副本分片都已分配。你的集群是 100% 可用的</strong></li><li><strong>yellow，黄色</strong>。<strong>所有的主分片已经分片了，但至少还有一个副本是缺失的</strong>。不会有数据丢失，所以搜索结果依然是完整的。不过，你的高可用性在某种程度上被弱化。如果更多的分片消失，你就会丢数据了。所以可把 yellow 想象成一个需要及时调查的警告。</li><li><strong>red，红色</strong>。<strong>至少一个主分片以及它的全部副本都在缺失中</strong>。这意味着你在缺少数据：搜索只能返回部分数据，而分配到这个分片上的写入请求会返回一个异常。</li></ul><h2 id="7-5-集群选主过程"><a href="#7-5-集群选主过程" class="headerlink" title="7.5 集群选主过程"></a>7.5 集群选主过程</h2><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/esmaster.png" alt=""></p><h2 id="7-6-如何避免脑裂问题"><a href="#7-6-如何避免脑裂问题" class="headerlink" title="7.6 如何避免脑裂问题"></a>7.6 如何避免脑裂问题</h2><ul><li><p>限定⼀个选举条件，设置 quorum(仲裁)，只有在 Master eligible 节点数⼤于 quorum 时，才能进⾏选举</p><ul><li>Quorum = （master 节点总数 /2）+ 1 </li><li>当 3 个 master eligible 时，设置 discovery.zen.minimum_master_nodes 为 2，即可避免脑裂</li></ul></li><li><p>从 7.0 开始，⽆需这个配置</p><ul><li>移除 minimum_master_nodes 参数，让Elasticsearch⾃⼰选择可以形成仲裁的节点。</li><li>典型的主节点选举现在只需要很短的时间就可以完成。集群的伸缩变得更安全、更容易，并且可能造成丢失数据的系统配置选项更少了。</li><li>节点更清楚地记录它们的状态，有助于诊断为什么它们不能加⼊集群或为什么⽆法选举出主节点</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Elaticsearch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elaticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>6.ES算法</title>
      <link href="/2020/03/03/6-ES%E7%AE%97%E6%B3%95/"/>
      <url>/2020/03/03/6-ES%E7%AE%97%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h2 id="6-1-相关性"><a href="#6-1-相关性" class="headerlink" title="6.1 相关性"></a>6.1 相关性</h2><p>搜索的相关性算分，描述了一个<strong>文档和査询语句匹配的程度</strong>。ES会对每个匹配查询条件的结果进行算分_score</p><p><strong>打分的本质是排序，需要把最符合用户需求的文档排在前面。</strong></p><p><strong>ES5之前，默认的相关性算分采用TF-IDF,现在采用BM 25</strong></p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/esrele.png" alt=""></p><h2 id="6-2-词频-TF"><a href="#6-2-词频-TF" class="headerlink" title="6.2 词频 TF"></a>6.2 词频 TF</h2><ul><li><strong>Term Frequency：检索词在一篇文档中出现的频率</strong><ul><li><strong>检索词出现的次数除以文档的总字数</strong></li></ul></li><li>度量一条查询和结果文档相关性的简单方法：简单将搜索中<strong>每一个词的TF进行相加</strong><ul><li>TF（区块链）+ TF（的）+ TF（应用）</li></ul></li><li>Stop Word<ul><li>“的”在文档中出现了很多次，但是对贡献相关度几乎没有用处，不应该考虑他们的TF</li></ul></li></ul><h2 id="6-3-逆⽂档频率-IDF"><a href="#6-3-逆⽂档频率-IDF" class="headerlink" title="6.3     逆⽂档频率 IDF"></a>6.3     逆⽂档频率 IDF</h2><ul><li>DF：检索词索词在所有文档中出现的频率<ul><li>“区块链”在相对比较少的文档中出现</li><li>“应用”在相对比较多的文档中出现</li><li>“Stop Word”在大量的文档中出现</li></ul></li><li>Inverse Document Frequency :<strong>简单说=log（全部文档数/検索词出现过的文档总数）</strong></li><li>TF-IDF本质上就是将TF求和变成了加权求和<ul><li><code>TF（区块链）*IDF（区块链）+ TF（的）*IDF（的）+ TF（应用）*IDF（应用）</code></li></ul></li></ul><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/esidf.png" alt=""></p><h2 id="6-4-TF-IDF-评分公式"><a href="#6-4-TF-IDF-评分公式" class="headerlink" title="6.4 TF-IDF 评分公式"></a>6.4 TF-IDF 评分公式</h2><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/estf-idf.png" alt=""></p><h2 id="6-5-BM25"><a href="#6-5-BM25" class="headerlink" title="6.5 BM25"></a>6.5 BM25</h2><ul><li>从ES5开始，默认算法改为BM 25</li><li>和经典的TF-IDF相比，当TF无限增加时,BM 25算分会趋于一个数值</li></ul><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/esbm25.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Elaticsearch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elaticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>5.ESMapping介绍</title>
      <link href="/2020/03/03/5-ESMaping%E4%BB%8B%E7%BB%8D/"/>
      <url>/2020/03/03/5-ESMaping%E4%BB%8B%E7%BB%8D/</url>
      
        <content type="html"><![CDATA[<h2 id="5-1-什么是Mapping"><a href="#5-1-什么是Mapping" class="headerlink" title="5.1 什么是Mapping"></a>5.1 什么是Mapping</h2><ul><li>Mapping类似数据库中的schema的定义，作用如下<ul><li>定义索引中的字段的名称</li><li>定义字段的数据类型，例如字符串，数字，布尔……<ul><li>字段，倒排索引的相关配置，(Analyzed r Nt Analyzed,Analyzer)</li></ul></li></ul></li><li>Mapping会把JSN文档映射成Lucene所需要的扁平格式</li><li>—个Mapping属于一个索引的Type<ul><li>每个文档都属于一个Type</li><li>—个Type有一个Mapping定义</li><li>7.0开始，不需要在Mapping定义中指定type信息</li></ul></li></ul><h2 id="5-2-字段的数据类型"><a href="#5-2-字段的数据类型" class="headerlink" title="5.2 字段的数据类型"></a>5.2 字段的数据类型</h2><ul><li><p>简单类型</p><ul><li><p>Text / Keyword</p></li><li><p>Date</p></li><li><p>Integer / Floating</p></li><li><p>Boolean</p></li><li><p>IPv4 &amp; IPv6</p></li></ul></li><li><p>复杂类型-对象和嵌套对象</p><ul><li>对象类型/嵌套类型</li></ul></li><li><p>特殊类型</p><ul><li>geo_point &amp; geo_shape / percolator</li></ul></li></ul><h2 id="5-3-什么是Dynamic-Mapping"><a href="#5-3-什么是Dynamic-Mapping" class="headerlink" title="5.3 什么是Dynamic Mapping"></a>5.3 什么是Dynamic Mapping</h2><ul><li>在写入文档时候，如果索引不存在,会自动创建索引</li><li>Dynamic Mapping的机制，使得我们无需手动定义Mappings</li><li>Elasticsearch会自动根据文档信息，推算出字段的类型</li><li>但是有时候会推算的不对，例如地理位置信息</li><li>当类型如果设置不对时，会导致一些功能无法正常运行，例如Range查询</li></ul><h2 id="5-4-类型的自动识别"><a href="#5-4-类型的自动识别" class="headerlink" title="5.4 类型的自动识别"></a>5.4 类型的自动识别</h2><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/esmapping.png" alt=""></p><h2 id="5-5-能否更改Mapping的字段类型"><a href="#5-5-能否更改Mapping的字段类型" class="headerlink" title="5.5 能否更改Mapping的字段类型"></a>5.5 能否更改Mapping的字段类型</h2><h3 id="5-5-1-新增加字段"><a href="#5-5-1-新增加字段" class="headerlink" title="5.5.1 新增加字段"></a>5.5.1 新增加字段</h3><ul><li>Dynamic设为true时，一旦有新增字段的文档写入，Mapping也同时被</li><li>Dynamic设为false, Mapping不会被更新，新增字段的数据无法被索引,但是信息会出现在_source中</li><li>Dynamic设置成Strict,文档写入失败</li></ul><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/esdynamic.png" alt=""></p><h3 id="5-5-2-对已有字段"><a href="#5-5-2-对已有字段" class="headerlink" title="5.5.2 对已有字段"></a>5.5.2 对已有字段</h3><p><strong>一旦已经有数据写入，就不再支持修改字段定义</strong><br><strong>Lucene实现的倒排索引，一旦生成后，就不允许修改!如果希望改变字段类型，必须Reindex API,重建索引</strong></p><p>原因</p><ul><li>如果修改了字段的数据类型，会导致已被索引的属于无法被搜索</li><li>但是如果是增加新的字段，就不会有这样的影响</li></ul>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Elaticsearch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elaticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>4.ES分词器</title>
      <link href="/2020/03/02/4-ES%E5%88%86%E8%AF%8D%E5%99%A8/"/>
      <url>/2020/03/02/4-ES%E5%88%86%E8%AF%8D%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<h2 id="4-1-Analysis"><a href="#4-1-Analysis" class="headerlink" title="4.1 Analysis"></a>4.1 Analysis</h2><p><strong>文本分析,把全文本转换一系列单词(term/token)的过程,也叫作分词</strong></p><h2 id="4-2-Analyzer"><a href="#4-2-Analyzer" class="headerlink" title="4.2 Analyzer"></a>4.2 Analyzer</h2><p><strong>分词通过分词器来实现,可以使用ES内置的分词器,也可以按需定制化分词器</strong></p><h3 id="4-2-1-Analyzer组成"><a href="#4-2-1-Analyzer组成" class="headerlink" title="4.2.1 Analyzer组成"></a>4.2.1 Analyzer组成</h3><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/esalsis.png" alt=""></p><ul><li>Character Filters （针对原始文本处理，例如去除html）</li><li>Tokenizer （按照规则切分为单词）</li><li>Token Filter（将切分的的单词进行加工，小写，删除stopwords,增加同义词）</li></ul><h3 id="4-2-2-Character-Filters"><a href="#4-2-2-Character-Filters" class="headerlink" title="4.2.2 Character Filters"></a>4.2.2 Character Filters</h3><ul><li>在Tokenizer之前对文本进行处理，例如增加删除及替换字符。可以配置多个 Character Filters。会影响 Tokenizer的 position 和 offset 信息</li><li>—些自带的 Character Filters<ul><li>HTML strip —出除 html 标签</li><li>Mapping 一字符串替换</li><li>Pattern replace —正则匹配替换</li></ul></li></ul><h3 id="4-2-3-Tokenizer"><a href="#4-2-3-Tokenizer" class="headerlink" title="4.2.3 Tokenizer"></a>4.2.3 Tokenizer</h3><ul><li><p>将原始的文本按照一定的规则，切分为词(term or token)</p></li><li><p>Elasticsearch 内置的 Tokenizers</p><ul><li>whitespace / standard / uax_url_email / pattern / keyword / path hierarchy</li></ul></li><li><p>可以用Java开发插件，实现自己的Tokenizer</p></li></ul><h3 id="4-2-4-Token-Filters"><a href="#4-2-4-Token-Filters" class="headerlink" title="4.2.4 Token Filters"></a>4.2.4 Token Filters</h3><ul><li>将Tokenizer输出的单词（term ）,进行增加，修改，删除</li><li>自带的 Token Filters<ul><li>Lowercase / stop / synonym （添加近义词）</li></ul></li></ul><h3 id="4-2-2-ES内置分词器"><a href="#4-2-2-ES内置分词器" class="headerlink" title="4.2.2 ES内置分词器"></a>4.2.2 ES内置分词器</h3><ul><li><strong>Standard Analyzer</strong> 一默认分词器，按词切分，小写处理</li><li><strong>Simple Analyzer</strong> 一按照非字母切分（符号被过滤），小写处理</li><li><strong>Stop Analyzer</strong> —小写处理，停用词过滤（the, a, is）</li><li><strong>Whitespace Analyzer</strong> —按照空格切分，不转小写</li><li><strong>Keyword Analyzer</strong> 一不分词，直接将输入当作输出</li><li><strong>Patter Analyzer</strong> -正则表达式，默认\W+ （非字符分隔）</li><li><strong>Language</strong> 一提供了30多种常见语言的分词器</li><li><strong>Customer Analyzer</strong>自定义分词器</li></ul><h2 id="4-3-中文分词"><a href="#4-3-中文分词" class="headerlink" title="4.3 中文分词"></a>4.3 中文分词</h2><p>常用的中文分词器如下:</p><ul><li><strong><a href="https://github.com/medcl/elasticsearch-analysis-ik" target="_blank" rel="noopener">IK</a></strong>:支持自定义词库，支持热更新分词字典</li><li><strong><a href="https://github.com/microbun/elasticsearch-thulac-plugin" target="_blank" rel="noopener">THULAC</a></strong>:清华大学自然语言处理和社会人文计算实验室的一套中文分词器 </li></ul>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Elaticsearch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elaticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>3.Lucene倒排索引</title>
      <link href="/2020/03/02/3-Lucene%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95/"/>
      <url>/2020/03/02/3-Lucene%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95/</url>
      
        <content type="html"><![CDATA[<h2 id="3-1-介绍"><a href="#3-1-介绍" class="headerlink" title="3.1 介绍"></a>3.1 介绍</h2><p><strong>Lucene是Apache软件基金会中一个开放源代码的全文搜索引擎工具包，是一个全文搜索引擎的架构，提供了完整的查询引擎和索引引擎，部分文本分析引擎</strong>。Lucene的目的是为软件开发人员提供一个简单易用的工具包，以方便在目标系统中实现全文检索的功能，或者是以此为基础建立起完整的全文搜索引擎。</p><h2 id="3-2-倒排索引"><a href="#3-2-倒排索引" class="headerlink" title="3.2 倒排索引"></a>3.2 倒排索引</h2><p>倒排索引源于实际应用中需要根据属性的值来查找记录。这种索引表中的每一项都包括一个属性值和具有该属性值的各记录的地址。<strong>由于不是由记录来确定属性值，而是由属性值来确定记录的位置，因而称为倒排索引(inverted index)</strong>。带有倒排索引的文件我们称为倒排索引文件，简称倒排文件(inverted file)</p><p><strong>倒排索引中的索引对象是文档或者文档集合中的单词等</strong>，用来存储这些单词在一个文档或者一组文档中的存储位置，是对文档或者文档集合的一种最常用的索引机制.</p><p><strong>搜索引擎的关键步骤就是建立倒排索引，倒排索引一般表示为一个关键词，然后是它的频度(出现的次数)、位置</strong>(出现在哪一篇文章或网页中，及有关的日期，作者等信息)，好比一本书的目录、标签一般，读者想看哪一个主题相关的章节，直接根据目录即可找到相关的页面.不必再从书的第一页到最后一页，一页一页地查找.</p><p>下面用例子介绍该结构及相应的生成算法° 假设有两篇文章1和文章2.</p><p>文章 1 的内容为：Tom lives in Guangzhou,! live in Guangzhou too.</p><p>文章 2 的内容为：He once lived in Shanghai.</p><h2 id="3-3-取得关键字"><a href="#3-3-取得关键字" class="headerlink" title="3.3 取得关键字"></a>3.3 取得关键字</h2><p>首先会进行一遍过滤,一般过滤的方式如下:</p><ul><li><strong>时态的转换</strong></li><li><strong>单复数的转换</strong></li><li><strong>同义词的转换</strong></li><li><strong>大小写的转换</strong></li><li><strong>删除没有实际意义的词</strong></li></ul><p>最后得到的处理结果如下:</p><pre><code>文章1的所有关键词为：[tom] [live] [guangzhou] [i] [live] [guangzhou]文章2的所有关键词为：[he] [live] [shanghai]</code></pre><h2 id="3-4-建立倒排索引"><a href="#3-4-建立倒排索引" class="headerlink" title="3.4 建立倒排索引"></a>3.4 建立倒排索引</h2><p><strong>我们注意到关键字是按字符顺序排列的（Lucene没有使用B树结构），因此Lucene可以用二元搜索算法快速定位关键词。</strong></p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/essort.png" alt=""></p><h2 id="3-5-实现"><a href="#3-5-实现" class="headerlink" title="3.5 实现"></a>3.5 实现</h2><p>实现时,Lucene将上面三列分别作为<strong>词典文件(TermDictionary),频率文件(frequencies)、位置文件(positions)</strong>保存。其中词典文件不仅保存了每个关键词，还保留了指向频率文件和位置文件的指针，通过指针可以找到该关键字的频率信息和位置信息。</p><h2 id="3-6-压缩算法"><a href="#3-6-压缩算法" class="headerlink" title="3.6 压缩算法"></a>3.6 压缩算法</h2><p>为了减小索引文件的大小，Lucene对索引还使用了压缩技术</p><p>首先，<strong>对词典文件中的关键词进行了压缩</strong>，关键词压缩为＜前缀长度.后缀＞，例如:当前词为“阿拉伯语”，上一个词为“阿拉伯”，那么“阿拉伯语”压缩为＜3,语＞<br>其次大量用到的是对数字的压缩，数字只保存与上一个值的差值（这样可以减少数字的长度，进而减少保存该数字需要的字节数）。例如当前文章号是16389 （不压缩要用3个字节保存）.上一文章号是16382,压缩后保存7（只用一个字节）</p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Elaticsearch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elaticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2.ES核心概念及基本操作</title>
      <link href="/2020/03/02/2-ES%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/"/>
      <url>/2020/03/02/2-ES%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/</url>
      
        <content type="html"><![CDATA[<h2 id="2-1-核心概念"><a href="#2-1-核心概念" class="headerlink" title="2.1 核心概念"></a>2.1 核心概念</h2><ul><li><strong>Near Realtime（NRT）</strong>：近实时，两个意思，从写入数据到数据可以被搜索到有一个小延迟（大概1秒）；基于es执行搜索和分析可以达到秒级</li><li><strong>Cluster</strong>：集群，包含多个节点，每个节点属于哪个集群是通过一个配置（集群名称，默认是elasticsearch）来决定的，对于中小型应用来说，刚开始一个集群就一个节点很正常</li><li><strong>Node</strong>：节点，集群中的一个节点，节点也有一个名称（默认是随机分配的），节点名称很重要（在执行运维管理操作的时候），默认节点会去加入一个名称为“elasticsearch”的集群，如果直接启动一堆节点，那么它们会自动组成一个elasticsearch集群，当然一个节点也可以组成一个elasticsearch集群</li><li><strong>Document&amp;field</strong>：文档，<strong>es中的最小数据单元</strong>，一个document可以是一条客户数据，一条商品分类数据，一条订单数据，通常用JSON数据结构表示，每个index下的type中，都可以去存储多个document。一个document里面有多个field，每个field就是一个数据字段。</li><li><strong>Index</strong>：索引，包含一堆有相似结构的文档数据，比如可以有一个客户索引，商品分类索引，订单索引，索引有一个名称。一个index包含很多document，一个index就代表了一类类似的或者相同的document。比如说建立一个product index，商品索引，里面可能就存放了所有的商品数据，所有的商品document。</li><li><strong>Type</strong>：类型，每个索引里都可以有一个或多个type，type是index中的一个逻辑数据分类，一个type下的document，都有相同的field，比如博客系统，有一个索引，可以定义用户数据type，博客数据type，评论数据type。</li></ul><pre><code>举例商品index，里面存放了所有的商品数据，商品document但是商品分很多种类，每个种类的document的field可能不太一样，比如说电器商品，可能还包含一些诸如售后时间范围这样的特殊field；生鲜商品，还包含一些诸如生鲜保质期之类的特殊fieldtype，日化商品type，电器商品type，生鲜商品type日化商品type：product_id，product_name，product_desc，category_id，category_name电器商品type：product_id，product_name，product_desc，category_id，category_name，service_period生鲜商品type：product_id，product_name，product_desc，category_id，category_name，eat_period每一个type里面，都会包含一堆document</code></pre><ul><li><strong>shard</strong>：单台机器无法存储大量数据，es可以将一个索引中的数据切分为多个shard，分布在多台服务器上存储。<strong>有了shard就可以横向扩展</strong>，存储更多数据，<strong>让搜索和分析等操作分布到多台服务器上去执行，提升吞吐量和性能</strong>。每个shard都是一个lucene index。</li><li><strong>replica</strong>：任何一个服务器随时可能故障或宕机，此时shard可能就会丢失，因此可以为每个shard创建多个replica副本。replica可以在shard故障时提供备用服务，保证数据不丢失，多个replica还可以提升搜索操作的吞吐量和性能。primary shard（建立索引时一次设置，不能修改，默认5个），replica shard（随时修改数量，默认1个），<strong>默认每个索引10个shard，5个primary shard，5个replica shard，最小的高可用配置，是2台服务器</strong>。</li></ul><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/Es-cluster.png" alt=""></p><h2 id="2-2-elasticsearch-vs-数据库核心概念"><a href="#2-2-elasticsearch-vs-数据库核心概念" class="headerlink" title="2.2 elasticsearch vs. 数据库核心概念"></a>2.2 elasticsearch vs. 数据库核心概念</h2><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/esandrdbms.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Elaticsearch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elaticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>1.ES简介</title>
      <link href="/2020/03/02/1-ES%E7%AE%80%E4%BB%8B/"/>
      <url>/2020/03/02/1-ES%E7%AE%80%E4%BB%8B/</url>
      
        <content type="html"><![CDATA[<h2 id="1-1-介绍"><a href="#1-1-介绍" class="headerlink" title="1.1 介绍"></a>1.1 介绍</h2><p>Elaticsearch，简称为es， es是一个开源的<strong>高扩展的分布式全文检索引擎</strong>，它可以近<strong>乎实时的存储、检索数据</strong>；本身扩展性很好，可以扩展到上百台服务器，处理PB级别（大数据时代）的数据。es也使用Java开发并使用Lucene作为其核心来实现所有索引和搜索的功能，但是它的目的是通过简单<strong>RESTful API</strong>来隐藏Lucene的复杂性，从而让全文搜索变得简单。<br>据国际权威的数据库产品评测机构DB Engines的统计，在2016年1月，ElasticSearch已超过Solr等，<strong>成为排名第一的搜索引擎类应用</strong></p><h2 id="1-2-功能"><a href="#1-2-功能" class="headerlink" title="1.2 功能"></a>1.2 功能</h2><h3 id="1-2-1-分布式的搜索引擎和数据分析引擎"><a href="#1-2-1-分布式的搜索引擎和数据分析引擎" class="headerlink" title="1.2.1 分布式的搜索引擎和数据分析引擎"></a>1.2.1 分布式的搜索引擎和数据分析引擎</h3><p>搜索：百度，网站的站内搜索，IT系统的检索<br>数据分析：电商网站，最近7天牙膏这种商品销量排名前10的商家有哪些；新闻网站，最近1个月访问量排名前3的新闻版块是哪些<br>分布式，搜索，数据分析</p><h3 id="1-2-2-全文检索，结构化检索，数据分析"><a href="#1-2-2-全文检索，结构化检索，数据分析" class="headerlink" title="1.2.2 全文检索，结构化检索，数据分析"></a>1.2.2 全文检索，结构化检索，数据分析</h3><p><strong>全文检索</strong>：我想搜索商品名称包含牙膏的商品，select * from products where product_name like “%牙膏%”<br><strong>结构化检索</strong>：我想搜索商品分类为日化用品的商品都有哪些，<code>select * from products where category_id=&#39;日化用品&#39;</code></p><p>部分匹配、自动完成、搜索纠错、搜索推荐</p><p><strong>数据分析</strong>：我们分析每一个商品分类下有多少个商品，select category_id,count(*) from products group by category_id</p><h3 id="1-2-3-对海量数据进行近实时的处理"><a href="#1-2-3-对海量数据进行近实时的处理" class="headerlink" title="1.2.3 对海量数据进行近实时的处理"></a>1.2.3 对海量数据进行近实时的处理</h3><p><strong>分布式</strong>：ES自动可以将海量数据分散到多台服务器上去存储和检索<br>海联数据的处理：分布式以后，就可以采用大量的服务器去存储和检索数据，自然而然就可以实现海量数据的处理了<br><strong>近实时</strong>：检索个数据要花费1小时（这就不要近实时，离线批处理，batch-processing）；在秒级别对数据进行搜索和分析</p><p>跟分布式/海量数据相反的：lucene，单机应用，只能在单台服务器上使用，最多只能处理单台服务器可以处理的数据量</p><h2 id="1-3-主要概念"><a href="#1-3-主要概念" class="headerlink" title="1.3 主要概念"></a>1.3 主要概念</h2><p>Elasticsearch的主要概念如下:</p><ul><li><strong>节点</strong> - 它指的是Elasticsearch的单个正在运行的实例。单个物理和虚拟服务器容纳多个节点，这取决于其物理资源的能力，如RAM，存储和处理能力。</li><li><strong>集群</strong> - 它是一个或多个节点的集合。 集群为整个数据提供跨所有节点的集合索引和搜索功能。</li><li><strong>索引</strong> - 它是不同类型的文档和文档属性的集合。索引还使用分片的概念来提高性能。 例如，一组文档包含社交网络应用的数据。</li><li><strong>类型/映射</strong> - 它是共享同一索引中存在的一组公共字段的文档的集合。 例如，索引包含社交网络应用的数据，然后它可以存在用于用户简档数据的特定类型，另一类型可用于消息的数据，以及另一类型可用于评论的数据。</li><li><strong>文档</strong> - 它是以JSON格式定义的特定方式的字段集合。每个文档都属于一个类型并驻留在索引中。每个文档都与唯一标识符(称为UID)相关联。</li><li><strong>碎片</strong> - 索引被水平细分为碎片。这意味着每个碎片包含文档的所有属性，但包含的数量比索引少。水平分隔使碎片成为一个独立的节点，可以存储在任何节点中。主碎片是索引的原始水平部分，然后这些主碎片被复制到副本碎片中。</li><li><strong>副本</strong> - Elasticsearch允许用户创建其索引和分片的副本。 复制不仅有助于在故障情况下增加数据的可用性，而且还通过在这些副本中执行并行搜索操作来提高搜索的性能。</li></ul><h2 id="1-4-优点"><a href="#1-4-优点" class="headerlink" title="1.4 优点"></a>1.4 优点</h2><p>Elasticsearch的优点:</p><ul><li>Elasticsearch是基于Java开发的，这使得它在几乎每个平台上都兼容。</li><li>Elasticsearch是实时的，换句话说，一秒钟后，添加的文档可以在这个引擎中搜索得到</li><li>Elasticsearch是分布式的，这使得它易于在任何大型组织中扩展和集成。</li><li>通过使用Elasticsearch中的网关概念，创建完整备份很容易。</li><li>与Apache Solr相比，在Elasticsearch中处理多租户非常容易。</li><li>Elasticsearch使用JSON对象作为响应，这使得可以使用不同的编程语言调用Elasticsearch服务器</li><li>Elasticsearch支持几乎大部分文档类型，但不支持文本呈现的文档类型。</li></ul><h2 id="1-5-缺点"><a href="#1-5-缺点" class="headerlink" title="1.5 缺点"></a>1.5 缺点</h2><p>Elasticsearch的缺点:</p><ul><li>Elasticsearch在处理请求和响应数据方面没有多语言和数据格式支持(仅在JSON中可用)，与Apache Solr不同，Elasticsearch不可以使用CSV，XML等格式</li></ul><h2 id="1-6-特点"><a href="#1-6-特点" class="headerlink" title="1.6 特点"></a>1.6 特点</h2><ul><li>可以作为一个大型分布式集群（数百台服务器）技术，处理PB级数据，服务大公司；也可以运行在单机上，服务小公司</li><li>Elasticsearch不是什么新技术，主要是将全文检索、数据分析以及分布式技术，合并在了一起，才形成了独一无二的ES；lucene（全文检索），商用的数据分析软件（也是有的），分布式数据库（mycat）</li><li>对用户而言，是开箱即用的，非常简单，作为中小型的应用，直接3分钟部署一下ES，就可以作为生产环境的系统来使用了，数据量不大，操作不是太复杂</li><li>数据库的功能面对很多领域是不够用的（事务，还有各种联机事务型的操作）；特殊的功能，比如全文检索，同义词处理，相关度排名，复杂数据分析，海量数据的近实时处理；Elasticsearch作为传统数据库的一个补充，提供了数据库所不不能提供的很多功能</li></ul>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Elaticsearch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elaticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>消息顺序性的保证</title>
      <link href="/2020/03/01/%E6%B6%88%E6%81%AF%E9%A1%BA%E5%BA%8F%E6%80%A7%E7%9A%84%E4%BF%9D%E8%AF%81/"/>
      <url>/2020/03/01/%E6%B6%88%E6%81%AF%E9%A1%BA%E5%BA%8F%E6%80%A7%E7%9A%84%E4%BF%9D%E8%AF%81/</url>
      
        <content type="html"><![CDATA[<h2 id="1-什么是顺序性"><a href="#1-什么是顺序性" class="headerlink" title="1 什么是顺序性"></a>1 什么是顺序性</h2><p>顾名思义，消息顺序性是指保证消息有序。这个功能有个很常见的应用场景就是CDC（Change Data Chapture），以MySQL为例，如果其传输的binlog的顺序出错，比如原本是先对一条数据加1，然后再乘以2，发送错序之后就变成了先乘以2后加1了，造成了数据不一致。</p><h2 id="2-会出现顺序错乱的场景"><a href="#2-会出现顺序错乱的场景" class="headerlink" title="2 会出现顺序错乱的场景"></a>2 会出现顺序错乱的场景</h2><h3 id="2-1-RabbitMQ"><a href="#2-1-RabbitMQ" class="headerlink" title="2.1 RabbitMQ"></a>2.1 RabbitMQ</h3><p><strong>一个 queue，多个 consumer</strong>。比如，生产者向 RabbitMQ 里发送了三条数据，顺序依次是 data1/data2/data3，压入的是 RabbitMQ 的一个内存队列。有三个消费者分别从 MQ 中消费这三条数据中的一条，结果消费者2先执行完操作，把 data2 存入数据库，然后是 data1/data3。这不明显乱了。</p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/rabbitmq-order-01.png" alt=""></p><h3 id="2-2-Kafka"><a href="#2-2-Kafka" class="headerlink" title="2.2 Kafka"></a>2.2 Kafka</h3><p><strong>一个topic，一个partition，一个consumer，内部多线程</strong></p><p>比如说我们建了一个 topic，有三个 partition。生产者在写的时候，其实可以指定一个 key，比如说我们指定了某个订单 id 作为 key，那么这个订单相关的数据，一定会被分发到同一个 partition 中去，而且这个 partition 中的数据一定是有顺序的。<br>消费者从 partition 中取出来数据的时候，也一定是有顺序的。到这里，顺序还是 ok 的，没有错乱。接着，我们在消费者里可能会搞多个线程来并发处理消息。因为如果消费者是单线程消费处理，而处理比较耗时的话，比如处理一条消息耗时几十 ms，那么 1 秒钟只能处理几十条消息，这吞吐量太低了。而<strong>多个线程并发跑的话，顺序可能就乱掉了</strong>。</p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/kafka-order-01.png" alt=""></p><h2 id="3-解决方式"><a href="#3-解决方式" class="headerlink" title="3 解决方式"></a>3 解决方式</h2><h3 id="3-1-RabbitMQ"><a href="#3-1-RabbitMQ" class="headerlink" title="3.1 RabbitMQ"></a>3.1 RabbitMQ</h3><p>在 MQ 里面<strong>创建多个 queue，同一规则的数据（对唯一标识进行 hash），有顺序的放入 MQ 的 queue 里面</strong>，消费者只取一个 queue 里面获取数据消费，这样执行的顺序是有序的。</p><p>或者还是只有一个 queue 但是对应一个消费者，然后这个消费者<strong>内部用内存队列做排队</strong>，然后分发给底层不同的 worker 来处理。</p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/rabbitmq-order-02.png" alt=""></p><h3 id="3-2-Kafka"><a href="#3-2-Kafka" class="headerlink" title="3.2 Kafka"></a>3.2 Kafka</h3><p>由于kafka没有多个队列概念可以用不同的partition来做,原理和多个队列相同，同一规则的数据（对唯一标识进行 hash)放到不同的partition中,但这种不常用,常用的是所有的都放到一个partition中<strong>,一个消费者,然后根据同一规则的数据（对唯一标识进行 hash），有顺序的放入消费者的不同内存队列中</strong>,保证有序性</p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/kafka-order-02.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> 消息队列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 消息队列 </tag>
            
            <tag> RabbitMQ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>消息幂等性保证</title>
      <link href="/2020/03/01/%E6%B6%88%E6%81%AF%E5%B9%82%E7%AD%89%E6%80%A7%E4%BF%9D%E8%AF%81/"/>
      <url>/2020/03/01/%E6%B6%88%E6%81%AF%E5%B9%82%E7%AD%89%E6%80%A7%E4%BF%9D%E8%AF%81/</url>
      
        <content type="html"><![CDATA[<h2 id="1-传输保证机制"><a href="#1-传输保证机制" class="headerlink" title="1 传输保证机制"></a>1 传输保证机制</h2><p>对于确保消息在生产者和消费者之间进行传输而言一般有三种传输保障（delivery guarantee）：</p><ul><li><strong>At least once</strong>:至少一次，消息绝不会丢，但是可能会重复；</li><li><strong>Exactly once</strong>:精确一次，每条消息肯定会被传输一次且仅一次。</li></ul><p>对于大多数消息中间件而言，<strong>一般只提供At most once和At least once两种传输保障</strong>，对于第三种一般很难做到，由此消息幂等性也很难保证。</p><p><strong>Kafka自0.11版本开始引入了幂等性和事务，Kafka的幂等性是指单个生产者对于单分区单会话的幂等，而事务可以保证原子性地写入到多个分区，即写入到多个分区的消息要么全部成功，要么全部回滚，这两个功能加起来可以让Kafka具备EOS（Exactly Once Semantic）的能力。</strong></p><p>我们实现消息的幂等性一般都是通过下游消费的代码来实现其幂等性:</p><h2 id="2-出现非幂等的情况"><a href="#2-出现非幂等的情况" class="headerlink" title="2 出现非幂等的情况"></a>2 出现非幂等的情况</h2><ol><li><strong>生产者已把消息发送到mq</strong>，在mq给生产者返回ack的时候网络中断，故生产者未收到确定信息，生产者认为消息未发送成功，但实际情况是，mq已成功接收到了消息，在网络重连后，生产者会重新发送刚才的消息，造成mq接收了重复的消息</li><li><strong>消费者在消费mq中的消息时，mq已把消息发送给消费者</strong>，消费者在给mq返回ack时网络中断，故mq未收到确认信息，该条消息会重新发给其他的消费者，或者在网络重连后再次发送给该消费者，但实际上该消费者已成功消费了该条消息，造成消费者消费了重复的消息；</li></ol><h2 id="3-实现幂等必备条件"><a href="#3-实现幂等必备条件" class="headerlink" title="3 实现幂等必备条件"></a>3 实现幂等必备条件</h2><ul><li>全局唯一的id</li><li>根据全局唯一id滤重</li></ul><h2 id="4-具体实现方式"><a href="#4-具体实现方式" class="headerlink" title="4 具体实现方式"></a>4 具体实现方式</h2><h3 id="4-1-全局唯一id"><a href="#4-1-全局唯一id" class="headerlink" title="4.1 全局唯一id"></a>4.1 全局唯一id</h3><p>生成全局以为id的方式有很多:</p><ul><li>可以生成一个与业务无关的全局id,比如使用twitter的雪花算法</li><li>也可以根据业务来指定全局唯一id,比如使用订单号,用户唯一id等</li></ul><h3 id="4-2-根据全局唯一id滤重"><a href="#4-2-根据全局唯一id滤重" class="headerlink" title="4.2 根据全局唯一id滤重"></a>4.2 根据全局唯一id滤重</h3><p>可以使用的方式:</p><ol><li><strong>如果使用的是业务id来做全局唯一</strong>，那么可以在业务表字段加上唯一约束条件，<strong>每次操作时有就更新,没有就插入</strong></li><li><strong>添加消息表</strong>:再数据库里面，添加一张消息消费记录表，表字段加上唯一约束条件,消费完之后就往表里插入一条数据。因为加了唯一约束条件，第二次保存的时候，MySQL 就会报错，就插入不进去；通过数据库可以限制重复消费。</li><li><strong>使用Redis的Set类型保存消费过的id</strong>,每次操作前先查一下是否在set中,如果在,则过滤</li></ol><h3 id="4-3-高并发下需要考虑的问题"><a href="#4-3-高并发下需要考虑的问题" class="headerlink" title="4.3 高并发下需要考虑的问题"></a>4.3 高并发下需要考虑的问题</h3><p>在高并发下,消费端消费id=2的数据过程中,<strong>还没有使用上面的方式将全局唯一id加入滤重复表</strong>,也有可能造成重复消费的情况,此时我们需要考虑在消费消息前加入<strong>分布式锁(Redis/Zookeeper实现)</strong>,先判断是否有锁,如果有锁则等待</p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> 消息队列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 消息队列 </tag>
            
            <tag> RabbitMQ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>消息积压处理</title>
      <link href="/2020/03/01/%E6%B6%88%E6%81%AF%E7%A7%AF%E5%8E%8B%E5%A4%84%E7%90%86/"/>
      <url>/2020/03/01/%E6%B6%88%E6%81%AF%E7%A7%AF%E5%8E%8B%E5%A4%84%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h2 id="1-核心思路"><a href="#1-核心思路" class="headerlink" title="1 核心思路"></a>1 核心思路</h2><p><strong>快速增加消费者</strong></p><h2 id="2-RabbitMQ处理消息堆积"><a href="#2-RabbitMQ处理消息堆积" class="headerlink" title="2 RabbitMQ处理消息堆积"></a>2 RabbitMQ处理消息堆积</h2><p><strong>RabbitMQ可以直接增加消费者进行消费</strong></p><h2 id="3-Kafka处理消息堆积"><a href="#3-Kafka处理消息堆积" class="headerlink" title="3 Kafka处理消息堆积"></a>3 Kafka处理消息堆积</h2><p>Kafka由于partition的扩容需要分区重新分配，在生产的同时进行数据迁移会出现重复数据。所以迁移的时候避免重复生产数据，<strong>应该停止迁移主题的生产</strong>。所以一般都不会进行原有topic的partition的扩容,一般kafka增加消费者的方式如下:</p><ol><li><p><strong>新建一个topic，partition是原来的10倍</strong>，临时建立好原先10倍或者20倍的queue数量</p></li><li><p>然后写一个临时的分发数据的consumer程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，<strong>直接均匀轮询写入临时建立好的10倍数量的queue</strong></p></li><li><p>这是增加<strong>十倍的consumer数量,订阅新的topic,</strong>来处理堆积</p></li><li><p>消费完成后需要<strong>切换回旧的topic和consumer</strong></p></li></ol><p><strong>这里要注意一点是consumer的数量要根据下游Mysql的最大并发来调整,不要把Mysql写挂了！</strong></p><h2 id="4-RabbitMQ消息队列过期了怎么办"><a href="#4-RabbitMQ消息队列过期了怎么办" class="headerlink" title="4 RabbitMQ消息队列过期了怎么办"></a>4 RabbitMQ消息队列过期了怎么办</h2><p>这种情况是对RabbitMQ设置了TTL,我们需要记住的原则是:</p><p><strong>线上不要对MQ设置TTL！即使设置了也要设置死信队列来接收!</strong></p><p>假如没有设置死信,消息也过期了,没有别的办法,只有<strong>通宵熬夜补数据+写事故报告了</strong></p><h2 id="5-消息队列快写满了怎么办"><a href="#5-消息队列快写满了怎么办" class="headerlink" title="5 消息队列快写满了怎么办"></a>5 消息队列快写满了怎么办</h2><p>这种要分情况来看:</p><ul><li>一般来说看了快写满了都是某个下游消费者出了问题造成的<strong>,这种情况下</strong>第一要保证的是MQ不挂<strong>,MQ挂了导致的一系列连锁反应可以把初级程序员吓尿,</strong>解决方式一般就是暴力的快速对消息进行消费,不做任何逻辑处理<strong>,保证MQ不倒,然后同上一条:</strong>通宵熬夜补数据+写事故报告了**</li><li>如果是因为业务量自然增长造成的快写满了,那<strong>就需要提前进行扩容,运维做预警</strong>,一般来说这种原因满了的话,运维也可以收拾东西领单子走人了= =||</li></ul>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> 消息队列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 消息队列 </tag>
            
            <tag> RabbitMQ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>消息队列的作用</title>
      <link href="/2020/02/27/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%9A%84%E4%BD%9C%E7%94%A8/"/>
      <url>/2020/02/27/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%9A%84%E4%BD%9C%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<h2 id="1-作用"><a href="#1-作用" class="headerlink" title="1 作用"></a>1 作用</h2><ul><li>解耦</li><li>异步</li><li>削峰</li><li>数据同步</li></ul><h3 id="1-1-解耦"><a href="#1-1-解耦" class="headerlink" title="1.1 解耦"></a>1.1 解耦</h3><p>比如，用户成功支付完成订单后，需要通知生产配货系统、发票系统、库存系统、推荐系统、搜索系统等进行业务处理，而未来需要支持哪些业务是不知道的，并且这些业务不需要实时处理、不需要强一致，只需要保证最終一致性即可，因此，可以通过消息队列/任务队列进行系统解耦。</p><p>看这么个场景。A 系统发送数据到 BCD 三个系统，通过接口调用发送。如果 E 系统也要这个数据呢？那如果 C 系统现在不需要了呢？A 系统负责人几乎崩溃……</p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/mq-1.png" alt=""></p><p>在这个场景中，A 系统跟其它各种乱七八糟的系统严重耦合，A 系统产生一条比较关键的数据，很多系统都需要 A 系统将这个数据发送过来。A 系统要时时刻刻考虑 BCDE 四个系统如果挂了该咋办？要不要重发，要不要把消息存起来？头发都白了啊！</p><p>如果使用 MQ，Pub/Sub 发布订阅消息这么一个模型，A 系统就跟其它系统彻底解耦了</p><p>A 系统产生一条数据，发送到 MQ 里面去，哪个系统需要数据自己去 MQ 里面消费。如果新系统需要数据，直接从 MQ 里消费即可；如果某个系统不需要这条数据了，就取消对 MQ 消息的消费即可。这样下来，A 系统压根儿不需要去考虑要给谁发送数据，不需要维护这个代码，也不需要考虑人家是否调用成功、失败超时等情况。</p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/mq-2.png" alt=""></p><h3 id="1-2-异步"><a href="#1-2-异步" class="headerlink" title="1.2 异步"></a>1.2 异步</h3><p>使用队列的一个主要原因是进行异步处理，比如，用户注册成功后，需要发送注册成功邮件/新用户积分/优患券等；缓存过期时，先返回过期数据，然后异步更新缓存、异步写日志等。通过异步处理，可以提升主流程响应速度，而非主流程/非重要处理可以集中处理，这样还可以将任务聚合批量处理。因此，可以使用消息队列/任务队列来进行异步处理。</p><p>再来看一个场景，A 系统接收一个请求，需要在自己本地写库，还需要在 BCD 三个系统写库，自己本地写库要 3ms，BCD 三个系统分别写库要 300ms、450ms、200ms。最终请求总延时是 3 + 300 + 450 + 200 = 953ms，接近 1s，用户感觉搞个什么东西，慢死了慢死了。用户通过浏览器发起请求，等待个 1s，这几乎是不可接受的。</p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/mq-3.png" alt=""></p><p>一般互联网类的企业，对于用户直接的操作，一般要求是每个请求都<strong>必须在 200 ms 以内</strong>完成，对用户几乎是无感知的。</p><p>如果使用 MQ，那么 A 系统连续发送 3 条消息到 MQ 队列中，假如耗时 5ms，A 系统从接受一个请求到返回响应给用户，总时长是 3 + 5 = 8ms，对于用户而言，其实感觉上就是点个按钮，8ms 以后就直接返回了，爽！网站做得真好，真快！</p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/mq-4.png" alt=""></p><h3 id="1-3-削峰"><a href="#1-3-削峰" class="headerlink" title="1.3 削峰"></a>1.3 削峰</h3><p>流量削峰：系统瓶颈一般在数据库上，比如扣减库存、下单等。此时可以考虑使用队列将变更请求暂时放入队列，通过缓存+队列暫存的方式将数据库流量削峰。同样，对于秒杀系统，下单服务会是该系统的瓶颈，此时，可以使用队列进行排队和限流，从而保护下单服务，通过队列暂存或者队列限流进行流量削峰。</p><p>场景:每天 0:00 到 12:00，A 系统风平浪静，每秒并发请求数量就 50 个。结果每次一到 12:00 ~ 13:00 ，每秒并发请求数量突然会暴增到 5k+ 条。但是系统是直接基于 MySQL 的，大量的请求涌入 MySQL，每秒钟对 MySQL 执行约 5k 条 SQL。</p><p>一般的 MySQL，扛到每秒 2k 个请求就差不多了，如果每秒请求到 5k 的话，可能就直接把 MySQL 给打死了，导致系统崩溃，用户也就没法再使用系统了。</p><p>但是高峰期一过，到了下午的时候，就成了低峰期，可能也就 1w 的用户同时在网站上操作，每秒中的请求数量可能也就 50 个请求，对整个系统几乎没有任何的压力。</p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/mq-5.png" alt=""></p><p>如果使用 MQ，每秒 5k 个请求写入 MQ，A 系统每秒钟最多处理 2k 个请求，因为 MySQL 每秒钟最多处理 2k 个。A 系统从 MQ 中慢慢拉取请求，每秒钟就拉取 2k 个请求，不要超过自己每秒能处理的最大请求数量就 ok，这样下来，哪怕是高峰期的时候，A 系统也绝对不会挂掉。而 MQ 每秒钟 5k 个请求进来，就 2k 个请求出去，结果就导致在中午高峰期（1 个小时），可能有几十万甚至几百万的请求积压在 MQ 中。</p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/mq-6.png" alt=""></p><p>这个短暂的高峰期积压是 ok 的，因为高峰期过了之后，每秒钟就 50 个请求进 MQ，但是 A 系统依然会按照每秒 2k 个请求的速度在处理。所以说，只要高峰期一过，A 系统就会快速将积压的消息给解决掉</p><h3 id="1-4-数据同步"><a href="#1-4-数据同步" class="headerlink" title="1.4 数据同步"></a>1.4 数据同步</h3><p>比如，想把MySQL变更的数据同步到Redis,或者将MySQL的数据同步到Mongodb,或者让机房之间的数据同步，或者主从数据同步等，此时可以考虑使用databus、canal、otter等。使用数据总线队列进行数据同步的好处是可以保证数据修改的有序性。</p><h2 id="2-缺点"><a href="#2-缺点" class="headerlink" title="2 缺点"></a>2 缺点</h2><ul><li>系统可用性降低</li><li>系统复杂度提高</li><li>一致性问题</li></ul><h3 id="2-1-系统可用性降低"><a href="#2-1-系统可用性降低" class="headerlink" title="2.1 系统可用性降低"></a>2.1 系统可用性降低</h3><p>系统引入的外部依赖越多，越容易挂掉。本来你就是 A 系统调用 BCD 三个系统的接口就好了，ABCD 四个系统还好好的，没啥问题，你偏加个 MQ 进来，万一 MQ 挂了咋整？MQ 一挂，整套系统崩溃，你不就完了？如何保证消息队列的高可用，可以点击这里查看。</p><h3 id="2-2-系统复杂度提高"><a href="#2-2-系统复杂度提高" class="headerlink" title="2.2 系统复杂度提高"></a>2.2 系统复杂度提高</h3><p>硬生生加个 MQ 进来，你怎么保证消息没有重复消费？怎么处理消息丢失的情况？怎么保证消息传递的顺序性？头大头大，问题一大堆，痛苦不已。</p><h3 id="2-3-一致性问题"><a href="#2-3-一致性问题" class="headerlink" title="2.3 一致性问题"></a>2.3 一致性问题</h3><p>A 系统处理完了直接返回成功了，人都以为你这个请求就成功了；但是问题是，要是 BCD 三个系统那里，BD 两个系统写库成功了，结果 C 系统写库失败了，咋整？你这数据就不一致了。</p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> 消息队列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 消息队列 </tag>
            
            <tag> RabbitMQ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>消息队列可靠性保证</title>
      <link href="/2020/02/27/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E5%8F%AF%E9%9D%A0%E6%80%A7%E4%BF%9D%E8%AF%81/"/>
      <url>/2020/02/27/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E5%8F%AF%E9%9D%A0%E6%80%A7%E4%BF%9D%E8%AF%81/</url>
      
        <content type="html"><![CDATA[<p>消息丢失是使用消息中间件时所不得不面对的一个痛点，其背后消息可靠性也是衡量消息中间件好坏的一个关键因素。尤其是在金融支付领域，消息可靠性尤为重要。</p><p>我们要保证数据不丢失，下面我们看下RabbitMQ和Kafka怎样实现的消息可靠性</p><h2 id="RabbitMQ"><a href="#RabbitMQ" class="headerlink" title="RabbitMQ"></a>RabbitMQ</h2><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/rmqsis.png" alt=""></p><h2 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h2><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/kafkasis.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> 消息队列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 消息队列 </tag>
            
            <tag> RabbitMQ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kafka和RabbitMQ的比较</title>
      <link href="/2020/02/27/Kafka%E5%92%8CRabbitmq%E7%9A%84%E6%AF%94%E8%BE%83/"/>
      <url>/2020/02/27/Kafka%E5%92%8CRabbitmq%E7%9A%84%E6%AF%94%E8%BE%83/</url>
      
        <content type="html"><![CDATA[<table><thead><tr><th align="center">功能项</th><th align="center">Kafka（1.1.0版本）</th><th align="center">RabbitMQ（3.6.10版本）</th></tr></thead><tbody><tr><td align="center">优先级队列</td><td align="center">不支持</td><td align="center">支持。建议优先级大小设置在0-10之间</td></tr><tr><td align="center">延迟队列</td><td align="center">不支持</td><td align="center">支持</td></tr><tr><td align="center">死信队列</td><td align="center">不支持</td><td align="center">支持</td></tr><tr><td align="center">重试队列</td><td align="center">不支持</td><td align="center">不支持</td></tr><tr><td align="center">消费模式</td><td align="center">pull</td><td align="center">pull+push</td></tr><tr><td align="center">广播消费</td><td align="center">支持</td><td align="center">支持</td></tr><tr><td align="center">消息回溯</td><td align="center">Kafka支持按照offset和timestamp两种维度进行消息回溯</td><td align="center">不支持。RabbitMQ中消息一旦被确认消费就会被标记删除</td></tr><tr><td align="center">消息堆积</td><td align="center">支持</td><td align="center">支持</td></tr><tr><td align="center">持久化</td><td align="center">支持</td><td align="center">支持</td></tr><tr><td align="center">消息过滤</td><td align="center">通过客户端interceptor拦截器实现</td><td align="center">不支持</td></tr><tr><td align="center">消息追踪</td><td align="center">不支持。消息追踪可以通过外部系统来支持，但是支持粒度没有内置的细腻。</td><td align="center">支持。RabbitMQ中可以采用Firehose或者rabbitmq_tracing插件实现。不过开启rabbitmq_tracing插件件会大幅影响性能，不建议生产环境开启，反倒是可以使用Firehose与外部链路系统结合提供高细腻度的消息追踪支持。</td></tr><tr><td align="center">多租户(vhost)支持</td><td align="center">不支持</td><td align="center">支持</td></tr><tr><td align="center">多协议支持</td><td align="center">只支持定义协议</td><td align="center">RabbitMQ本身就是AMQP协议的实现，同时支持MQTT、STOMP等协议</td></tr><tr><td align="center">跨语言支持</td><td align="center">采用Scala和Java编写，支持多种语言的客户端</td><td align="center">采用Erlang编写，支持多种语言的客户端</td></tr><tr><td align="center">幂等性</td><td align="center">支持单个生产者单分区单会话的幂等性</td><td align="center">不支持</td></tr><tr><td align="center">事务性消息</td><td align="center">支持</td><td align="center">支持</td></tr><tr><td align="center">消息顺序性</td><td align="center">支持单分区（partition）级别的顺序性</td><td align="center">顺序性的条件比较苛刻，需要单线程发送、单线程消费并且不采用延迟队列、优先级队列等一些高级功能，从某种意义上来说不算支持顺序性</td></tr><tr><td align="center">安全机制</td><td align="center">（TLS/SSL、SASL）身份认证和（读写）权限控制</td><td align="center">与Kafka相似</td></tr><tr><td align="center">控制中心</td><td align="center">外部依赖zookeeper</td><td align="center">自己实现的NameSrv</td></tr><tr><td align="center">单机吞吐量</td><td align="center">十万级</td><td align="center">万级</td></tr><tr><td align="center">topic对吞吐量影响</td><td align="center">topic 从几十到几百个时候，吞吐量会大幅度下降，在同等机器下，Kafka 尽量保证 topic 数量不要过多，如果要支撑大规模的 topic，需要增加更多的机器资源</td><td align="center">－</td></tr><tr><td align="center">时效性</td><td align="center">微妙级</td><td align="center">ms级</td></tr><tr><td align="center">可靠性</td><td align="center">基本不丢</td><td align="center">经过参数优化配置，可以做到 0 丢失</td></tr></tbody></table><p>​        </p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> 消息队列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 消息队列 </tag>
            
            <tag> RabbitMQ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kafka幂等性保证</title>
      <link href="/2020/02/26/Kafka%E5%B9%82%E7%AD%89%E6%80%A7%E4%BF%9D%E8%AF%81/"/>
      <url>/2020/02/26/Kafka%E5%B9%82%E7%AD%89%E6%80%A7%E4%BF%9D%E8%AF%81/</url>
      
        <content type="html"><![CDATA[<h2 id="1-Kafka生产端自带幂等性"><a href="#1-Kafka生产端自带幂等性" class="headerlink" title="1 Kafka生产端自带幂等性"></a>1 Kafka生产端自带幂等性</h2><p>为了实现Producer的幂等性，Kafka引入了Producer ID（即PID）和Sequence Number。</p><ul><li>PID。每个新的Producer在初始化的时候会被分配一个唯一的PID，这个PID对用户是不可见的。</li><li>Sequence Numbler。（对于每个PID，该Producer发送数据的每个&lt;Topic, Partition&gt;都对应一个从0开始单调递增的Sequence Number</li></ul><p>Kafka可能存在多个生产者，会同时产生消息，但对Kafka来说，<strong>只需要保证每个生产者内部的消息幂等就可以了</strong>，所有引入了PID来标识不同的生产者。</p><p>对于Kafka来说，要解决的是生产者发送消息的幂等问题。也即需要区分每条消息是否重复。<br>Kafka通过为每条消息增加一个Sequence Numbler，通过Sequence Numbler来区分每条消息。每条消息对应一个分区，不同的分区产生的消息不可能重复。所有Sequence Numbler对应每个分区</p><p>Broker端在缓存中保存了这seq number，对于接收的每条消息，如果其序号比Broker缓存中序号大于1则接受它，否则将其丢弃。这样就可以实现了消息重复提交了。</p><p><strong>但是，只能保证单个Producer对于同一个&lt;Topic, Partition&gt;的Exactly Once语义。不能保证同一个Producer一个topic不同的partion幂等。</strong></p><h2 id="2-消费端幂等性"><a href="#2-消费端幂等性" class="headerlink" title="2 消费端幂等性"></a>2 消费端幂等性</h2><p>将在消息队列幂等性文章中统一说明</p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> 消息队列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kafka </tag>
            
            <tag> 消息队列 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kafka可靠性保证</title>
      <link href="/2020/02/26/Kafka%E5%8F%AF%E9%9D%A0%E6%80%A7%E4%BF%9D%E8%AF%81/"/>
      <url>/2020/02/26/Kafka%E5%8F%AF%E9%9D%A0%E6%80%A7%E4%BF%9D%E8%AF%81/</url>
      
        <content type="html"><![CDATA[<h2 id="1-生产者可靠性保证"><a href="#1-生产者可靠性保证" class="headerlink" title="1. 生产者可靠性保证"></a>1. 生产者可靠性保证</h2><p>设置<strong>acks=-1(all)&amp;&amp;retries=MAX</strong>，一定不会丢，要求是，你的 leader 接收到消息，所有的 follower 都同步到了消息之后，才认为本次写成功了。如果没满足这个条件，生产者会自动不断的重试，重试无限次。</p><h2 id="2-消费者可靠性保证"><a href="#2-消费者可靠性保证" class="headerlink" title="2. 消费者可靠性保证"></a>2. 消费者可靠性保证</h2><h3 id="2-1-消费者提交方式"><a href="#2-1-消费者提交方式" class="headerlink" title="2.1 消费者提交方式"></a>2.1 消费者提交方式</h3><ul><li>自动提交</li><li>手动提交<ul><li>同步提交(阻塞线程)</li><li>异步提交(非阻塞)</li></ul></li></ul><p><strong>无论是同步提交还是异步提交 offset，都有可能会造成数据的漏消费或者重复消费。</strong></p><p><strong>先提交 offset 后消费，有可能造成数据的漏消费；</strong></p><p><strong>而先消费后提交 offset，有可能会造成数据的重复消费</strong></p><h3 id="2-2-消费者可靠性选择"><a href="#2-2-消费者可靠性选择" class="headerlink" title="2.2 消费者可靠性选择"></a>2.2 消费者可靠性选择</h3><p><strong>我们采取异步先消费后提交的方式来保证消费者端的可靠性,造成的重复消费我们使用幂等性来规避</strong></p><h2 id="3-Broker可靠性保证"><a href="#3-Broker可靠性保证" class="headerlink" title="3 Broker可靠性保证"></a>3 Broker可靠性保证</h2><p><strong>这块比较常见的一个场景，就是 Kafka 某个 broker 宕机，然后重新选举 partition 的 leader。要是此时其他的 follower 刚好还有些数据没有同步，结果此时 leader 挂了，然后选举某个 follower 成 leader 之后，就会丢一些数据</strong></p><p>所以此时一般是要求起码设置如下 2 个参数：</p><ul><li><strong>给 topic 设置 replication.factor 参数：这个值必须大于 1，要求每个 partition 必须有至少 2 个副本。</strong></li><li>在 Kafka 服务端设置 <strong>min.insync.replicas</strong> 参数：<strong>这个值必须大于 1，这个是要求一个 leader 至少感知到有至少一个 follower 还跟自己保持联系，没掉队，这样才能确保 leader 挂了还有一个 follower 吧。</strong></li></ul><p>我们生产环境就是按照上述要求配置的，这样配置之后，至少在 Kafka broker 端就可以保证在 leader 所在 broker 发生故障，进行 leader 切换时，数据不会丢失。</p><h2 id="4-总结"><a href="#4-总结" class="headerlink" title="4 总结"></a>4 总结</h2><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/kafkasis.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> 消息队列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kafka </tag>
            
            <tag> 消息队列 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kafka介绍</title>
      <link href="/2020/02/26/Kafka%E4%BB%8B%E7%BB%8D/"/>
      <url>/2020/02/26/Kafka%E4%BB%8B%E7%BB%8D/</url>
      
        <content type="html"><![CDATA[<h2 id="1-基础架构"><a href="#1-基础架构" class="headerlink" title="1 基础架构"></a>1 基础架构</h2><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/kafkaarc.png" alt=""></p><ul><li><strong>Producer</strong> ：消息生产者，就是向kafka broker发消息的客户端；</li><li><strong>Consumer</strong> ：消息消费者，向kafka broker取消息的客户端；</li><li><strong>ConsumerGroup （CG）</strong>：消费者组，由多个consumer组成。<strong>消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费；消费者组之间互不影响</strong>。所有的消费者都属于某个消费者组，即消费者组是<strong>逻辑上的一个订阅者</strong>。</li><li><strong>Broker</strong> ：一台kafka服务器就是一个broker。一个集群由多个broker组成。一个broker 可以容纳多个topic。</li><li><strong>Topic</strong> ：可以理解为一个队列，<strong>生产者和消费者面向的都是一个topic</strong>；</li><li><strong>Partition</strong>：为了实现扩展性，一个非常大的topic可以分布到多个broker（即服务器）上，<strong>一个topic可以分为多个partition，每个partition是一个有序的队列</strong>；</li><li><strong>Replica</strong>：副本，为保证集群中的某个节点发生故障时，<strong>该节点上的partition数据不丢失，且kafka仍然能够继续工作</strong>，kafka提供了副本机制，一个topic的每个分区都有若干个副本，一个leader和若干个follower。</li><li><strong>leader</strong>：每个分区多个副本的“主”，生产者发送数据的对象，以及消费者消费数据的对象都是leader。</li><li><strong>follower</strong>：每个分区多个副本中的“从”，实时从leader中同步数据，保持和leader数据的同步。leader发生故障时，某个follower会成为新的follower。</li></ul><h2 id="2-Kafka工作流程"><a href="#2-Kafka工作流程" class="headerlink" title="2 Kafka工作流程"></a>2 Kafka工作流程</h2><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/kafkaworkflow.png" alt=""></p><p>Kafka中消息是以<strong>topic</strong>进行分类的，生产者生产消息，消费者消费消息，都是面向topic的</p><p>topic是逻辑上的概念，而partition是物理上的概念，每个partition对应于一个log文件，该log文件中存储的就是producer生产的数据。Producer生产的数据会被不断追加到该log文件末端，且每条数据都有自己的offset。<strong>消费者组中的每个消费者，都会实时记录自己消费到了哪个offset</strong>，以便出错恢复时，从上次的位置继续消费。</p><h2 id="3-Kafka文件储存机制"><a href="#3-Kafka文件储存机制" class="headerlink" title="3 Kafka文件储存机制"></a>3 Kafka文件储存机制</h2><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/kafkafilearc.png" alt=""></p><p>由于生产者生产的消息会不断追加到 log 文件末尾，为防止 log 文件过大导致数据定位<br>效率低下，Kafka 采取了<strong>分片和索引</strong>机制，将每个 partition 分为多个 segment。每个 segment<br>对应两个文件——“.index”文件和“.log”文件。这些文件位于一个文件夹下，该文件夹的命名<br>规则为：<strong>topic 名称+分区序号</strong>。例如，first 这个 topic 有三个分区，则其对应的文件夹为 first-<br>0,first-1,first-2。</p><pre><code class="ini">00000000000000000000.index00000000000000000000.log00000000000000170410.index00000000000000170410.log00000000000000239430.index00000000000000239430.log</code></pre><p>index 和 log 文件以当前 segment 的<strong>第一条消息的 offset</strong> 命名。下图为 index 文件和 log<br>文件的结构示意图</p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/kafkafileindex.png" alt=""></p><p><strong>“.index”文件存储大量的索引信息，“.log”文件存储大量的数据，索引文件中的元数据指向对应数据文件中message的物理偏移地址。</strong></p><h2 id="4-Kafka生产者"><a href="#4-Kafka生产者" class="headerlink" title="4 Kafka生产者"></a>4 Kafka生产者</h2><h3 id="4-1-分区策略"><a href="#4-1-分区策略" class="headerlink" title="4.1 分区策略"></a>4.1 分区策略</h3><h4 id="4-1-1-分区原因"><a href="#4-1-1-分区原因" class="headerlink" title="4.1.1 分区原因"></a>4.1.1 分区原因</h4><ul><li><strong>方便在集群中扩展</strong>，每个Partition可以通过调整以适应它所在的机器，而一个topic 又可以有多个Partition组成，因此整个集群就可以适应任意大小的数据了；</li><li><strong>可以提高并发</strong>，因为可以以Partition为单位读写了</li></ul><h4 id="4-1-2-分区原则"><a href="#4-1-2-分区原则" class="headerlink" title="4.1.2 分区原则"></a>4.1.2 分区原则</h4><p>在生产端发送数据的时候,发送到的分区根据以下顺序选择:</p><ol><li>指明partition 的情况下，直接将指明的值直接作为partiton 值；</li><li>没有指明partition 值但有key 的情况下，将key 的hash 值与topic 的partition 数进行取余得到partition 值；</li><li>既没有partition 值又没有key 值的情况下，第一次调用时随机生成一个整数（后面每次调用在这个整数上自增），将这个值与topic 可用的partition 总数取余得到partition 值，也就是常说的round-robin 算法。</li></ol><h3 id="4-2-数据可靠性"><a href="#4-2-数据可靠性" class="headerlink" title="4.2 数据可靠性"></a>4.2 数据可靠性</h3><p><strong>为保证producer发送的数据，能可靠的发送到指定的topic，topic的每个partition收到producer发送的数据后，都需要向producer发送ack（acknowledgement确认收到），如果producer收到ack，就会进行下一轮的发送，否则重新发送数据。</strong></p><h4 id="4-2-1-发送方案"><a href="#4-2-1-发送方案" class="headerlink" title="4.2.1 发送方案"></a>4.2.1 发送方案</h4><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/kafkaack.png" alt=""></p><p>Kafka 选择了<strong>第二种</strong>方案，原因如下：</p><ul><li><p>同样为了容忍 n 台节点的故障，第一种方案需要 2n+1 个副本，而第二种方案只需要 n+1个副本，而 Kafka 的每个分区都有大量的数据，<strong>第一种方案会造成大量数据的冗余</strong>。</p></li><li><p>虽然第二种方案的网络延迟会比较高，但网络延迟对 Kafka 的影响较小。</p></li></ul><h4 id="4-2-2-ISR"><a href="#4-2-2-ISR" class="headerlink" title="4.2.2 ISR"></a>4.2.2 ISR</h4><p>采用第二种方案之后，设想以下情景：leader 收到数据，所有 follower 都开始同步数据，<br>但有一个 follower，因为某种故障，迟迟不能与 leader 进行同步，那 leader 就要一直等下去，<br>直到它完成同步，才能发送 ack。这个问题怎么解决呢？</p><p><strong>Leader维护了一个动态的in-syncreplicaset(ISR)，意为和leader保持同步的follower集合。当ISR中的follower完成数据的同步之后，leader就会给follower发送ack。如果follower长时间未向leader同步数据，则该follower将被踢出ISR，该时间阈值由replica.lag.time.max.ms参数设定。Leader发生故障之后，就会从ISR中选举新的leader。</strong></p><h4 id="4-2-3-ACK应答机制"><a href="#4-2-3-ACK应答机制" class="headerlink" title="4.2.3 ACK应答机制"></a>4.2.3 ACK应答机制</h4><p>对于某些不太重要的数据，对数据的可靠性要求不是很高，能够容忍数据的少量丢失，所以没必要等ISR中的follower全部接收成功。所以<strong>Kafka为用户提供了三种可靠性级别</strong>，用户根据对可靠性和延迟的要求进行权衡，选择以下的配置。</p><ul><li><strong>0</strong>：<strong>producer不等待broker的ack</strong>，这一操作提供了一个最低的延迟，broker一接收到还没有写入磁盘就已经返回，当broker故障时有可能丢失数据；</li><li><strong>1</strong>：<strong>producer等待broker的ack，partition的leader落盘成功后返回ack</strong>，如果在follower同步成功之前leader故障，那么将会丢失数据；</li><li><strong>-1</strong>（all）：<strong>producer等待broker的ack，partition的leader和follower全部落盘成功后才返回ack</strong>。但是如果在follower同步完成后，broker发送ack之前，leader发生故障，那么会造成<strong>数据重复</strong></li></ul><h4 id="4-2-4-HW和LEO"><a href="#4-2-4-HW和LEO" class="headerlink" title="4.2.4 HW和LEO"></a>4.2.4 HW和LEO</h4><p><strong>LEO：指的是每个副本最大的 offset；</strong><br><strong>HW：指的是消费者能见到的最大的 offset，ISR 队列中最小的 LEO。</strong></p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/kafkahw.png" alt=""></p><ul><li><p><strong>follower故障</strong>：follower发生故障后会被临时踢出ISR，待该follower恢复后，follower会读取本地磁盘记录的上次的HW，并将log文件高于HW的部分截取掉，从HW开始向leader进行同步。等该<strong>follower的LEO大于等于该Partition的HW</strong>，即follower追上leader之后，就可以重新加入ISR了。</p></li><li><p><strong>leader故障</strong>:leader发生故障之后，会从ISR中选出一个新的leader，之后，为保证多个副本之间的数据一致性，其余的follower会先将各自的log文件高于<strong>HW的部分截掉</strong>，然后从新的leader 同步数据。</p></li></ul><p><strong>注意：这只能保证副本之间的数据一致性，并不能保证数据不丢失或者不重复。</strong></p><h3 id="4-3-ExactlyOnce语义"><a href="#4-3-ExactlyOnce语义" class="headerlink" title="4.3 ExactlyOnce语义"></a>4.3 ExactlyOnce语义</h3><p>将服务器的ACK级别设置为-1,可以保证Producer到Server之间不会丢失数据，即<strong>At Least Once语义</strong>。相对的，将服务器ACK级别设置为0,可以保证生产者每条消息只会被发送一次，即<strong>AtMostOnce语义</strong>。</p><p><strong>AtLeastOnce可以保证数据不丢失，但是不能保证数据不重复</strong></p><p><strong>AtLeastOnce 可以保证数据不重复，但是不能保证数据不丢失</strong></p><p>但是，对于一些非常重要的信息，比如说交易数据，下游数据消费者要求数据既不重复也不丢失，即ExactlyOnce语义。在0.11版本以前的Kafka，对此是无能为力的，只<strong>能保证数据不丢失，再在下游消费者对数据做全局去重</strong>。对于多个下游应用的情况，每个都需要单独做全局去重，这就对性能造成了很大影响。</p><p>0.11版本的Kafka，引入了一项重大特性：<strong>幂等性</strong>。<strong>所谓的幂等性就是指Producer不论向Server发送多少次重复数据，Server端都只会持久化一条</strong>。幂等性结合AtLeastOnce语义，就构成了Kafka的ExactlyOnce语义。即：</p><pre><code>AtLeastOnce+幂等性=ExactlyOnce</code></pre><p>要启用幂等性，只需要将<strong>Producer的参数中enable.idompotence设置为true即可</strong>。</p><p><strong>Kafka 的幂等性实现其实就是将原来下游需要做的去重放在了数据上游</strong>。开启幂等性的Producer在初始化的时候会被分配一个PID，发往同一Partition的消息会附带SequenceNumber。<strong>而Broker端会对&lt;PID,Partition,SeqNumber&gt;做缓存，当具有相同主键的消息提交时，Broker只会持久化一条</strong>。</p><p><strong>但是PID重启就会变化，同时不同的Partition也具有不同主键，所以幂等性无法保证跨分区跨会话的ExactlyOnce。</strong></p><h2 id="5-Kafka消费者"><a href="#5-Kafka消费者" class="headerlink" title="5 Kafka消费者"></a>5 Kafka消费者</h2><h3 id="5-1-消费方式"><a href="#5-1-消费方式" class="headerlink" title="5.1 消费方式"></a>5.1 消费方式</h3><p><strong>consumer采用pull（拉）模式从broker中读取数据</strong>。</p><p>push（推）模式很难适应消费速率不同的消费者，因为消息发送速率是由broker决定的。它的目标是尽可能以最快速度传递消息，但是这样很容易造成consumer来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。而pull模式则可以根据consumer的消费能力以适当的速率消费消息。</p><p><strong>pull模式不足之处是，如果kafka没有数据，消费者可能会陷入循环中，一直返回空数据</strong>。针对这一点，Kafka的消费者在消费数据时会传入一个时长参数<strong>timeout</strong>，如果当前没有数据可供消费，consumer会等待一段时间之后再返回，这段时长即为timeout。</p><h3 id="5-2-offset维护"><a href="#5-2-offset维护" class="headerlink" title="5.2 offset维护"></a>5.2 offset维护</h3><p>由于consumer在消费过程中可能会出现断电宕机等故障，consumer恢复后，需要从故障前的位置的继续消费，所以<strong>consumer需要实时记录自己消费到了哪个offset，以便故障恢复后继续消费</strong>。</p><p><strong>Kafka0.9版本之前，consumer默认将offset保存在Zookeeper中，从0.9版本开始，consumer默认将offset保存在Kafka一个内置的topic中，该topic为__consumer_offsets</strong></p><h2 id="6-Kafka高效读写数据原因"><a href="#6-Kafka高效读写数据原因" class="headerlink" title="6 Kafka高效读写数据原因"></a>6 Kafka高效读写数据原因</h2><ul><li>顺序写磁盘</li><li>零拷贝技术</li></ul><h3 id="6-1-顺序读写磁盘"><a href="#6-1-顺序读写磁盘" class="headerlink" title="6.1 顺序读写磁盘"></a>6.1 顺序读写磁盘</h3><p>Kafka的producer生产数据，要写入到log文件中，写的过程是一直追加到文件末端,为顺序写。官网有数据表明，同样的磁盘，顺序写能到600M/s，而随机写只有100K/s。这与磁盘的机械机构有关，顺序写之所以快，是因为其省去了大量磁头寻址的时间。</p><h3 id="6-2-零拷贝技术"><a href="#6-2-零拷贝技术" class="headerlink" title="6.2 零拷贝技术"></a>6.2 零拷贝技术</h3><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/kafkazero.png" alt=""></p><h2 id="7-Zookeeper在Kafka中的作用"><a href="#7-Zookeeper在Kafka中的作用" class="headerlink" title="7 Zookeeper在Kafka中的作用"></a>7 Zookeeper在Kafka中的作用</h2><p><strong>Kafka 集群中有一个 broker 会被选举为 Controller，负责管理集群 broker 的上下线，所有 topic 的分区副本分配和 leader 选举等工作。</strong><br><strong>Controller 的管理工作都是依赖于 Zookeeper 的。</strong></p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/kafkazk.png" alt=""></p><h2 id="8-Kafka事务"><a href="#8-Kafka事务" class="headerlink" title="8 Kafka事务"></a>8 Kafka事务</h2><p>Kafka 从 0.11 版本开始引入了事务支持。事务可以保证 Kafka 在 Exactly Once 语义的基<br>础上，<strong>生产和消费可以跨分区和会话，要么全部成功，要么全部失败</strong></p><h3 id="8-1-Producer事务"><a href="#8-1-Producer事务" class="headerlink" title="8.1 Producer事务"></a>8.1 Producer事务</h3><p>为了实现跨分区跨会话的事务，需要引入一个全局唯一的 Transaction ID，并将 Producer<br>获得的PID 和Transaction ID 绑定。这样当Producer 重启后就可以通过正在进行的 Transaction<br>ID 获得原来的 PID。<br>为了管理 Transaction，Kafka 引入了一个新的组件 <strong>Transaction Coordinator</strong>。Producer 就<br>是通过和 Transaction Coordinator 交互获得 Transaction ID 对应的任务状态。Transaction<br>Coordinator 还负责将事务所有写入 Kafka 的一个内部 Topic，这样即使整个服务重启，由于<br>事务状态得到保存，进行中的事务状态可以得到恢复，从而继续进行。</p><h3 id="8-2-Consumer事务"><a href="#8-2-Consumer事务" class="headerlink" title="8.2 Consumer事务"></a>8.2 Consumer事务</h3><p>上述事务机制主要是从 Producer 方面考虑，对于 Consumer 而言，事务的保证就会相对<br>较弱，尤其时无法保证 Commit 的信息被精确消费。<strong>这是由于 Consumer 可以通过 offset 访</strong><br><strong>问任意信息，而且不同的 Segment File 生命周期不同，同一事务的消息可能会出现重启后被</strong><br><strong>删除的情况</strong></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> 消息队列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kafka </tag>
            
            <tag> 消息队列 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RabbitMQ集群模式</title>
      <link href="/2020/02/25/RabbitMQ%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F/"/>
      <url>/2020/02/25/RabbitMQ%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<ul><li>主备模式(了解)</li><li>远程模式(了解)</li><li>镜像模式(推荐使用)</li><li>多活模式(推荐使用)</li></ul><h2 id="1-主备模式"><a href="#1-主备模式" class="headerlink" title="1 主备模式"></a>1 主备模式</h2><p>使用Haproxy做的主备模式</p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/rmqwarren.png" alt=""></p><h2 id="2-远程模式"><a href="#2-远程模式" class="headerlink" title="2 远程模式"></a>2 远程模式</h2><p>远距离通信和复制，所谓Shovel就是我们可以把消息进行不同数据中心的复制工作，我们可以跨地域的让两个mq集群互联。</p><p>在使用了shovel插件后，<strong>模型变成了近端同步确认，远端异步确认方式</strong>，大大提高了订单确认速度，并且还能保证可靠性。</p><p>我们下面看一下Shovel架构模型：</p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/rmqshovel.png" alt=""></p><h2 id="3-镜像模式"><a href="#3-镜像模式" class="headerlink" title="3 镜像模式"></a>3 镜像模式</h2><ul><li><p>镜像模式：集群模式非常经典的就是Mirror镜像模式，保证100%数据不丢失，在实际工作中用的最多的。并且实现集群非常的简单，<strong>一般互联网大厂都会构建这种镜像集群模式</strong>。</p></li><li><p>Mirror镜像队列，目的是为了保证rabbitmq数据的高可靠性解决方案，主要就是实现数据的同步，一般来讲是3-5个实现数据同步（对于100%数据可靠性解决方案一般是3个节点）集群架构如下：</p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/rmqmirror.png" alt=""></p></li></ul><h2 id="4-多活模式"><a href="#4-多活模式" class="headerlink" title="4 多活模式"></a>4 多活模式</h2><ul><li><p>多活模式：这种模式也是实现异地数据复制的主流模式，因为Shovel模式配置比较复杂，所以一般来说实现异地集群都是使用双活或者多活模式来实现的。这种模式需要依赖rabbitmq的<strong>federation</strong>插件，可以实现继续的可靠AMQP数据通信，多活模式在实际配置与应用非常的简单。</p></li><li><p>RabbitMQ部署架构采用双中心模式（多中心），那么在两套（或多套）数据中心中各部署一套RabbitMQ集群，各中心之间还需要实现部分队列消息共享。多活集群架构如下：</p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/rmqfeder.png" alt=""></p></li><li><p><strong>Federation</strong>插件是一个不需要构建Cluster，而在Brokers之间传输消息的高性能插件，Federation插件可以在Brokers或者Cluster之间传输消息，连接双方可以使用<strong>不同的users和vistual hosts</strong>，双方也可以使用版本不同的RabbitMQ和Erlang。Federation插件使用AMQP协议通信，可以接收不连续的传输。</p></li><li><p>Federation Exchanges,可以看成<strong>Downstream从Upstream主动拉取消息</strong>，但并不是拉取所有消息，必须是在Downstream上已经明确定义Bindings关系的Exchange，也就是有实际的物理Queue来接收消息，才会从Upstream拉取消息到Downstream。使用AMQP协议实施代理间通信，Downstream会将绑定关系组合在一起，绑定/解绑命令将会发送到Upstream交换机。因此，FederationExchange只接收具有订阅的消息。</p></li></ul><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/rmqfederation.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> 消息队列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 消息队列 </tag>
            
            <tag> RabbitMQ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RabbitMQ特殊队列</title>
      <link href="/2020/02/25/RabbitMQ%E7%89%B9%E6%AE%8A%E9%98%9F%E5%88%97/"/>
      <url>/2020/02/25/RabbitMQ%E7%89%B9%E6%AE%8A%E9%98%9F%E5%88%97/</url>
      
        <content type="html"><![CDATA[<ul><li>死信队列</li><li>延时队列</li><li>优先级队列</li></ul><h2 id="1-死信队列"><a href="#1-死信队列" class="headerlink" title="1 死信队列"></a>1 死信队列</h2><p>DLX, Dead-Letter-Exchange</p><p>利用DLX, 当消息在一个队列中变成死信（dead message）之后，它能被重新publish到<strong>另一个Exchange</strong>，这个Exchange就是DLX。</p><h3 id="1-1-产生情况"><a href="#1-1-产生情况" class="headerlink" title="1.1 产生情况"></a>1.1 产生情况</h3><p>消息变成死信一向有一下几种情况:</p><ul><li><strong>消息被拒绝（basic.reject/ basic.nack）并且requeue=false</strong></li><li><strong>消息TTL过期</strong></li><li><strong>队列达到最大长度</strong></li></ul><h3 id="1-2-特性"><a href="#1-2-特性" class="headerlink" title="1.2 特性"></a>1.2 特性</h3><ul><li>DLX也是一个<strong>正常的Exchange</strong>,和一般的Exchange没有区别，它能在任何的队列上被指定，实际上就是设置某个队列的属性。</li><li>当这个队列中有死信时，RabbitMQ就会<strong>自动的将这个消息重新发布</strong>到设置的Exchange上去，进而被路由到另一个队列。</li><li><strong>可以监听这个队列中消息</strong>做相应的处理，这个特性可以弥补RabbitMQ3.0以前支持的immediate参数的功能。</li></ul><h3 id="1-3-设置"><a href="#1-3-设置" class="headerlink" title="1.3 设置"></a>1.3 设置</h3><ul><li>首先需要设置死信队列的exchange和queue,然后进行绑定:<ul><li>Exchange: dlx.exchange</li><li>Queue: dlx.queue</li><li>Routing Key: #</li></ul></li><li>然后我们进行正常声明交换机、队列、绑定，只不过我们需要在队列加上一个参数即可：arguments.put(nx-dead-letter-exchange”,”dlx.exchange”)；</li><li>这样消息在过期、requeue、队列在达到最大长度时，消息就可以直接路由到死信队列</li></ul><h2 id="2-延时队列"><a href="#2-延时队列" class="headerlink" title="2 延时队列"></a>2 延时队列</h2><p><strong>延时队列</strong>，首先，它是一种队列，队列意味着内部的元素是<strong>有序</strong>的，元素出队和入队是有方向性的，元素从一端进入，从另一端取出。</p><p>其次，<strong>延时队列</strong>，最重要的特性就体现在它的<strong>延时</strong>属性上，跟普通的队列不一样的是，<strong>普通队列中的元素总是等着希望被早点取出处理，而延时队列中的元素则是希望被在指定时间得到取出和处理</strong>，所以延时队列中的元素是都是带时间属性的，通常来说是需要被处理的消息或者任务。</p><p>简单来说，延时队列就是用来存放需要在指定时间被处理的元素的队列。</p><h3 id="2-1-使用场景"><a href="#2-1-使用场景" class="headerlink" title="2.1 使用场景"></a>2.1 使用场景</h3><p>那么什么时候需要用延时队列呢？考虑一下以下场景：</p><ul><li>订单在十分钟之内未支付则自动取消。</li><li>新创建的店铺，如果在十天内都没有上传过商品，则自动发送消息提醒。</li><li>账单在一周内未支付，则自动结算。</li><li>用户注册成功后，如果三天内没有登陆则进行短信提醒。</li><li>用户发起退款，如果三天内没有得到处理则通知相关运营人员。</li><li>预定会议后，需要在预定的时间点前十分钟通知各个与会人员参加会议。</li></ul><p>这些场景都有一个特点，需要在某个事件发生之后或者之前的指定时间点完成某一项任务，如：发生订单生成事件，在十分钟之后检查该订单支付状态，然后将未支付的订单进行关闭；发生店铺创建事件，十天后检查该店铺上新商品数，然后通知上新数为0的商户；发生账单生成事件，检查账单支付状态，然后自动结算未支付的账单；发生新用户注册事件，三天后检查新注册用户的活动数据，然后通知没有任何活动记录的用户；发生退款事件，在三天之后检查该订单是否已被处理，如仍未被处理，则发送消息给相关运营人员；发生预定会议事件，判断离会议开始是否只有十分钟了，如果是，则通知各个与会人员。</p><p>看起来<strong>似乎使用定时任务</strong>，一直轮询数据，每秒查一次，取出需要被处理的数据，然后处理不就完事了吗？如果数据量比较少，确实可以这样做，比如：对于“如果账单一周内未支付则进行自动结算”这样的需求，如果对于时间不是严格限制，而是宽松意义上的一周，那么每天晚上跑个定时任务检查一下所有未支付的账单，确实也是一个可行的方案。但对于数据量比较大，并且时效性较强的场景，如：“订单十分钟内未支付则关闭“，短期内未支付的订单数据可能会有很多，活动期间甚至会达到百万甚至千万级别，对这么庞大的数据量仍旧使用轮询的方式显然是不可取的，很可能在一秒内无法完成所有订单的检查，同时会给数据库带来很大压力，无法满足业务要求而且性能低下。</p><p>这时候，延时队列就可以闪亮登场了，<strong>以上场景，正是延时队列的用武之地</strong>。</p><p>既然延时队列可以解决很多特定场景下，带时间属性的任务需求，那么如何构造一个延时队列呢？接下来，本文将介绍如何用RabbitMQ来实现延时队列。</p><h3 id="2-2-RabbitMQ中的TTL"><a href="#2-2-RabbitMQ中的TTL" class="headerlink" title="2.2 RabbitMQ中的TTL"></a>2.2 RabbitMQ中的TTL</h3><p>在介绍延时队列之前，还需要先介绍一下RabbitMQ中的一个高级特性——<strong>TTL（Time To Live）</strong>。</p><p>TTL是什么呢？TTL是RabbitMQ中一个消息或者队列的属性，表明一条消息或者该队列中的所有消息的最大存活时间，单位是毫秒。换句话说，如果一条消息设置了TTL属性或者进入了设置TTL属性的队列，那么这条消息如果在TTL设置的时间内没有被消费，则会成为“死信”（至于什么是死信，请翻看上一篇）。如果同时配置了队列的TTL和消息的TTL，那么较小的那个值将会被使用。</p><p>那么，如何设置这个TTL值呢？有两种方式，第一种是在创建队列的时候设置队列的“<strong>x-message-ttl</strong>”属性，如下：</p><pre><code class="java">Map&lt;String, Object&gt; args = new HashMap&lt;String, Object&gt;();args.put(&quot;x-message-ttl&quot;, 6000);channel.queueDeclare(queueName, durable, exclusive, autoDelete, args);</code></pre><p>这样所有被投递到该队列的消息都最多不会存活超过6s。</p><p>另一种方式便是针对每条消息设置TTL，代码如下：</p><pre><code class="java">AMQP.BasicProperties.Builder builder = new AMQP.BasicProperties.Builder();builder.expiration(&quot;6000&quot;);AMQP.BasicProperties properties = builder.build();channel.basicPublish(exchangeName, routingKey, mandatory, properties, &quot;msg body&quot;.getBytes());</code></pre><p>这样这条消息的过期时间也被设置成了6s。</p><p>但这两种方式是有区别的，<strong>如果设置了队列的TTL属性，那么一旦消息过期，就会被队列丢弃，而第二种方式，消息即使过期，也不一定会被马上丢弃，因为消息是否过期是在即将投递到消费者之前判定的，如果当前队列有严重的消息积压情况，则已过期的消息也许还能存活较长时间</strong>。</p><p>另外，还需要注意的一点是，如果不设置TTL，表示消息永远不会过期，如果将TTL设置为0，则表示除非此时可以直接投递该消息到消费者，否则该消息将会被丢弃。</p><h3 id="2-3-实现延时队列"><a href="#2-3-实现延时队列" class="headerlink" title="2.3 实现延时队列"></a>2.3 实现延时队列</h3><h4 id="2-3-1-通过死信队列实现"><a href="#2-3-1-通过死信队列实现" class="headerlink" title="2.3.1 通过死信队列实现"></a>2.3.1 通过死信队列实现</h4><p>延时队列，不就是想要消息延迟多久被处理吗，TTL则刚好能让消息在延迟多久之后成为死信，另一方面，成为死信的消息都会被投递到死信队列里，这样只需要消费者一直消费死信队列里的消息就万事大吉了，因为里面的消息都是希望被立即处理的消息。</p><p>但如果使用在消息属性上设置TTL的方式，消息可能并不会按时“死亡“，因为RabbitMQ只会检查第一个消息是否过期，如果过期则丢到死信队列，索引如果第一个消息的延时时长很长，而第二个消息的延时时长很短，则第二个消息并不会优先得到执行</p><p><strong>所以不推荐使用此种方式!</strong></p><h4 id="2-3-2-通过插件实现"><a href="#2-3-2-通过插件实现" class="headerlink" title="2.3.2 通过插件实现"></a>2.3.2 通过插件实现</h4><p>安装一个插件即可：<a href="https://www.rabbitmq.com/community-plugins.html" target="_blank" rel="noopener">https://www.rabbitmq.com/community-plugins.html</a> ，下载rabbitmq_delayed_message_exchange插件，然后解压放置到RabbitMQ的插件目录。</p><p>接下来，进入RabbitMQ的安装目录下的sbin目录，执行下面命令让该插件生效，然后重启RabbitMQ。</p><h2 id="3-优先级队列"><a href="#3-优先级队列" class="headerlink" title="3 优先级队列"></a>3 优先级队列</h2><p>优先级队列，顾名思义，具有更高优先级的队列具有较高的优先权，优先级高的消息具备优先被消费的特权。</p><h3 id="3-1-实现方式"><a href="#3-1-实现方式" class="headerlink" title="3.1 实现方式"></a>3.1 实现方式</h3><p>可以通过设置<strong>x-max-priority</strong>属性来实现优先级队列</p><p>当然，在消费端速度大于生产端速度，且broker中没有消息堆积的话，对发送的消息设置优先级也没什么实际意义，因为发送端刚发送完一条消息就被消费端消费了，那么就相当于broker至多只有一条消息，那么对于单条消息来说优先级是没有什么意义的。</p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> 消息队列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 消息队列 </tag>
            
            <tag> RabbitMQ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RabbitMQ数据可靠性保证</title>
      <link href="/2020/02/25/RabbitMQ%E5%8F%AF%E9%9D%A0%E6%80%A7%E4%BF%9D%E8%AF%81/"/>
      <url>/2020/02/25/RabbitMQ%E5%8F%AF%E9%9D%A0%E6%80%A7%E4%BF%9D%E8%AF%81/</url>
      
        <content type="html"><![CDATA[<h2 id="1-生产者可靠性保证"><a href="#1-生产者可靠性保证" class="headerlink" title="1 生产者可靠性保证"></a>1 生产者可靠性保证</h2><p>在使用RabbitMQ的时候，我们可以通过消息持久化操作来解决因为服务器的异常奔溃导致的消息丢失，除此之外我们还会遇到一个问题，当消息的发布者在将消息发送出去之后，消息到底有没有正确到达broker代理服务器</p><p>如果不进行特殊配置的话，默认情况下发布操作<strong>是不会返回任何信息给生产者的</strong>，也就是默认情况下我们的生产者是不知道消息有没有正确到达broker的，如果在消息到达broker之前已经丢失的话，持久化操作也解决不了这个问题，因为消息根本就没到达代理服务器，你怎么进行持久化，那么这个问题该怎么解决呢？</p><p>RabbitMQ为我们提供了两种方式：</p><ul><li>通过AMQP<strong>事务机制</strong>实现，这也是AMQP协议层面提供的解决方案；</li><li>通过将channel设置成<strong>confirm模式</strong>来实现；</li></ul><h3 id="1-1-事务机制"><a href="#1-1-事务机制" class="headerlink" title="1.1 事务机制"></a>1.1 事务机制</h3><p>选择用 RabbitMQ 提供的事务功能，就是生产者发送数据之前开启 RabbitMQ 事务channel.txSelect，然后发送消息，如果消息没有成功被 RabbitMQ 接收到，那么生产者会收到异常报错，此时就可以回滚事务channel.txRollback，然后重试发送消息；如果收到了消息，那么可以提交事务channel.txCommit。</p><pre><code class="java">// 开启事务channel.txSelecttry {    // 这里发送消息} catch (Exception e) {    channel.txRollback    // 这里再次重发这条消息}// 提交事务channel.txCommit</code></pre><p>但是问题是，RabbitMQ 事务机制（同步）一搞，基本上<strong>吞吐量会下来，因为太耗性能</strong>。</p><h3 id="1-2-Comfirm机制"><a href="#1-2-Comfirm机制" class="headerlink" title="1.2 Comfirm机制"></a>1.2 Comfirm机制</h3><p>生产者将信道设置成confirm模式，一旦信道进入confirm模式，所有在该信道上面发布的消息都会被指派一个唯一的ID(从1开始)，一旦消息被投递到所有匹配的队列之后，broker就会发送一个确认给生产者（包含消息的唯一ID）,这就使得生产者知道消息已经正确到达目的队列了，如果消息和队列是可持久化的，那么确认消息会将消息写入磁盘之后发出，broker回传给生产者的确认消息中deliver-tag域包含了确认消息的序列号，此外broker也可以设置basic.ack的multiple域，表示到这个序列号之前的所有消息都已经得到了处理。</p><p>confirm模式最大的好处在于他是<strong>异步的</strong>，一旦发布一条消息，生产者应用程序就可以在等信道返回确认的同时继续发送下一条消息，当消息最终得到确认之后，生产者应用便可以通过回调方法来处理该确认消息，如果RabbitMQ因为自身内部错误导致消息丢失，就会发送一条nack消息，生产者应用程序同样可以在回调方法中处理该nack消息。</p><p>在channel 被设置成 confirm 模式之后，所有被 publish 的后续消息都将被 confirm（即 ack） 或者被nack一次。但是没有对消息被 confirm 的快慢做任何保证，并且同一条消息不会既被 confirm又被nack 。</p><h4 id="1-2-1-编程模式"><a href="#1-2-1-编程模式" class="headerlink" title="1.2.1 编程模式"></a>1.2.1 编程模式</h4><p>confirm有三种编程方式：</p><ul><li><strong>批量confirm模式</strong>：每发送一批消息后，调用waitForConfirms()方法，等待服务器端confirm。</li><li><strong>异步confirm模式</strong>：提供一个回调方法，服务端confirm了一条或者多条消息后Client端会回调这个方法(推荐使用的)</li></ul><h2 id="2-消费者可靠性保证"><a href="#2-消费者可靠性保证" class="headerlink" title="2 消费者可靠性保证"></a>2 消费者可靠性保证</h2><p>在Consumer中Confirm模式中分为</p><ul><li>手动确认</li><li>自动确认</li></ul><h3 id="2-1-自动确认"><a href="#2-1-自动确认" class="headerlink" title="2.1 自动确认"></a>2.1 自动确认</h3><p>默认模式是自动确认模式:消息在发送后立即被认为是发送成功。 这种模式可以提高吞吐量（只要消费者能够跟上），不过会降低投递和消费者处理的安全性。 这种模式通常被称为“发后即忘”。 与手动确认模式不同，如果消费者的TCP连接或信道在成功投递之前关闭，该消息则会丢失。</p><h3 id="2-２-手动确认"><a href="#2-２-手动确认" class="headerlink" title="2.２ 手动确认"></a>2.２ 手动确认</h3><p>为了保证消息从队列可靠地到达消费者，RabbitMQ提供消息确认机制(message acknowledgment)。消费者在声明队列时，可以指定noAck参数，当<strong>noAck=false时，RabbitMQ会等待消费者显式发回ack信号后才从内存(和磁盘，如果是持久化消息的话)中移去消息</strong>。否则，RabbitMQ会在队列中消息被消费后<strong>立即删除</strong>它。</p><p>采用消息确认机制后，只要令noAck=false，消费者就有足够的时间处理消息(任务)，不用担心处理消息过程中消费者进程挂掉后消息丢失的问题，因为RabbitMQ会一直持有消息直到消费者显式调用basicAck为止。</p><p>当noAck=false时，对于RabbitMQ服务器端而言，队列中的消息分成了两部分：</p><ul><li><p>一部分是等待投递给消费者的消息；</p></li><li><p>一部分是已经投递给消费者，但是还没有收到消费者ack信号的消息。</p></li></ul><p>RabbitMQ<strong>不会为没有ack确认的消息设置超时时间</strong>，它判断此消息是否需要重新投递给消费者的唯一依据是消费该消息的消费者连接是否已经断开。这么设计的原因是RabbitMQ允许消费者消费一条消息的时间可以很久很久。</p><p><strong>建议使用手动模式</strong></p><ul><li>如果服务器端<strong>一直没有收到消费者的ack信号，并且消费此消息的消费者已经断开连接</strong>，则服务器端会<strong>安排该消息重新进入队列，靠近队列头位置</strong>，等待投递给下一个消费者（也可能还是原来的那个消费者）。</li><li>如果收到了<strong>nack/reject信号且requeue为true</strong>,服务器端也会<strong>安排该消息重新进入队列，靠近队列头位置</strong>，等待投递给下一个消费者（也可能还是原来的那个消费者）。</li><li>如果收到了<strong>nack/reject信号且requeue为false</strong>,则<strong>进入死信队列</strong></li></ul><h2 id="3-broke可靠性保证"><a href="#3-broke可靠性保证" class="headerlink" title="3 broke可靠性保证"></a>3 broke可靠性保证</h2><p>broke可靠性需要两方面保证:</p><ul><li>持久化保证</li><li>集群高可用保证</li></ul><h3 id="3-1-持久化保证"><a href="#3-1-持久化保证" class="headerlink" title="3.1 持久化保证"></a>3.1 持久化保证</h3><p>就是 RabbitMQ 自己弄丢了数据，这个你必须<strong>开启 RabbitMQ 的持久化</strong>，就是消息写入之后会持久化到磁盘，哪怕是 RabbitMQ 自己挂了，恢复之后会自动读取之前存储的数据，一般数据不会丢。除非极其罕见的是，RabbitMQ 还没持久化，自己就挂了，可能导致少量数据丢失，但是这个概率较小。</p><p>设置持久化有两个步骤：</p><ul><li><strong>创建 queue 的时候将其设置为持久化</strong>,这样就可以保证 RabbitMQ 持久化 queue 的元数据，但是它是不会持久化 queue 里的数据的</li><li>发送消息的时候将消息的 <strong>deliveryMode 设置为 2</strong>就是将消息设置为持久化的，此时 RabbitMQ 就会将消息持久化到磁盘上去。</li></ul><p><strong>必须要同时设置这两个持久化才行</strong>，RabbitMQ 哪怕是挂了，再次重启，也会从磁盘上重启恢复 queue，恢复这个 queue 里的数据。</p><p>注意，哪怕是你给 RabbitMQ 开启了持久化机制，也有一种可能，就是这个消息写到了 RabbitMQ 中，但是还没来得及持久化到磁盘上，结果不巧，此时 RabbitMQ 挂了，就会导致内存里的一点点数据丢失。</p><p>所以，持久化可以跟生产者那边的 confirm 机制配合起来，只有消息被持久化到磁盘之后，才会通知生产者 ack 了，所以哪怕是在持久化到磁盘之前，RabbitMQ 挂了，数据丢了，生产者收不到 ack，你也是可以自己重发的。</p><h3 id="3-2-集群高可用"><a href="#3-2-集群高可用" class="headerlink" title="3.2 集群高可用"></a>3.2 集群高可用</h3><p><strong>开启镜像高可用模式</strong>。跟普通集群模式不一样的是，在镜像集群模式下，你创建的 queue，无论元数据还是 queue 里的消息都会存在于多个实例上，就是说，<strong>每个 RabbitMQ 节点都有这个 queue 的一个完整镜像</strong>，包含 queue 的全部数据的意思。然后每次你写消息到 queue 的时候，都会自动把消息同步到多个实例的 queue 上。</p><h2 id="4-总结"><a href="#4-总结" class="headerlink" title="4 总结"></a>4 总结</h2><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/rmqsis.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> 消息队列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 消息队列 </tag>
            
            <tag> RabbitMQ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RabbitMQ介绍</title>
      <link href="/2020/02/25/RabbitMQ%E4%BB%8B%E7%BB%8D/"/>
      <url>/2020/02/25/RabbitMQ%E4%BB%8B%E7%BB%8D/</url>
      
        <content type="html"><![CDATA[<h2 id="1-RabbitMQ是什么"><a href="#1-RabbitMQ是什么" class="headerlink" title="1 RabbitMQ是什么"></a>1 RabbitMQ是什么</h2><p>RabbitMQ 是一个由 Erlang 语言开发的 AMQP 的开源实现。</p><blockquote><p>AMQP ：Advanced Message Queue，高级消息队列协议。它是应用层协议的一个开放标准，为面向消息的中间件设计，基于此协议的客户端与消息中间件可传递消息，并不受产品、开发语言等条件的限制。</p></blockquote><h2 id="2-RabbitMQ特点"><a href="#2-RabbitMQ特点" class="headerlink" title="2 RabbitMQ特点"></a>2 RabbitMQ特点</h2><ul><li>可靠性</li><li>灵活路由机制</li><li>消息集群</li><li>高可用</li></ul><h3 id="2-1-可靠性"><a href="#2-1-可靠性" class="headerlink" title="2.1 可靠性"></a>2.1 可靠性</h3><p>RabbitMQ 使用一些机制来保证可靠性，如持久化、传输确认、发布确认。</p><h3 id="2-2-灵活路由机制"><a href="#2-2-灵活路由机制" class="headerlink" title="2.2 灵活路由机制"></a>2.2 灵活路由机制</h3><p>在消息进入队列之前，通过 Exchange 来路由消息的。对于典型的路由功能，RabbitMQ 已经提供了一些内置的 Exchange 来实现。针对更复杂的路由功能，可以将多个 Exchange 绑定在一起，也通过插件机制实现自己的 Exchange 。</p><h3 id="2-3-消息集群"><a href="#2-3-消息集群" class="headerlink" title="2.3 消息集群"></a>2.3 消息集群</h3><p>多个 RabbitMQ 服务器可以组成一个集群，形成一个逻辑 Broker 。</p><h3 id="2-4-高可用"><a href="#2-4-高可用" class="headerlink" title="2.4 高可用"></a>2.4 高可用</h3><p>队列可以在集群中的机器上进行镜像，使得在部分节点出问题的情况下队列仍然可用。</p><h2 id="3-AMQP协议"><a href="#3-AMQP协议" class="headerlink" title="3 AMQP协议"></a>3 AMQP协议</h2><h3 id="3-1-什么是AMQP协议"><a href="#3-1-什么是AMQP协议" class="headerlink" title="3.1 什么是AMQP协议"></a>3.1 什么是AMQP协议</h3><p>是具有现代特征的二进制协议。是一个提供统一消息服务的应用层标准高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计。</p><h3 id="3-2-协议模型"><a href="#3-2-协议模型" class="headerlink" title="3.2 协议模型"></a>3.2 协议模型</h3><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/amqpprot.png" alt=""></p><h3 id="3-3-核心概念"><a href="#3-3-核心概念" class="headerlink" title="3.3 核心概念"></a>3.3 核心概念</h3><ul><li><strong>Server</strong>:又称<strong>Broker</strong>,接受客户端的连接，实现AMQP实体服务</li><li><strong>Connection</strong>:连接，应用程序与Broker的网络连接</li><li><strong>Channel</strong>:网络信道，几乎所有的操作都在Channel中进行，Channel是进行消息读写的通道。客户端可建立多个Channel,每个Channel代表一个会话任务</li><li><strong>Message</strong>:消息，服务器和应用程序之间传送的数据，由Properties和Body组成。Properties可以对消息进行修饰，比如消息的优先级、延迟等高级特性；Body则就是消息体内容</li><li><strong>Virtual host</strong>:虚拟地址，用于进行逻辑隔离，最上层的消息路由。—个Virtual Host里面可以有若干个Exchange和Queue,<strong>同一个 VHost里面不能有相同名称的Exchange或Queue</strong></li><li><strong>Exchange</strong>:交换机，接收消息，根据路由键转发消息到绑定的队列</li><li><strong>Binding</strong>: Exchange和Queue之间的虚拟连接，binding中可以包含routing key</li><li><strong>Routing key</strong>: 一个路由规则,虚拟机可用它来确定如何路由一个特定消息</li><li><strong>Queue</strong>:也称为Message Queue,消息队列，保存消息并将它们转发给消费者</li></ul><h4 id="3-3-1-channel"><a href="#3-3-1-channel" class="headerlink" title="3.3.1 channel"></a>3.3.1 channel</h4><p>信道是生产消费者与rabbit通信的渠道，生产者publish或是消费者subscribe一个队列都是通过信道来通信的。信道是建立在TCP连接上的虚拟连接，rabbitmq在一条TCP上建立成百上千个信道来达到多个线程处理，这个TCP被多个线程共享，每个线程对应一个信道，信道在rabbit都有唯一的ID ,保证了信道私有性，对应上唯一的线程使用。</p><blockquote><p>疑问：为什么不建立多个TCP连接呢？原因是rabbit保证性能，系统为每个线程开辟一个TCP是非常消耗性能，每秒成百上千的建立销毁TCP会严重消耗系统。所以rabbitmq选择建立多个信道（建立在tcp的虚拟连接）连接到rabbit上。</p></blockquote><h4 id="3-3-2-queue"><a href="#3-3-2-queue" class="headerlink" title="3.3.2 queue"></a>3.3.2 queue</h4><ol><li>推模式：通过AMQP的basic.consume命令订阅，有消息会自动接收，吞吐量高</li><li>拉模式：通过AMQP的bsaic.get命令</li></ol><p>注：当队列拥有多个消费者时，队列收到的消息将以循环的方式发送给消费者。每条消息只会发送给一个订阅的消费者</p><h2 id="4-RabbitMQ整体结构"><a href="#4-RabbitMQ整体结构" class="headerlink" title="4 RabbitMQ整体结构"></a>4 RabbitMQ整体结构</h2><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/rabbitserver.png" alt=""></p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/rabbitmqtxt.png" alt=""></p><h2 id="5-工作模式"><a href="#5-工作模式" class="headerlink" title="5 工作模式"></a>5 工作模式</h2><h3 id="5-1-simple-queue"><a href="#5-1-simple-queue" class="headerlink" title="5.1 simple queue"></a>5.1 simple queue</h3><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/rmqsimple.png" alt=""></p><ol><li>消息产生消息，将消息放入队列</li><li>消息的消费者(consumer) 监听 消息队列,如果队列中有消息,就消费掉,消息被拿走后,自动从队列中删除</li></ol><h3 id="5-2-work-queue"><a href="#5-2-work-queue" class="headerlink" title="5.2 work queue"></a>5.2 work queue</h3><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/rmqwork.png" alt=""></p><ol><li>消息产生者将消息放入队列消费者可以有多个,消费者1,消费者2同时监听同一个队列,消息被消费。C1 C2共同争抢当前的消息队列内容,谁先拿到谁负责消费消息(隐患：高并发情况下,默认会产生某一个消息被多个消费者共同使用,可以设置一个开关(syncronize) 保证一条消息只能被一个消费者使用)。</li></ol><h3 id="5-3-publish-subscribe"><a href="#5-3-publish-subscribe" class="headerlink" title="5.3 publish/subscribe"></a>5.3 publish/subscribe</h3><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/rmqsub.png" alt=""></p><ol><li>每个消费者监听自己的队列；</li><li>生产者将消息发给broker，由交换机将消息转发到绑定此交换机的每个队列，每个绑定交换机的队列都将接收到消息。</li></ol><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/rmqfanout.png" alt=""></p><h3 id="5-4-routing"><a href="#5-4-routing" class="headerlink" title="5.4 routing"></a>5.4 routing</h3><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/rmqroute.png" alt=""></p><ol><li>消息生产者将消息发送给交换机按照路由判断,路由是字符串(info) 当前产生的消息携带路由字符(对象的方法),交换机根据路由的key,只能匹配上路由key对应的消息队列,对应的消费者才能消费消息;</li><li>根据业务功能定义路由字符串</li><li>从系统的代码逻辑中获取对应的功能字符串,将消息任务扔到对应的队列中。</li><li>业务场景:error 通知;EXCEPTION;错误通知的功能;传统意义的错误通知;客户通知;利用key路由,可以将程序中的错误封装成消息传入到消息队列中,开发者可以自定义消费者,实时接收错误;</li></ol><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/rmqdirect.png" alt=""></p><h3 id="5-5-topic"><a href="#5-5-topic" class="headerlink" title="5.5 topic"></a>5.5 topic</h3><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/rmqtopic.png" alt=""></p><ol><li>星号井号代表通配符</li><li>星号代表多个单词,井号代表一个单词</li><li>路由功能添加模糊匹配</li><li>消息产生者产生消息,把消息交给交换机</li><li>交换机根据key的规则模糊匹配到对应的队列,由队列的监听消费者接收消息消费</li></ol><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/rmqtopicex.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> 消息队列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 消息队列 </tag>
            
            <tag> RabbitMQ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>20.Redis缓存数据库读写一致性</title>
      <link href="/2020/02/23/20-Redis%E7%BC%93%E5%AD%98%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AF%BB%E5%86%99%E4%B8%80%E8%87%B4%E6%80%A7/"/>
      <url>/2020/02/23/20-Redis%E7%BC%93%E5%AD%98%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AF%BB%E5%86%99%E4%B8%80%E8%87%B4%E6%80%A7/</url>
      
        <content type="html"><![CDATA[<h2 id="20-1-Cache-Aside-Pattern"><a href="#20-1-Cache-Aside-Pattern" class="headerlink" title="20.1 Cache Aside Pattern"></a>20.1 Cache Aside Pattern</h2><p>最经典的缓存+数据库读写的模式:Cache Aside Pattern 　旁路缓存</p><p>有几个原则:</p><ul><li>读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。</li><li>更新的时候，先<strong>删除缓存</strong>，然后再更新数据库。</li></ul><h3 id="20-1-1-删除缓存"><a href="#20-1-1-删除缓存" class="headerlink" title="20.1.1 删除缓存"></a>20.1.1 删除缓存</h3><p>更新时是删除缓存，而不是更新缓存</p><ul><li><p>缓存有的时候不但是从数据库里取出的一个简单值,可能会经过复杂计算</p></li><li><p>更新的数据不一定会被频繁访问到,如果去更新缓存可能会<strong>造成大量的冷数据</strong></p></li><li><p>懒加载思想:<strong>用到缓存才去算缓存</strong></p></li></ul><h2 id="20-2-双写不一致问题"><a href="#20-2-双写不一致问题" class="headerlink" title="20.2 双写不一致问题"></a>20.2 双写不一致问题</h2><h3 id="20-2-1-更新顺序颠倒情形"><a href="#20-2-1-更新顺序颠倒情形" class="headerlink" title="20.2.1 更新顺序颠倒情形"></a>20.2.1 更新顺序颠倒情形</h3><p>问题描述: <strong>先修改数据库,再删除缓存</strong>,当删除缓存失败了,会导致数据库中是新数据,缓存中是旧数据</p><p>解决思路: <strong>先删除缓存,再更新数据库</strong>,如果删除缓存成功了,修改数据库失败了,那么数据库中是旧数据,缓存中是空的,那么数据不会不一致,因为读的时候缓存没有,则读数据库中的旧数据,然后更新到缓存中</p><h3 id="20-2-2-更新数据库并发读情形"><a href="#20-2-2-更新数据库并发读情形" class="headerlink" title="20.2.2 更新数据库并发读情形"></a>20.2.2 更新数据库并发读情形</h3><p>问题描述:数据发生了变更,先删除了缓存,然后要去修改数据库,<strong>此时还没有修改数据库</strong>,一个请求过来去读缓存,没有读到,去查数据库,<strong>查到了修改前的旧数据,放到缓存中</strong>,数据变更的程序完成了数据库的修改,此时数据库和缓存的数据不一致了</p><p>解决思路:　更新数据的时候，根据数据的唯一标识，hash之后，<strong>发送到一个队列中,队列可是redis的队列,Java的内存队列</strong>等,读取数据的时候，如果发现数据不在缓存中，那么将重新执行“读取数据+更新缓存”的操作，根据唯一标识路由之后，也发送到同一个队列中。</p><p>一个队列对应一个工作线程，每个工作线程串行拿到对应的操作，然后一条一条的执行。这样的话，一个数据变更的操作，先删除缓存，然后再去更新数据库，但是还没完成更新。此时如果一个读请求过来，没有读到缓存，那么可以先将缓存更新的请求发送到队列中，此时会在队列中积压，然后同步等待缓存更新完成。</p><p>这里有一个<strong>优化点</strong>，一个队列中，<strong>其实多个更新缓存请求串在一起是没意义的</strong>，因此可以做过滤，如果发现队列中已经有一个更新缓存的请求了，那么就不用再放个更新请求操作进去了，直接等待前面的更新操作请求完成即可。</p><p>待那个队列对应的工作线程完成了上一个操作的数据库的修改之后，才会去执行下一个操作，也就是缓存更新的操作，此时会从数据库中读取最新的值，然后写入缓存中。</p><p>如果请求还在等待时间范围内，不断轮询发现可以取到值了，那么就直接返回；如果请求等待的时间超过一定时长，那么这一次直接从数据库中读取当前的旧值</p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>19.Redis雪崩击穿穿透</title>
      <link href="/2020/02/23/19-Redis%E9%9B%AA%E5%B4%A9%E5%87%BB%E7%A9%BF%E7%A9%BF%E9%80%8F/"/>
      <url>/2020/02/23/19-Redis%E9%9B%AA%E5%B4%A9%E5%87%BB%E7%A9%BF%E7%A9%BF%E9%80%8F/</url>
      
        <content type="html"><![CDATA[<h2 id="19-1-雪崩"><a href="#19-1-雪崩" class="headerlink" title="19.1 雪崩"></a>19.1 雪崩</h2><h3 id="19-1-1-定义"><a href="#19-1-1-定义" class="headerlink" title="19.1.1 定义"></a>19.1.1 定义</h3><p>缓存同一时间大面积的失效，后面的请求都会落到数据库上，造成数据库短时间内承受大量请求而崩掉。</p><h3 id="19-1-2-解决方式"><a href="#19-1-2-解决方式" class="headerlink" title="19.1.2 解决方式"></a>19.1.2 解决方式</h3><ul><li><p>事前:尽量保证整个 redis 集群的高可用性，发现机器宕机尽快补上。选择合适的内存淘汰策略</p><ul><li><strong>缓存预热</strong>:数据加热的含义就是在正式部署之前，把可能的数据先预先访问一遍，这样部分可能大量访问的数据就会加载到缓存中。可以使用阿里开源的<strong>canal</strong></li><li><strong>设置热点数据永远不过期</strong>，有更新操作就更新缓存就好了</li><li>往Redis存数据的时候，把每个Key的<strong>失效时间都加个随机值</strong>就好了，这样可以保证数据不会在同一时间大面积失效</li></ul><pre><code class="java">setRedis（Key，value，time + Math.random() * 10000）；</code></pre></li><li><p>事中：本地ehcache缓存 + hystrix限流&amp;降级，避免MySQL崩掉</p></li><li><p>事后：利用 redis 持久化机制保存的数据尽快恢复缓存</p></li></ul><h2 id="19-2-击穿"><a href="#19-2-击穿" class="headerlink" title="19.2 击穿"></a>19.2 击穿</h2><h3 id="19-2-1-定义"><a href="#19-2-1-定义" class="headerlink" title="19.2.1 定义"></a>19.2.1 定义</h3><p>缓存击穿，就是说某个 key 非常热点，访问非常频繁，处于集中式高并发访问的情况，当这个 key 在失效的瞬间，大量的请求就击穿了缓存，直接请求数据库，就像是在一道屏障上凿开了一个洞。</p><h3 id="19-2-2-解决方式"><a href="#19-2-2-解决方式" class="headerlink" title="19.2.2 解决方式"></a>19.2.2 解决方式</h3><p>不同场景下的解决方式可如下：</p><ul><li>若缓存的数据是基本不会发生更新的，则可尝试将该热点数据设置为永不过期。</li><li>若缓存的数据更新不频繁，且缓存刷新的整个流程耗时较少的情况下，则可以采用基于 redis、zookeeper 等分布式中间件的分布式互斥锁，或者本地互斥锁以保证仅少量的请求能请求数据库并重新构建缓存，其余线程则在锁释放后能访问到新缓存。</li><li>若缓存的数据更新频繁或者缓存刷新的流程耗时较长的情况下，可以利用定时线程在缓存过期前主动的重新构建缓存或者延后缓存的过期时间，以保证所有的请求能一直访问到对应的缓存。</li></ul><h2 id="19-3-穿透"><a href="#19-3-穿透" class="headerlink" title="19.3 穿透"></a>19.3 穿透</h2><h3 id="19-3-1-定义"><a href="#19-3-1-定义" class="headerlink" title="19.3.1 定义"></a>19.3.1 定义</h3><p>对于系统A，假设一秒 5000 个请求，结果其中 4000 个请求是黑客发出的恶意攻击。</p><p>黑客发出的那 4000 个攻击，缓存中查不到，每次你去数据库里查，也查不到。</p><p>举个栗子。数据库 id 是从 1 开始的，结果黑客发过来的请求 id 全部都是负数。这样的话，缓存中不会有，请求每次都“视缓存于无物”，直接查询数据库。这种恶意攻击场景的缓存穿透就会直接把数据库给打死。</p><h3 id="19-3-2-解决方式"><a href="#19-3-2-解决方式" class="headerlink" title="19.3.2 解决方式"></a>19.3.2 解决方式</h3><ul><li><strong>初级</strong>:每次系统 A 从数据库中只要没查到，就<strong>写一个空值到缓存</strong>里去，比如 <code>set -999 UNKNOWN</code>。然后设置一个过期时间，这样的话，下次有相同的 key 来访问的时候，在缓存失效之前，都可以直接从缓存中取数据。</li><li><strong>进阶</strong>: <strong>在接口层增加校验</strong>，比如用户鉴权校验，参数做校验，不合法的参数直接代码Return，比如：id 做基础校验，id &lt;=0的直接拦截等。</li><li><strong>高级</strong>: 使用<strong>布隆过滤器（Bloom Filter）</strong>这个也能很好的防止缓存穿透的发生，他的原理也很简单就是利用高效的数据结构和算法快速<strong>判断出你这个Key是否在数据库中存在，不存在你return就好了，存在你就去查了DB刷新KV再return</strong>。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>18.Redis高可用模式总结</title>
      <link href="/2020/02/23/18-Redis%E9%AB%98%E5%8F%AF%E7%94%A8%E6%A8%A1%E5%BC%8F%E6%80%BB%E7%BB%93/"/>
      <url>/2020/02/23/18-Redis%E9%AB%98%E5%8F%AF%E7%94%A8%E6%A8%A1%E5%BC%8F%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<h2 id="18-1-Redis的三种高可用模式"><a href="#18-1-Redis的三种高可用模式" class="headerlink" title="18.1 Redis的三种高可用模式"></a>18.1 Redis的三种高可用模式</h2><ul><li>Redis主从模式</li><li>Redis哨兵模式</li><li>Redis cluster模式</li></ul><h2 id="18-2-使用场景"><a href="#18-2-使用场景" class="headerlink" title="18.2 使用场景"></a>18.2 使用场景</h2><h3 id="18-2-1-Redis主从"><a href="#18-2-1-Redis主从" class="headerlink" title="18.2.1 Redis主从"></a>18.2.1 Redis主从</h3><p>单机Redis无法支撑较大的QPS，如果业务类型是读多写少类型，需要采用多个只读节点的部署方式来突破Redis单线程的性能瓶颈。</p><h3 id="18-2-2-Redis哨兵"><a href="#18-2-2-Redis哨兵" class="headerlink" title="18.2.2 Redis哨兵"></a>18.2.2 Redis哨兵</h3><p>通常搭建了主从之后建议再配合哨兵模式使用,去保证redis主从架构的高可用性</p><h3 id="18-2-3-Redis-cluster"><a href="#18-2-3-Redis-cluster" class="headerlink" title="18.2.3 Redis cluster"></a>18.2.3 Redis cluster</h3><p>redis cluster 主要是针对海量数据+高并发+高可用的场景，如果是海量数据，如果你的数据量很大，那么建议就用redis cluster</p><h2 id="18-3-应用连接方式"><a href="#18-3-应用连接方式" class="headerlink" title="18.3 应用连接方式"></a>18.3 应用连接方式</h2><p>不同的高可用模式,应用的连接方式会发生改变,下面以python代码示例:</p><h3 id="18-3-1-连接-sentinel"><a href="#18-3-1-连接-sentinel" class="headerlink" title="18.3.1 连接 sentinel"></a>18.3.1 连接 sentinel</h3><pre><code class="python">&gt;&gt;&gt; from redis.sentinel import Sentinel&gt;&gt;&gt; sentinel = Sentinel([(&#39;localhost&#39;, 26379)], socket_timeout=0.1)&gt;&gt;&gt; master = sentinel.master_for(&#39;mymaster&#39;, socket_timeout=0.1)&gt;&gt;&gt; master.set(&#39;foo&#39;, &#39;bar&#39;)&gt;&gt;&gt; slave = sentinel.slave_for(&#39;mymaster&#39;, socket_timeout=0.1)&gt;&gt;&gt; slave.get(&#39;foo&#39;)&#39;bar&#39;</code></pre><h3 id="18-3-2-连接cluster"><a href="#18-3-2-连接cluster" class="headerlink" title="18.3.2 连接cluster"></a>18.3.2 连接cluster</h3><pre><code class="python">&gt;&gt;&gt; from rediscluster import RedisCluster&gt;&gt;&gt; # Requires at least one node for cluster discovery. Multiple nodes is recommended.&gt;&gt;&gt; startup_nodes = [{&quot;host&quot;: &quot;127.0.0.1&quot;, &quot;port&quot;: &quot;7000&quot;}]&gt;&gt;&gt; rc = RedisCluster(startup_nodes=startup_nodes, decode_responses=True)&gt;&gt;&gt; rc.set(&quot;foo&quot;, &quot;bar&quot;)True&gt;&gt;&gt; print(rc.get(&quot;foo&quot;))&#39;bar&#39;</code></pre><h2 id="18-4-Redis云产品"><a href="#18-4-Redis云产品" class="headerlink" title="18.4 Redis云产品"></a>18.4 Redis云产品</h2><p>阿里云的云产品Redis提供三类产品:</p><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/alredis.png" alt=""></p><p>我之前用过读写分离版本很稳定,<strong>实践证明了花钱真香～</strong>,推荐开发进度紧张,没时间运维的公司可以尝试使用下</p><h3 id="18-4-1-优势"><a href="#18-4-1-优势" class="headerlink" title="18.4.1 优势"></a>18.4.1 优势</h3><p>相比自己搭建Redis数据库，云数据库Redis版在数据安全、运维投入、内核优化等方面都有一定的优势。</p><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/alredisdiff.png" alt=""></p><h3 id="18-4-2-劣势"><a href="#18-4-2-劣势" class="headerlink" title="18.4.2 劣势"></a>18.4.2 劣势</h3><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/money.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>17.RedisCluster</title>
      <link href="/2020/02/22/17-RedisCluster/"/>
      <url>/2020/02/22/17-RedisCluster/</url>
      
        <content type="html"><![CDATA[<h2 id="17-1-redis-cluster介绍"><a href="#17-1-redis-cluster介绍" class="headerlink" title="17.1 redis cluster介绍"></a>17.1 redis cluster介绍</h2><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/rediscluster.png" alt=""></p><ul><li>自动将数据进行分片,每个master上放一部分数据</li><li>提供内置的高可用支持,部分master不可用时,还是可以继续工作的，因为每个master都有salve节点，那么如果mater挂掉，redis cluster这套机制，就会自动将某个slave切换成master；</li><li>支持读写分离：对于每个master来说，都负责写请求，写就写到master，然后读就从mater对应的slave去读；</li></ul><p>redisCluster是Redis的官方分布式解决方案,解决了上一章提到的Redis主从模式的1,2,3缺陷</p><p>redisCluster = 多master+读写分离+sentinal</p><h2 id="17-2-分区规则"><a href="#17-2-分区规则" class="headerlink" title="17.2 分区规则"></a>17.2 分区规则</h2><h3 id="17-2-1-常见分区规则"><a href="#17-2-1-常见分区规则" class="headerlink" title="17.2.1 常见分区规则"></a>17.2.1 常见分区规则</h3><p>分布式数据库首要解决把整个数据集按照分区规则映射到多个节点的问题，即把数据集划分到多个节点上，每个节点负责整个数据的一个子集。</p><p>常见的分区规则有<code>哈希分区和顺序分区</code>。Redis Cluster采用哈希分区规则，因此接下来会讨论哈希分区规则。常见的哈希分区有以下几种：</p><ul><li>节点取余分区</li><li>一致性哈希分区</li><li>虚拟槽分区</li></ul><p>Redis Cluster采用虚拟槽分区</p><h3 id="17-2-2-hash算法"><a href="#17-2-2-hash算法" class="headerlink" title="17.2.2 hash算法"></a>17.2.2 hash算法</h3><p>来了一个 key，首先计算 hash 值，然后对节点数取模。然后打在不同的 master 节点上。一旦某一个 master 节点宕机，所有请求过来，都会基于最新的剩余 master 节点数去取模，尝试去取数据。这会<strong>导致大部分的请求过来，全部无法拿到有效的缓存，导致大量的流量涌入数据库</strong></p><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/hash-1.png" alt=""></p><h3 id="17-2-3-一致性-hash-算法"><a href="#17-2-3-一致性-hash-算法" class="headerlink" title="17.2.3 一致性 hash 算法"></a>17.2.3 一致性 hash 算法</h3><p>一致性 hash 算法将整个 hash 值空间组织成一个虚拟的圆环，整个空间按顺时针方向组织，下一步将各个 master 节点（使用服务器的 ip 或主机名）进行 hash。这样就能确定每个节点在其哈希环上的位置。</p><p>来了一个 key，首先计算 hash 值，并确定此数据在环上的位置，从此位置沿环<strong>顺时针“行走”</strong>，遇到的第一个 master 节点就是 key 所在位置。</p><p>在一致性哈希算法中，如果<strong>一个节点挂了，受影响的数据仅仅是此节点到环空间前一个节点（沿着逆时针方向行走遇到的第一个节点）之间的数据，其它不受影响</strong>。增加一个节点也同理。</p><p>燃鹅，一致性哈希算法在节点太少时，容易因为节点分布不均匀而造成<strong>缓存热点</strong>的问题。为了解决这种热点问题，<strong>一致性 hash 算法引入了虚拟节点机制，即对每一个节点计算多个 hash，每个计算结果位置都放置一个虚拟节点</strong>。这样就实现了数据的均匀分布，负载均衡。</p><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/consistent-hashing-algorithm.png" alt=""></p><h3 id="17-2-2-redis使用的hash-slot"><a href="#17-2-2-redis使用的hash-slot" class="headerlink" title="17.2.2 redis使用的hash slot"></a>17.2.2 redis使用的hash slot</h3><p>虚拟槽分区巧妙地使用了哈希空间，使用分散度良好的哈希函数把所有的数据映射到一个固定范围内的整数集合，整数定义为槽（slot）。</p><p>redis cluster有固定的16384个hash slot，对每个key计算CRC16值，然后对16384取模，可以获取key对应的hash slot<br>redis cluster中每个master都会持有部分slot，比如有3个master，那么可能每个master持有5000多个hash slot<br>hash slot让node的增加和移除很简单，增加一个master，就将其他master的hash slot移动部分过去，减少一个master，就将它的hash slot移动到其他master上去<br>移动hash slot的成本是非常低的<br>客户端的api，可以对指定的数据，让他们走同一个hash slot，通过hash tag来实现出处。</p><h2 id="17-3-节点间的通信协议"><a href="#17-3-节点间的通信协议" class="headerlink" title="17.3 节点间的通信协议"></a>17.3 节点间的通信协议</h2><h3 id="17-3-1-基本通信原理"><a href="#17-3-1-基本通信原理" class="headerlink" title="17.3.1 基本通信原理"></a>17.3.1 基本通信原理</h3><p>集群元数据的维护有两种方式：</p><ul><li>集中式协议</li><li>Gossip 协议</li></ul><p>redis cluster 节点间采用 gossip 协议进行通信。</p><h3 id="17-3-2-集中式协议"><a href="#17-3-2-集中式协议" class="headerlink" title="17.3.2 集中式协议"></a>17.3.2 集中式协议</h3><p>集中式是将集群元数据（节点信息、故障等等）几种存储在某个节点上。集中式元数据集中存储的一个典型代表，就是大数据领域的 storm。它是分布式的大数据实时计算引擎，是集中式的元数据存储的结构，底层基于 zookeeper（分布式协调的中间件）对所有元数据进行存储维护。</p><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/zookeeper-centralized-storage.png" alt=""></p><ul><li>集中式的好处: 元数据的读取和更新，时效性非常好，一旦元数据出现了变更，就立即更新到集中式的存储中，其它节点读取的时候就可以感知到</li><li>不好在于，所有的元数据的更新压力全部集中在一个地方，可能会导致元数据的存储有压力。</li></ul><h3 id="17-3-3-gossip-协议"><a href="#17-3-3-gossip-协议" class="headerlink" title="17.3.3 gossip 协议"></a>17.3.3 gossip 协议</h3><p>gossip 协议包含多种消息，包含 ping,pong,meet,fail 等等。</p><ul><li><p>meet：某个节点发送 meet 给新加入的节点，让新节点加入集群中，然后新节点就会开始与其它节点进行通信。</p><pre><code>aredis-trib.rb add-node其实内部就是发送了一个 gossip meet 消息给新加入的节点，通知那个节点去加入我们的集群</code></pre></li><li><p>ping：每个节点都会频繁给其它节点发送 ping，其中包含自己的状态还有自己维护的集群元数据，互相通过 ping 交换元数据。</p></li><li><p>pong：返回 ping 和 meeet，包含自己的状态和其它信息，也用于信息广播和更新。</p></li><li><p>fail：某个节点判断另一个节点 fail 之后，就发送 fail 给其它节点，通知其它节点说，某个节点宕机啦。</p></li></ul><p>gossip协议优缺点:</p><ul><li>gossip 好处在于，元数据的更新比较分散，不是集中在一个地方，更新请求会陆陆续续打到所有节点上去更新，降低了压力</li><li>不好在于，元数据的更新有延时，可能导致集群中的一些操作会有一些滞后。</li></ul><h3 id="17-3-4-Redis中的gossip协议"><a href="#17-3-4-Redis中的gossip协议" class="headerlink" title="17.3.4 Redis中的gossip协议"></a>17.3.4 Redis中的gossip协议</h3><p>redis 维护集群元数据采用另一个方式， gossip 协议，所有节点都持有一份元数据，不同的节点如果出现了元数据的变更，就不断将元数据发送给其它的节点，让其它节点也进行元数据的变更。</p><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/redis-gossip.png" alt=""></p><ul><li>10000 端口：每个节点都有一个专门用于节点间通信的端口，就是自己提供服务的端口号+10000，比如 7001，那么用于节点间通信的就是 17001 端口。每个节点每隔一段时间都会往另外几个节点发送 ping 消息，同时其它几个节点接收到 ping 之后返回 pong。</li><li>交换的信息：信息包括故障信息，节点的增加和删除，hash slot 信息等等。</li></ul><h2 id="17-4Redis-cluster功能限制"><a href="#17-4Redis-cluster功能限制" class="headerlink" title="17.4Redis cluster功能限制"></a>17.4Redis cluster功能限制</h2><p>Redis集群相对单机在功能上有一定限制:</p><ul><li>key批量操作支持有限。如：MSET,MGET，目前只支持具有相同slot值的key执行批量操作。</li><li>key事务操作支持有限。支持多key在同一节点上的事务操作，不支持分布在多个节点的事务功能。</li><li>key作为数据分区的最小粒度，因此不能将一个大的键值对象映射到不同的节点。如：hash、list。</li><li>不支持多数据库空间。单机下Redis支持16个数据库，集群模式下只能使用一个数据库空间，即db0。</li><li>复制结构只支持一层，不支持嵌套树状复制结构。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>16.Redis哨兵模式</title>
      <link href="/2020/02/22/16-Redis%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F/"/>
      <url>/2020/02/22/16-Redis%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<p>类似与Mysql的主备切换，Sentinel是Redis的高可用性解决方案之一</p><h2 id="16-1-主从复制的问题"><a href="#16-1-主从复制的问题" class="headerlink" title="16.1 主从复制的问题"></a>16.1 主从复制的问题</h2><ul><li>一旦 主节点宕机，从节点 晋升成 主节点，同时需要修改 应用方 的 主节点地址，还需要命令所有 从节点去复制 新的主节点，整个过程需要人工干预。</li><li>主节点的写能力受到 单机的限制。</li><li>主节点的存储能力受到单机的限制。</li></ul><h2 id="16-2-哨兵模式作用"><a href="#16-2-哨兵模式作用" class="headerlink" title="16.2 哨兵模式作用"></a>16.2 哨兵模式作用</h2><p>哨兵模式可以解决主从的第一个问题</p><ul><li>集群监控：负责监控 redis master 和 slave 进程是否正常工作</li><li>消息通知：如果某个 redis 实例有故障，那么哨兵负责发送消息作为报警通知给管理员</li><li>故障转移：如果 master node 挂掉了，会自动转移到 slave node 上</li><li>配置中心：如果故障转移发生了，通知 client 客户端新的 master 地址</li><li>应用透明 : 应用不需要重启改配置文件</li></ul><h2 id="16-3-哨兵模式架构"><a href="#16-3-哨兵模式架构" class="headerlink" title="16.3 哨兵模式架构"></a>16.3 哨兵模式架构</h2><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/sentinel.png" alt=""></p><ul><li><p>哨兵至少需要 3 个实例，来保证自己的健壮性。(分布式quorum选举)</p></li><li><p>哨兵 + redis 主从的部署架构，是<strong>不保证数据零丢失的，只能保证 redis 集群的高可用性</strong>。</p></li></ul><h2 id="16-4-工作原理"><a href="#16-4-工作原理" class="headerlink" title="16.4 工作原理"></a>16.4 工作原理</h2><p>每个 Sentinel 节点都需要 定期执行 以下任务：</p><ul><li>每个 Sentinel 以 每秒钟 一次的频率，向它所知的 主服务器、从服务器 以及其他 Sentinel 实例 发送一个 PING 命令。</li><li>如果一个 实例（instance）距离 最后一次 有效回复 PING 命令的时间超过 down-after-milliseconds 所指定的值，那么这个实例会被 Sentinel 标记为 主观下线。</li><li>如果一个 主服务器 被标记为 主观下线，那么正在 监视 这个 主服务器 的所有 Sentinel 节点，要以 每秒一次 的频率确认 主服务器 的确进入了 主观下线 状态。</li><li>如果一个 主服务器 被标记为 主观下线，并且有 足够数量 的 Sentinel（至少要达到 配置文件 指定的数量）在指定的 时间范围 内同意这一判断，那么这个 主服务器 被标记为 客观下线。</li><li>在一般情况下， 每个 Sentinel 会以每 10 秒一次的频率，向它已知的所有 主服务器 和 从服务器 发送 INFO 命令。当一个 主服务器 被 Sentinel 标记为 客观下线 时，Sentinel 向 下线主服务器 的所有 从服务器 发送 INFO 命令的频率，会从 10 秒一次改为 每秒一次</li><li>Sentinel 和其他 Sentinel 协商 主节点 的状态，如果 主节点 处于 SDOWN 状态，则投票自动选出新的 主节点。将剩余的 从节点 指向 新的主节点 进行 数据复制。</li><li>当没有足够数量的 Sentinel 同意 主服务器 下线时， 主服务器 的 客观下线状态 就会被移除。当 主服务器 重新向 Sentinel 的 PING 命令返回 有效回复 时，主服务器 的 主观下线状态 就会被移除。</li></ul><h3 id="16-4-1-sdown-和-odown-转换机制"><a href="#16-4-1-sdown-和-odown-转换机制" class="headerlink" title="16.4.1 sdown 和 odown 转换机制"></a>16.4.1 sdown 和 odown 转换机制</h3><ul><li>sdown 是主观宕机，就一个哨兵如果自己觉得一个 master 宕机了，那么就是主观宕机</li><li>odown 是客观宕机，如果 quorum 数量的哨兵都觉得一个 master 宕机了，那么就是客观宕机</li></ul><p>sdown 达成的条件很简单，如果一个哨兵 ping 一个 master，超过了 is-master-down-after-milliseconds 指定的毫秒数之后，就主观认为 master 宕机了；如果一个哨兵在指定时间内，收到了 quorum 数量的其它哨兵也认为那个 master 是 sdown 的，那么就认为是 odown 了。</p><h3 id="16-4-2-哨兵集群的自动发现机制"><a href="#16-4-2-哨兵集群的自动发现机制" class="headerlink" title="16.4.2 哨兵集群的自动发现机制"></a>16.4.2 哨兵集群的自动发现机制</h3><p>哨兵互相之间的发现，是通过 redis 的 pub/sub 系统实现的，每个哨兵都会往 <strong>sentinel</strong>:hello 这个 channel 里发送一个消息，这时候所有其他哨兵都可以消费到这个消息，并感知到其他的哨兵的存在。</p><p>每隔两秒钟，每个哨兵都会往自己监控的某个 master+slaves 对应的 <strong>sentinel</strong>:hello channel 里发送一个消息，内容是自己的 host、ip 和 runid 还有对这个 master 的监控配置。</p><p>每个哨兵也会去监听自己监控的每个 master+slaves 对应的 <strong>sentinel</strong>:hello channel，然后去感知到同样在监听这个 master+slaves 的其他哨兵的存在。</p><p>每个哨兵还会跟其他哨兵交换对 master 的监控配置，互相进行监控配置的同步。</p><h3 id="16-4-3-选举算法"><a href="#16-4-3-选举算法" class="headerlink" title="16.4.3 选举算法"></a>16.4.3 选举算法</h3><p>如果一个 master 被认为 odown 了，而且 majority 数量的哨兵都允许主备切换，那么某个哨兵就会执行主备切换操作，此时首先要选举一个 slave 来，会考虑 slave 的一些信息：</p><ul><li>跟 master 断开连接的时长</li><li>slave 优先级</li><li>复制 offset</li><li>run id</li></ul><p>如果一个 slave 跟 master 断开连接的时间已经超过了 down-after-milliseconds 的 10 倍，外加 master 宕机的时长，那么 slave 就被认为不适合选举为 master。</p><p>接下来会对 slave 进行排序：</p><ul><li>按照 slave 优先级进行排序，slave priority 越低，优先级就越高。</li><li>如果 slave priority 相同，那么看 replica offset，哪个 slave 复制了越多的数据，offset 越靠后，优先级就越高。</li><li>如果上面两个条件都相同，那么选择一个 run id 比较小的那个 slave。</li></ul><h3 id="16-4-4-configuration传播"><a href="#16-4-4-configuration传播" class="headerlink" title="16.4.4 configuration传播"></a>16.4.4 configuration传播</h3><p>执行切换的那个哨兵，会从要切换到的新 master（salve-&gt;master）那里得到一个 configuration epoch，这就是一个 version 号，每次切换的 <code>version</code>号都必须是唯一的。</p><p>如果第一个选举出的哨兵切换失败了，那么其他哨兵，会等待 failover-timeout 时间，然后接替继续执行切换，此时会重新获取一个新的 configuration epoch，作为新的 <code>version</code> 号。</p><p>哨兵完成切换之后，会在自己本地更新生成最新的 master 配置，然后同步给其他的哨兵，就是通过之前说的 pub/sub 消息机制。</p><p>这里之前的 version 号就很重要了，因为各种消息都是通过一个 channel 去发布和监听的，所以一个哨兵完成一次新的切换之后，新的 master 配置是跟着新的<code>version</code> 号的。其他的哨兵都是根据版本号的大小来更新自己的 master 配置的。</p><h2 id="16-5-主备切换数据丢失问题"><a href="#16-5-主备切换数据丢失问题" class="headerlink" title="16.5 主备切换数据丢失问题"></a>16.5 主备切换数据丢失问题</h2><p>主备切换的过程，可能会导致数据丢失：</p><ul><li>异步复制导致的数据丢失</li><li>脑裂导致的数据丢失</li></ul><h3 id="16-5-1-异步复制导致的数据丢失"><a href="#16-5-1-异步复制导致的数据丢失" class="headerlink" title="16.5.1 异步复制导致的数据丢失"></a>16.5.1 异步复制导致的数据丢失</h3><p>因为 master-&gt;slave 的复制是异步的，所以可能有部分数据还没复制到 slave，master 就宕机了，此时这部分数据就丢失了</p><h3 id="16-5-2-脑裂导致的数据丢失"><a href="#16-5-2-脑裂导致的数据丢失" class="headerlink" title="16.5.2 脑裂导致的数据丢失"></a>16.5.2 脑裂导致的数据丢失</h3><p>脑裂，也就是说，某个 master 所在机器突然脱离了正常的网络，跟其他 slave 机器不能连接，但是实际上 master 还运行着。此时哨兵可能就会认为 master 宕机了，然后开启选举，将其他 slave 切换成了 master。这个时候，集群里就会有两个 master ，也就是所谓的<strong>脑裂</strong>。</p><p>此时虽然某个 slave 被切换成了 master，但是可能 client 还没来得及切换到新的 master，还继续向旧 master 写数据。因此旧 master 再次恢复的时候，会被作为一个 slave 挂到新的 master 上去，自己的数据会清空，重新从新的 master 复制数据。而新的 master 并没有后来 client 写入的数据，因此，这部分数据也就丢失了。</p><h3 id="16-5-3-数据丢失问题的解决方案"><a href="#16-5-3-数据丢失问题的解决方案" class="headerlink" title="16.5.3 数据丢失问题的解决方案"></a>16.5.3 数据丢失问题的解决方案</h3><p><strong>注意：数据丢失只能说减少丢失不能完全规避丢失</strong></p><p>进行如下配置：</p><pre><code class="ini">min-slaves-to-write 1min-slaves-max-lag 10</code></pre><p>表示，要求至少有 1 个 slave，数据复制和同步的延迟不能超过 10 秒。</p><p>如果说一旦所有的 slave，数据复制和同步的延迟都超过了 10 秒钟，那么这个时候，master 就不会再接收任何请求了。</p><ul><li>减少异步复制数据的丢失</li></ul><p>有了 min-slaves-max-lag 这个配置，就可以确保说，一旦 slave 复制数据和 ack 延时太长，就认为可能 master 宕机后损失的数据太多了，那么就拒绝写请求，这样可以把 master 宕机时由于部分数据未同步到 slave 导致的数据丢失降低的可控范围内。</p><ul><li>减少脑裂的数据丢失</li></ul><p>如果一个 master 出现了脑裂，跟其他 slave 丢了连接，那么上面两个配置可以确保说，如果不能继续给指定数量的 slave 发送数据，而且 slave 超过 10 秒没有给自己 ack 消息，那么就直接拒绝客户端的写请求。因此在脑裂场景下，最多就丢失 10 秒的数据</p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>15.Redis主从架构</title>
      <link href="/2020/02/22/15-Redis%E4%B8%BB%E4%BB%8E%E6%9E%B6%E6%9E%84/"/>
      <url>/2020/02/22/15-Redis%E4%B8%BB%E4%BB%8E%E6%9E%B6%E6%9E%84/</url>
      
        <content type="html"><![CDATA[<p>在Redis中,用户可以使用<code>SLAVE OF</code>命令或者设置<code>slave of</code>选项,让一个Redis服务去复制另一个Redis服务,从而来实现类似于Mysql的读写分离</p><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/slave.png" alt=""></p><p>同样的Redis也可以和Mysql一样,做级联模式</p><h2 id="15-1-旧版复制功能实现"><a href="#15-1-旧版复制功能实现" class="headerlink" title="15.1 旧版复制功能实现"></a>15.1 旧版复制功能实现</h2><p>Redis2.8之前Redis的复制分为两个阶段 ： </p><ul><li>同步</li><li>命令传播</li></ul><h3 id="15-1-1-同步"><a href="#15-1-1-同步" class="headerlink" title="15.1.1 同步"></a>15.1.1 同步</h3><ul><li>从服务器向主服务器发送SYNC命令</li><li>收到SYNC命令后，主服务器开始执行BGSAVE操作生成RDB文件，并使用一个缓冲区记录现在开始执行的所有写命令（用于命令传播阶段保持数据库一致性）</li><li>当主服务器的BGSAVE操作执行完时，主服务器会将BGSAVE命令生成的RDB文件发送给从服务器，从服务器接收并载入这个RDB文件，将自己的数据库状态更新至主服务器执行BGSAVE命令时的数据库状态</li><li>主服务器将记录在缓冲区里面的所有写命令发送给从服务器，从服务器执行这些写命令。将自己数据库状态更新至主服务器数据库当前状态</li></ul><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/sync.jpg" alt=""></p><h3 id="15-1-2-命令传播"><a href="#15-1-2-命令传播" class="headerlink" title="15.1.2 命令传播"></a>15.1.2 命令传播</h3><p>主服务器将执行的写命令，发送给从服务器执行，当从服务器执行了相同写命令后，主从服务器将再次回到一致性状态</p><h3 id="15-1-3-旧版复制功能的缺陷"><a href="#15-1-3-旧版复制功能的缺陷" class="headerlink" title="15.1.3 旧版复制功能的缺陷"></a>15.1.3 旧版复制功能的缺陷</h3><p><strong>为了让从服务器补足一小部分缺失的数据，而让主服务器重新执行一次BGSAVE操作，造成断线重连后的效率会很低</strong></p><h2 id="15-2-新版复制功能的实现"><a href="#15-2-新版复制功能的实现" class="headerlink" title="15.2 新版复制功能的实现"></a>15.2 新版复制功能的实现</h2><h3 id="15-2-1-SYNC命令换成PSYNC"><a href="#15-2-1-SYNC命令换成PSYNC" class="headerlink" title="15.2.1 SYNC命令换成PSYNC"></a>15.2.1 SYNC命令换成PSYNC</h3><p>PSYNC命令具有完整重同步和部分重同步两种模式：</p><ul><li>完整重同步用于处理初次复制的情况：与SYNC命令的执行步骤基本一致 ， 都是通过让主服务器创建并发送RDB文件，以及向从服务器发送保存在缓冲区里面的写命令来进行同步。</li><li>部分重同步用于处理断线后重复制的情况：当从服务器在断线后重新连接主服务器时，如果条件允许，主服务器可以将主从服务器连接断开期间执行的写命令发送给从服务器，从服务器只要接收并执行这些写命令，就可以将数据库更新至主服务器当前所在状态了。</li></ul><h3 id="15-2-2-部分重同步的实现"><a href="#15-2-2-部分重同步的实现" class="headerlink" title="15.2.2 部分重同步的实现"></a>15.2.2 部分重同步的实现</h3><ul><li><p>主从服务器的复制偏移量</p></li><li><p>主服务器的复制积压缓冲区,默认大小为1MB，为安全期间建议按照如下公式设置</p><pre><code>复制积压缓冲区大小 :    2 * second * writer_size_per_secondsecond: 从服务断线重连需要的秒数writer_size_per_second: 主服务器每秒写书的数据量</code></pre></li></ul><ul><li>从服务器记录主服务器运行ID</li></ul><h3 id="15-2-3-主从复制核心原理"><a href="#15-2-3-主从复制核心原理" class="headerlink" title="15.2.3 主从复制核心原理"></a>15.2.3 主从复制核心原理</h3><p>当启动一个 slave node 的时候，它会发送一个 PSYNC 命令给 master node。</p><p>如果这是 slave node 初次连接到 master node，那么会触发一次<code>full resynchronization</code> 全量复制。此时 master 会启动一个后台线程，开始生成一份 RDB 快照文件，同时还会将从客户端 client 新收到的所有写命令缓存在内存中。RDB 文件生成完毕后， master 会将这个 RDB 发送给 slave，slave 会先<strong>写入本地磁盘，然后再从本地磁盘加载到内存中</strong>，接着 master 会将内存中缓存的写命令发送到 slave，slave 也会同步这些数据。slave node 如果跟 master node 有网络故障，断开了连接，会自动重连，连接之后 master node 仅会复制给 slave 部分缺少的数据。</p><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/redis-master-slave-replication.png" alt=""></p><h3 id="15-2-4-复制完整流程"><a href="#15-2-4-复制完整流程" class="headerlink" title="15.2.4 复制完整流程"></a>15.2.4 复制完整流程</h3><ol><li>从服务上设置主服务器的地址和端口</li><li>建立socket连接</li><li>发送ping命令</li><li>身份验证</li><li>从服务器发送端口信息</li><li>同步</li><li>命令传播</li></ol><h3 id="15-2-5-过期-key-处理"><a href="#15-2-5-过期-key-处理" class="headerlink" title="15.2.5 过期 key 处理"></a>15.2.5 过期 key 处理</h3><p>slave 不会过期 key，只会等待 master 过期 key。如果 master 过期了一个 key，或者通过 LRU 淘汰了一个 key，那么会模拟一条 del 命令发送给 slave。</p><h2 id="15-3-心跳检测"><a href="#15-3-心跳检测" class="headerlink" title="15.3 心跳检测"></a>15.3 心跳检测</h2><p>在命令传播阶段,从服务器会每秒向主服务器发送心跳检测,作用如下:</p><ul><li>检测主从服务器的网络连接状态 看延时多少，一般延时0-1秒</li><li>辅助实现min-slaves选项</li><li>检测命令丢失</li></ul><h3 id="15-3-1-辅助实现min-slaves选项"><a href="#15-3-1-辅助实现min-slaves选项" class="headerlink" title="15.3.1 辅助实现min-slaves选项"></a>15.3.1 辅助实现min-slaves选项</h3><p>Redis的<code>min-slaves-to-write</code>和<code>min-slaves-max-lag</code>两个选项可以防止主服务器在不安全的情况下执行写命令<br>举个例子，如果我们向主服务器提供以下设置：</p><pre><code class="ini">min-slaves-to-write 3min-slaves-max-lag 10</code></pre><p>那么在从服务器的数量少于3个，或者三个从服务器的延迟（lag）值都大于或等于10秒时，主服务器将拒绝执行写命令</p><h3 id="15-3-2-检测命令丢失"><a href="#15-3-2-检测命令丢失" class="headerlink" title="15.3.2 检测命令丢失"></a>15.3.2 检测命令丢失</h3><p>主服务器向从服务器补发缺失数据这一操作的原理和部分重同步操作的原理非常相似，这两个操作的区别在于：<strong>补发缺失数据操作在主从服务器没有断线的情况下执行，而部分重同步操作则在主从服务器断线并重连之后执行</strong></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>14.Redis持久化总结</title>
      <link href="/2020/02/21/14-Redis%E6%8C%81%E4%B9%85%E5%8C%96%E6%80%BB%E7%BB%93/"/>
      <url>/2020/02/21/14-Redis%E6%8C%81%E4%B9%85%E5%8C%96%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<h2 id="14-1-持久化方式"><a href="#14-1-持久化方式" class="headerlink" title="14.1 持久化方式"></a>14.1 持久化方式</h2><p>Redis有两种持久化的方式：</p><ul><li>RDB持久化方式:在一个特定的间隔保存那个时间点的一个数据快照。</li><li>AOF持久化方式:记录每一个服务器收到的写操作。</li></ul><p>Redis的持久化是可以禁用的，就是说你可以让数据的生命周期只存在于服务器的运行时间里。<br>两种方式的持久化是可以同时存在的，但是当Redis重启时，<strong>AOF文件会被优先用于RDB</strong></p><h2 id="14-2-优缺点"><a href="#14-2-优缺点" class="headerlink" title="14.2 优缺点"></a>14.2 优缺点</h2><h3 id="14-2-1-RDB-优缺点"><a href="#14-2-1-RDB-优缺点" class="headerlink" title="14.2.1 RDB 优缺点"></a>14.2.1 RDB 优缺点</h3><ul><li>RDB 会生成多个数据文件，每个数据文件都代表了某一个时刻中 redis 的数据，这种多个数据文件的方式，非常适合做冷备，可以将这种完整的数据文件发送到一些远程的安全存储上去，比如说 Amazon 的 S3 云服务上去，在国内可以是阿里云的 ODPS 分布式存储上，以预定好的备份策略来定期备份 redis 中的数据。</li><li>RDB 对 redis 对外提供的读写服务，影响非常小，可以让 redis 保持高性能，因为 redis 主进程只需要 fork 一个子进程，让子进程执行磁盘 IO 操作来进行 RDB 持久化即可。</li><li>相对于 AOF 持久化机制来说，直接基于 RDB 数据文件来重启和恢复 redis 进程，更加快速。</li><li>如果想要在 redis 故障时，尽可能少的丢失数据，那么 RDB 没有 AOF 好。一般来说，RDB 数据快照文件，都是每隔 5 分钟，或者更长时间生成一次，这个时候就得接受一旦 redis 进程宕机，那么会丢失最近 5 分钟的数据。</li><li>RDB 每次在 fork 子进程来执行 RDB 快照数据文件生成的时候，如果数据文件特别大，可能会导致对客户端提供的服务暂停数毫秒，或者甚至数秒。</li></ul><h3 id="14-2-2-AOF-优缺点"><a href="#14-2-2-AOF-优缺点" class="headerlink" title="14.2.2 AOF 优缺点"></a>14.2.2 AOF 优缺点</h3><ul><li>AOF 可以更好的保护数据不丢失，一般 AOF 会每隔 1 秒，通过一个后台线程执行一次fsync操作，最多丢失 1 秒钟的数据。</li><li>AOF 日志文件以 append-only 模式写入，所以没有任何磁盘寻址的开销，写入性能非常高，而且文件不容易破损，即使文件尾部破损，也很容易修复。</li><li>AOF 日志文件即使过大的时候，出现后台重写操作，也不会影响客户端的读写。因为在 rewrite log 的时候，会对其中的指令进行压缩，创建出一份需要恢复数据的最小日志出来。在创建新日志文件的时候，老的日志文件还是照常写入。当新的 merge 后的日志文件 ready 的时候，再交换新老日志文件即可。</li><li>AOF 日志文件的命令通过非常可读的方式进行记录，这个特性非常适合做灾难性的误删除的紧急恢复。比如某人不小心用 flushall 命令清空了所有数据，只要这个时候后台 rewrite 还没有发生，那么就可以立即拷贝 AOF 文件，将最后一条 flushall 命令给删了，然后再将该 AOF 文件放回去，就可以通过恢复机制，自动恢复所有数据。</li><li>对于同一份数据来说，AOF 日志文件通常比 RDB 数据快照文件更大。</li><li>AOF 开启后，支持的写 QPS 会比 RDB 支持的写 QPS 低，因为 AOF 一般会配置成每秒 fsync 一次日志文件，当然，每秒一次 fsync，性能也还是很高的。（如果实时写入，那么 QPS 会大降，redis 性能会大大降低）</li><li>以前 AOF 发生过 bug，就是通过 AOF 记录的日志，进行数据恢复的时候，没有恢复一模一样的数据出来。所以说，类似 AOF 这种较为复杂的基于命令日志 / merge / 回放的方式，比基于 RDB 每次持久化一份完整的数据快照文件的方式，更加脆弱一些，容易有 bug。不过 AOF 就是为了避免 rewrite 过程导致的 bug，因此每次 rewrite 并不是基于旧的指令日志进行 merge 的，而是基于当时内存中的数据进行指令的重新构建，这样健壮性会好很多。</li></ul><h2 id="14-3-如何选择持久化方式"><a href="#14-3-如何选择持久化方式" class="headerlink" title="14.3 如何选择持久化方式"></a>14.3 如何选择持久化方式</h2><p>redis 支持同时开启开启两种持久化方式，我们可以综合使用 AOF 和 RDB 两种持久化机制，用 AOF 来保证数据不丢失，作为数据恢复的第一选择; 用 RDB 来做不同程度的冷备，在 AOF 文件都丢失或损坏不可用的时候，还可以使用 RDB 来进行快速的数据恢复。</p><h2 id="14-3-混合持久化"><a href="#14-3-混合持久化" class="headerlink" title="14.3 混合持久化"></a>14.3 混合持久化</h2><p>重启 Redis 时，我们很少使用 rdb 来恢复内存状态，因为会丢失大量数据。</p><p>如果使用 AOF 日志重放，性能则相对 rdb 来说要慢很多，这样在 Redis 实例很大的情况下，启动的时候需要花费很长的时间。</p><p>Redis 4.0 为了解决这个问题，带来了一个新的持久化选项——混合持久化。</p><p>混合持久化同样也是通过<code>bgrewriteaof</code>完成的，不同的是当开启混合持久化时，fork出的子进程先将共享的内存副本全量的以RDB方式写入aof文件，然后在将aof_rewrite_buf重写缓冲区的增量命令以AOF方式写入到文件，写入完成后通知主进程更新统计信息，并将新的含有RDB格式和AOF格式的AOF文件替换旧的的AOF文件。</p><p>简单的说：<strong>新的AOF文件前半段是RDB格式的全量数据后半段是AOF格式的增量数据</strong>，如下图：</p><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/redis40.png" alt=""></p><p>在redis重启的时候，加载 aof 文件进行恢复数据：先加载 rdb 内容再加载剩余的 aof。</p><p>混合持久化配置：</p><pre><code class="ini">aof-use-rdb-preamble yes  # yes：开启，no：关闭</code></pre><h2 id="14-4-云厂商的改进"><a href="#14-4-云厂商的改进" class="headerlink" title="14.4 云厂商的改进"></a>14.4 云厂商的改进</h2><p>不同云厂商为了<code>赚钱</code>都对Redis做了不同的二次开发,阿里云做了一个Redis基于AOF日志的增量同步机制设计方案还不错,具体可以参考此篇文章:</p><p><a href="https://yq.aliyun.com/articles/68350" target="_blank" rel="noopener">Redis内核基于时间点的备份恢复和基于AOF日志的增量同步机制设计</a></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>13.Redis持久化——AOF</title>
      <link href="/2020/02/21/13-Redis%E6%8C%81%E4%B9%85%E5%8C%96-AOF/"/>
      <url>/2020/02/21/13-Redis%E6%8C%81%E4%B9%85%E5%8C%96-AOF/</url>
      
        <content type="html"><![CDATA[<h2 id="13-1-AOF机制"><a href="#13-1-AOF机制" class="headerlink" title="13.1 AOF机制"></a>13.1 AOF机制</h2><p>AOF 机制对每条写入命令作为日志，以 append-only 的模式写入一个日志文件中，在 redis 重启的时候，可以通过回放 AOF 日志中的写入指令来重新构建整个数据集。</p><p>类似于mysql的<code>redo log</code></p><h2 id="13-2-配置"><a href="#13-2-配置" class="headerlink" title="13.2 配置"></a>13.2 配置</h2><pre><code class="ini">############ APPEND ONLY MODE ###########......#如果 appendonly 配置为 no，则不启用 AOF 方式进行备份。如果 appendonly 配置为 yes，则以 AOF 方式备份 Redis 数据，那么此时 Redis 会按照配置，在特定的时候执行追加命令，用以备份数据。appendonly no......#这里定义追加的写入文件为 appendonly.aofappendfilename &quot;appendonly.aof&quot;......#appendfsync always#每次有新命令追加到 AOF 文件时就执行一次 fsync ：非常慢，也非常安全。appendfsync everysec#每秒 fsync 一次：足够快（和使用 RDB 持久化差不多），并且在故障时只会丢失 1 秒钟的数据。#appendfsync no#从不 fsync ：将数据交给操作系统来处理。更快，也更不安全的选择。......#它指定 Redis 重写 AOF 文件的条件，默认为 100，表示与上次 rewrite 的 AOF 文件大小相比，当前 AOF 文件增长量超过上次 AOF 文件大小的 100% 时，就会触发 background rewrite。若配置为 0，则会禁用自动 rewriteauto-aof-rewrite-percentage 100#它指定触发 rewrite 的AOF文件大小。若AOF文件小于该值，即使当前文件的增量比例达到 auto-aof-rewrite-percentage的配置值，也不会触发自动rewrite。即这两个配置项同时满足时，才会触发rewrite。auto-aof-rewrite-min-size 64mb......#Redis 在恢复时会忽略最后一条可能存在问题的指令，默认为 yes。即在 AOF 写入时，可能存在指令写错的问题（突然断电、写了一半），这种情况下 yes 会 log 并继续，而 no 会直接恢复失败。aof-load-truncated yes......</code></pre><h2 id="13-3-AOF持久化过程"><a href="#13-3-AOF持久化过程" class="headerlink" title="13.3 AOF持久化过程"></a>13.3 AOF持久化过程</h2><pre><code class="c">#file: src/aof.c/*  * 将 AOF 缓存写入到文件中。 * * 因为程序需要在回复客户端之前对 AOF 执行写操作。 * 而客户端能执行写操作的唯一机会就是在事件 loop 中， * 因此，程序将所有 AOF 写累积到缓存中， * 并在重新进入事件 loop 之前，将缓存写入到文件中。 * * 关于 force 参数： * * 当 fsync 策略为每秒钟保存一次时，如果后台线程仍然有 fsync 在执行， * 那么我们可能会延迟执行冲洗（flush）操作， * 因为 Linux 上的 write(2) 会被后台的 fsync 阻塞。 * * 当这种情况发生时，说明需要尽快冲洗 aof 缓存， * 程序会尝试在 serverCron() 函数中对缓存进行冲洗。 * * 不过，如果 force 为 1 的话，那么不管后台是否正在 fsync ， * 程序都直接进行写入。 */#define AOF_WRITE_LOG_ERROR_RATE 30 /* Seconds between errors logging. */void flushAppendOnlyFile(int force) {    ssize_t nwritten;    int sync_in_progress = 0;    // 缓冲区中没有任何内容，直接返回    if (sdslen(server.aof_buf) == 0) return;    // 策略为每秒 FSYNC     if (server.aof_fsync == AOF_FSYNC_EVERYSEC)        // 是否有 SYNC 正在后台进行？        sync_in_progress = bioPendingJobsOfType(REDIS_BIO_AOF_FSYNC) != 0;    // 每秒 fsync ，并且强制写入为假    if (server.aof_fsync == AOF_FSYNC_EVERYSEC &amp;&amp; !force) {        /*         * 当 fsync 策略为每秒钟一次时， fsync 在后台执行。         *         * 如果后台仍在执行 FSYNC ，那么我们可以延迟写操作一两秒         * （如果强制执行 write 的话，服务器主线程将阻塞在 write 上面）         */        if (sync_in_progress) {            // 有 fsync 正在后台进行 。。。            if (server.aof_flush_postponed_start == 0) {                /*                 * 前面没有推迟过 write 操作，这里将推迟写操作的时间记录下来                 * 然后就返回，不执行 write 或者 fsync                 */                server.aof_flush_postponed_start = server.unixtime;                return;            } else if (server.unixtime - server.aof_flush_postponed_start &lt; 2) {                /*                 * 如果之前已经因为 fsync 而推迟了 write 操作                 * 但是推迟的时间不超过 2 秒，那么直接返回                 * 不执行 write 或者 fsync                 */                return;            }            /*              * 如果后台还有 fsync 在执行，并且 write 已经推迟 &gt;= 2 秒             * 那么执行写操作（write 将被阻塞）             */            server.aof_delayed_fsync++;            redisLog(REDIS_NOTICE,&quot;Asynchronous AOF fsync is taking too long (disk is busy?). Writing the AOF buffer without waiting for fsync to complete, this may slow down Redis.&quot;);        }    }    /*      * 执行到这里，程序会对 AOF 文件进行写入。     *     * 清零延迟 write 的时间记录     */    server.aof_flush_postponed_start = 0;    /*      * 执行单个 write 操作，如果写入设备是物理的话，那么这个操作应该是原子的     *     * 当然，如果出现像电源中断这样的不可抗现象，那么 AOF 文件也是可能会出现问题的     * 这时就要用 redis-check-aof 程序来进行修复。     */    nwritten = write(server.aof_fd,server.aof_buf,sdslen(server.aof_buf));    if (nwritten != (signed)sdslen(server.aof_buf)) {        static time_t last_write_error_log = 0;        int can_log = 0;        // 将日志的记录频率限制在每行 AOF_WRITE_LOG_ERROR_RATE 秒        if ((server.unixtime - last_write_error_log) &gt; AOF_WRITE_LOG_ERROR_RATE) {            can_log = 1;            last_write_error_log = server.unixtime;        }        // 如果写入出错，那么尝试将该情况写入到日志里面        if (nwritten == -1) {            if (can_log) {                redisLog(REDIS_WARNING,&quot;Error writing to the AOF file: %s&quot;,                    strerror(errno));                server.aof_last_write_errno = errno;            }        } else {            if (can_log) {                redisLog(REDIS_WARNING,&quot;Short write while writing to &quot;                                       &quot;the AOF file: (nwritten=%lld, &quot;                                       &quot;expected=%lld)&quot;,                                       (long long)nwritten,                                       (long long)sdslen(server.aof_buf));            }            // 尝试移除新追加的不完整内容            if (ftruncate(server.aof_fd, server.aof_current_size) == -1) {                if (can_log) {                    redisLog(REDIS_WARNING, &quot;Could not remove short write &quot;                             &quot;from the append-only file.  Redis may refuse &quot;                             &quot;to load the AOF the next time it starts.  &quot;                             &quot;ftruncate: %s&quot;, strerror(errno));                }            } else {                nwritten = -1;            }            server.aof_last_write_errno = ENOSPC;        }        // 处理写入 AOF 文件时出现的错误        if (server.aof_fsync == AOF_FSYNC_ALWAYS) {            redisLog(REDIS_WARNING,&quot;Can&#39;t recover from AOF write error when the AOF fsync policy is &#39;always&#39;. Exiting...&quot;);            exit(1);        } else {            server.aof_last_write_status = REDIS_ERR;            if (nwritten &gt; 0) {                server.aof_current_size += nwritten;                sdsrange(server.aof_buf,nwritten,-1);            }            return;         }    } else {        /* Successful write(2). If AOF was in error state, restore the         * OK state and log the event. */        // 写入成功，更新最后写入状态        if (server.aof_last_write_status == REDIS_ERR) {            redisLog(REDIS_WARNING,                &quot;AOF write error looks solved, Redis can write again.&quot;);            server.aof_last_write_status = REDIS_OK;        }    }    // 更新写入后的 AOF 文件大小    server.aof_current_size += nwritten;    /*     * 如果 AOF 缓存的大小足够小的话，那么重用这个缓存，     * 否则的话，释放 AOF 缓存。     */    if ((sdslen(server.aof_buf)+sdsavail(server.aof_buf)) &lt; 4000) {        // 清空缓存中的内容，等待重用        sdsclear(server.aof_buf);    } else {        // 释放缓存        sdsfree(server.aof_buf);        server.aof_buf = sdsempty();    }    /*      * 如果 no-appendfsync-on-rewrite 选项为开启状态，     * 并且有 BGSAVE 或者 BGREWRITEAOF 正在进行的话，     * 那么不执行 fsync      */    if (server.aof_no_fsync_on_rewrite &amp;&amp;        (server.aof_child_pid != -1 || server.rdb_child_pid != -1))            return;    // 总是执行 fsnyc    if (server.aof_fsync == AOF_FSYNC_ALWAYS) {        aof_fsync(server.aof_fd);         // 更新最后一次执行 fsnyc 的时间        server.aof_last_fsync = server.unixtime;    // 策略为每秒 fsnyc ，并且距离上次 fsync 已经超过 1 秒    } else if ((server.aof_fsync == AOF_FSYNC_EVERYSEC &amp;&amp;                server.unixtime &gt; server.aof_last_fsync)) {        // 放到后台执行        if (!sync_in_progress) aof_background_fsync(server.aof_fd);        // 更新最后一次执行 fsync 的时间        server.aof_last_fsync = server.unixtime;    }}</code></pre><h2 id="13-4-AOF重写"><a href="#13-4-AOF重写" class="headerlink" title="13.4 AOF重写"></a>13.4 AOF重写</h2><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/aofDuring.png" alt=""></p><p>AOF文件重写过程与RDB快照bgsave工作过程有点相似，都是通过fork子进程，由子进程完成相应的操作，同样的在fork子进程简短的时间内，redis是阻塞的。</p><p>（1）开始bgrewriteaof，判断当前有没有bgsave命令(RDB持久化)/bgrewriteaof在执行，倘若有，则这些命令执行完成以后在执行。</p><p>（2）主进程fork出子进程，在这一个短暂的时间内，redis是阻塞的。</p><p>（3）主进程fork完子进程继续接受客户端请求。此时，客户端的写请求不仅仅写入aof_buf缓冲区，还写入aof_rewrite_buf重写缓冲区。一方面是写入aof_buf缓冲区并根据appendfsync策略同步到磁盘，保证原有AOF文件完整和正确。另一方面写入aof_rewrite_buf重写缓冲区，保存fork之后的客户端的写请求，防止新AOF文件生成期间丢失这部分数据。</p><p>（4.1）子进程写完新的AOF文件后，向主进程发信号，父进程更新统计信息。</p><p>（4.2）主进程把aof_rewrite_buf中的数据写入到新的AOF文件。</p><p>（5）使用新的AOF文件覆盖旧的AOF文件，标志AOF重写完成。</p><h2 id="13-5-文件类型"><a href="#13-5-文件类型" class="headerlink" title="13.5 文件类型"></a>13.5 文件类型</h2><p>可读文本文件,但大小比RDB文件大的多</p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>12.Redis持久化——RDB</title>
      <link href="/2020/02/21/12-Redis%E6%8C%81%E4%B9%85%E5%8C%96-RDB/"/>
      <url>/2020/02/21/12-Redis%E6%8C%81%E4%B9%85%E5%8C%96-RDB/</url>
      
        <content type="html"><![CDATA[<h2 id="12-1-RDB机制"><a href="#12-1-RDB机制" class="headerlink" title="12.1 RDB机制"></a>12.1 RDB机制</h2><p>RDB其实就是把数据以快照的形式保存在磁盘上。</p><p>RDB持久化是指在指定的时间间隔内将内存中的数据集快照写入磁盘。也是<code>默认的持久化方式</code>，这种方式是就是将内存中数据以快照的方式写入到二进制文件中,默认的文件名为dump.rdb。</p><h2 id="12-2-触发方式"><a href="#12-2-触发方式" class="headerlink" title="12.2 触发方式"></a>12.2 触发方式</h2><ul><li>手动触发：执行BGSAVE命令</li><li>自动触发：配置SAVE选项，在指定时间内发生指定次数的key修改，自动进行后台RDB SAVE</li></ul><pre><code class="c">#file: src/rdb.cvoid saveCommand(redisClient *c) {    // BGSAVE 已经在执行中，不能再执行 SAVE    // 否则将产生竞争条件    if (server.rdb_child_pid != -1) {        addReplyError(c,&quot;Background save already in progress&quot;);        return;    }    // 执行     if (rdbSave(server.rdb_filename) == REDIS_OK) {        addReply(c,shared.ok);    } else {        addReply(c,shared.err);    }}void bgsaveCommand(redisClient *c) {    // 不能重复执行 BGSAVE    if (server.rdb_child_pid != -1) {        addReplyError(c,&quot;Background save already in progress&quot;);    // 不能在 BGREWRITEAOF 正在运行时执行    } else if (server.aof_child_pid != -1) {        addReplyError(c,&quot;Can&#39;t BGSAVE while AOF log rewriting is in progress&quot;);    // 执行 BGSAVE    } else if (rdbSaveBackground(server.rdb_filename) == REDIS_OK) {        addReplyStatus(c,&quot;Background saving started&quot;);    } else {        addReply(c,shared.err);    }}int rdbSaveBackground(char *filename) {    pid_t childpid;    long long start;......    start = ustime();    if ((childpid = fork()) == 0) {        int retval;        /* Child */        // 关闭网络连接 fd        closeListeningSockets(0);        // 设置进程的标题，方便识别        redisSetProcTitle(&quot;redis-rdb-bgsave&quot;);        // 执行保存操作        retval = rdbSave(filename);......        // 向父进程发送信号        exitFromChild((retval == REDIS_OK) ? 0 : 1);    } else {......    }    return REDIS_OK; /* unreached */}/* Save the DB on disk. Return REDIS_ERR on error, REDIS_OK on success  * * 将数据库保存到磁盘上。 * * 保存成功返回 REDIS_OK ，出错/失败返回 REDIS_ERR 。 */int rdbSave(char *filename) {    dictIterator *di = NULL;    dictEntry *de;    char tmpfile[256];    char magic[10];    int j;    long long now = mstime();    FILE *fp;    rio rdb;    uint64_t cksum;    // 创建临时文件    snprintf(tmpfile,256,&quot;temp-%d.rdb&quot;, (int) getpid());    fp = fopen(tmpfile,&quot;w&quot;);    if (!fp) {        redisLog(REDIS_WARNING, &quot;Failed opening .rdb for saving: %s&quot;,            strerror(errno));        return REDIS_ERR;    }    // 初始化 I/O    rioInitWithFile(&amp;rdb,fp);    // 设置校验和函数    if (server.rdb_checksum)        rdb.update_cksum = rioGenericUpdateChecksum;    // 写入 RDB 版本号    snprintf(magic,sizeof(magic),&quot;REDIS%04d&quot;,REDIS_RDB_VERSION);    if (rdbWriteRaw(&amp;rdb,magic,9) == -1) goto werr;    // 遍历所有数据库    for (j = 0; j &lt; server.dbnum; j++) {        // 指向数据库        redisDb *db = server.db+j;        // 指向数据库键空间        dict *d = db-&gt;dict;        // 跳过空数据库        if (dictSize(d) == 0) continue;        // 创建键空间迭代器        di = dictGetSafeIterator(d);        if (!di) {            fclose(fp);            return REDIS_ERR;        }        /* Write the SELECT DB opcode          *         * 写入 DB 选择器         */        if (rdbSaveType(&amp;rdb,REDIS_RDB_OPCODE_SELECTDB) == -1) goto werr;        if (rdbSaveLen(&amp;rdb,j) == -1) goto werr;        /* Iterate this DB writing every entry          *         * 遍历数据库，并写入每个键值对的数据         */        while((de = dictNext(di)) != NULL) {            sds keystr = dictGetKey(de);            robj key, *o = dictGetVal(de);            long long expire;            // 根据 keystr ，在栈中创建一个 key 对象            initStaticStringObject(key,keystr);            // 获取键的过期时间            expire = getExpire(db,&amp;key);            // 保存键值对数据            if (rdbSaveKeyValuePair(&amp;rdb,&amp;key,o,expire,now) == -1) goto werr;        }        dictReleaseIterator(di);    }    di = NULL; /* So that we don&#39;t release it again on error. */    /* EOF opcode      *     * 写入 EOF 代码     */    if (rdbSaveType(&amp;rdb,REDIS_RDB_OPCODE_EOF) == -1) goto werr;    /*      * CRC64 校验和。     */    cksum = rdb.cksum;    memrev64ifbe(&amp;cksum);    rioWrite(&amp;rdb,&amp;cksum,8);    /* Make sure data will not remain on the OS&#39;s output buffers */    // 冲洗缓存，确保数据已写入磁盘    if (fflush(fp) == EOF) goto werr;    if (fsync(fileno(fp)) == -1) goto werr;    if (fclose(fp) == EOF) goto werr;    /*      * 使用 RENAME ，原子性地对临时文件进行改名，覆盖原来的 RDB 文件。     */    if (rename(tmpfile,filename) == -1) {        redisLog(REDIS_WARNING,&quot;Error moving temp DB file on the final destination: %s&quot;, strerror(errno));        unlink(tmpfile);        return REDIS_ERR;    }    // 写入完成，打印日志    redisLog(REDIS_NOTICE,&quot;DB saved on disk&quot;);    // 清零数据库脏状态    server.dirty = 0;    // 记录最后一次完成 SAVE 的时间    server.lastsave = time(NULL);    // 记录最后一次执行 SAVE 的状态    server.lastbgsave_status = REDIS_OK;    return REDIS_OK;werr:    // 关闭文件    fclose(fp);    // 删除文件    unlink(tmpfile);    redisLog(REDIS_WARNING,&quot;Write error saving DB on disk: %s&quot;, strerror(errno));    if (di) dictReleaseIterator(di);    return REDIS_ERR;}</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/rdbduring.png" alt=""></p><h2 id="12-3-配置"><a href="#12-3-配置" class="headerlink" title="12.3 配置"></a>12.3 配置</h2><pre><code class="ini">#file: redis.conf############SNAPSHOTTING#######......#当900秒执行1个写命令时，启用快照备份save 900 1#当300秒执行10个写命令时，启用快照备份save 300 10#当60秒内执行10000个写命令时，启用快照备份save 60 10000......#Redis 执行 save 命令的时候，将禁止写入命令#在默认情况下，如果 Redis 执行 bgsave 失败后，Redis 将停止接受写操作，这样以一种强硬的方式让用户知道数据不能正确的持久化到磁盘，否则就会没人注意到灾难的发生，如果后台保存进程重新启动工作了，Redis 也将自动允许写操作。然而如果安装了靠谱的监控，可能不希望 Redis 这样做，那么你可以将其修改为 no。stop-writes-on-bgsave-error yes......#这个命令意思是是否对 rbd 文件进行检验，如果是将对 rdb 文件检验。从 dbfilename 的配置可以知道，rdb 文件实际是 Redis 持久化的数据文件。rdbcompression yes......dbfilename dump.rdb</code></pre><h2 id="12-4-文件类型"><a href="#12-4-文件类型" class="headerlink" title="12.4 文件类型"></a>12.4 文件类型</h2><p>RDB保存的文件是一个二进制文件，可以通过redis自带的工具<code>redis-check-dump</code>来查看里面的内容</p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>11.Redis过期机制</title>
      <link href="/2020/02/20/11-Redis%E8%BF%87%E6%9C%9F%E6%9C%BA%E5%88%B6/"/>
      <url>/2020/02/20/11-Redis%E8%BF%87%E6%9C%9F%E6%9C%BA%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<h2 id="11-1-RedisDb结构"><a href="#11-1-RedisDb结构" class="headerlink" title="11.1 RedisDb结构"></a>11.1 RedisDb结构</h2><p>每个Redis服务都有多个Db库,每个库记录了不同应用的数据信息</p><p>RedisDb的结构如下:</p><pre><code class="c">#file : src/redis.htypedef struct redisDb {    // 数据库键空间，保存着数据库中的所有键值对    dict *dict;                 /* The keyspace for this DB */    // 键的过期时间，字典的键为键，字典的值为过期事件 UNIX 时间戳    dict *expires;              /* Timeout of keys with a timeout set */    // 正处于阻塞状态的键    dict *blocking_keys;        /* Keys with clients waiting for data (BLPOP) */    // 可以解除阻塞的键    dict *ready_keys;           /* Blocked keys that received a PUSH */    // 正在被 WATCH 命令监视的键    dict *watched_keys;         /* WATCHED keys for MULTI/EXEC CAS */    struct evictionPoolEntry *eviction_pool;    /* Eviction pool of keys */    // 数据库号码    int id;                     /* Database ID */    // 数据库的键的平均 TTL ，统计信息    long long avg_ttl;          /* Average TTL, just for stats */} redisDb;</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/redisdb.png" alt=""></p><p>redisDb结构的expires字典保存了数据库中所有键的过期时间:</p><ul><li>过期字典的键是一个指针,指向某个键对象</li><li>过期字典的值是一个long long 类型的整数,这个整数报错了键所指向数据库的过期时间,是一个毫秒精度的UNIX时间戳</li></ul><h2 id="11-2-设置过期时间"><a href="#11-2-设置过期时间" class="headerlink" title="11.2 设置过期时间"></a>11.2 设置过期时间</h2><pre><code class="c">#file : src/redis.cvoid expireCommand(redisClient *c) {    expireGenericCommand(c,mstime(),UNIT_SECONDS);}void expireatCommand(redisClient *c) {    expireGenericCommand(c,0,UNIT_SECONDS);}void pexpireCommand(redisClient *c) {    expireGenericCommand(c,mstime(),UNIT_MILLISECONDS);}void pexpireatCommand(redisClient *c) {    expireGenericCommand(c,0,UNIT_MILLISECONDS);}/*  * 这个函数是 EXPIRE 、 PEXPIRE 、 EXPIREAT 和 PEXPIREAT 命令的底层实现函数。 * * 命令的第二个参数可能是绝对值，也可能是相对值。 * 当执行 *AT 命令时， basetime 为 0 ，在其他情况下，它保存的就是当前的绝对时间。 * * unit 用于指定 argv[2] （传入过期时间）的格式， * 它可以是 UNIT_SECONDS 或 UNIT_MILLISECONDS ， * basetime 参数则总是毫秒格式的。 */void expireGenericCommand(redisClient *c, long long basetime, int unit) {    robj *key = c-&gt;argv[1], *param = c-&gt;argv[2];    long long when; /* unix time in milliseconds when the key will expire. */    // 取出 when 参数    if (getLongLongFromObjectOrReply(c, param, &amp;when, NULL) != REDIS_OK)        return;    // 如果传入的过期时间是以秒为单位的，那么将它转换为毫秒    if (unit == UNIT_SECONDS) when *= 1000;    when += basetime;    /* No key, return zero. */    // 取出键    if (lookupKeyRead(c-&gt;db,key) == NULL) {        addReply(c,shared.czero);        return;    }    /*      * 在载入数据时，或者服务器为附属节点时，     * 即使 EXPIRE 的 TTL 为负数，或者 EXPIREAT 提供的时间戳已经过期，     * 服务器也不会主动删除这个键，而是等待主节点发来显式的 DEL 命令。     *     * 程序会继续将（一个可能已经过期的 TTL）设置为键的过期时间，     * 并且等待主节点发来 DEL 命令。     */    if (when &lt;= mstime() &amp;&amp; !server.loading &amp;&amp; !server.masterhost) {        // when 提供的时间已经过期，服务器为主节点，并且没在载入数据        robj *aux;        redisAssertWithInfo(c,key,dbDelete(c-&gt;db,key));        server.dirty++;        // 传播 DEL 命令        aux = createStringObject(&quot;DEL&quot;,3);        rewriteClientCommandVector(c,2,aux,key);        decrRefCount(aux);        signalModifiedKey(c-&gt;db,key);        notifyKeyspaceEvent(REDIS_NOTIFY_GENERIC,&quot;del&quot;,key,c-&gt;db-&gt;id);        addReply(c, shared.cone);        return;    } else {        // 设置键的过期时间        // 如果服务器为附属节点，或者服务器正在载入，        // 那么这个 when 有可能已经过期的        setExpire(c-&gt;db,key,when);        addReply(c,shared.cone);        signalModifiedKey(c-&gt;db,key);        notifyKeyspaceEvent(REDIS_NOTIFY_GENERIC,&quot;expire&quot;,key,c-&gt;db-&gt;id);        server.dirty++;        return;    }}</code></pre><h2 id="11-3-过期键的删除策略"><a href="#11-3-过期键的删除策略" class="headerlink" title="11.3 过期键的删除策略"></a>11.3 过期键的删除策略</h2><ul><li>被动删除机制——惰性删除</li><li>主动删除机制——定期删除</li></ul><p>这两种删除机制下,如果内存满了需要释放,会走Redis的内存淘汰机制</p><h3 id="11-3-1-惰性删除"><a href="#11-3-1-惰性删除" class="headerlink" title="11.3.1 惰性删除"></a>11.3.1 惰性删除</h3><p>惰性删除: 放任过期键不管,但是每次从键空间获取建时,都检查取得的键是否过期,如果过期就删除该键,如果没过期就返回该键</p><p>优点:对CPU时间来说最友好</p><p>缺点:对内存最不友好,占用的内存一直不释放</p><p>实现代码：</p><pre><code class="c">#file: src/db.c/* * 检查 key 是否已经过期，如果是的话，将它从数据库中删除。 * 返回 0 表示键没有过期时间，或者键未过期。 * 返回 1 表示键已经因为过期而被删除了。 */int expireIfNeeded(redisDb *db, robj *key) {    // 取出键的过期时间    mstime_t when = getExpire(db,key);    mstime_t now;    // 没有过期时间    if (when &lt; 0) return 0; /* No expire for this key */    // 如果服务器正在进行载入，那么不进行任何过期检查    if (server.loading) return 0;    now = server.lua_caller ? server.lua_time_start : mstime();    // 当服务器运行在 replication 模式时    // 附属节点并不主动删除 key    // 它只返回一个逻辑上正确的返回值    // 真正的删除操作要等待主节点发来删除命令时才执行    // 从而保证数据的同步    if (server.masterhost != NULL) return now &gt; when;    // 运行到这里，表示键带有过期时间，并且服务器为主节点    // 如果未过期，返回 0    if (now &lt;= when) return 0;    /* Delete the key */    server.stat_expiredkeys++;    // 向 AOF 文件和附属节点传播过期信息    propagateExpire(db,key);    // 发送事件通知    notifyKeyspaceEvent(REDIS_NOTIFY_EXPIRED,        &quot;expired&quot;,key,db-&gt;id);    // 将过期键从数据库中删除    return dbDelete(db,key);}</code></pre><h3 id="11-3-2-定期删除"><a href="#11-3-2-定期删除" class="headerlink" title="11.3.2 定期删除"></a>11.3.2 定期删除</h3><p>定期删除:每隔一段时间,程序就会对数据库进行检查,删除里面的过期键，定期删除通过限制删除操作执行的时长和频率来减少删除操作对CPU的影响，通过定期删除可以有效的减少因为过期键而带来的内存浪费</p><p>定期删除策略是通过redis指定周期性函数<code>serverCron</code>时,调用对数据库执行的各种操作<code>databasesCron</code>,<code>databasesCron</code>调用<code>redis.c/activeExpireCycle</code>函数实现的,serverCron的调用频率是10HZ,所以定期删除`每100ms执行一次</p><blockquote><p>server.hz = 10 一秒钟执行10次</p><p>serverCron—-&gt;databasesCron—–&gt;activeExpireCycle</p></blockquote><pre><code class="c">#file: src/redis.c/*  * 函数尝试删除数据库中已经过期的键。 * 当带有过期时间的键比较少时，函数运行得比较保守， * 如果带有过期时间的键比较多，那么函数会以更积极的方式来删除过期键， * 从而可能地释放被过期键占用的内存。 * * 每次循环中被测试的数据库数目不会超过 REDIS_DBCRON_DBS_PER_CALL　默认16 。 * * * 如果 timelimit_exit 为真，那么说明还有更多删除工作要做， * 那么在 beforeSleep() 函数调用时，程序会再次执行这个函数。 * * * 过期循环的类型： * * 如果循环的类型为 ACTIVE_EXPIRE_CYCLE_FAST ， * 那么函数会以“快速过期”模式执行， * 执行的时间不会长过 EXPIRE_FAST_CYCLE_DURATION 毫秒， * 并且在 EXPIRE_FAST_CYCLE_DURATION 毫秒之内不会再重新执行。 * * 如果循环的类型为 ACTIVE_EXPIRE_CYCLE_SLOW ， * 那么函数会以“正常过期”模式执行， * 函数的执行时限为 REDIS_HS 常量的一个百分比， * 这个百分比由 REDIS_EXPIRELOOKUPS_TIME_PERC 定义。 */void activeExpireCycle(int type) {    // 静态变量，用来累积函数连续执行时的数据    static unsigned int current_db = 0; /* Last DB tested. */    static int timelimit_exit = 0;      /* Time limit hit in previous call? */    static long long last_fast_cycle = 0; /* When last fast cycle ran. */    unsigned int j, iteration = 0;    // 默认每次处理的数据库数量    unsigned int dbs_per_call = REDIS_DBCRON_DBS_PER_CALL;    // 函数开始的时间    long long start = ustime(), timelimit;    // 快速模式    if (type == ACTIVE_EXPIRE_CYCLE_FAST) {        // 如果上次函数没有触发 timelimit_exit ，那么不执行处理        if (!timelimit_exit) return;        // 如果距离上次执行未够一定时间，那么不执行处理        if (start &lt; last_fast_cycle + ACTIVE_EXPIRE_CYCLE_FAST_DURATION*2) return;        // 运行到这里，说明执行快速处理，记录当前时间        last_fast_cycle = start;    }    /*      * 一般情况下，函数只处理 REDIS_DBCRON_DBS_PER_CALL 个数据库，     * 除非：     *     * 1) 当前数据库的数量小于 REDIS_DBCRON_DBS_PER_CALL     * 2) 如果上次处理遇到了时间上限，那么这次需要对所有数据库进行扫描，     *     这可以避免过多的过期键占用空间     */    if (dbs_per_call &gt; server.dbnum || timelimit_exit)        dbs_per_call = server.dbnum;    // 函数处理的微秒时间上限    // ACTIVE_EXPIRE_CYCLE_SLOW_TIME_PERC 默认为 25 ，也即是 25 % 的 CPU 时间    timelimit = 1000000*ACTIVE_EXPIRE_CYCLE_SLOW_TIME_PERC/server.hz/100;    timelimit_exit = 0;    if (timelimit &lt;= 0) timelimit = 1;    // 如果是运行在快速模式之下    // 那么最多只能运行 FAST_DURATION 微秒     // 默认值为 1000 （微秒）    if (type == ACTIVE_EXPIRE_CYCLE_FAST)        timelimit = ACTIVE_EXPIRE_CYCLE_FAST_DURATION; /* in microseconds. */    // 遍历数据库    for (j = 0; j &lt; dbs_per_call; j++) {        int expired;        // 指向要处理的数据库        redisDb *db = server.db+(current_db % server.dbnum);        // 为 DB 计数器加一，如果进入 do 循环之后因为超时而跳出        // 那么下次会直接从下个 DB 开始处理        current_db++;        do {            unsigned long num, slots;            long long now, ttl_sum;            int ttl_samples;            // 获取数据库中带过期时间的键的数量            // 如果该数量为 0 ，直接跳过这个数据库            if ((num = dictSize(db-&gt;expires)) == 0) {                db-&gt;avg_ttl = 0;                break;            }            // 获取数据库中键值对的数量            slots = dictSlots(db-&gt;expires);            // 当前时间            now = mstime();            // 这个数据库的使用率低于 1% ，扫描起来太费力了（大部分都会 MISS）            // 跳过，等待字典收缩程序运行            if (num &amp;&amp; slots &gt; DICT_HT_INITIAL_SIZE &amp;&amp;                (num*100/slots &lt; 1)) break;            /*             * 样本计数器             */            // 已处理过期键计数器            expired = 0;            // 键的总 TTL 计数器            ttl_sum = 0;            // 总共处理的键计数器            ttl_samples = 0;            // 每次最多只能检查 LOOKUPS_PER_LOOP 个键            if (num &gt; ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP)                num = ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP;            // 开始遍历数据库            while (num--) {                dictEntry *de;                long long ttl;                // 从 expires 中随机取出一个带过期时间的键                if ((de = dictGetRandomKey(db-&gt;expires)) == NULL) break;                // 计算 TTL                ttl = dictGetSignedIntegerVal(de)-now;                // 如果键已经过期，那么删除它，并将 expired 计数器增一                if (activeExpireCycleTryExpire(db,de,now)) expired++;                if (ttl &lt; 0) ttl = 0;                // 累积键的 TTL                ttl_sum += ttl;                // 累积处理键的个数                ttl_samples++;            }            // 为这个数据库更新平均 TTL 统计数据            if (ttl_samples) {                // 计算当前平均值                long long avg_ttl = ttl_sum/ttl_samples;                // 如果这是第一次设置数据库平均 TTL ，那么进行初始化                if (db-&gt;avg_ttl == 0) db-&gt;avg_ttl = avg_ttl;                /* Smooth the value averaging with the previous one. */                // 取数据库的上次平均 TTL 和今次平均 TTL 的平均值                db-&gt;avg_ttl = (db-&gt;avg_ttl+avg_ttl)/2;            }            // 我们不能用太长时间处理过期键，            // 所以这个函数执行一定时间之后就要返回            // 更新遍历次数            iteration++;            // 每遍历 16 次执行一次            if ((iteration &amp; 0xf) == 0 &amp;&amp; /* check once every 16 iterations. */                (ustime()-start) &gt; timelimit)            {                // 如果遍历次数正好是 16 的倍数                // 并且遍历的时间超过了 timelimit                // 那么断开 timelimit_exit                timelimit_exit = 1;            }            // 已经超时了，返回            if (timelimit_exit) return;            // 如果已删除的过期键占当前总数据库带过期时间的键数量的 25 %            // 那么不再遍历        } while (expired &gt; ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP/4);    }}</code></pre><ol><li>设置每次遍历数据库数量的最大值:REDIS_DBCRON_DBS_PER_CALL(16)个</li><li>设置运行的最长时间:<ul><li>slow模式下最多运行25000微秒＝1000000*ACTIVE_EXPIRE_CYCLE_SLOW_TIME_PERC/server.hz/100</li><li>fast模式下最多运行1000微妙＝ACTIVE_EXPIRE_CYCLE_FAST_DURATION</li></ul></li><li>设置每遍历一个数据库最多取ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP(20)个键值</li><li>如果已删除的过期键占当前总数据库带过期时间的键数量的 25 %不再进行遍历</li></ol><h2 id="11-4-内存淘汰机制"><a href="#11-4-内存淘汰机制" class="headerlink" title="11.4 内存淘汰机制"></a>11.4 内存淘汰机制</h2><p>如果定期删除漏掉了很多键，惰性删除也没有进行,Redis会使用内存淘汰机制来释放内存</p><ul><li><p>noeviction：当内存不足以容纳新写入数据时，新写入操作会报错。<code>默认策略</code></p></li><li><p>allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key。</p></li><li><p>allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key。</p></li><li><p>volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key。</p></li><li><p>volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key。</p></li><li><p>volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除。</p></li><li><p>allkey-lfu: 获取所有key的访问频度删除访问最少的key</p></li><li><p>volatile-lfu:获取过期key的访问频度删除访问最少的key</p></li></ul><blockquote><p>如何选取合适的策略？</p><p>比较推荐的是两种lru策略。根据自己的业务需求。如果你使用Redis只是作为缓存，不作为DB持久化，那推荐选择allkeys-lru；如果你使用Redis同时用于缓存和数据持久化，那推荐选择volatile-lru。</p></blockquote><pre><code class="ini">#file : redis.conf# MAXMEMORY POLICY: how Redis will select what to remove when maxmemory# is reached. You can select among five behaviors:# # volatile-lru -&gt; remove the key with an expire set using an LRU algorithm# allkeys-lru -&gt; remove any key accordingly to the LRU algorithm# volatile-random -&gt; remove a random key with an expire set# allkeys-random -&gt; remove a random key, any key# volatile-ttl -&gt; remove the key with the nearest expire time (minor TTL)# noeviction -&gt; don&#39;t expire at all, just return an error on write operations## The default is:# maxmemory-policy noeviction</code></pre><h2 id="11-5-LRU算法"><a href="#11-5-LRU算法" class="headerlink" title="11.5 LRU算法"></a>11.5 LRU算法</h2><h3 id="11-5-1-什么是LRU"><a href="#11-5-1-什么是LRU" class="headerlink" title="11.5.1 什么是LRU"></a>11.5.1 什么是LRU</h3><p>就是一种缓存淘汰策略。</p><p>计算机的缓存容量有限，如果缓存满了就要删除一些内容，给新内容腾位置。但问题是，删除哪些内容呢？我们肯定希望删掉哪些没什么用的缓存，而把有用的数据继续留在缓存里，方便之后继续使用。那么，什么样的数据，我们判定为「有用的」的数据呢？</p><p>LRU 缓存淘汰算法就是一种常用策略。LRU 的全称是 Least Recently Used，也就是说我们认为最近使用过的数据应该是是「有用的」，很久都没用过的数据应该是无用的，内存满了就优先删那些很久没用过的数据。</p><h3 id="11-5-2-LRU的实现"><a href="#11-5-2-LRU的实现" class="headerlink" title="11.5.2 LRU的实现"></a>11.5.2 LRU的实现</h3><p>LRU 算法实际上是让你设计数据结构：首先要接收一个 capacity 参数作为缓存的最大容量，然后实现两个 API，一个是 put(key, val) 方法存入键值对，另一个是 get(key) 方法获取 key 对应的 val，如果 key 不存在则返回 -1。get 和 put 方法必须都是 O(1) 的时间复杂度</p><p>常用的方式是构造一个结构体包含一个HashMap和双链表</p><p>HashMap做取数据使用</p><p>双链表存访问的顺序</p><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/LRU.png" alt=""></p><p>我们看下go语言实现的LRU</p><pre><code class="go">type (    LRUCache struct {        Capacity int        HashMap  map[int]*Node        Head     *Node        Last     *Node    }    Node struct {        Val  int        Key  int        Pre  *Node        Next *Node    })func Constructor(capacity int) LRUCache {    cache := LRUCache{        Capacity: capacity,        HashMap:  make(map[int]*Node, capacity),        Head:     &amp;Node{},        Last:     &amp;Node{},    }    cache.Head.Next = cache.Last    cache.Last.Pre = cache.Head    return cache}func (this *LRUCache) Get(key int) int {    node, ok := this.HashMap[key]    if !ok {        return -1    }    this.remove(node)    this.setHead(node)    return node.Val}func (this *LRUCache) Put(key int, value int) {    node, ok := this.HashMap[key]    if ok {        node.Val = value        this.remove(node)    } else {        if len(this.HashMap) == this.Capacity {            delete(this.HashMap, this.Last.Pre.Key)            this.remove(this.Last.Pre)        }        node = &amp;Node{            Val:  value,            Key:  key,            Pre:  nil,            Next: nil,        }        this.HashMap[node.Key] = node    }    this.setHead(node)}func (this *LRUCache) setHead(node *Node) {    this.Head.Next.Pre = node    node.Next = this.Head.Next    this.Head.Next = node    node.Pre = this.Head}func (this *LRUCache) remove(node *Node) {    node.Pre.Next = node.Next    node.Next.Pre = node.Pre}/*============================*//*使用方法 * obj := Constructor(capacity); * param_1 := obj.Get(key); * obj.Put(key,value); */</code></pre><h3 id="11-5-3-Redis-LRU的实现"><a href="#11-5-3-Redis-LRU的实现" class="headerlink" title="11.5.3 Redis LRU的实现"></a>11.5.3 Redis LRU的实现</h3><pre><code class="c"># file: src/redis.cint freeMemoryIfNeeded(void) {....../* volatile-lru and allkeys-lru policy */            // 如果使用的是 LRU 策略，            // 那么从一集 sample 键中选出 IDLE 时间最长的那个键            else if (server.maxmemory_policy == REDIS_MAXMEMORY_ALLKEYS_LRU ||                server.maxmemory_policy == REDIS_MAXMEMORY_VOLATILE_LRU)            {                struct evictionPoolEntry *pool = db-&gt;eviction_pool;                while(bestkey == NULL) {                    evictionPoolPopulate(dict, db-&gt;dict, db-&gt;eviction_pool);                    /* Go backward from best to worst element to evict. */                    for (k = REDIS_EVICTION_POOL_SIZE-1; k &gt;= 0; k--) {                        if (pool[k].key == NULL) continue;                        de = dictFind(dict,pool[k].key);                        /* Remove the entry from the pool. */                        sdsfree(pool[k].key);                        /* Shift all elements on its right to left. */                        memmove(pool+k,pool+k+1,                            sizeof(pool[0])*(REDIS_EVICTION_POOL_SIZE-k-1));                        /* Clear the element on the right which is empty                         * since we shifted one position to the left.  */                        pool[REDIS_EVICTION_POOL_SIZE-1].key = NULL;                        pool[REDIS_EVICTION_POOL_SIZE-1].idle = 0;                        /* If the key exists, is our pick. Otherwise it is                         * a ghost and we need to try the next element. */                        if (de) {                            bestkey = dictGetKey(de);                            break;                        } else {                            /* Ghost... */                            continue;                        }                    }                }            }....../* This is an helper function for freeMemoryIfNeeded(), it is used in order * to populate the evictionPool with a few entries every time we want to * expire a key. Keys with idle time smaller than one of the current * keys are added. Keys are always added if there are free entries. * * We insert keys on place in ascending order, so keys with the smaller * idle time are on the left, and keys with the higher idle time on the * right. */#define EVICTION_SAMPLES_ARRAY_SIZE 16void evictionPoolPopulate(dict *sampledict, dict *keydict, struct evictionPoolEntry *pool) {    int j, k, count;    dictEntry *_samples[EVICTION_SAMPLES_ARRAY_SIZE];    dictEntry **samples;    /* Try to use a static buffer: this function is a big hit...     * Note: it was actually measured that this helps. */    if (server.maxmemory_samples &lt;= EVICTION_SAMPLES_ARRAY_SIZE) {        samples = _samples;    } else {        samples = zmalloc(sizeof(samples[0])*server.maxmemory_samples);    }#if 1 /* Use bulk get by default. */    count = dictGetRandomKeys(sampledict,samples,server.maxmemory_samples);#else    count = server.maxmemory_samples;    for (j = 0; j &lt; count; j++) samples[j] = dictGetRandomKey(sampledict);#endif    for (j = 0; j &lt; count; j++) {        unsigned long long idle;        sds key;        robj *o;        dictEntry *de;        de = samples[j];        key = dictGetKey(de);        /* If the dictionary we are sampling from is not the main         * dictionary (but the expires one) we need to lookup the key         * again in the key dictionary to obtain the value object. */        if (sampledict != keydict) de = dictFind(keydict, key);        o = dictGetVal(de);        idle = estimateObjectIdleTime(o);        /* Insert the element inside the pool.         * First, find the first empty bucket or the first populated         * bucket that has an idle time smaller than our idle time. */        k = 0;        while (k &lt; REDIS_EVICTION_POOL_SIZE &amp;&amp;               pool[k].key &amp;&amp;               pool[k].idle &lt; idle) k++;        if (k == 0 &amp;&amp; pool[REDIS_EVICTION_POOL_SIZE-1].key != NULL) {            /* Can&#39;t insert if the element is &lt; the worst element we have             * and there are no empty buckets. */            continue;        } else if (k &lt; REDIS_EVICTION_POOL_SIZE &amp;&amp; pool[k].key == NULL) {            /* Inserting into empty position. No setup needed before insert. */        } else {            /* Inserting in the middle. Now k points to the first element             * greater than the element to insert.  */            if (pool[REDIS_EVICTION_POOL_SIZE-1].key == NULL) {                /* Free space on the right? Insert at k shifting                 * all the elements from k to end to the right. */                memmove(pool+k+1,pool+k,                    sizeof(pool[0])*(REDIS_EVICTION_POOL_SIZE-k-1));            } else {                /* No free space on right? Insert at k-1 */                k--;                /* Shift all elements on the left of k (included) to the                 * left, so we discard the element with smaller idle time. */                sdsfree(pool[0].key);                memmove(pool,pool+1,sizeof(pool[0])*k);            }        }        pool[k].key = sdsdup(key);        pool[k].idle = idle;    }    if (samples != _samples) zfree(samples);}/* This is a version of dictGetRandomKey() that is modified in order to * return multiple entries by jumping at a random place of the hash table * and scanning linearly for entries. * * Returned pointers to hash table entries are stored into &#39;des&#39; that * points to an array of dictEntry pointers. The array must have room for * at least &#39;count&#39; elements, that is the argument we pass to the function * to tell how many random elements we need. * * The function returns the number of items stored into &#39;des&#39;, that may * be less than &#39;count&#39; if the hash table has less than &#39;count&#39; elements * inside. * * Note that this function is not suitable when you need a good distribution * of the returned items, but only when you need to &quot;sample&quot; a given number * of continuous elements to run some kind of algorithm or to produce * statistics. However the function is much faster than dictGetRandomKey() * at producing N elements, and the elements are guaranteed to be non * repeating. */int dictGetRandomKeys(dict *d, dictEntry **des, int count) {    int j; /* internal hash table id, 0 or 1. */    int stored = 0;    if (dictSize(d) &lt; count) count = dictSize(d);    while(stored &lt; count) {        for (j = 0; j &lt; 2; j++) {            /* Pick a random point inside the hash table 0 or 1. */            unsigned int i = random() &amp; d-&gt;ht[j].sizemask;            int size = d-&gt;ht[j].size;            /* Make sure to visit every bucket by iterating &#39;size&#39; times. */            while(size--) {                dictEntry *he = d-&gt;ht[j].table[i];                while (he) {                    /* Collect all the elements of the buckets found non                     * empty while iterating. */                    *des = he;                    des++;                    he = he-&gt;next;                    stored++;                    if (stored == count) return stored;                }                i = (i+1) &amp; d-&gt;ht[j].sizemask;            }            /* If there is only one table and we iterated it all, we should             * already have &#39;count&#39; elements. Assert this condition. */            assert(dictIsRehashing(d) != 0);        }    }    return stored; /* Never reached. */}typedef struct redisDb {......    struct evictionPoolEntry *eviction_pool;    /* Eviction pool of keys */......} redisDb;typedef struct redisObject {......    // 对象最后一次被访问的时间    unsigned lru:REDIS_LRU_BITS; /* lru time (relative to server.lruclock)......} robj;</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/LRUDuring.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>10.Redis数据结构——object</title>
      <link href="/2020/02/20/10-Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-object/"/>
      <url>/2020/02/20/10-Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-object/</url>
      
        <content type="html"><![CDATA[<h2 id="10-1-什么是object"><a href="#10-1-什么是object" class="headerlink" title="10.1 什么是object"></a>10.1 什么是object</h2><p>在前面的数个章节里， 我们陆续介绍了 Redis 用到的所有主要数据结构， 比如简单动态字符串（SDS）、双端链表、字典、压缩列表、整数集合， 等等。</p><p>Redis 并没有直接使用这些数据结构来实现键值对数据库， 而是基于这些数据结构创建了一个<code>对象系统</code>， 这个系统包含字符串对象、列表对象、哈希对象、集合对象和有序集合对象这五种类型的对象， 每种对象都用到了至少一种我们前面所介绍的数据结构。</p><p>通过这五种不同类型的对象， Redis 可以在执行命令之前， 根据对象的类型来判断一个对象是否可以执行给定的命令。 使用对象的另一个好处是， 我们可以针对不同的使用场景， 为对象设置多种不同的数据结构实现， 从而优化对象在不同场景下的使用效率</p><h2 id="10-2-数据结构"><a href="#10-2-数据结构" class="headerlink" title="10.2 数据结构"></a>10.2 数据结构</h2><pre><code class="c">#file : src/redis.ctypedef struct redisObject {    // 类型    unsigned type:4;    // 编码    unsigned encoding:4;    // 对象最后一次被访问的时间    unsigned lru:REDIS_LRU_BITS; /* lru time (relative to server.lruclock) */    // 引用计数    int refcount;    // 指向实际值的指针    void *ptr;} robj;</code></pre><p>Redis 使用对象来表示数据库中的键和值， 每次当我们在 Redis 的数据库中新创建一个键值对时， 我们至少会创建两个对象， 一个对象用作键值对的键（键对象）， 另一个对象用作键值对的值（值对象）。</p><h3 id="10-2-1-type"><a href="#10-2-1-type" class="headerlink" title="10.2.1 type"></a>10.2.1 type</h3><p>对象的 type 属性记录了对象的类型:</p><pre><code class="c">#file : src/redis.c// 对象类型#define REDIS_STRING 0  #字符串对象 &quot;string&quot;#define REDIS_LIST 1    #列表对象 &quot;list&quot;#define REDIS_SET 2     #哈希对象 &quot;hash&quot;#define REDIS_ZSET 3    #集合对象 &quot;set&quot;#define REDIS_HASH 4    #有序集合对象 &quot;zset&quot;</code></pre><h3 id="10-2-2-encoding"><a href="#10-2-2-encoding" class="headerlink" title="10.2.2 encoding"></a>10.2.2 encoding</h3><p>对象的 ptr 指针指向对象的底层实现数据结构， 而这些数据结构由对象的 encoding 属性决定。</p><p>encoding 属性记录了对象所使用的编码， 也即是说这个对象使用了什么数据结构作为对象的底层实现:</p><pre><code class="c">#file : src/redis.c// 对象编码#简单动态字符串#define REDIS_ENCODING_RAW 0     /* Raw representation */ #long 类型的整数#long 类型的整数#define REDIS_ENCODING_INT 1     /* Encoded as integer */#字典#define REDIS_ENCODING_HT 2      /* Encoded as hash table */#压缩字典#define REDIS_ENCODING_ZIPMAP 3  /* Encoded as zipmap */#双端链表#define REDIS_ENCODING_LINKEDLIST 4 /* Encoded as regular linked list */#压缩列表#define REDIS_ENCODING_ZIPLIST 5 /* Encoded as ziplist */#整数集合#define REDIS_ENCODING_INTSET 6  /* Encoded as intset */#跳表#define REDIS_ENCODING_SKIPLIST 7  /* Encoded as skiplist */#embstr编码的简单动态字符串#define REDIS_ENCODING_EMBSTR 8  /* Embedded sds string encoding */</code></pre><h2 id="10-3-Redis键的底层实现"><a href="#10-3-Redis键的底层实现" class="headerlink" title="10.3 Redis键的底层实现"></a>10.3 Redis键的底层实现</h2><p>对于 Redis 数据库保存的键值对来说， 键总是一个字符串对象， 而值则可以是字符串对象、列表对象、哈希对象、集合对象或者有序集合对象的其中一种</p><h2 id="10-4-Redis值的底层实现"><a href="#10-4-Redis值的底层实现" class="headerlink" title="10.4 Redis值的底层实现"></a>10.4 Redis值的底层实现</h2><h3 id="10-4-1-字符串对象"><a href="#10-4-1-字符串对象" class="headerlink" title="10.4.1 字符串对象"></a>10.4.1 字符串对象</h3><pre><code class="c">#file: src/t_string.c/* SET key value [NX] [XX] [EX &lt;seconds&gt;] [PX &lt;milliseconds&gt;] */void setCommand(redisClient *c) {    int j;    robj *expire = NULL;    int unit = UNIT_SECONDS;    int flags = REDIS_SET_NO_FLAGS;    // 设置选项参数    for (j = 3; j &lt; c-&gt;argc; j++) {        char *a = c-&gt;argv[j]-&gt;ptr;        robj *next = (j == c-&gt;argc-1) ? NULL : c-&gt;argv[j+1];        if ((a[0] == &#39;n&#39; || a[0] == &#39;N&#39;) &amp;&amp;            (a[1] == &#39;x&#39; || a[1] == &#39;X&#39;) &amp;&amp; a[2] == &#39;\0&#39;) {            flags |= REDIS_SET_NX;        } else if ((a[0] == &#39;x&#39; || a[0] == &#39;X&#39;) &amp;&amp;                   (a[1] == &#39;x&#39; || a[1] == &#39;X&#39;) &amp;&amp; a[2] == &#39;\0&#39;) {            flags |= REDIS_SET_XX;        } else if ((a[0] == &#39;e&#39; || a[0] == &#39;E&#39;) &amp;&amp;                   (a[1] == &#39;x&#39; || a[1] == &#39;X&#39;) &amp;&amp; a[2] == &#39;\0&#39; &amp;&amp; next) {            unit = UNIT_SECONDS;            expire = next;            j++;        } else if ((a[0] == &#39;p&#39; || a[0] == &#39;P&#39;) &amp;&amp;                   (a[1] == &#39;x&#39; || a[1] == &#39;X&#39;) &amp;&amp; a[2] == &#39;\0&#39; &amp;&amp; next) {            unit = UNIT_MILLISECONDS;            expire = next;            j++;        } else {            addReply(c,shared.syntaxerr);            return;        }    }    // 尝试对值对象进行编码    c-&gt;argv[2] = tryObjectEncoding(c-&gt;argv[2]);    setGenericCommand(c,flags,c-&gt;argv[1],c-&gt;argv[2],expire,unit,NULL,NULL);}void setnxCommand(redisClient *c) {    c-&gt;argv[2] = tryObjectEncoding(c-&gt;argv[2]);    setGenericCommand(c,REDIS_SET_NX,c-&gt;argv[1],c-&gt;argv[2],NULL,0,shared.cone,shared.czero);}void setexCommand(redisClient *c) {    c-&gt;argv[3] = tryObjectEncoding(c-&gt;argv[3]);    setGenericCommand(c,REDIS_SET_NO_FLAGS,c-&gt;argv[1],c-&gt;argv[3],c-&gt;argv[2],UNIT_SECONDS,NULL,NULL);}void psetexCommand(redisClient *c) {    c-&gt;argv[3] = tryObjectEncoding(c-&gt;argv[3]);    setGenericCommand(c,REDIS_SET_NO_FLAGS,c-&gt;argv[1],c-&gt;argv[3],c-&gt;argv[2],UNIT_MILLISECONDS,NULL,NULL);}void setGenericCommand(redisClient *c, int flags, robj *key, robj *val, robj *expire, int unit, robj *ok_reply, robj *abort_reply) {    long long milliseconds = 0; /* initialized to avoid any harmness warning */    // 取出过期时间    if (expire) {        // 取出 expire 参数的值        // T = O(N)        if (getLongLongFromObjectOrReply(c, expire, &amp;milliseconds, NULL) != REDIS_OK)            return;        // expire 参数的值不正确时报错        if (milliseconds &lt;= 0) {            addReplyError(c,&quot;invalid expire time in SETEX&quot;);            return;        }        // 不论输入的过期时间是秒还是毫秒        // Redis 实际都以毫秒的形式保存过期时间        // 如果输入的过期时间为秒，那么将它转换为毫秒        if (unit == UNIT_SECONDS) milliseconds *= 1000;    }    // 如果设置了 NX 或者 XX 参数，那么检查条件是否不符合这两个设置    // 在条件不符合时报错，报错的内容由 abort_reply 参数决定    if ((flags &amp; REDIS_SET_NX &amp;&amp; lookupKeyWrite(c-&gt;db,key) != NULL) ||        (flags &amp; REDIS_SET_XX &amp;&amp; lookupKeyWrite(c-&gt;db,key) == NULL))    {        addReply(c, abort_reply ? abort_reply : shared.nullbulk);        return;    }    // 将键值关联到数据库    setKey(c-&gt;db,key,val);    // 将数据库设为脏    server.dirty++;    // 为键设置过期时间    if (expire) setExpire(c-&gt;db,key,mstime()+milliseconds);    // 发送事件通知    notifyKeyspaceEvent(REDIS_NOTIFY_STRING,&quot;set&quot;,key,c-&gt;db-&gt;id);    // 发送事件通知    if (expire) notifyKeyspaceEvent(REDIS_NOTIFY_GENERIC,        &quot;expire&quot;,key,c-&gt;db-&gt;id);    // 设置成功，向客户端发送回复    // 回复的内容由 ok_reply 决定    addReply(c, ok_reply ? ok_reply : shared.ok);}#file:src/object// 尝试对字符串对象进行编码，以节约内存。robj *tryObjectEncoding(robj *o) {    long value;    sds s = o-&gt;ptr;    size_t len;    redisAssertWithInfo(NULL,o,o-&gt;type == REDIS_STRING);    // 只在字符串的编码为 RAW 或者 EMBSTR 时尝试进行编码    if (!sdsEncodedObject(o)) return o;     // 不对共享对象进行编码     if (o-&gt;refcount &gt; 1) return o;    // 对字符串进行检查    // 只对长度小于或等于 21 字节，并且可以被解释为整数的字符串进行编码    len = sdslen(s);    if (len &lt;= 21 &amp;&amp; string2l(s,len,&amp;value)) {        if (server.maxmemory == 0 &amp;&amp;            value &gt;= 0 &amp;&amp;            value &lt; REDIS_SHARED_INTEGERS)        {            decrRefCount(o);            incrRefCount(shared.integers[value]);            return shared.integers[value];        } else {            if (o-&gt;encoding == REDIS_ENCODING_RAW) sdsfree(o-&gt;ptr);            o-&gt;encoding = REDIS_ENCODING_INT;            o-&gt;ptr = (void*) value;            return o;        }    }    // 尝试将 RAW 编码的字符串编码为 EMBSTR 编码    if (len &lt;= REDIS_ENCODING_EMBSTR_SIZE_LIMIT) {        robj *emb;        if (o-&gt;encoding == REDIS_ENCODING_EMBSTR) return o;        emb = createEmbeddedStringObject(s,sdslen(s));        decrRefCount(o);        return emb;    }    // 这个对象没办法进行编码，尝试从 SDS 中移除所有空余空间    if (o-&gt;encoding == REDIS_ENCODING_RAW &amp;&amp;        sdsavail(s) &gt; len/10)    {        o-&gt;ptr = sdsRemoveFreeSpace(o-&gt;ptr);    }    /* Return the original object. */    return o;}</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/stringadd.png" alt=""></p><h3 id="10-4-2-列表对象"><a href="#10-4-2-列表对象" class="headerlink" title="10.4.2 列表对象"></a>10.4.2 列表对象</h3><pre><code class="c"># file : src/t_list.cvoid lpushxCommand(redisClient *c) {    c-&gt;argv[2] = tryObjectEncoding(c-&gt;argv[2]);    pushxGenericCommand(c,NULL,c-&gt;argv[2],REDIS_HEAD);}void rpushxCommand(redisClient *c) {    c-&gt;argv[2] = tryObjectEncoding(c-&gt;argv[2]);    pushxGenericCommand(c,NULL,c-&gt;argv[2],REDIS_TAIL);}void pushxGenericCommand(redisClient *c, robj *refval, robj *val, int where) {    robj *subject;    listTypeIterator *iter;    listTypeEntry entry;    int inserted = 0;    // 取出列表对象    if ((subject = lookupKeyReadOrReply(c,c-&gt;argv[1],shared.czero)) == NULL ||        checkType(c,subject,REDIS_LIST)) return;    // 执行的是 LINSERT 命令    if (refval != NULL) {        // 看保存值 value 是否需要将列表编码转换为双端链表        listTypeTryConversion(subject,val);        /* Seek refval from head to tail */        // 在列表中查找 refval 对象        iter = listTypeInitIterator(subject,0,REDIS_TAIL);        while (listTypeNext(iter,&amp;entry)) {            if (listTypeEqual(&amp;entry,refval)) {                // 找到了，将值插入到节点的前面或后面                listTypeInsert(&amp;entry,val,where);                inserted = 1;                break;            }        }        listTypeReleaseIterator(iter);        if (inserted) {            /* Check if the length exceeds the ziplist length threshold. */            // 查看插入之后是否需要将编码转换为双端链表            if (subject-&gt;encoding == REDIS_ENCODING_ZIPLIST &amp;&amp;                ziplistLen(subject-&gt;ptr) &gt; server.list_max_ziplist_entries)                    listTypeConvert(subject,REDIS_ENCODING_LINKEDLIST);            signalModifiedKey(c-&gt;db,c-&gt;argv[1]);            notifyKeyspaceEvent(REDIS_NOTIFY_LIST,&quot;linsert&quot;,                                c-&gt;argv[1],c-&gt;db-&gt;id);            server.dirty++;        } else {            /* Notify client of a failed insert */            // refval 不存在，插入失败            addReply(c,shared.cnegone);            return;        }    // 执行的是 LPUSHX 或 RPUSHX 命令    } else {        char *event = (where == REDIS_HEAD) ? &quot;lpush&quot; : &quot;rpush&quot;;        listTypePush(subject,val,where);        signalModifiedKey(c-&gt;db,c-&gt;argv[1]);        notifyKeyspaceEvent(REDIS_NOTIFY_LIST,event,c-&gt;argv[1],c-&gt;db-&gt;id);        server.dirty++;    }    addReplyLongLong(c,listTypeLength(subject));}/* * 将给定元素添加到列表的表头或表尾。 * * 参数 where 决定了新元素添加的位置： * *  - REDIS_HEAD 将新元素添加到表头 *  - REDIS_TAIL 将新元素添加到表尾 * * 调用者无须担心 value 的引用计数，因为这个函数会负责这方面的工作。 */void listTypePush(robj *subject, robj *value, int where) {    /* Check if we need to convert the ziplist */    // 是否需要转换编码？    listTypeTryConversion(subject,value);    if (subject-&gt;encoding == REDIS_ENCODING_ZIPLIST &amp;&amp;        ziplistLen(subject-&gt;ptr) &gt;= server.list_max_ziplist_entries)            listTypeConvert(subject,REDIS_ENCODING_LINKEDLIST);    // ZIPLIST    if (subject-&gt;encoding == REDIS_ENCODING_ZIPLIST) {        int pos = (where == REDIS_HEAD) ? ZIPLIST_HEAD : ZIPLIST_TAIL;        // 取出对象的值，因为 ZIPLIST 只能保存字符串或整数        value = getDecodedObject(value);        subject-&gt;ptr = ziplistPush(subject-&gt;ptr,value-&gt;ptr,sdslen(value-&gt;ptr),pos);        decrRefCount(value);    // 双端链表    } else if (subject-&gt;encoding == REDIS_ENCODING_LINKEDLIST) {        if (where == REDIS_HEAD) {            listAddNodeHead(subject-&gt;ptr,value);        } else {            listAddNodeTail(subject-&gt;ptr,value);        }        incrRefCount(value);    // 未知编码    } else {        redisPanic(&quot;Unknown list encoding&quot;);    }}/* * 对输入值 value 进行检查，看是否需要将 subject 从 ziplist 转换为双端链表， * 以便保存值 value 。 * * 函数只对 REDIS_ENCODING_RAW 编码的 value 进行检查， * 因为整数编码的值不可能超长。 */void listTypeTryConversion(robj *subject, robj *value) {    // 确保 subject 为 ZIPLIST 编码    if (subject-&gt;encoding != REDIS_ENCODING_ZIPLIST) return;    if (sdsEncodedObject(value) &amp;&amp;        // 看字符串是否过长        sdslen(value-&gt;ptr) &gt; server.list_max_ziplist_value)            // 将编码转换为双端链表            listTypeConvert(subject,REDIS_ENCODING_LINKEDLIST);}/* * 将列表的底层编码从 ziplist 转换成双端链表 */void listTypeConvert(robj *subject, int enc) {    listTypeIterator *li;    listTypeEntry entry;    redisAssertWithInfo(NULL,subject,subject-&gt;type == REDIS_LIST);    // 转换成双端链表    if (enc == REDIS_ENCODING_LINKEDLIST) {        list *l = listCreate();        listSetFreeMethod(l,decrRefCountVoid);        // 遍历 ziplist ，并将里面的值全部添加到双端链表中        li = listTypeInitIterator(subject,0,REDIS_TAIL);        while (listTypeNext(li,&amp;entry)) listAddNodeTail(l,listTypeGet(&amp;entry));        listTypeReleaseIterator(li);        // 更新编码        subject-&gt;encoding = REDIS_ENCODING_LINKEDLIST;        // 释放原来的 ziplist        zfree(subject-&gt;ptr);        // 更新对象值指针        subject-&gt;ptr = l;    } else {        redisPanic(&quot;Unsupported list conversion&quot;);    }}#file : src/object.c/* * 创建一个 ZIPLIST 编码的列表对象 */robj *createZiplistObject(void) {    unsigned char *zl = ziplistNew();    robj *o = createObject(REDIS_LIST,zl);    o-&gt;encoding = REDIS_ENCODING_ZIPLIST;    return o;}</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/listadd.png" alt=""></p><h3 id="10-4-3-哈希对象"><a href="#10-4-3-哈希对象" class="headerlink" title="10.4.3 哈希对象"></a>10.4.3 哈希对象</h3><pre><code class="c">#file src/t_hash.c/*----------------------------------------------------------------------------- * Hash type commands *----------------------------------------------------------------------------*/void hsetCommand(redisClient *c) {    int update;    robj *o;    // 取出或新创建哈希对象    if ((o = hashTypeLookupWriteOrCreate(c,c-&gt;argv[1])) == NULL) return;    // 如果需要的话，转换哈希对象的编码    hashTypeTryConversion(o,c-&gt;argv,2,3);    // 编码 field 和 value 对象以节约空间    hashTypeTryObjectEncoding(o,&amp;c-&gt;argv[2], &amp;c-&gt;argv[3]);    // 设置 field 和 value 到 hash    update = hashTypeSet(o,c-&gt;argv[2],c-&gt;argv[3]);    // 返回状态：显示 field-value 对是新添加还是更新    addReply(c, update ? shared.czero : shared.cone);    // 发送键修改信号    signalModifiedKey(c-&gt;db,c-&gt;argv[1]);    // 发送事件通知    notifyKeyspaceEvent(REDIS_NOTIFY_HASH,&quot;hset&quot;,c-&gt;argv[1],c-&gt;db-&gt;id);    // 将服务器设为脏    server.dirty++;}void hsetnxCommand(redisClient *c) {    robj *o;    // 取出或新创建哈希对象    if ((o = hashTypeLookupWriteOrCreate(c,c-&gt;argv[1])) == NULL) return;    // 如果需要的话，转换哈希对象的编码    hashTypeTryConversion(o,c-&gt;argv,2,3);    // 如果 field-value 对已经存在    // 那么回复 0     if (hashTypeExists(o, c-&gt;argv[2])) {        addReply(c, shared.czero);    // 否则，设置 field-value 对    } else {        // 对 field 和 value 对象编码，以节省空间        hashTypeTryObjectEncoding(o,&amp;c-&gt;argv[2], &amp;c-&gt;argv[3]);        // 设置        hashTypeSet(o,c-&gt;argv[2],c-&gt;argv[3]);        // 回复 1 ，表示设置成功        addReply(c, shared.cone);        // 发送键修改信号        signalModifiedKey(c-&gt;db,c-&gt;argv[1]);        // 发送事件通知        notifyKeyspaceEvent(REDIS_NOTIFY_HASH,&quot;hset&quot;,c-&gt;argv[1],c-&gt;db-&gt;id);       // 将数据库设为脏        server.dirty++;    }}void hmsetCommand(redisClient *c) {    int i;    robj *o;    // field-value 参数必须成对出现    if ((c-&gt;argc % 2) == 1) {        addReplyError(c,&quot;wrong number of arguments for HMSET&quot;);        return;    }    // 取出或新创建哈希对象    if ((o = hashTypeLookupWriteOrCreate(c,c-&gt;argv[1])) == NULL) return;    // 如果需要的话，转换哈希对象的编码    hashTypeTryConversion(o,c-&gt;argv,2,c-&gt;argc-1);    // 遍历并设置所有 field-value 对    for (i = 2; i &lt; c-&gt;argc; i += 2) {        // 编码 field-value 对，以节约空间        hashTypeTryObjectEncoding(o,&amp;c-&gt;argv[i], &amp;c-&gt;argv[i+1]);        // 设置        hashTypeSet(o,c-&gt;argv[i],c-&gt;argv[i+1]);    }    // 向客户端发送回复    addReply(c, shared.ok);    // 发送键修改信号    signalModifiedKey(c-&gt;db,c-&gt;argv[1]);    // 发送事件通知    notifyKeyspaceEvent(REDIS_NOTIFY_HASH,&quot;hset&quot;,c-&gt;argv[1],c-&gt;db-&gt;id);    // 将数据库设为脏    server.dirty++;}/* * 对 argv 数组中的多个对象进行检查， * 看是否需要将对象的编码从 REDIS_ENCODING_ZIPLIST 转换成 REDIS_ENCODING_HT * * 注意程序只检查字符串值，因为它们的长度可以在常数时间内取得。 */void hashTypeTryConversion(robj *o, robj **argv, int start, int end) {    int i;    // 如果对象不是 ziplist 编码，那么直接返回    if (o-&gt;encoding != REDIS_ENCODING_ZIPLIST) return;    // 检查所有输入对象，看它们的字符串值是否超过了指定长度    for (i = start; i &lt;= end; i++) {        if (sdsEncodedObject(argv[i]) &amp;&amp;            sdslen(argv[i]-&gt;ptr) &gt; server.hash_max_ziplist_value)        {            // 将对象的编码转换成 REDIS_ENCODING_HT            hashTypeConvert(o, REDIS_ENCODING_HT);            break;        }    }}/* * 对哈希对象 o 的编码方式进行转换 * * 目前只支持将 ZIPLIST 编码转换成 HT 编码 */void hashTypeConvert(robj *o, int enc) {    if (o-&gt;encoding == REDIS_ENCODING_ZIPLIST) {        hashTypeConvertZiplist(o, enc);    } else if (o-&gt;encoding == REDIS_ENCODING_HT) {        redisPanic(&quot;Not implemented&quot;);    } else {        redisPanic(&quot;Unknown hash encoding&quot;);    }}/*  * 将给定的 field-value 对添加到 hash 中， * 如果 field 已经存在，那么删除旧的值，并关联新值。 * 这个函数负责对 field 和 value 参数进行引用计数自增。 * * 返回 0 表示元素已经存在，这次函数调用执行的是更新操作。 * 返回 1 则表示函数执行的是新添加操作。 */int hashTypeSet(robj *o, robj *field, robj *value) {    int update = 0;    // 添加到 ziplist    if (o-&gt;encoding == REDIS_ENCODING_ZIPLIST) {        unsigned char *zl, *fptr, *vptr;        // 解码成字符串或者数字        field = getDecodedObject(field);        value = getDecodedObject(value);        // 遍历整个 ziplist ，尝试查找并更新 field （如果它已经存在的话）        zl = o-&gt;ptr;        fptr = ziplistIndex(zl, ZIPLIST_HEAD);        if (fptr != NULL) {            // 定位到域 field            fptr = ziplistFind(fptr, field-&gt;ptr, sdslen(field-&gt;ptr), 1);            if (fptr != NULL) {                /* Grab pointer to the value (fptr points to the field) */                // 定位到域的值                vptr = ziplistNext(zl, fptr);                redisAssert(vptr != NULL);                // 标识这次操作为更新操作                update = 1;                /* Delete value */                // 删除旧的键值对                zl = ziplistDelete(zl, &amp;vptr);                /* Insert new value */                // 添加新的键值对                zl = ziplistInsert(zl, vptr, value-&gt;ptr, sdslen(value-&gt;ptr));            }        }        // 如果这不是更新操作，那么这就是一个添加操作        if (!update) {            /* Push new field/value pair onto the tail of the ziplist */            // 将新的 field-value 对推入到 ziplist 的末尾            zl = ziplistPush(zl, field-&gt;ptr, sdslen(field-&gt;ptr), ZIPLIST_TAIL);            zl = ziplistPush(zl, value-&gt;ptr, sdslen(value-&gt;ptr), ZIPLIST_TAIL);        }        // 更新对象指针        o-&gt;ptr = zl;        // 释放临时对象        decrRefCount(field);        decrRefCount(value);        // 检查在添加操作完成之后，是否需要将 ZIPLIST 编码转换成 HT 编码        if (hashTypeLength(o) &gt; server.hash_max_ziplist_entries)            hashTypeConvert(o, REDIS_ENCODING_HT);    // 添加到字典    } else if (o-&gt;encoding == REDIS_ENCODING_HT) {        // 添加或替换键值对到字典        // 添加返回 1 ，替换返回 0        if (dictReplace(o-&gt;ptr, field, value)) { /* Insert */            incrRefCount(field);        } else { /* Update */            update = 1;        }        incrRefCount(value);    } else {        redisPanic(&quot;Unknown hash encoding&quot;);    }    // 更新/添加指示变量    return update;}#file: src/object.c/* * 创建一个 ZIPLIST 编码的哈希对象 */robj *createHashObject(void) {    unsigned char *zl = ziplistNew();    robj *o = createObject(REDIS_HASH, zl);    o-&gt;encoding = REDIS_ENCODING_ZIPLIST;    return o;}</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/hashadd.png" alt=""></p><h3 id="10-4-4-集合对象"><a href="#10-4-4-集合对象" class="headerlink" title="10.4.4 集合对象"></a>10.4.4 集合对象</h3><pre><code class="c">#file: src/t_set.cvoid saddCommand(redisClient *c) {    robj *set;    int j, added = 0;    // 取出集合对象    set = lookupKeyWrite(c-&gt;db,c-&gt;argv[1]);    // 对象不存在，创建一个新的，并将它关联到数据库    if (set == NULL) {        set = setTypeCreate(c-&gt;argv[2]);        dbAdd(c-&gt;db,c-&gt;argv[1],set);    // 对象存在，检查类型    } else {        if (set-&gt;type != REDIS_SET) {            addReply(c,shared.wrongtypeerr);            return;        }    }    // 将所有输入元素添加到集合中    for (j = 2; j &lt; c-&gt;argc; j++) {        c-&gt;argv[j] = tryObjectEncoding(c-&gt;argv[j]);        // 只有元素未存在于集合时，才算一次成功添加        if (setTypeAdd(set,c-&gt;argv[j])) added++;    }    // 如果有至少一个元素被成功添加，那么执行以下程序    if (added) {        // 发送键修改信号        signalModifiedKey(c-&gt;db,c-&gt;argv[1]);        // 发送事件通知        notifyKeyspaceEvent(REDIS_NOTIFY_SET,&quot;sadd&quot;,c-&gt;argv[1],c-&gt;db-&gt;id);    }    // 将数据库设为脏    server.dirty += added;    // 返回添加元素的数量    addReplyLongLong(c,added);}/*  * 返回一个可以保存值 value 的集合。 * 当对象的值可以被编码为整数时，返回 intset ， * 否则，返回普通的哈希表。 */robj *setTypeCreate(robj *value) {    if (isObjectRepresentableAsLongLong(value,NULL) == REDIS_OK)        return createIntsetObject();    return createSetObject();}/*  * 将集合对象 setobj 的编码转换为 REDIS_ENCODING_HT 。 * * 新创建的结果字典会被预先分配为和原来的集合一样大。 */void setTypeConvert(robj *setobj, int enc) {    setTypeIterator *si;    // 确认类型和编码正确    redisAssertWithInfo(NULL,setobj,setobj-&gt;type == REDIS_SET &amp;&amp;                             setobj-&gt;encoding == REDIS_ENCODING_INTSET);    if (enc == REDIS_ENCODING_HT) {        int64_t intele;        // 创建新字典        dict *d = dictCreate(&amp;setDictType,NULL);        robj *element;        /* Presize the dict to avoid rehashing */        // 预先扩展空间        dictExpand(d,intsetLen(setobj-&gt;ptr));        /* To add the elements we extract integers and create redis objects */        // 遍历集合，并将元素添加到字典中        si = setTypeInitIterator(setobj);        while (setTypeNext(si,NULL,&amp;intele) != -1) {            element = createStringObjectFromLongLong(intele);            redisAssertWithInfo(NULL,element,dictAdd(d,element,NULL) == DICT_OK);        }        setTypeReleaseIterator(si);        // 更新集合的编码        setobj-&gt;encoding = REDIS_ENCODING_HT;        zfree(setobj-&gt;ptr);        // 更新集合的值对象        setobj-&gt;ptr = d;    } else {        redisPanic(&quot;Unsupported set conversion&quot;);    }}/* * 多态 add 操作 * * 添加成功返回 1 ，如果元素已经存在，返回 0 。 */int setTypeAdd(robj *subject, robj *value) {    long long llval;    // 字典    if (subject-&gt;encoding == REDIS_ENCODING_HT) {        // 将 value 作为键， NULL 作为值，将元素添加到字典中        if (dictAdd(subject-&gt;ptr,value,NULL) == DICT_OK) {            incrRefCount(value);            return 1;        }    // intset    } else if (subject-&gt;encoding == REDIS_ENCODING_INTSET) {        // 如果对象的值可以编码为整数的话，那么将对象的值添加到 intset 中        if (isObjectRepresentableAsLongLong(value,&amp;llval) == REDIS_OK) {            uint8_t success = 0;            subject-&gt;ptr = intsetAdd(subject-&gt;ptr,llval,&amp;success);            if (success) {                /* Convert to regular set when the intset contains                 * too many entries. */                // 添加成功                // 检查集合在添加新元素之后是否需要转换为字典                if (intsetLen(subject-&gt;ptr) &gt; server.set_max_intset_entries)                    setTypeConvert(subject,REDIS_ENCODING_HT);                return 1;            }        // 如果对象的值不能编码为整数，那么将集合从 intset 编码转换为 HT 编码        // 然后再执行添加操作        } else {            /* Failed to get integer from object, convert to regular set. */            setTypeConvert(subject,REDIS_ENCODING_HT);            /* The set *was* an intset and this value is not integer             * encodable, so dictAdd should always work. */            redisAssertWithInfo(NULL,value,dictAdd(subject-&gt;ptr,value,NULL) == DICT_OK);            incrRefCount(value);            return 1;        }    // 未知编码    } else {        redisPanic(&quot;Unknown set encoding&quot;);    }    // 添加失败，元素已经存在    return 0;}#file: src/db.c/* * 为执行写入操作而取出键 key 在数据库 db 中的值。 * 和 lookupKeyRead 不同，这个函数不会更新服务器的命中/不命中信息。 * 找到时返回值对象，没找到返回 NULL 。 */robj *lookupKeyWrite(redisDb *db, robj *key) {    // 删除过期键    expireIfNeeded(db,key);    // 查找并返回 key 的值对象    return lookupKey(db,key);}</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/setadd.png" alt=""></p><h3 id="10-4-5-有序集合对象"><a href="#10-4-5-有序集合对象" class="headerlink" title="10.4.5 有序集合对象"></a>10.4.5 有序集合对象</h3><pre><code class="c">#file : src/t_zset.cvoid zaddCommand(redisClient *c) {    zaddGenericCommand(c,0);}void zincrbyCommand(redisClient *c) {    zaddGenericCommand(c,1);}/* This generic command implements both ZADD and ZINCRBY. */void zaddGenericCommand(redisClient *c, int incr) {    static char *nanerr = &quot;resulting score is not a number (NaN)&quot;;    robj *key = c-&gt;argv[1];    robj *ele;    robj *zobj;    robj *curobj;    double score = 0, *scores = NULL, curscore = 0.0;    int j, elements = (c-&gt;argc-2)/2;    int added = 0, updated = 0;    // 输入的 score - member 参数必须是成对出现的    if (c-&gt;argc % 2) {        addReply(c,shared.syntaxerr);        return;    }    // 取出所有输入的 score 分值    scores = zmalloc(sizeof(double)*elements);    for (j = 0; j &lt; elements; j++) {        if (getDoubleFromObjectOrReply(c,c-&gt;argv[2+j*2],&amp;scores[j],NULL)            != REDIS_OK) goto cleanup;    }    /* Lookup the key and create the sorted set if does not exist. */    // 取出有序集合对象    zobj = lookupKeyWrite(c-&gt;db,key);    if (zobj == NULL) {        // 有序集合不存在，创建新有序集合        if (server.zset_max_ziplist_entries == 0 ||            server.zset_max_ziplist_value &lt; sdslen(c-&gt;argv[3]-&gt;ptr))        {            zobj = createZsetObject();        } else {            zobj = createZsetZiplistObject();        }        // 关联对象到数据库        dbAdd(c-&gt;db,key,zobj);    } else {        // 对象存在，检查类型        if (zobj-&gt;type != REDIS_ZSET) {            addReply(c,shared.wrongtypeerr);            goto cleanup;        }    }    // 处理所有元素    for (j = 0; j &lt; elements; j++) {        score = scores[j];        // 有序集合为 ziplist 编码        if (zobj-&gt;encoding == REDIS_ENCODING_ZIPLIST) {            unsigned char *eptr;            /* Prefer non-encoded element when dealing with ziplists. */            // 查找成员            ele = c-&gt;argv[3+j*2];            if ((eptr = zzlFind(zobj-&gt;ptr,ele,&amp;curscore)) != NULL) {                // 成员已存在                // ZINCRYBY 命令时使用                if (incr) {                    score += curscore;                    if (isnan(score)) {                        addReplyError(c,nanerr);                        goto cleanup;                    }                }                // 执行 ZINCRYBY 命令时，                // 或者用户通过 ZADD 修改成员的分值时执行                if (score != curscore) {                    // 删除已有元素                    zobj-&gt;ptr = zzlDelete(zobj-&gt;ptr,eptr);                    // 重新插入元素                    zobj-&gt;ptr = zzlInsert(zobj-&gt;ptr,ele,score);                    // 计数器                    server.dirty++;                    updated++;                }            } else {                // 元素不存在，直接添加                zobj-&gt;ptr = zzlInsert(zobj-&gt;ptr,ele,score);                // 查看元素的数量，                // 看是否需要将 ZIPLIST 编码转换为有序集合                if (zzlLength(zobj-&gt;ptr) &gt; server.zset_max_ziplist_entries)                    zsetConvert(zobj,REDIS_ENCODING_SKIPLIST);                // 查看新添加元素的长度                // 看是否需要将 ZIPLIST 编码转换为有序集合                if (sdslen(ele-&gt;ptr) &gt; server.zset_max_ziplist_value)                    zsetConvert(zobj,REDIS_ENCODING_SKIPLIST);                server.dirty++;                added++;            }        // 有序集合为 SKIPLIST 编码        } else if (zobj-&gt;encoding == REDIS_ENCODING_SKIPLIST) {            zset *zs = zobj-&gt;ptr;            zskiplistNode *znode;            dictEntry *de;            // 编码对象            ele = c-&gt;argv[3+j*2] = tryObjectEncoding(c-&gt;argv[3+j*2]);            // 查看成员是否存在            de = dictFind(zs-&gt;dict,ele);            if (de != NULL) {                // 成员存在                // 取出成员                curobj = dictGetKey(de);                // 取出分值                curscore = *(double*)dictGetVal(de);                // ZINCRYBY 时执行                if (incr) {                    score += curscore;                    if (isnan(score)) {                        addReplyError(c,nanerr);                        /* Don&#39;t need to check if the sorted set is empty                         * because we know it has at least one element. */                        goto cleanup;                    }                }                // 执行 ZINCRYBY 命令时，                // 或者用户通过 ZADD 修改成员的分值时执行                if (score != curscore) {                    // 删除原有元素                    redisAssertWithInfo(c,curobj,zslDelete(zs-&gt;zsl,curscore,curobj));                    // 重新插入元素                    znode = zslInsert(zs-&gt;zsl,score,curobj);                    incrRefCount(curobj); /* Re-inserted in skiplist. */                    // 更新字典的分值指针                    dictGetVal(de) = &amp;znode-&gt;score; /* Update score ptr. */                    server.dirty++;                    updated++;                }            } else {                // 元素不存在，直接添加到跳跃表                znode = zslInsert(zs-&gt;zsl,score,ele);                incrRefCount(ele); /* Inserted in skiplist. */                // 将元素关联到字典                redisAssertWithInfo(c,NULL,dictAdd(zs-&gt;dict,ele,&amp;znode-&gt;score) == DICT_OK);                incrRefCount(ele); /* Added to dictionary. */                server.dirty++;                added++;            }        } else {            redisPanic(&quot;Unknown sorted set encoding&quot;);        }    }    if (incr) /* ZINCRBY */        addReplyDouble(c,score);    else /* ZADD */        addReplyLongLong(c,added);cleanup:    zfree(scores);    if (added || updated) {        signalModifiedKey(c-&gt;db,key);        notifyKeyspaceEvent(REDIS_NOTIFY_ZSET,            incr ? &quot;zincr&quot; : &quot;zadd&quot;, key, c-&gt;db-&gt;id);    }}/* * 将跳跃表对象 zobj 的底层编码转换为 encoding 。 */void zsetConvert(robj *zobj, int encoding) {    zset *zs;    zskiplistNode *node, *next;    robj *ele;    double score;    if (zobj-&gt;encoding == encoding) return;    // 从 ZIPLIST 编码转换为 SKIPLIST 编码    if (zobj-&gt;encoding == REDIS_ENCODING_ZIPLIST) {        unsigned char *zl = zobj-&gt;ptr;        unsigned char *eptr, *sptr;        unsigned char *vstr;        unsigned int vlen;        long long vlong;        if (encoding != REDIS_ENCODING_SKIPLIST)            redisPanic(&quot;Unknown target encoding&quot;);        // 创建有序集合结构        zs = zmalloc(sizeof(*zs));        // 字典        zs-&gt;dict = dictCreate(&amp;zsetDictType,NULL);        // 跳跃表        zs-&gt;zsl = zslCreate();        // 有序集合在 ziplist 中的排列：        //        // | member-1 | score-1 | member-2 | score-2 | ... |        //        // 指向 ziplist 中的首个节点（保存着元素成员）        eptr = ziplistIndex(zl,0);        redisAssertWithInfo(NULL,zobj,eptr != NULL);        // 指向 ziplist 中的第二个节点（保存着元素分值）        sptr = ziplistNext(zl,eptr);        redisAssertWithInfo(NULL,zobj,sptr != NULL);        // 遍历所有 ziplist 节点，并将元素的成员和分值添加到有序集合中        while (eptr != NULL) {            // 取出分值            score = zzlGetScore(sptr);            // 取出成员            redisAssertWithInfo(NULL,zobj,ziplistGet(eptr,&amp;vstr,&amp;vlen,&amp;vlong));            if (vstr == NULL)                ele = createStringObjectFromLongLong(vlong);            else                ele = createStringObject((char*)vstr,vlen);            /* Has incremented refcount since it was just created. */            // 将成员和分值分别关联到跳跃表和字典中            node = zslInsert(zs-&gt;zsl,score,ele);            redisAssertWithInfo(NULL,zobj,dictAdd(zs-&gt;dict,ele,&amp;node-&gt;score) == DICT_OK);            incrRefCount(ele); /* Added to dictionary. */            // 移动指针，指向下个元素            zzlNext(zl,&amp;eptr,&amp;sptr);        }        // 释放原来的 ziplist        zfree(zobj-&gt;ptr);        // 更新对象的值，以及编码方式        zobj-&gt;ptr = zs;        zobj-&gt;encoding = REDIS_ENCODING_SKIPLIST;    // 从 SKIPLIST 转换为 ZIPLIST 编码    } else if (zobj-&gt;encoding == REDIS_ENCODING_SKIPLIST) {        // 新的 ziplist        unsigned char *zl = ziplistNew();        if (encoding != REDIS_ENCODING_ZIPLIST)            redisPanic(&quot;Unknown target encoding&quot;);        /* Approach similar to zslFree(), since we want to free the skiplist at         * the same time as creating the ziplist. */        // 指向跳跃表        zs = zobj-&gt;ptr;        // 先释放字典，因为只需要跳跃表就可以遍历整个有序集合了        dictRelease(zs-&gt;dict);        // 指向跳跃表首个节点        node = zs-&gt;zsl-&gt;header-&gt;level[0].forward;        // 释放跳跃表表头        zfree(zs-&gt;zsl-&gt;header);        zfree(zs-&gt;zsl);        // 遍历跳跃表，取出里面的元素，并将它们添加到 ziplist        while (node) {            // 取出解码后的值对象            ele = getDecodedObject(node-&gt;obj);            // 添加元素到 ziplist            zl = zzlInsertAt(zl,NULL,ele,node-&gt;score);            decrRefCount(ele);            // 沿着跳跃表的第 0 层前进            next = node-&gt;level[0].forward;            zslFreeNode(node);            node = next;        }        // 释放跳跃表        zfree(zs);        // 更新对象的值，以及对象的编码方式        zobj-&gt;ptr = zl;        zobj-&gt;encoding = REDIS_ENCODING_ZIPLIST;    } else {        redisPanic(&quot;Unknown sorted set encoding&quot;);    }}</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/zsetadd.png" alt=""></p><h2 id="10-5-内存回收"><a href="#10-5-内存回收" class="headerlink" title="10.5 内存回收"></a>10.5 内存回收</h2><p>因为 C 语言并不具备自动的内存回收功能， 所以 Redis 在自己的对象系统中构建了一个引用计数（reference counting）技术实现的内存回收机制， 通过这一机制， 程序可以通过跟踪对象的引用计数信息， 在适当的时候自动释放对象并进行内存回收。</p><p>每个对象的引用计数信息由 redisObject 结构的 refcount 属性记录</p><p>对象的引用计数信息会随着对象的使用状态而不断变化：</p><ul><li>在创建一个新对象时， 引用计数的值会被初始化为 1 ；</li><li>当对象被一个新程序使用时， 它的引用计数值会被增一；</li><li>当对象不再被一个程序使用时， 它的引用计数值会被减一；</li><li>当对象的引用计数值变为 0 时， 对象所占用的内存会被释放。</li></ul><p>操作refcount的函数:</p><pre><code class="c">#file: src/object.c#incrRefCount 将对象的引用计数值增一。#decrRefCount 将对象的引用计数值减一，当对象的引用计数值等于0时，释放对象。#resetRefCount 将对象的引用计数值设置为0，但并不释放对象，这个函数通常在需要重新设置对象的引用计数值时使用/* * 为对象的引用计数增一 */void incrRefCount(robj *o) {    o-&gt;refcount++;}/* * 为对象的引用计数减一 * 当对象的引用计数降为 0 时，释放对象。 */void decrRefCount(robj *o) {    if (o-&gt;refcount &lt;= 0) redisPanic(&quot;decrRefCount against refcount &lt;= 0&quot;);    // 释放对象    if (o-&gt;refcount == 1) {        switch(o-&gt;type) {        case REDIS_STRING: freeStringObject(o); break;        case REDIS_LIST: freeListObject(o); break;        case REDIS_SET: freeSetObject(o); break;        case REDIS_ZSET: freeZsetObject(o); break;        case REDIS_HASH: freeHashObject(o); break;        default: redisPanic(&quot;Unknown object type&quot;); break;        }        zfree(o);    // 减少计数    } else {        o-&gt;refcount--;    }}robj *resetRefCount(robj *obj) {    obj-&gt;refcount = 0;    return obj;}</code></pre><h2 id="10-6-对象共享"><a href="#10-6-对象共享" class="headerlink" title="10.6 对象共享"></a>10.6 对象共享</h2><p>除了用于实现引用计数内存回收机制之外， 对象的引用计数属性还带有对象共享的作用。</p><p>在 Redis 中， 让多个键共享同一个值对象需要执行以下两个步骤：</p><ol><li>将数据库键的值指针指向一个现有的值对象；</li><li>将被共享的值对象的引用计数增一。</li></ol><p>目前来说， Redis 会在初始化服务器时， 创建一万个字符串对象， 这些对象包含了<code>从 0 到 9999 的所有整数值</code>， 当服务器需要用到值为 0 到 9999 的字符串对象时， 服务器就会使用这些共享对象， 而不是新创建对象。</p><p><code>【注意】redis只对包含整数值的字符串对象进行共享。</code></p><blockquote><p>尽管共享更复杂的对象可以节约更多的内存，但验证共享对象和目标对象是否相同所需的复杂度就会越高， 消耗的 CPU 时间也会越多</p></blockquote><h2 id="10-7-对象空转时长"><a href="#10-7-对象空转时长" class="headerlink" title="10.7 对象空转时长"></a>10.7 对象空转时长</h2><p>redisObject 结构包含一个属性为 lru 属性， 该属性记录了对象最后一次被命令程序访问的时间：</p><pre><code class="c">redis&gt; SET foo &quot;bar&quot;OKredis&gt; OBJECT IDLETIME foo(integer) 5redis&gt; OBJECT IDLETIME foo(integer) 15redis&gt; GET foo&quot;bar&quot;redis&gt; OBJECT IDLETIME foo(integer) 5</code></pre><p>如果服务器打开了 maxmemory 选项， 并且服务器用于回收内存的算法为 volatile-lru 或者 allkeys-lru ， 那么当服务器占用的内存数超过了 maxmemory 选项所设置的上限值时， 空转时长较高的那部分键会优先被服务器释放， 从而回收内存。</p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>9.Redis数据结构——zipmap</title>
      <link href="/2020/02/20/9-Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-zipmap/"/>
      <url>/2020/02/20/9-Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-zipmap/</url>
      
        <content type="html"><![CDATA[<p><code>【注意】注意，从 2.6 版本开始，Redis使用ziplist 来表示小Hash,而不再使用 zipmap</code></p><p>zipmap压缩字典为节约空间而实现的字符串到字符串映射结构<br>这个数据结构非常节约内存，并且支持复杂度为 O(N) 的查找操作。</p><p>Redis 使用这个数据结构来储存键值对数量不多的 Hash ，一旦键值对的数量超过某个给定值，Hash 的底层表示就会自动转换成哈希表。</p><p>因为很多时候，一个 Hash 都只保存少数几个 key-value 对，<br>所以使用 zipmap 比起直接使用真正的哈希表要节约不少内存。</p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>8.Redis数据结构——ziplist</title>
      <link href="/2020/02/20/8-Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-ziplist/"/>
      <url>/2020/02/20/8-Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-ziplist/</url>
      
        <content type="html"><![CDATA[<h2 id="8-1-什么是ziplist"><a href="#8-1-什么是ziplist" class="headerlink" title="8.1 什么是ziplist"></a>8.1 什么是ziplist</h2><p>压缩列表（ziplist）是列表键和哈希键的底层实现之一。</p><p>当一个列表键只包含少量列表项， 并且每个列表项要么就是小整数值， 要么就是长度比较短的字符串， 那么 Redis 就会使用压缩列表来做列表键的底层实现。</p><h2 id="8-2-数据结构"><a href="#8-2-数据结构" class="headerlink" title="8.2 数据结构"></a>8.2 数据结构</h2><p>在本质上就是一块连续的内存,逻辑上设计成了特殊编码的双端链表</p><pre><code class="c">#file: src/ziplist.c/*  * Ziplist 是为了尽可能地节约内存而设计的特殊编码双端链表。 * Ziplist 可以储存字符串值和整数值， * 其中，整数值被保存为实际的整数，而不是字符数组。 * Ziplist 允许在列表的两端进行 O(1) 复杂度的 push 和 pop 操作。 * 但是，因为这些操作都需要对整个 ziplist 进行内存重分配， * 所以实际的复杂度和 ziplist 占用的内存大小有关。 * ---------------------------------------------------------------------------- * * ZIPLIST OVERALL LAYOUT: * Ziplist 的整体布局： * * The general layout of the ziplist is as follows: * 以下是 ziplist 的一般布局： * * &lt;zlbytes&gt;&lt;zltail&gt;&lt;zllen&gt;&lt;entry&gt;&lt;entry&gt;&lt;zlend&gt; * * &lt;zlbytes&gt; 是一个无符号整数，保存着 ziplist 使用的内存数量。 * 通过这个值，程序可以直接对 ziplist 的内存大小进行调整， * 而无须为了计算 ziplist 的内存大小而遍历整个列表。 * * &lt;zltail&gt; 保存着到达列表中最后一个节点的偏移量。 * 这个偏移量使得对表尾的 pop 操作可以在无须遍历整个列表的情况下进行。 * * &lt;zllen&gt; 保存着列表中的节点数量。 *  * 当 zllen 保存的值大于 2**16-2 时， * 程序需要遍历整个列表才能知道列表实际包含了多少个节点。 * * &lt;zlend&gt; 的长度为 1 字节，值为 255 ，标识列表的末尾。 * * ZIPLIST 节点： * * 每个 ziplist 节点的前面都带有一个 header ，这个 header 包含两部分信息： * * 1)前置节点的长度，在程序从后向前遍历时使用。 * * 2)当前节点所保存的值的类型和长度。 * * 编码前置节点的长度的方法如下： * * 1) 如果前置节点的长度小于 254 字节，那么程序将使用 1 个字节来保存这个长度值。 * * 2) 如果前置节点的长度大于等于 254 字节，那么程序将使用 5 个字节来保存这个长度值： *    a) 第 1 个字节的值将被设为 254 ，用于标识这是一个 5 字节长的长度值。 *    b) 之后的 4 个字节则用于保存前置节点的实际长度。 * * * header 另一部分的内容和节点所保存的值有关。 * * 1) 如果节点保存的是字符串值， *    那么这部分 header 的头 2 个位将保存编码字符串长度所使用的类型， *    而之后跟着的内容则是字符串的实际长度。 * * |00pppppp| - 1 byte *      String value with length less than or equal to 63 bytes (6 bits). *      字符串的长度小于或等于 63 字节。 * |01pppppp|qqqqqqqq| - 2 bytes *      String value with length less than or equal to 16383 bytes (14 bits). *      字符串的长度小于或等于 16383 字节。 * |10______|qqqqqqqq|rrrrrrrr|ssssssss|tttttttt| - 5 bytes *      String value with length greater than or equal to 16384 bytes. *      字符串的长度大于或等于 16384 字节。 * * 2) 如果节点保存的是整数值， *    那么这部分 header 的头 2 位都将被设置为 1 ， *    而之后跟着的 2 位则用于标识节点所保存的整数的类型。 * * |11000000| - 1 byte *      Integer encoded as int16_t (2 bytes). *      节点的值为 int16_t 类型的整数，长度为 2 字节。 * |11010000| - 1 byte *      Integer encoded as int32_t (4 bytes). *      节点的值为 int32_t 类型的整数，长度为 4 字节。 * |11100000| - 1 byte *      Integer encoded as int64_t (8 bytes). *      节点的值为 int64_t 类型的整数，长度为 8 字节。 * |11110000| - 1 byte *      Integer encoded as 24 bit signed (3 bytes). *      节点的值为 24 位（3 字节）长的整数。 * |11111110| - 1 byte *      Integer encoded as 8 bit signed (1 byte). *      节点的值为 8 位（1 字节）长的整数。 * |1111xxxx| - (with xxxx between 0000 and 1101) immediate 4 bit integer. *      Unsigned integer from 0 to 12. The encoded value is actually from *      1 to 13 because 0000 and 1111 can not be used, so 1 should be *      subtracted from the encoded 4 bit value to obtain the right value. *      节点的值为介于 0 至 12 之间的无符号整数。 *      因为 0000 和 1111 都不能使用，所以位的实际值将是 1 至 13 。 *      程序在取得这 4 个位的值之后，还需要减去 1 ，才能计算出正确的值。 *      比如说，如果位的值为 0001 = 1 ，那么程序返回的值将是 1 - 1 = 0 。 * |11111111| - End of ziplist. *      ziplist 的结尾标识 * * All the integers are represented in little endian byte order. * * 所有整数都表示为小端字节序。 *</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/ziplist.png" alt=""></p><h2 id="8-3-数据插入"><a href="#8-3-数据插入" class="headerlink" title="8.3 数据插入"></a>8.3 数据插入</h2><pre><code class="c">#file: src/ziplist.c/* * 根据指针 p 所指定的位置，将长度为 slen 的字符串 s 插入到 zl 中。 * 函数的返回值为完成插入操作之后的 ziplist * T = O(N^2) */static unsigned char *__ziplistInsert(unsigned char *zl, unsigned char *p, unsigned char *s, unsigned int slen) {    // 记录当前 ziplist 的长度    size_t curlen = intrev32ifbe(ZIPLIST_BYTES(zl)), reqlen, prevlen = 0;    size_t offset;    int nextdiff = 0;    unsigned char encoding = 0;    long long value = 123456789; /* initialized to avoid warning. Using a value                                    that is easy to see if for some reason                                    we use it uninitialized. */    zlentry entry, tail;    /* Find out prevlen for the entry that is inserted. */    if (p[0] != ZIP_END) {        // 如果 p[0] 不指向列表末端，说明列表非空，并且 p 正指向列表的其中一个节点        // 那么取出 p 所指向节点的信息，并将它保存到 entry 结构中        // 然后用 prevlen 变量记录前置节点的长度        // （当插入新节点之后 p 所指向的节点就成了新节点的前置节点）        // T = O(1)        entry = zipEntry(p);        prevlen = entry.prevrawlen;    } else {        // 如果 p 指向表尾末端，那么程序需要检查列表是否为：        // 1)如果 ptail 也指向 ZIP_END ，那么列表为空；        // 2)如果列表不为空，那么 ptail 将指向列表的最后一个节点。        unsigned char *ptail = ZIPLIST_ENTRY_TAIL(zl);        if (ptail[0] != ZIP_END) {            // 表尾节点为新节点的前置节点            // 取出表尾节点的长度            // T = O(1)            prevlen = zipRawEntryLength(ptail);        }    }    // 尝试看能否将输入字符串转换为整数，如果成功的话：    // 1)value 将保存转换后的整数值    // 2)encoding 则保存适用于 value 的编码方式    // 无论使用什么编码， reqlen 都保存节点值的长度    // T = O(N)    if (zipTryEncoding(s,slen,&amp;value,&amp;encoding)) {        /* &#39;encoding&#39; is set to the appropriate integer encoding */        reqlen = zipIntSize(encoding);    } else {        /* &#39;encoding&#39; is untouched, however zipEncodeLength will use the         * string length to figure out how to encode it. */        reqlen = slen;    }    /* We need space for both the length of the previous entry and     * the length of the payload. */    // 计算编码前置节点的长度所需的大小    // T = O(1)    reqlen += zipPrevEncodeLength(NULL,prevlen);    // 计算编码当前节点值所需的大小    // T = O(1)    reqlen += zipEncodeLength(NULL,encoding,slen);    // 只要新节点不是被添加到列表末端，    // 那么程序就需要检查看 p 所指向的节点（的 header）能否编码新节点的长度。    // nextdiff 保存了新旧编码之间的字节大小差，如果这个值大于 0     // 那么说明需要对 p 所指向的节点（的 header ）进行扩展    // T = O(1)    nextdiff = (p[0] != ZIP_END) ? zipPrevLenByteDiff(p,reqlen) : 0;    // 因为重分配空间可能会改变 zl 的地址    // 所以在分配之前，需要记录 zl 到 p 的偏移量，然后在分配之后依靠偏移量还原 p     offset = p-zl;    // curlen 是 ziplist 原来的长度    // reqlen 是整个新节点的长度    // nextdiff 是新节点的后继节点扩展 header 的长度（要么 0 字节，要么 4 个字节）    // T = O(N)    zl = ziplistResize(zl,curlen+reqlen+nextdiff);    p = zl+offset;    /* Apply memory move when necessary and update tail offset. */    if (p[0] != ZIP_END) {        // 新元素之后还有节点，因为新元素的加入，需要对这些原有节点进行调整        /* Subtract one because of the ZIP_END bytes */        // 移动现有元素，为新元素的插入空间腾出位置        // T = O(N)        memmove(p+reqlen,p-nextdiff,curlen-offset-1+nextdiff);        /* Encode this entry&#39;s raw length in the next entry. */        // 将新节点的长度编码至后置节点        // p+reqlen 定位到后置节点        // reqlen 是新节点的长度        // T = O(1)        zipPrevEncodeLength(p+reqlen,reqlen);        /* Update offset for tail */        // 更新到达表尾的偏移量，将新节点的长度也算上        ZIPLIST_TAIL_OFFSET(zl) =            intrev32ifbe(intrev32ifbe(ZIPLIST_TAIL_OFFSET(zl))+reqlen);        // 如果新节点的后面有多于一个节点        // 那么程序需要将 nextdiff 记录的字节数也计算到表尾偏移量中        // 这样才能让表尾偏移量正确对齐表尾节点        // T = O(1)        tail = zipEntry(p+reqlen);        if (p[reqlen+tail.headersize+tail.len] != ZIP_END) {            ZIPLIST_TAIL_OFFSET(zl) =                intrev32ifbe(intrev32ifbe(ZIPLIST_TAIL_OFFSET(zl))+nextdiff);        }    } else {        // 新元素是新的表尾节点        ZIPLIST_TAIL_OFFSET(zl) = intrev32ifbe(p-zl);    }    // 当 nextdiff != 0 时，新节点的后继节点的（header 部分）长度已经被改变，    // 所以需要级联地更新后续的节点    if (nextdiff != 0) {        offset = p-zl;        // T  = O(N^2)        zl = __ziplistCascadeUpdate(zl,p+reqlen);        p = zl+offset;    }    // 一切搞定，将前置节点的长度写入新节点的 header    p += zipPrevEncodeLength(p,prevlen);    // 将节点值的长度写入新节点的 header    p += zipEncodeLength(p,encoding,slen);    // 写入节点值    if (ZIP_IS_STR(encoding)) {        // T = O(N)        memcpy(p,s,slen);    } else {        // T = O(1)        zipSaveInteger(p,value,encoding);    }    // 更新列表的节点数量计数器    // T = O(1)    ZIPLIST_INCR_LENGTH(zl,1);    return zl;}</code></pre><h2 id="8-4-数据删除"><a href="#8-4-数据删除" class="headerlink" title="8.4 数据删除"></a>8.4 数据删除</h2><pre><code class="c">#file: src/ziplist.c/*  * 从位置 p 开始，连续删除 num 个节点。 * 函数的返回值为处理删除操作之后的 ziplist 。 * * T = O(N^2) */static unsigned char *__ziplistDelete(unsigned char *zl, unsigned char *p, unsigned int num) {    unsigned int i, totlen, deleted = 0;    size_t offset;    int nextdiff = 0;    zlentry first, tail;    // 计算被删除节点总共占用的内存字节数    // 以及被删除节点的总个数    // T = O(N)    first = zipEntry(p);    for (i = 0; p[0] != ZIP_END &amp;&amp; i &lt; num; i++) {        p += zipRawEntryLength(p);        deleted++;    }    // totlen 是所有被删除节点总共占用的内存字节数    totlen = p-first.p;    if (totlen &gt; 0) {        if (p[0] != ZIP_END) {            // 执行这里，表示被删除节点之后仍然有节点存在            // 因为位于被删除范围之后的第一个节点的 header 部分的大小            // 可能容纳不了新的前置节点，所以需要计算新旧前置节点之间的字节数差            // T = O(1)            nextdiff = zipPrevLenByteDiff(p,first.prevrawlen);            // 如果有需要的话，将指针 p 后退 nextdiff 字节，为新 header 空出空间            p -= nextdiff;            // 将 first 的前置节点的长度编码至 p 中            // T = O(1)            zipPrevEncodeLength(p,first.prevrawlen);            // 更新到达表尾的偏移量            // T = O(1)            ZIPLIST_TAIL_OFFSET(zl) =                intrev32ifbe(intrev32ifbe(ZIPLIST_TAIL_OFFSET(zl))-totlen);            // 如果被删除节点之后，有多于一个节点            // 那么程序需要将 nextdiff 记录的字节数也计算到表尾偏移量中            // 这样才能让表尾偏移量正确对齐表尾节点            // T = O(1)            tail = zipEntry(p);            if (p[tail.headersize+tail.len] != ZIP_END) {                ZIPLIST_TAIL_OFFSET(zl) =                   intrev32ifbe(intrev32ifbe(ZIPLIST_TAIL_OFFSET(zl))+nextdiff);            }            // 从表尾向表头移动数据，覆盖被删除节点的数据            // T = O(N)            memmove(first.p,p,                intrev32ifbe(ZIPLIST_BYTES(zl))-(p-zl)-1);        } else {            // 执行这里，表示被删除节点之后已经没有其他节点了            // T = O(1)            ZIPLIST_TAIL_OFFSET(zl) =                intrev32ifbe((first.p-zl)-first.prevrawlen);        }        // 缩小并更新 ziplist 的长度        offset = first.p-zl;        zl = ziplistResize(zl, intrev32ifbe(ZIPLIST_BYTES(zl))-totlen+nextdiff);        ZIPLIST_INCR_LENGTH(zl,-deleted);        p = zl+offset;        // 如果 p 所指向的节点的大小已经变更，那么进行级联更新        // 检查 p 之后的所有节点是否符合 ziplist 的编码要求        // T = O(N^2)        if (nextdiff != 0)            zl = __ziplistCascadeUpdate(zl,p);    }    return zl;}</code></pre><h2 id="8-5-联级更新"><a href="#8-5-联级更新" class="headerlink" title="8.5 联级更新"></a>8.5 联级更新</h2><p>我们看到插入和删除的时候都调用了<code>__ziplistCascadeUpdate</code>函数来更新后面节点的大小</p><pre><code class="c">#file: src/ziplist.c/* * 当将一个新节点添加到某个节点之前的时候， * 如果原节点的 header 空间不足以保存新节点的长度， * 那么就需要对原节点的 header 空间进行扩展（从 1 字节扩展到 5 字节）。 * * 但是，当对原节点进行扩展之后，原节点的下一个节点的 prevlen 可能出现空间不足， * 这种情况在多个连续节点的长度都接近 ZIP_BIGLEN 时可能发生。 * * 这个函数就用于检查并修复后续节点的空间问题。 * * 反过来说， * 因为节点的长度变小而引起的连续缩小也是可能出现的， * 不过，为了避免扩展-缩小-扩展-缩小这样的情况反复出现（flapping，抖动）， * 我们不处理这种情况，而是任由 prevlen 比所需的长度更长。 * * 注意，程序的检查是针对 p 的后续节点，而不是 p 所指向的节点。 * 因为节点 p 在传入之前已经完成了所需的空间扩展工作。 * * T = O(N^2) */static unsigned char *__ziplistCascadeUpdate(unsigned char *zl, unsigned char *p) {    size_t curlen = intrev32ifbe(ZIPLIST_BYTES(zl)), rawlen, rawlensize;    size_t offset, noffset, extra;    unsigned char *np;    zlentry cur, next;    // T = O(N^2)    while (p[0] != ZIP_END) {        // 将 p 所指向的节点的信息保存到 cur 结构中        cur = zipEntry(p);        // 当前节点的长度        rawlen = cur.headersize + cur.len;        // 计算编码当前节点的长度所需的字节数        // T = O(1)        rawlensize = zipPrevEncodeLength(NULL,rawlen);        // 如果已经没有后续空间需要更新了，跳出        if (p[rawlen] == ZIP_END) break;        // 取出后续节点的信息，保存到 next 结构中        // T = O(1)        next = zipEntry(p+rawlen);        // 后续节点编码当前节点的空间已经足够，无须再进行任何处理，跳出        // 可以证明，只要遇到一个空间足够的节点，        // 那么这个节点之后的所有节点的空间都是足够的        if (next.prevrawlen == rawlen) break;        if (next.prevrawlensize &lt; rawlensize) {            // 执行到这里，表示 next 空间的大小不足以编码 cur 的长度            // 所以程序需要对 next 节点的（header 部分）空间进行扩展            // 记录 p 的偏移量            offset = p-zl;            // 计算需要增加的节点数量            extra = rawlensize-next.prevrawlensize;            // 扩展 zl 的大小            // T = O(N)            zl = ziplistResize(zl,curlen+extra);            // 还原指针 p            p = zl+offset;            // 记录下一节点的偏移量            np = p+rawlen;            noffset = np-zl;            // 当 next 节点不是表尾节点时，更新列表到表尾节点的偏移量            //             // 不用更新的情况（next 为表尾节点）：            //            // |     | next |      ==&gt;    |     | new next          |            //       ^                          ^            //       |                          |            //     tail                        tail            //            // 需要更新的情况（next 不是表尾节点）：            //            // | next |     |   ==&gt;     | new next          |     |            //        ^                        ^            //        |                        |            //    old tail                 old tail            //             // 更新之后：            //            // | new next          |     |            //                     ^            //                     |            //                  new tail            // T = O(1)            if ((zl+intrev32ifbe(ZIPLIST_TAIL_OFFSET(zl))) != np) {                ZIPLIST_TAIL_OFFSET(zl) =                    intrev32ifbe(intrev32ifbe(ZIPLIST_TAIL_OFFSET(zl))+extra);            }            /* Move the tail to the back. */            // 向后移动 cur 节点之后的数据，为 cur 的新 header 腾出空间            //            // 示例：            //            // | header | value |  ==&gt;  | header |    | value |  ==&gt;  | header      | value |            //                                   |&lt;--&gt;|            //                            为新 header 腾出的空间            // T = O(N)            memmove(np+rawlensize,                np+next.prevrawlensize,                curlen-noffset-next.prevrawlensize-1);            // 将新的前一节点长度值编码进新的 next 节点的 header            // T = O(1)            zipPrevEncodeLength(np,rawlen);            /* Advance the cursor */            // 移动指针，继续处理下个节点            p += rawlen;            curlen += extra;        } else {            if (next.prevrawlensize &gt; rawlensize) {                /* This would result in shrinking, which we want to avoid.                 * So, set &quot;rawlen&quot; in the available bytes. */                // 执行到这里，说明 next 节点编码前置节点的 header 空间有 5 字节                // 而编码 rawlen 只需要 1 字节                // 但是程序不会对 next 进行缩小，                // 所以这里只将 rawlen 写入 5 字节的 header 中就算了。                // T = O(1)                zipPrevEncodeLengthForceLarge(p+rawlen,rawlen);            } else {                // 运行到这里，                // 说明 cur 节点的长度正好可以编码到 next 节点的 header 中                // T = O(1)                zipPrevEncodeLength(p+rawlen,rawlen);            }            /* Stop here, as the raw length of &quot;next&quot; has not changed. */            break;        }    }    return zl;}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>6.Redis数据结构——跳表</title>
      <link href="/2020/02/19/6-Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E8%B7%B3%E8%A1%A8/"/>
      <url>/2020/02/19/6-Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E8%B7%B3%E8%A1%A8/</url>
      
        <content type="html"><![CDATA[<h2 id="6-1-什么是跳表"><a href="#6-1-什么是跳表" class="headerlink" title="6.1 什么是跳表"></a>6.1 什么是跳表</h2><p>跳表全称叫做跳跃表，简称跳表。是redis有序集合的底层实现</p><p>redis 的跳跃表实现由 zskiplist 和 zskiplistNode 两个结构组成， 其中 zskiplist 用于保存跳跃表信息（比如表头节点、表尾节点、长度）， 而 zskiplistNode 则用于表示跳跃表节点。<br>每个跳跃表节点的层高都是 1 至 32 之间的随机数。<br>在同一个跳跃表中， 多个节点可以包含相同的分值， 但每个节点的成员对象必须是唯一的。<br>跳跃表中的节点按照分值大小进行排序， 当分值相同时， 节点按照成员对象的大小进行排序。</p><h2 id="6-2-跳表的数据结构"><a href="#6-2-跳表的数据结构" class="headerlink" title="6.2 跳表的数据结构"></a>6.2 跳表的数据结构</h2><pre><code class="c">#file : reids.htypedef struct zskiplistNode {    // 成员对象    robj *obj;    // 分值   double score;    // 后退指针    struct zskiplistNode *backward;    // 层    struct zskiplistLevel {        // 前进指针        struct zskiplistNode *forward;        // 跨度        unsigned int span;    } level[];} zskiplistNode;/* * 跳跃表 */typedef struct zskiplist {    // 表头节点和表尾节点    struct zskiplistNode *header, *tail;    // 表中节点的数量    unsigned long length;    // 表中层数最大的节点的层数    int level;} zskiplist;</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/skipnode.png" alt=""></p><h2 id="6-3-跳表的初始化与插入"><a href="#6-3-跳表的初始化与插入" class="headerlink" title="6.3 跳表的初始化与插入"></a>6.3 跳表的初始化与插入</h2><pre><code class="c">#file : src/t_zset.c#define ZSKIPLIST_MAXLEVEL 32/* * 创建并返回一个新的跳跃表 * T = O(1) */zskiplist *zslCreate(void) {    int j;    zskiplist *zsl;    // 分配空间    zsl = zmalloc(sizeof(*zsl));    // 设置高度和起始层数    zsl-&gt;level = 1;    zsl-&gt;length = 0;    // 初始化表头节点    // T = O(1)    zsl-&gt;header = zslCreateNode(ZSKIPLIST_MAXLEVEL,0,NULL);    for (j = 0; j &lt; ZSKIPLIST_MAXLEVEL; j++) {        zsl-&gt;header-&gt;level[j].forward = NULL;        zsl-&gt;header-&gt;level[j].span = 0;    }    zsl-&gt;header-&gt;backward = NULL;    // 设置表尾    zsl-&gt;tail = NULL;    return zsl;}/* * 创建一个层数为 level 的跳跃表节点， * 并将节点的成员对象设置为 obj ，分值设置为 score 。 * 返回值为新创建的跳跃表节点 * T = O(1) */zskiplistNode *zslCreateNode(int level, double score, robj *obj) {    // 分配空间    zskiplistNode *zn = zmalloc(sizeof(*zn)+level*sizeof(struct zskiplistLevel));    // 设置属性    zn-&gt;score = score;    zn-&gt;obj = obj;    return zn;}/* * 创建一个成员为 obj ，分值为 score 的新节点， * 并将这个新节点插入到跳跃表 zsl 中。 * 函数的返回值为新节点。 * T_wrost = O(N^2), T_avg = O(NlogN) */zskiplistNode *zslInsert(zskiplist *zsl, double score, robj *obj) {    zskiplistNode *update[ZSKIPLIST_MAXLEVEL], *x;    unsigned int rank[ZSKIPLIST_MAXLEVEL];    int i, level;    //判断给的分值是够合理    redisAssert(!isnan(score));    // 在各个层查找节点的插入位置    // T_wrost = O(N^2), T_avg = O(N log N)    x = zsl-&gt;header;    for (i = zsl-&gt;level-1; i &gt;= 0; i--) {        // 如果 i 不是 zsl-&gt;level-1 层        // 那么 i 层的起始 rank 值为 i+1 层的 rank 值        // 各个层的 rank 值一层层累积        // 最终 rank[0] 的值加一就是新节点的前置节点的排位        // rank[0] 会在后面成为计算 span 值和 rank 值的基础        rank[i] = i == (zsl-&gt;level-1) ? 0 : rank[i+1];        // 沿着前进指针遍历跳跃表        // T_wrost = O(N^2), T_avg = O(N log N)        while (x-&gt;level[i].forward &amp;&amp;            (x-&gt;level[i].forward-&gt;score &lt; score ||                // 比对分值                (x-&gt;level[i].forward-&gt;score == score &amp;&amp;                // 比对成员， T = O(N)                compareStringObjects(x-&gt;level[i].forward-&gt;obj,obj) &lt; 0))) {            // 记录沿途跨越了多少个节点            rank[i] += x-&gt;level[i].span;            // 移动至下一指针            x = x-&gt;level[i].forward;        }        // 记录将要和新节点相连接的节点        update[i] = x;    }    /*      * zslInsert() 的调用者会确保同分值且同成员的元素不会出现，     * 所以这里不需要进一步进行检查，可以直接创建新元素。     */    // 获取一个随机值作为新节点的层数    // T = O(N)    level = zslRandomLevel();    // 如果新节点的层数比表中其他节点的层数都要大    // 那么初始化表头节点中未使用的层，并将它们记录到 update 数组中    // 将来也指向新节点    if (level &gt; zsl-&gt;level) {        // 初始化未使用层        // T = O(1)        for (i = zsl-&gt;level; i &lt; level; i++) {            rank[i] = 0;            update[i] = zsl-&gt;header;            update[i]-&gt;level[i].span = zsl-&gt;length;        }        // 更新表中节点最大层数        zsl-&gt;level = level;    }    // 创建新节点    x = zslCreateNode(level,score,obj);    // 将前面记录的指针指向新节点，并做相应的设置    // T = O(1)    for (i = 0; i &lt; level; i++) {        // 设置新节点的 forward 指针        x-&gt;level[i].forward = update[i]-&gt;level[i].forward;        // 将沿途记录的各个节点的 forward 指针指向新节点        update[i]-&gt;level[i].forward = x;        /* update span covered by update[i] as x is inserted here */        // 计算新节点跨越的节点数量        x-&gt;level[i].span = update[i]-&gt;level[i].span - (rank[0] - rank[i]);        // 更新新节点插入之后，沿途节点的 span 值        // 其中的 +1 计算的是新节点        update[i]-&gt;level[i].span = (rank[0] - rank[i]) + 1;    }    /* increment span for untouched levels */    // 未接触的节点的 span 值也需要增一，这些节点直接从表头指向新节点    // T = O(1)    for (i = level; i &lt; zsl-&gt;level; i++) {        update[i]-&gt;level[i].span++;    }    // 设置新节点的后退指针    x-&gt;backward = (update[0] == zsl-&gt;header) ? NULL : update[0];    if (x-&gt;level[0].forward)        x-&gt;level[0].forward-&gt;backward = x;    else        zsl-&gt;tail = x;    // 跳跃表的节点计数增一    zsl-&gt;length++;    return x;}</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/skiplist.png" alt=""></p><h2 id="6-4-跳表的层数确定"><a href="#6-4-跳表的层数确定" class="headerlink" title="6.4 跳表的层数确定"></a>6.4 跳表的层数确定</h2><p>理论上每层的比例为1:2,但是在实际使用中，我们的链表是通过多次插入/删除形成的，换句话说是“动态”的。这个比例就被被破坏了。因此跳表（skip list）表示，我们就不强制要求 1:2 了，一个节点要不要被索引，建几层的索引，都在节点插入时由<code>zslRandomLevel</code>决定:</p><pre><code class="c">#file : src/t_zset.c/*  * 返回一个随机值，用作新跳跃表节点的层数。 * 返回值介乎 1 和 ZSKIPLIST_MAXLEVEL 之间（包含 ZSKIPLIST_MAXLEVEL）， * 根据随机算法所使用的幂次定律，越大的值生成的几率越小。 * T = O(N) */int zslRandomLevel(void) {    int level = 1;    while ((random()&amp;0xFFFF) &lt; (ZSKIPLIST_P * 0xFFFF))        level += 1;    return (level&lt;ZSKIPLIST_MAXLEVEL) ? level : ZSKIPLIST_MAXLEVEL;}</code></pre><h2 id="6-5-删除跳表节点"><a href="#6-5-删除跳表节点" class="headerlink" title="6.5 删除跳表节点"></a>6.5 删除跳表节点</h2><pre><code class="c">#file : src/t_zset.c/*  * 内部删除函数， * 被 zslDelete 、 zslDeleteRangeByScore 和 zslDeleteByRank 等函数调用。 * T = O(1) */void zslDeleteNode(zskiplist *zsl, zskiplistNode *x, zskiplistNode **update) {    int i;    // 更新所有和被删除节点 x 有关的节点的指针，解除它们之间的关系    // T = O(1)    for (i = 0; i &lt; zsl-&gt;level; i++) {        if (update[i]-&gt;level[i].forward == x) {            update[i]-&gt;level[i].span += x-&gt;level[i].span - 1;            update[i]-&gt;level[i].forward = x-&gt;level[i].forward;        } else {            update[i]-&gt;level[i].span -= 1;        }    }    // 更新被删除节点 x 的前进和后退指针    if (x-&gt;level[0].forward) {        x-&gt;level[0].forward-&gt;backward = x-&gt;backward;    } else {        zsl-&gt;tail = x-&gt;backward;    }    // 更新跳跃表最大层数（只在被删除节点是跳跃表中最高的节点时才执行）    // T = O(1)    while(zsl-&gt;level &gt; 1 &amp;&amp; zsl-&gt;header-&gt;level[zsl-&gt;level-1].forward == NULL)        zsl-&gt;level--;    // 跳跃表节点计数器减一    zsl-&gt;length--;}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>7.Redis数据结构——iniset</title>
      <link href="/2020/02/19/7-Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-iniset/"/>
      <url>/2020/02/19/7-Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-iniset/</url>
      
        <content type="html"><![CDATA[<h2 id="7-1-什么是iniset"><a href="#7-1-什么是iniset" class="headerlink" title="7.1 什么是iniset"></a>7.1 什么是iniset</h2><p>整数集合（intset）是集合键的底层实现之一,当一个集合只包含整数值元素,并且这个集合的元素数量不多时,Redis就会使用整数集合作为集合键的底层实现</p><h2 id="7-1-数据结构"><a href="#7-1-数据结构" class="headerlink" title="7.1 数据结构"></a>7.1 数据结构</h2><pre><code class="c">#file: src/intset.htypedef struct intset {    // 编码方式    uint32_t encoding;    // 集合包含的元素数量    uint32_t length;    // 保存元素的数组    int8_t contents[];} intset;/* * encoding的取值　intset 的编码方式 */#define INTSET_ENC_INT16 (sizeof(int16_t))#define INTSET_ENC_INT32 (sizeof(int32_t))#define INTSET_ENC_INT64 (sizeof(int64_t))</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/intsetadd.png" alt=""></p><h2 id="7-2-centent类型"><a href="#7-2-centent类型" class="headerlink" title="7.2 centent类型"></a>7.2 centent类型</h2><p><code>struct iniset</code>里的<code>content</code>数据的真正类型取决于encoding的属性值</p><pre><code class="c">#file: src/intset.c/*  * 返回适用于传入值 v 的编码方式 * T = O(1) */static uint8_t _intsetValueEncoding(int64_t v) {    if (v &lt; INT32_MIN || v &gt; INT32_MAX)        return INTSET_ENC_INT64;    else if (v &lt; INT16_MIN || v &gt; INT16_MAX)        return INTSET_ENC_INT32;    else        return INTSET_ENC_INT16;}</code></pre><ul><li>如果 encoding 属性的值为 INTSET_ENC_INT16 ， 那么 contents 就是一个 int16_t 类型的数组， 数组里的每个项都是一个 int16_t 类型的整数值 （最小值为 -32,768 ，最大值为 32,767 ）。</li><li>如果 encoding 属性的值为 INTSET_ENC_INT32 ， 那么 contents 就是一个 int32_t 类型的数组， 数组里的每个项都是一个 int32_t 类型的整数值 （最小值为 -2,147,483,648 ，最大值为 2,147,483,647 ）。</li><li>如果 encoding 属性的值为 INTSET_ENC_INT64 ， 那么 contents 就是一个 int64_t 类型的数组， 数组里的每个项都是一个 int64_t 类型的整数值 （最小值为 -9,223,372,036,854,775,808 ，最大值为 9,223,372,036,854,775,807 ）。</li></ul><h2 id="7-3-类型升级"><a href="#7-3-类型升级" class="headerlink" title="7.3 类型升级"></a>7.3 类型升级</h2><p>每当我们要将一个新元素添加到整数集合里面， 并且新元素的类型比整数集合现有所有元素的类型都要长时， 整数集合需要先进行升级（upgrade）， 然后才能将新元素添加到整数集合里面。</p><p>升级整数集合并添加新元素共分为三步进行：</p><ul><li>根据新元素的类型， 扩展整数集合底层数组的空间大小， 并为新元素分配空间。</li><li>将底层数组现有的所有元素都转换成与新元素相同的类型， 并将类型转换后的元素放置到正确的位上， 而且在放置元素的过程中，需要继续维持底层数组的有序性质不变。</li><li>将新元素添加到底层数组里面。</li></ul><pre><code class="c">#file: src/intset.c/*  * 根据值 value 所使用的编码方式，对整数集合的编码进行升级， * 并将值 value 添加到升级后的整数集合中。 * 返回值：添加新元素之后的整数集合 * T = O(N) */static intset *intsetUpgradeAndAdd(intset *is, int64_t value) {    // 当前的编码方式    uint8_t curenc = intrev32ifbe(is-&gt;encoding);    // 新值所需的编码方式    uint8_t newenc = _intsetValueEncoding(value);    // 当前集合的元素数量    int length = intrev32ifbe(is-&gt;length);    // 根据 value 的值，决定是将它添加到底层数组的最前端还是最后端    // 注意，因为 value 的编码比集合原有的其他元素的编码都要大    // 所以 value 要么大于集合中的所有元素，要么小于集合中的所有元素    // 因此，value 只能添加到底层数组的最前端或最后端    int prepend = value &lt; 0 ? 1 : 0;    /* First set new encoding and resize */    // 更新集合的编码方式    is-&gt;encoding = intrev32ifbe(newenc);    // 根据新编码对集合（的底层数组）进行空间调整    // T = O(N)    is = intsetResize(is,intrev32ifbe(is-&gt;length)+1);    // 根据集合原来的编码方式，从底层数组中取出集合元素    // 然后再将元素以新编码的方式添加到集合中    // 当完成了这个步骤之后，集合中所有原有的元素就完成了从旧编码到新编码的转换    // 因为新分配的空间都放在数组的后端，所以程序先从后端向前端移动元素    // 举个例子，假设原来有 curenc 编码的三个元素，它们在数组中排列如下：    // | x | y | z |     // 当程序对数组进行重分配之后，数组就被扩容了（符号 ？ 表示未使用的内存）：    // | x | y | z | ? |   ?   |   ?   |    // 这时程序从数组后端开始，重新插入元素：    // | x | y | z | ? |   z   |   ?   |    // | x | y |   y   |   z   |   ?   |    // |   x   |   y   |   z   |   ?   |    // 最后，程序可以将新元素添加到最后 ？ 号标示的位置中：    // |   x   |   y   |   z   |  new  |    // 上面演示的是新元素比原来的所有元素都大的情况，也即是 prepend == 0    // 当新元素比原来的所有元素都小时（prepend == 1），调整的过程如下：    // | x | y | z | ? |   ?   |   ?   |    // | x | y | z | ? |   ?   |   z   |    // | x | y | z | ? |   y   |   z   |    // | x | y |   x   |   y   |   z   |    // 当添加新值时，原本的 | x | y | 的数据将被新值代替    // |  new  |   x   |   y   |   z   |    // T = O(N)    while(length--)        _intsetSet(is,length+prepend,_intsetGetEncoded(is,length,curenc));    /* Set the value at the beginning or the end. */    // 设置新值，根据 prepend 的值来决定是添加到数组头还是数组尾    if (prepend)        _intsetSet(is,0,value);    else        _intsetSet(is,intrev32ifbe(is-&gt;length),value);    // 更新整数集合的元素数量    is-&gt;length = intrev32ifbe(intrev32ifbe(is-&gt;length)+1);    return is;}</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/intsetupgrade.png" alt=""></p><h2 id="7-4-类型降级"><a href="#7-4-类型降级" class="headerlink" title="7.4 类型降级"></a>7.4 类型降级</h2><p>我们在起删除给定元素的代码中可以发现:<code>intset不支持降级操作!</code></p><pre><code class="c">/* * 从整数集合中删除值 value 。 * *success 的值指示删除是否成功： * - 因值不存在而造成删除失败时该值为 0 。 * - 删除成功时该值为 1 。 * T = O(N) */intset *intsetRemove(intset *is, int64_t value, int *success) {    // 计算 value 的编码方式    uint8_t valenc = _intsetValueEncoding(value);    uint32_t pos;    // 默认设置标识值为删除失败    if (success) *success = 0;    // 当 value 的编码大小小于或等于集合的当前编码方式（说明 value 有可能存在于集合）    // 并且 intsetSearch 的结果为真，那么执行删除    // T = O(log N)    if (valenc &lt;= intrev32ifbe(is-&gt;encoding) &amp;&amp; intsetSearch(is,value,&amp;pos)) {        // 取出集合当前的元素数量        uint32_t len = intrev32ifbe(is-&gt;length);        /* We know we can delete */        // 设置标识值为删除成功        if (success) *success = 1;        /* Overwrite value with tail and update length */        // 如果 value 不是位于数组的末尾        // 那么需要对原本位于 value 之后的元素进行移动        //        // 举个例子，如果数组表示如下，而 b 为删除的目标        // | a | b | c | d |        // 那么 intsetMoveTail 将 b 之后的所有数据向前移动一个元素的空间，        // 覆盖 b 原来的数据        // | a | c | d | d |        // 之后 intsetResize 缩小内存大小时，        // 数组末尾多出来的一个元素的空间将被移除        // | a | c | d |        if (pos &lt; (len-1)) intsetMoveTail(is,pos+1,pos);        // 缩小数组的大小，移除被删除元素占用的空间        // T = O(N)        is = intsetResize(is,len-1);        // 更新集合的元素数量        is-&gt;length = intrev32ifbe(len-1);    }    return is;}</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/intsetdel.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>5.Redis数据结构——字典</title>
      <link href="/2020/02/19/5-Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E5%AD%97%E5%85%B8/"/>
      <url>/2020/02/19/5-Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E5%AD%97%E5%85%B8/</url>
      
        <content type="html"><![CDATA[<h2 id="5-1-什么是字典"><a href="#5-1-什么是字典" class="headerlink" title="5.1 什么是字典"></a>5.1 什么是字典</h2><p>字典经常作为一种数据结构内置在很多高级编程语言里面， 但 Redis 所使用的 C 语言并没有内置这种数据结构， 因此 Redis 构建了自己的字典实现。</p><p>字典在 Redis 中的应用相当广泛， 比如 Redis 的数据库就是使用字典来作为底层实现的， 对数据库的增、删、查、改操作也是构建在对字典的操作之上的。</p><p>Redis 的字典使用哈希表作为底层实现， 一个哈希表里面可以有多个哈希表节点， 而每个哈希表节点就保存了字典中的一个键值对。</p><h2 id="5-2-dict-hash-dictEntry数据结构"><a href="#5-2-dict-hash-dictEntry数据结构" class="headerlink" title="5.2 dict hash dictEntry数据结构"></a>5.2 dict hash dictEntry数据结构</h2><pre><code class="c">#file: src/dict.h/* * 字典 */typedef struct dict {    // 类型特定函数    dictType *type;    // 私有数据    void *privdata;    // 哈希表    dictht ht[2];    // rehash 索引    // 当 rehash 不在进行时，值为 -1    int rehashidx; /* rehashing not in progress if rehashidx == -1 */    // 目前正在运行的安全迭代器的数量    int iterators; /* number of iterators currently running */} dict;/* * 哈希表 * 每个字典都使用两个哈希表，从而实现渐进式 rehash 。 */typedef struct dictht {       // 哈希表数组    dictEntry **table;    // 哈希表大小    // 哈希表的大小总是 2 的某个次方，并且哈希表使用链表来解决冲突    unsigned long size;    // 哈希表大小掩码，用于计算索引值    // 总是等于 size - 1    unsigned long sizemask;    // 该哈希表已有节点的数量    unsigned long used;} dictht;/* * 哈希表节点 */typedef struct dictEntry {    // 键    void *key;    // 值    union {        void *val;        uint64_t u64;        int64_t s64;    } v;    // 指向下个哈希表节点，形成链表    struct dictEntry *next;} dictEntry;</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/dict.png" alt=""></p><h2 id="5-3-添加字典"><a href="#5-3-添加字典" class="headerlink" title="5.3 添加字典"></a>5.3 添加字典</h2><pre><code class="c"># file:src/dict.c/* * 尝试将给定键值对添加到字典中 * 只有给定键key不存在于字典时,添加操作才会成功 * 添加成功返回DICT_OK ，失败返回 DICT_ERR * 最坏T=O(N),平均O(1)  */int dictAdd(dict *d, void *key, void *val){    // 尝试添加键到字典，并返回包含了这个键的新哈希节点    dictEntry *entry = dictAddRaw(d,key);    // 键已存在，添加失败    if (!entry) return DICT_ERR;    // 键不存在，设置节点的值    // T = O(1)    dictSetVal(d, entry, val);    // 添加成功    return DICT_OK;}/* * 尝试将键插入到字典中 * 如果键已经在字典存在，那么返回 NULL * 如果键不存在，那么程序创建新的哈希节点， * 将节点和键关联，并插入到字典，然后返回节点本身 */dictEntry *dictAddRaw(dict *d, void *key){    int index;    dictEntry *entry;    dictht *ht;    // 如果条件允许的话，进行单步 rehash    if (dictIsRehashing(d)) _dictRehashStep(d);    // 计算键在哈希表中的索引值 使用MurmurHash算法    // 如果值为 -1 ，那么表示键已经存在    // T = O(N)    if ((index = _dictKeyIndex(d, key)) == -1)        return NULL;    // T = O(1)    // 如果字典正在 rehash ，那么将新键添加到 1 号哈希表    // 否则，将新键添加到 0 号哈希表    ht = dictIsRehashing(d) ? &amp;d-&gt;ht[1] : &amp;d-&gt;ht[0];    // 为新节点分配空间    entry = zmalloc(sizeof(*entry));    // 将新节点插入到链表表头    entry-&gt;next = ht-&gt;table[index];    ht-&gt;table[index] = entry;    // 更新哈希表已使用节点数量    ht-&gt;used++;    // 设置新节点的键    // T = O(1)    dictSetKey(d, entry, key);    return entry;}</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/dictadd.png" alt=""></p><h2 id="5-3-Rehash"><a href="#5-3-Rehash" class="headerlink" title="5.3 Rehash"></a>5.3 Rehash</h2><pre><code class="c"># file:src/dict.c/*  * 执行 N 步渐进式 rehash 。 * 返回 1 表示仍有键需要从 0 号哈希表移动到 1 号哈希表， * 返回 0 则表示所有键都已经迁移完毕。 * * 注意，每步 rehash 都是以一个哈希表索引（桶）作为单位的， * 一个桶里可能会有多个节点， * 被 rehash 的桶里的所有节点都会被移动到新哈希表。 * T = O(N) */int dictRehash(dict *d, int n) {    // 只可以在 rehash 进行中时执行    if (!dictIsRehashing(d)) return 0;    // 进行 N 步迁移    // T = O(N)    while(n--) {        dictEntry *de, *nextde;        /* Check if we already rehashed the whole table... */        // 如果 0 号哈希表为空，那么表示 rehash 执行完毕        // T = O(1)        if (d-&gt;ht[0].used == 0) {            // 释放 0 号哈希表            zfree(d-&gt;ht[0].table);            // 将原来的 1 号哈希表设置为新的 0 号哈希表            d-&gt;ht[0] = d-&gt;ht[1];            // 重置旧的 1 号哈希表            _dictReset(&amp;d-&gt;ht[1]);            // 关闭 rehash 标识            d-&gt;1rehashidx = -1;            // 返回 0 ，向调用者表示 rehash 已经完成            return 0;        }        /* Note that rehashidx can&#39;t overflow as we are sure there are more         * elements because ht[0].used != 0 */        // 确保 rehashidx 没有越界        assert(d-&gt;ht[0].size &gt; (unsigned)d-&gt;rehashidx);        // 略过数组中为空的索引，找到下一个非空索引        while(d-&gt;ht[0].table[d-&gt;rehashidx] == NULL) d-&gt;rehashidx++;        // 指向该索引的链表表头节点        de = d-&gt;ht[0].table[d-&gt;rehashidx];        /* Move all the keys in this bucket from the old to the new hash HT */        // 将链表中的所有节点迁移到新哈希表        // T = O(1)        while(de) {            unsigned int h;            // 保存下个节点的指针            nextde = de-&gt;next;            /* Get the index in the new hash table */            // 计算新哈希表的哈希值，以及节点插入的索引位置            h = dictHashKey(d, de-&gt;key) &amp; d-&gt;ht[1].sizemask;            // 插入节点到新哈希表            de-&gt;next = d-&gt;ht[1].table[h];            d-&gt;ht[1].table[h] = de;            // 更新计数器            d-&gt;ht[0].used--;            d-&gt;ht[1].used++;            // 继续处理下个节点            de = nextde;        }        // 将刚迁移完的哈希表索引的指针设为空        d-&gt;ht[0].table[d-&gt;rehashidx] = NULL;        // 更新 rehash 索引        d-&gt;rehashidx++;    }    return 1;}/* * 在给定毫秒数内，以 100 步为单位，对字典进行 rehash 。 * * T = O(N) */int dictRehashMilliseconds(dict *d, int ms) {    // 记录开始时间    long long start = timeInMilliseconds();    int rehashes = 0;    while(dictRehash(d,100)) {        rehashes += 100;        // 如果时间已过，跳出        if (timeInMilliseconds()-start &gt; ms) break;    }    return rehashes;}/* * 创建一个新的哈希表，并根据字典的情况，选择以下其中一个动作来进行： * 1) 如果字典的 0 号哈希表为空，那么将新哈希表设置为 0 号哈希表 * 2) 如果字典的 0 号哈希表非空，那么将新哈希表设置为 1 号哈希表， *    并打开字典的 rehash 标识，使得程序可以开始对字典进行 rehash * size 参数不够大，或者 rehash 已经在进行时，返回 DICT_ERR 。 * 成功创建 0 号哈希表，或者 1 号哈希表时，返回 DICT_OK 。 */int dictExpand(dict *d, unsigned long size){    // 新哈希表    dictht n; /* the new hash table */    // 根据 size 参数，计算哈希表的大小    // T = O(1)    unsigned long realsize = _dictNextPower(size);    /* the size is invalid if it is smaller than the number of     * elements already inside the hash table */    // 不能在字典正在 rehash 时进行    // size 的值也不能小于 0 号哈希表的当前已使用节点    if (dictIsRehashing(d) || d-&gt;ht[0].used &gt; size)        return DICT_ERR;    /* Allocate the new hash table and initialize all pointers to NULL */    // 为哈希表分配空间，并将所有指针指向 NULL    n.size = realsize;    n.sizemask = realsize-1;    // T = O(N)    n.table = zcalloc(realsize*sizeof(dictEntry*));    n.used = 0;    /* Is this the first initialization? If so it&#39;s not really a rehashing     * we just set the first hash table so that it can accept keys. */    // 如果 0 号哈希表为空，那么这是一次初始化：    // 程序将新哈希表赋给 0 号哈希表的指针，然后字典就可以开始处理键值对了。    if (d-&gt;ht[0].table == NULL) {        d-&gt;ht[0] = n;        return DICT_OK;    }    /* Prepare a second hash table for incremental rehashing */    // 如果 0 号哈希表非空，那么这是一次 rehash ：    // 程序将新哈希表设置为 1 号哈希表，    // 并将字典的 rehash 标识打开，让程序可以开始对字典进行 rehash    d-&gt;ht[1] = n;    d-&gt;rehashidx = 0;    return DICT_OK;}/* * 计算第一个大于等于 size 的 2 的 N 次方，用作哈希表的值 * T = O(1) */static unsigned long _dictNextPower(unsigned long size){    unsigned long i = DICT_HT_INITIAL_SIZE;    if (size &gt;= LONG_MAX) return LONG_MAX;    while(1) {        if (i &gt;= size)            return i;        i *= 2;    }}</code></pre><p>随着操作的不断执行， 哈希表保存的键值对会逐渐地增多或者减少， 为了让哈希表的负载因子（load factor）维持在一个合理的范围之内， 当哈希表保存的键值对数量太多或者太少时， 程序需要对哈希表的大小进行相应的扩展或者收缩。</p><p>扩展和收缩哈希表的工作可以通过执行 rehash （重新散列）操作来完成， Redis 对字典的哈希表执行 rehash 的步骤如下：</p><ul><li><p>为字典的 ht[1] 哈希表分配空间(使用函数dictExpand)， 这个哈希表的空间大小(使用_dictNextPower计算大小)取决于要执行的操作， 以及 ht[0] 当前包含的键值对数量 （也即是 ht[0].used 属性的值）：</p><ul><li><p>如果执行的是扩展操作， 那么 ht[1] 的大小为第一个大于等于 ht[0].used * 2 的 2^n</p></li><li><p>如果执行的是收缩操作， 那么 ht[1] 的大小为第一个大于等于 ht[0].used 的 2^n </p></li></ul></li><li><p>将保存在 ht[0] 中的所有键值对 rehash 到 ht[1] 上面： rehash 指的是重新计算键的哈希值和索引值， 然后将键值对放置到 ht[1] 哈希表的指定位置上</p></li><li><p>当 ht[0] 包含的所有键值对都迁移到了 ht[1] 之后 （ht[0] 变为空表）, 释放 ht[0] ,将 ht[1] 设置为 ht[0] ， 并在 ht[1] 新创建一个空白哈希表，为下一次 rehash 做准备</p></li></ul><p>实际过程大多通过渐进式rehash来将数据做转移:</p><ul><li>为 ht[1] 分配空间， 让字典同时持有 ht[0] 和 ht[1] 两个哈希表。</li><li>在字典中维持一个索引计数器变量 rehashidx ， 并将它的值设置为 0 ， 表示 rehash 工作正式开始。</li><li>在 rehash 进行期间， 每次对字典执行添加、删除、查找或者更新操作时， 程序除了执行指定的操作以外， 还会顺带将 ht[0] 哈希表在 rehashidx 索引上的所有键值对 rehash 到 ht[1] ， 当 rehash 工作完成之后， 程序将 rehashidx 属性的值增一。</li><li>随着字典操作的不断执行， 最终在某个时间点上， ht[0] 的所有键值对都会被 rehash 至 ht[1] ， 这时程序将 rehashidx 属性的值设为 -1 ， 表示 rehash 操作已完成。</li></ul><p>另外， 在渐进式 rehash 执行期间， 新添加到字典的键值对一律会被保存到 ht[1] 里面， 而 ht[0] 则不再进行任何添加操作： 这一措施保证了 ht[0] 包含的键值对数量会只减不增， 并随着 rehash 操作的执行而最终变成空表。</p><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/rehash0.png" alt=""><br><img src="http://cache410.oss-cn-beijing.aliyuncs.com/rehash1.png" alt=""><br><img src="http://cache410.oss-cn-beijing.aliyuncs.com/rehash2.png" alt=""><br><img src="http://cache410.oss-cn-beijing.aliyuncs.com/rehash3.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>11.Mysql日志</title>
      <link href="/2020/02/18/11-Mysql%E6%97%A5%E5%BF%97/"/>
      <url>/2020/02/18/11-Mysql%E6%97%A5%E5%BF%97/</url>
      
        <content type="html"><![CDATA[<p>主要包括:</p><ol><li>错误日志 Error Log</li><li>慢查询日志 Slow Query Log</li><li>二进制日志 Bin Log</li><li>重做日志 Redo log</li><li>回滚日志 Undo Log</li><li>中继日志 Relay Log</li><li>一般查询日志 Gerneral Log</li></ol><h2 id="11-1-Error-Log"><a href="#11-1-Error-Log" class="headerlink" title="11.1 Error Log"></a>11.1 Error Log</h2><h3 id="11-1-1-作用"><a href="#11-1-1-作用" class="headerlink" title="11.1.1 作用"></a>11.1.1 作用</h3><p>用来记录从服务器启动和关闭过程中的信息（未必是错误信息，如mysql如何启动InnoDB的表空间文件的、如何初始化自己的存储引擎的等等）、服务器运行过程中的错误信息、事件调度器运行一个事件时产生的信息、在从服务器上启动服务器进程时产生的信息</p><p>在mysql数据库中，错误日志功能是默认开启的</p><p>默认情况下，错误日志存储在mysql数据库的数据文件中。</p><p>错误日志文件通常的名称为hostname.err。其中，hostname表示服务器主机名。</p><h3 id="11-1-2-相关参数"><a href="#11-1-2-相关参数" class="headerlink" title="11.1.2 相关参数"></a>11.1.2 相关参数</h3><pre><code class="mysql">#错误日志存储的位置以及名称mysql&gt; select @@log_error;+-----------------+| @@log_error     |+-----------------+| ./centos7-1.err |+-----------------+1 row in set (0.00 sec)#错误级别mysql&gt; select @@log_error_verbosity;+-----------------------+| @@log_error_verbosity |+-----------------------+|                     3 |+-----------------------+1 row in set (0.00 sec)#错误级别　已废弃不推荐使用的　等同于log_error_verbositymysql&gt; select @@log_warnings;+----------------+| @@log_warnings |+----------------+|              2 |+----------------+1 row in set, 1 warning (0.00 sec)</code></pre><h3 id="11-1-3-修改记录级别"><a href="#11-1-3-修改记录级别" class="headerlink" title="11.1.3 修改记录级别"></a>11.1.3 修改记录级别</h3><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/error_verbosity.png" alt=""></p><h3 id="11-1-4-清空归档日志"><a href="#11-1-4-清空归档日志" class="headerlink" title="11.1.4 清空归档日志"></a>11.1.4 清空归档日志</h3><pre><code class="shell">mv host_name.err host_name.err-oldmysqladmin flush-logsmv host_name.err-old backup-directory</code></pre><h2 id="11-2-Slow-Query-Log"><a href="#11-2-Slow-Query-Log" class="headerlink" title="11.2 Slow Query Log"></a>11.2 Slow Query Log</h2><h3 id="11-2-1-作用"><a href="#11-2-1-作用" class="headerlink" title="11.2.1 作用"></a>11.2.1 作用</h3><p>查询日志是用来记录执行时间超过指定时间的查询语句。通过慢查询日志，可以查找出哪些查询语句的执行效率很低，以便进行优化。一般建议开启，它对服务器性能的影响微乎其微，但是可以记录mysql服务器上执行了很长时间的查询语句。可以帮助我们定位性能问题</p><h3 id="11-2-2-相关参数"><a href="#11-2-2-相关参数" class="headerlink" title="11.2.2 相关参数"></a>11.2.2 相关参数</h3><pre><code class="mysql">#是否开启慢查询 1开启 0关闭mysql&gt; select @@slow_query_log;+------------------+| @@slow_query_log |+------------------+|                1 |+------------------+1 row in set (0.00 sec)# 慢查询文件位置mysql&gt; select @@slow_query_log_file;+----------------------------+| @@slow_query_log_file      |+----------------------------+| /log/3306/slowlog/slow.log |+----------------------------+1 row in set (0.00 sec)# 慢查询时间阀值　单位为秒mysql&gt; select @@long_query_time;+-------------------+| @@long_query_time |+-------------------+|          5.000000 |+-------------------+1 row in set (0.00 sec)# 1开启　０关闭# 运行的SQL语句没有使用索引，则MySQL数据库同样会将这条SQL语句记录到慢查询日志文件mysql&gt; select @@log_queries_not_using_indexes;+---------------------------------+| @@log_queries_not_using_indexes |+---------------------------------+|                               1 |+---------------------------------+1 row in set (0.00 sec)</code></pre><h3 id="11-2-3-查看slow-log"><a href="#11-2-3-查看slow-log" class="headerlink" title="11.2.3 查看slow.log"></a>11.2.3 查看slow.log</h3><p>slow.log属于文本日志,我们可以通过linux命令查看slow.log</p><pre><code class="shell">[root@centos7-1 slowlog]# tail -f slow.log # Time: 2019-07-09T02:00:48.300499Z# User@Host: root[root] @ localhost []  Id:     5# Query_time: 5.075423  Lock_time: 0.000123 Rows_sent: 174  Rows_examined: 4994309SET timestamp=1562637648;select * from t_scrm_pet_info where pet_name =&quot;Winter&quot;;</code></pre><p>含义如下:</p><ul><li>SQL 的执行时间：# Time: 2019-07-09T02:00:48.300499Z</li><li>SQL 的执行主机：# User@Host: root[root] @ localhost []  Id:     5</li><li>SQL 的执行信息：# Query_time: 5.075423  Lock_time: 0.000123 Rows_sent: 174  Rows_examined: 4994309</li><li>SQL 的执行时间：SET timestamp=1562637648;</li><li>SQL 的执行内容：select * from t_scrm_pet_info where pet_name =”Winter”;</li></ul><h3 id="11-2-4-mysqldumpslow"><a href="#11-2-4-mysqldumpslow" class="headerlink" title="11.2.4 mysqldumpslow"></a>11.2.4 mysqldumpslow</h3><p>mysqldumpslow 是一个针对于 MySQL 慢查询的命令行程序。可以通过 mysqldumpslow 查找出查询较慢的 SQL 语句。</p><pre><code class="shell">[root@centos7-1 slowlog]# mysqldumpslow --helpUsage: mysqldumpslow [ OPTS... ] [ LOGS... ]Parse and summarize the MySQL slow query log. Options are  --verbose    verbose  --debug      debug  --help       write this text to standard output  -v           verbose  -d           debug  -s ORDER     what to sort by (al, at, ar, c, l, r, t), &#39;at&#39; is default                al: average lock time                ar: average rows sent                at: average query time                 c: count                 l: lock time                 r: rows sent                 t: query time    -r           reverse the sort order (largest last instead of first)  -t NUM       just show the top n queries  -a           don&#39;t abstract all numbers to N and strings to &#39;S&#39;  -n NUM       abstract numbers with at least n digits within names  -g PATTERN   grep: only consider stmts that include this string  -h HOSTNAME  hostname of db server for *-slow.log filename (can be wildcard),               default is &#39;*&#39;, i.e. match all  -i NAME      name of server instance (if using mysql.server startup script)  -l           don&#39;t subtract lock time from total time</code></pre><p>通过mysqldumpslow  查看慢日志：</p><pre><code class="shell">[root@centos7-1 slowlog]# mysqldumpslow slow.log Reading mysql slow query log from slow.logCount: 3  Time=5.12s (15s)  Lock=0.00s (0s)  Rows=1661.3 (4984), root[root]@localhost  select * from t_scrm_pet_info where pet_name =&quot;S&quot;</code></pre><ul><li>Count：出现次数,</li><li>Time：执行最长时间和累计总耗费时间</li><li>Lock：等待锁的时间</li><li>Rows：返回客户端行总数和扫描行总数</li></ul><h2 id="11-3-Binlog"><a href="#11-3-Binlog" class="headerlink" title="11.3 Binlog"></a>11.3 Binlog</h2><h3 id="11-3-1-作用"><a href="#11-3-1-作用" class="headerlink" title="11.3.1 作用"></a>11.3.1 作用</h3><p>主要记录数据库变化(DDL,DCL,DML)性质的日志,是逻辑层性质日志</p><p>主要有以下作用:</p><ul><li>恢复(recovery)： 对于误删除的数据可以通过binlog恢复</li><li>复制(replication) :可以通过binlog做主从同步</li><li>审计(audit)：可以通过抓取binlog日志来满足审计需求</li></ul><h3 id="11-3-2-相关参数"><a href="#11-3-2-相关参数" class="headerlink" title="11.3.2 相关参数"></a>11.3.2 相关参数</h3><pre><code class="ini">cat /etc/my.cnf....#主机编号　主从同步的时候使用　开启binlog需要加此参数server_id=1            #日志存放的目录＋日志名前缀 :mysql-bin.000001 mysql-bin.000002 ...log_bin=/log/3306/binlog/mysql-bin#binlog日志刷盘策略【重要】sync_binlog=1#binlig的记录格式binlog_format=row#指定单个binlog文件的大小(默认1G)max_binlog_size=200M</code></pre><h4 id="11-3-2-1-binglog-format"><a href="#11-3-2-1-binglog-format" class="headerlink" title="11.3.2.1 binglog_format"></a>11.3.2.1 binglog_format</h4><p>二进制日志有以下几种格式可选:</p><ul><li><p>STATEMENT模式（SBR）</p><p>每一条会修改数据的sql语句会记录到binlog中。优点是并不需要记录每一条sql语句和每一行的数据变化，减少了binlog日志量，节约IO，提高性能。缺点是在某些情况下会导致master-slave中的数据不一致(如sleep()函数， last_insert_id()，以及user-defined functions(udf)等会出现问题</p></li><li><p>ROW模式（RBR）(<code>5.7版本默认</code>)</p><p>不记录每条sql语句的上下文信息，仅需记录哪条数据被修改了，修改成什么样了。而且不会出现某些特定情况下的存储过程、或function、或trigger的调用和触发无法被正确复制的问题。缺点是会产生大量的日志，尤其是alter table的时候会让日志暴涨。</p></li><li><p>MIXED模式（MBR）</p><p>以上两种模式的混合使用，一般的复制使用STATEMENT模式保存binlog，对于STATEMENT模式无法复制的操作使用ROW模式保存binlog，MySQL会根据执行的SQL语句选择日志保存方式。</p></li></ul><table><thead><tr><th align="center">模式</th><th align="left">优点</th><th align="center">缺点</th></tr></thead><tbody><tr><td align="center">SBR</td><td align="left">可读性高,日志量少,主从版本可以不一样</td><td align="center">不够严禁</td></tr><tr><td align="center">RBR</td><td align="left">可读性底,日志量大,主从版本需要统一</td><td align="center">足够严禁</td></tr></tbody></table><h2 id="11-4-Redo-Log"><a href="#11-4-Redo-Log" class="headerlink" title="11.4 Redo Log"></a>11.4 Redo Log</h2><h2 id="11-5-Undo-Log"><a href="#11-5-Undo-Log" class="headerlink" title="11.5 Undo Log"></a>11.5 Undo Log</h2>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> Mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>10.MysqlInnodb存储引擎</title>
      <link href="/2020/02/18/10-MysqlInnodb%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/"/>
      <url>/2020/02/18/10-MysqlInnodb%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/</url>
      
        <content type="html"><![CDATA[<h2 id="10-1-关键特性"><a href="#10-1-关键特性" class="headerlink" title="10.1 关键特性"></a>10.1 关键特性</h2><ul><li>B-tree索引+聚簇索引</li><li>数据缓存与加密</li><li>外键支持</li><li>行级锁</li><li>事务和MVCC</li><li>复制和备份恢复</li></ul><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/InnoDBStorageEngineFeatures.png" alt=""></p><h2 id="10-2-Innodb逻辑结构图"><a href="#10-2-Innodb逻辑结构图" class="headerlink" title="10.2 Innodb逻辑结构图"></a>10.2 Innodb逻辑结构图</h2><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/innodb-architecture5.7.png" alt=""></p><h2 id="10-3-Innodb内存结构"><a href="#10-3-Innodb内存结构" class="headerlink" title="10.3 Innodb内存结构"></a>10.3 Innodb内存结构</h2><p>主要包括以下几部分:</p><ul><li>Buffer Pool</li><li>Change Buffer</li><li>AHI</li><li>Log Buffer</li></ul><h3 id="10-3-1-Buffer-Pool"><a href="#10-3-1-Buffer-Pool" class="headerlink" title="10.3.1 Buffer Pool"></a>10.3.1 Buffer Pool</h3><h4 id="10-3-1-1-作用"><a href="#10-3-1-1-作用" class="headerlink" title="10.3.1.1 作用"></a>10.3.1.1 作用</h4><p>前面的文章Mysql索引介绍中,我们知道Innodb是以页为储存单位来保存数据的,<code>读取和处理数据的时候同样需要已页为单位将数据加载到内存中</code> </p><p>如果没有Buffer Pool会进行频繁的磁盘IO,这样会大大拉低Mysql的性能,因此Mysql使用Buffer Pool来做存储数据和索引的缓存,容许在内存中直接操作表数据,提高处理速度</p><blockquote><p>Buffer Pool 的功能就是 缓存“页” ，减少磁盘IO,提高读写效率。</p></blockquote><h4 id="10-3-1-2-Buffer-Pool结构"><a href="#10-3-1-2-Buffer-Pool结构" class="headerlink" title="10.3.1.2 Buffer Pool结构"></a>10.3.1.2 Buffer Pool结构</h4><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/buffer_pool1.png" alt=""></p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/bufferpoolself.png" alt=""></p><p>Buffer Poll是由一个个Instance组成,每个instance都有自己的锁，信号量，物理块(Buffer chunks)以及逻辑链表(下面的各种List)，即<code>各个instance之间没有竞争关系，可以并发读取与写入</code>。所有instance的物理块(Buffer chunks)在数据库启动的时候被分配，直到数据库关闭内存才予以释放</p><pre><code>innodb_buffer_pool_instances = innodb_buffer_pool_size/innodb_buffer_pool_instanceInstance实例数目=BufferPool总大小/每个Instance的大小【注意】当innodb_buffer_pool_size小于1GB时候，innodb_buffer_pool_instances被重置为1，主要是防止有太多小的instance从而导致性能问题</code></pre><p>每个Buffer Pool Instance有一个page hash链表，通过它，使用space_id和page_no就能快速找到已经被读入内存的数据页，而不用线性遍历LRU List去查找。</p><p>注意这个hash表不是InnoDB的自适应哈希(AHI)，自适应哈希是为了减少Btree的扫描，而page hash是为了避免扫描LRU List。</p><p><code>Buffer Pool会通过三种Page和链表来管理这些经常访问的数据，保证热数据不被置换出Buffer Pool</code></p><h4 id="10-3-1-3-Page的分类"><a href="#10-3-1-3-Page的分类" class="headerlink" title="10.3.1.3 Page的分类"></a>10.3.1.3 Page的分类</h4><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/pageclass.png" alt=""></p><h4 id="10-3-1-4-链表的分类"><a href="#10-3-1-4-链表的分类" class="headerlink" title="10.3.1.4 链表的分类"></a>10.3.1.4 链表的分类</h4><p>链表节点是数据页的控制体(控制体中有指针指向真正的数据页)，链表中的所有节点都有同一的属性，引入其的目的是方便管理</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/listclass.png" alt=""></p><ul><li><p>Free List</p><p>Free 链表 存放的是空闲页面，初始化的时候申请一定数量的页面</p><p>在执行SQL的过程中，每次成功load 页面到内存后，会判断Free 链表的页面是否够用。如果不够用的话，就flush LRU 链表和Flush 链表来释放空闲页。如果够用，就从Free 链表里面删除对应的页面，在LRU 链表增加页面，保持总数不变。</p></li><li><p>LRU List</p><p>默认情况下：</p><ol><li><p>Old 链表占整个LRU 链表的比例是3/8。该比例由<code>innodb_old_blocks_pct</code>控制，默认值是37（3/8*100）。该值取值范围为5~95，为全局动态变量。</p></li><li><p>当新的页被读取到Buffer Pool里面的时候，和<code>传统的LRU算法插入到LRU链表头部不同，Innodb LRU算法是将新的页面插入到Yong 链表的尾部和Old 链表的头部中间的位置，这个位置叫做Mid Point</code>，如下图所示</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/lrulist.png" alt=""></p></li></ol></li></ul><ol start="3"><li><p>频繁访问一个Buffer Pool的页面，会促使页面往Young链表的头部移动。如果一个Page在被读到Buffer Pool后很快就被访问(需要超过innodb_old_block_time)，那么该Page会往Young List的头部移动，但是如果一个页面是通过预读的方式读到Buffer Pool，且之后短时间内没有被访问，那么很可能在下次访问之前就被移动到Old List的尾部，而被驱逐了。</p></li><li><p>随着数据库的持续运行，新的页面被不断的插入到LRU链表的Mid Point，Old 链表里的页面会逐渐的被移动Old链表的尾部。同时，当经常被访问的页面移动到LRU链表头部的时候，那些没有被访问的页面会逐渐的被移动到链表的尾部。最终，位于Old 链表尾部的页面将被驱逐。</p></li><li><p>如果一个数据页已经处于Young 链表，当它再次被访问的时候，<code>只有当其处于Young 链表长度的1/4(大约值)之后，才会被移动到Young 链表的头部</code>。这样做的目的是减少对LRU 链表的修改，因为LRU 链表的目标是保证经常被访问的数据页不会被驱逐出去。</p></li><li><p>innodb_old_blocks_time 控制的Old 链表头部页面的转移策略。<code>该Page需要在Old 链表停留超过innodb_old_blocks_time 时间，之后再次被访问，才会移动到Young 链表</code>。这么操作是避免Young 链表被那些只在innodb_old_blocks_time时间间隔内频繁访问，之后就不被访问的页面塞满，从而有效的保护Young 链表。</p></li><li><p>在全表扫描或者全索引扫描的时候，Innodb会将大量的页面写入LRU 链表的Mid Point位置，并且只在短时间内访问几次之后就不再访问了。设置innodb_old_blocks_time的时间窗口可以有效的保护Young List，保证了真正的频繁访问的页面不被驱逐。<code>innodb_old_blocks_time 单位是毫秒，默认值是1000，即１秒。调大该值提高了从Old链表移动到Young链表的难度，会促使更多页面被移动到Old 链表，老化，从而被驱逐</code></p></li><li><p>当扫描的表很大，Buffer Pool都放不下时，可以将innodb_old_blocks_pct设置为较小的值，这样只读取一次的数据页就不会占据大部分的Buffer Pool。例如，设置innodb_old_blocks_pct = 5，会将仅读取一次的数据页在Buffer Pool的占用限制为5％。当经常扫描一些小表时，这些页面在Buffer Pool移动的开销较小，我们可以适当的调大innodb_old_blocks_pct，例如设置innodb_old_blocks_pct = 50</p></li></ol><p>  在SHOW ENGINE INNODB STATUS 里面提供了Buffer Pool一些监控指标，有几个我们需要关注一下：</p><pre><code class="mysql">  =====================================  mysql&gt; show engine innnodb status\G  ……  Pages made young 0, not young 0  0.00 youngs/s, 0.00 non-youngs/s  ======================================  数据页从冷到热，称为young；not young就是数据在没有成为热数据情况下就被刷走的量(累计值)。</code></pre><table><thead><tr><th align="left">指标</th><th align="left">场景</th><th align="left">处理方法</th><th>作用</th></tr></thead><tbody><tr><td align="left">youngs/s很小</td><td align="left">都是一些小事务，没有大表全扫描</td><td align="left">调大innodb_old_blocks_pct，减小innodb_old_blocks_time</td><td>使Old List 的长度更长，到Old List 的尾部消耗的时间会更久，提升下一次访问到Old List里面的页面的可能性</td></tr><tr><td align="left">youngs/s很大</td><td align="left"></td><td align="left">可以调小innodb_old_blocks_pct，同时调大innodb_old_blocks_time</td><td>保护热数据</td></tr><tr><td align="left">non-youngs/s很大</td><td align="left">大量的全表扫描</td><td align="left">可以调小innodb_old_blocks_pct，同时调大innodb_old_blocks_time</td><td>保护young list</td></tr><tr><td align="left">non-youngs/s不大</td><td align="left">存在大量全表扫描</td><td align="left">调大innodb_old_blocks_time</td><td>使得这些短时间频繁访问的页面保留在Old 链表里面</td></tr></tbody></table><p>  每隔1秒钟，Page Cleaner线程执行LRU List Flush的操作，来释放足够的Free Page。innodb_lru_scan_depth 变量控制每个Buffer Pool实例每次扫描LRU List的长度，来寻找对应的脏页，执行Flush操作。</p><ul><li><p>Flush List</p><ol><li>Flush 链表里面保存的都是脏页，也会存在于LRU 链表。</li><li>Flush 链表是按照oldest_modification排序，值大的在头部，值小的在尾部</li><li>当有页面访被修改的时候，使用mini-transaction，对应的page进入Flush 链表</li><li>如果当前页面已经是脏页，就不需要再次加入Flush list，否则是第一次修改，需要加入Flush 链表</li><li>当Page Cleaner线程执行flush操作的时候，从尾部开始scan，将一定的脏页写入磁盘，推进检查点，减少recover的时间</li></ol></li></ul><blockquote><p>LRU链表和FLUSH链表的区别 </p></blockquote><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/lru-flush-diff.png" alt=""></p><h3 id="10-3-2-Change-Buffer"><a href="#10-3-2-Change-Buffer" class="headerlink" title="10.3.2 Change Buffer"></a>10.3.2 Change Buffer</h3><h4 id="10-3-2-1-作用"><a href="#10-3-2-1-作用" class="headerlink" title="10.3.2.1 作用"></a>10.3.2.1 作用</h4><p>Change buffer的主要目的是将对<code>二级索引</code>的数据操作缓存下来，以此减少二级索引的随机IO，并达到操作合并的效果。</p><p>对表执行 INSERT，UPDATE和 DELETE操作时， 索引列的值（尤其是secondary keys的值）通常按未排序顺序排列，需要大量I / O才能使二级索引更新。Change Buffer会缓存这个更新当相关页面不在Buffer Pool中，从而磁盘上的相关页面不会立即被读避免了昂贵的I / O操作</p><h4 id="10-3-2-2-参数"><a href="#10-3-2-2-参数" class="headerlink" title="10.3.2.2 参数"></a>10.3.2.2 参数</h4><ul><li><p>参数：innodb_change_buffer_max_size</p><p>介绍：配置写缓冲的大小，占整个缓冲池的比例，默认值是25%，最大值是50%。</p><p><code>写多读少的业务，才需要调大这个值，读多写少的业务，25%其实也多了</code></p></li><li><p>参数：innodb_change_buffering<br>介绍：配置哪些写操作启用写缓冲，可以设置成all/none/inserts/deletes等</p></li></ul><pre><code class="mysql">mysql&gt; select @@innodb_change_buffer_max_size;+---------------------------------+| @@innodb_change_buffer_max_size |+---------------------------------+|                              25 |+---------------------------------+1 row in set (0.00 sec)mysql&gt; select @@innodb_change_buffering;+---------------------------+| @@innodb_change_buffering |+---------------------------+| all                       |+---------------------------+1 row in set (0.00 sec)</code></pre><h3 id="10-3-3-Adaptive-Hash-Index-AHI"><a href="#10-3-3-Adaptive-Hash-Index-AHI" class="headerlink" title="10.3.3 Adaptive Hash Index(AHI)"></a>10.3.3 Adaptive Hash Index(AHI)</h3><p>哈希(hash)是一种非常快的查找方法,在一般情况下这种查找的时间复杂度为O(1),即一般仅需要一次查找就能定位数据。而B+树的查找次数,取决于B+树的高度,在生产环境中,B+树的高度一般为3-4层,故需要3-4次的查询。</p><p>InnoDB存储引擎会监控对表上各索引页的查询。如果观察到建立哈希索引可以带来速度提升,则建立哈希索引,称之为<code>自适应哈希索引(Adaptive Hash Index,AHI)</code> AHI是通过缓冲池的B+树页构造而来,因此建立的速度很快,而且不需要对整张表构建哈希索引。 InnoDB存储引擎会自动根据访问的频率和模式来自动地为某些热点页建立哈希索引。</p><p>我们可以认为：<code>AHI是建立在B+Tree数索引上的索引</code>,是Innodb内部用来自身提高查询速度的自优化功能</p><h3 id="10-3-4-Log-Buffer"><a href="#10-3-4-Log-Buffer" class="headerlink" title="10.3.4 Log Buffer"></a>10.3.4 Log Buffer</h3><h4 id="10-3-4-1-功能"><a href="#10-3-4-1-功能" class="headerlink" title="10.3.4.1 功能"></a>10.3.4.1 功能</h4><p><code>负责redo日志的缓冲</code></p><p>redo log日志作用后面的文章将会介绍</p><h4 id="10-3-4-2-刷盘时机"><a href="#10-3-4-2-刷盘时机" class="headerlink" title="10.3.4.2 刷盘时机"></a>10.3.4.2 刷盘时机</h4><ul><li>redo log buffer 空间不足的时候</li><li>事务提交的时候</li><li>后台线程在不停的刷</li><li>服务正常关闭的时候</li><li>checkpoint的时候</li></ul><h4 id="10-3-4-3-关键参数"><a href="#10-3-4-3-关键参数" class="headerlink" title="10.3.4.3 关键参数"></a>10.3.4.3 关键参数</h4><ul><li>innodb_flush_log_at_trx_commit</li></ul><pre><code class="mysql">mysql&gt; select @@innodb_flush_log_at_trx_commit;+----------------------------------+| @@innodb_flush_log_at_trx_commit |+----------------------------------+|                                1 |+----------------------------------+1 row in set (0.00 sec)作用:主要控制了innodb将log buffer中的数据写入日志文件并flush磁盘的时间点取值分别为0、1、2三个参数说明:1.每次事物的提交都会引起日志文件写入、flush磁盘的操作，确保了事务的ACID；flush  到操作系统的文件系统缓存,fsync到物理磁盘.0.表示当事务提交时，不做日志写入操作，而是每秒钟将log buffer中的数据写入文件系统缓存并且秒fsync磁盘一次；2.每次事务提交引起写入文件系统缓存,但每秒钟完成一次fsync磁盘操作。</code></pre><ul><li>Innodb_flush_method</li></ul><pre><code class="mysql">mysql&gt; select @@Innodb_flush_method;+-----------------------+| @@Innodb_flush_method |+-----------------------+| NULL                  |+-----------------------+1 row in set (0.00 sec)</code></pre><p>可选模式:</p><ul><li><p>FSYNC(默认值):</p><ul><li>buffer pool的数据写磁盘时,要先经历os cache,然后再写到磁盘</li><li>log buffer的数据写磁盘时,要先经历os cache,然后再写到磁盘</li></ul></li><li><p>O_DSYNC:</p><ul><li>buffer pool的数据写磁盘时,要先经历os cache,然后再写到磁盘</li><li>log buffer 的数据写磁盘时,直接写到写到磁盘,跨过os cache</li></ul></li><li><p>O_DIRECT：</p><ul><li><p>buffer pool的数据写磁盘时,直接写到写到磁盘,跨过os cache</p></li><li><p>log buffer的数据写磁盘时,要先经历os cache,然后再写到磁盘</p></li></ul></li></ul><p>建议使用:O_DIRECT+固态硬盘</p><h2 id="10-4-Innodb物理存储结构"><a href="#10-4-Innodb物理存储结构" class="headerlink" title="10.4 Innodb物理存储结构"></a>10.4 Innodb物理存储结构</h2><p>​    主要包含以下几部分:</p><ul><li>系统表空间 System Tablespace</li><li>Undo日志</li><li>Redo日志</li><li>临时表空间</li><li>用户表空间</li><li>ib_buffer_pool</li></ul><h3 id="10-4-1-System-Tablespace"><a href="#10-4-1-System-Tablespace" class="headerlink" title="10.4.1 System Tablespace"></a>10.4.1 System Tablespace</h3><p>5.7版本的Mysql系统表空间用来存储以下信息:</p><ul><li>Innodb的数据字典</li><li>double buffer</li><li>change buffer</li><li>undo log</li></ul><p>5.6版本的Mysql系统表空间还存储是临时表数据</p><p>8.8版本的Mysql系统表空间取消存储数据字典信息并将undo log独立了出来</p><p>Mysql在慢慢瘦身系统表空间,把比较关键的数据独立出来了</p><h4 id="10-4-1-1-ibdata文件"><a href="#10-4-1-1-ibdata文件" class="headerlink" title="10.4.1.1 ibdata文件"></a>10.4.1.1 ibdata文件</h4><p>默认情况下,系统表空间在磁盘上的文件名为<code>ibdata1</code>,存在<code>/data</code>文件夹下</p><p>我们可以通过<code>innodb_data_file_path</code>参数修改系统表空间文件的数量</p><pre><code class="mysql">innodb_data_file_path=ibdata1:1G:ibdata2:1G:autoextend含义:有多个ibdata 第一个名称为ibdata1大小1G 第二个名称为ibdata2大小1Gautoextend意思是以此类推的生成ibdata</code></pre><p><code>innodb_data_file_path</code>参数通常要在初始化的时候加入到my.cnf文件下配置好</p><p>如果是在已运行的数据库上扩展多个ibdata文件,在设置<code>innodb_data_file_path</code>参数时,已有的ibdata1文件大小应该和磁盘上真正运行的ibdata1大小一致,而不是随便指定</p><h4 id="10-4-1-2-缩小系统表空间大小"><a href="#10-4-1-2-缩小系统表空间大小" class="headerlink" title="10.4.1.2 缩小系统表空间大小"></a>10.4.1.2 缩小系统表空间大小</h4><p>我们不能从系统表空间中删除数据,如果想减小系统表空间的大小我们只能做如下操作:</p><ol><li>mysqldump数据</li><li>关闭服务</li><li>删除所有 .ibd文件,ibdata文件ib_log文件</li><li>删除所有.frm文件</li><li>配置新系统表空间</li><li>重启服务</li><li>导入数据</li></ol><h3 id="10-4-2-Redo-log"><a href="#10-4-2-Redo-log" class="headerlink" title="10.4.2 Redo log"></a>10.4.2 Redo log</h3><p>Redo log　重做日志</p><h4 id="10-4-2-1-功能"><a href="#10-4-2-1-功能" class="headerlink" title="10.4.2.1 功能"></a>10.4.2.1 功能</h4><p>用户存储Mysql在做修改类操作时的数据页变化过程和版本号(LSN),属于物理日志</p><p>默认用两个文件存储redo log,是循环覆盖使用的</p><h4 id="10-4-2-2-文件位置"><a href="#10-4-2-2-文件位置" class="headerlink" title="10.4.2.2 文件位置"></a>10.4.2.2 文件位置</h4><p>一般也是存储在<code>/data</code>目录下,文件名为ib_logfile0 和 ib_logfile1</p><h4 id="10-4-2-3-控制参数"><a href="#10-4-2-3-控制参数" class="headerlink" title="10.4.2.3 控制参数"></a>10.4.2.3 控制参数</h4><pre><code class="ini">innodb_log_file_size=50331648    #设置文件大小innodb_log_files_in_group=2      #设置文件个数innodb_log_group_home_dir=./     #设置存储位置</code></pre><h3 id="10-4-3-Undo-log"><a href="#10-4-3-Undo-log" class="headerlink" title="10.4.3 Undo log"></a>10.4.3 Undo log</h3><p>Undo log　回滚日志</p><h4 id="10-4-3-1-功能"><a href="#10-4-3-1-功能" class="headerlink" title="10.4.3.1 功能"></a>10.4.3.1 功能</h4><p>用来存储回滚日志,记录每次操作的反操作,属于逻辑日志</p><ol><li>使用快照功能,提供Innodb多版本并发读写</li><li>通过记录的反操作,提供回滚功能</li></ol><h4 id="10-4-3-2-文件位置"><a href="#10-4-3-2-文件位置" class="headerlink" title="10.4.3.2 文件位置"></a>10.4.3.2 文件位置</h4><p>ibdataN里和ibtmp1里</p><h4 id="10-4-3-3-控制参数"><a href="#10-4-3-3-控制参数" class="headerlink" title="10.4.3.3 控制参数"></a>10.4.3.3 控制参数</h4><pre><code class="ini"> innodb_rollback_segments=128 #回滚段的个数</code></pre>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> Mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>4.Redis数据结构——listNode</title>
      <link href="/2020/02/18/4-Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-listNode/"/>
      <url>/2020/02/18/4-Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-listNode/</url>
      
        <content type="html"><![CDATA[<h2 id="4-1-什么是listNode"><a href="#4-1-什么是listNode" class="headerlink" title="4.1 什么是listNode"></a>4.1 什么是listNode</h2><p>listNode就是常规数据结构的一种——链表</p><p>Redis没有引用第三方的库来实现链表,而是自己手撸了一个</p><h2 id="4-2-list-amp-node数据结构"><a href="#4-2-list-amp-node数据结构" class="headerlink" title="4.2 list&amp;node数据结构"></a>4.2 list&amp;node数据结构</h2><pre><code class="c">#file:src/adlist.h/* * 双端链表节点 */typedef struct listNode {    // 前置节点    struct listNode *prev;    // 后置节点    struct listNode *next;    // 节点的值    void *value;} listNode;/* * 双端链表结构 */typedef struct list {   // 表头节点    listNode *head;    // 表尾节点    listNode *tail;    // 节点值复制函数    void *(*dup)(void *ptr);    // 节点值释放函数    void (*free)(void *ptr);    // 节点值对比函数    int (*match)(void *ptr, void *key);    // 链表所包含的节点数量    unsigned long len;} list;</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/listnode.png" alt=""></p><h2 id="4-3-新增结点"><a href="#4-3-新增结点" class="headerlink" title="4.3 新增结点"></a>4.3 新增结点</h2><p>没啥说的　就是双链表的新增</p><pre><code class="c">#file:src/adlist.c/* * 创建一个包含值 value 的新节点，并将它插入到 old_node 的之前或之后 * 如果 after 为 0 ，将新节点插入到 old_node 之前。 * 如果 after 为 1 ，将新节点插入到 old_node 之后。 * T = O(1) */list *listInsertNode(list *list, listNode *old_node, void *value, int after) {    listNode *node;    // 创建新节点    if ((node = zmalloc(sizeof(*node))) == NULL)        return NULL;    // 保存值    node-&gt;value = value;    // 将新节点添加到给定节点之后    if (after) {        node-&gt;prev = old_node;        node-&gt;next = old_node-&gt;next;        // 给定节点是原表尾节点        if (list-&gt;tail == old_node) {            list-&gt;tail = node;        }    // 将新节点添加到给定节点之前    } else {        node-&gt;next = old_node;        node-&gt;prev = old_node-&gt;prev;        // 给定节点是原表头节点        if (list-&gt;head == old_node) {            list-&gt;head = node;        }    }    // 更新新节点的前置指针    if (node-&gt;prev != NULL) {        node-&gt;prev-&gt;next = node;    }    // 更新新节点的后置指针    if (node-&gt;next != NULL) {        node-&gt;next-&gt;prev = node;    }    // 更新链表节点数    list-&gt;len++;    return list;}</code></pre><h2 id="4-4-删除结点"><a href="#4-4-删除结点" class="headerlink" title="4.4 删除结点"></a>4.4 删除结点</h2><p>也没啥说的,链表的删除操作</p><pre><code class="c">#file:src/adlist.c/* * 从链表 list 中删除给定节点 node  * T = O(1) */void listDelNode(list *list, listNode *node){    // 调整前置节点的指针    if (node-&gt;prev)        node-&gt;prev-&gt;next = node-&gt;next;    else        list-&gt;head = node-&gt;next;    // 调整后置节点的指针    if (node-&gt;next)        node-&gt;next-&gt;prev = node-&gt;prev;    else        list-&gt;tail = node-&gt;prev;    // 释放值    //对节点私有值的释放工作由list进行    if (list-&gt;free) list-&gt;free(node-&gt;value);    // 释放节点    zfree(node);    // 链表数减一    list-&gt;len--;}</code></pre><h2 id="4-5-查找结点"><a href="#4-5-查找结点" class="headerlink" title="4.5 查找结点"></a>4.5 查找结点</h2><pre><code class="c">#file:src/adlist.c/*  * 查找链表 list 中值和 key 匹配的节点。 * T = O(N) */listNode *listSearchKey(list *list, void *key){    listIter *iter;    listNode *node;    // 迭代整个链表    iter = listGetIterator(list, AL_START_HEAD);    while((node = listNext(iter)) != NULL) {        // 对比,对比操作由链表的 match 函数负责进行，        //如果没有设置 match 函数，那么直接通过对比值的指针来决定是否匹配        if (list-&gt;match) {            if (list-&gt;match(node-&gt;value, key)) {                listReleaseIterator(iter);                // 找到                return node;            }        } else {            if (key == node-&gt;value) {                listReleaseIterator(iter);                // 找到                return node;            }        }    }    listReleaseIterator(iter);    // 未找到    return NULL;}</code></pre><h2 id="4-6-修改结点"><a href="#4-6-修改结点" class="headerlink" title="4.6 修改结点"></a>4.6 修改结点</h2><p>在Redis实现的双链表里,<code>结点的值不能被修改只能被删除</code></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>3.Redis数据结构——SDS</title>
      <link href="/2020/02/18/3-Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-SDS/"/>
      <url>/2020/02/18/3-Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-SDS/</url>
      
        <content type="html"><![CDATA[<h2 id="3-1-什么是SDS"><a href="#3-1-什么是SDS" class="headerlink" title="3.1 什么是SDS"></a>3.1 什么是SDS</h2><p>C语言中有定义好的String字符串,但是Redis并没有使用String字符串来作为默认的字符串存储格式,而是定义了一个结构体SDS(简单动态字符串)来实现</p><p>Redis中的每一个键都是一个SDS,String类型的每一个值也都是SDS</p><h2 id="3-2-SDS结构"><a href="#3-2-SDS结构" class="headerlink" title="3.2 SDS结构"></a>3.2 SDS结构</h2><pre><code class="c">#file: /src/sds.h/* * 保存SDS对象的结构 */struct sdshdr {    // buf 中已占用空间的长度    int len;    // buf 中剩余可用空间的长度    int free;    // 数据空间    char buf[];};</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/sdsstruct.png" alt=""></p><h2 id="3-3-新建SDS"><a href="#3-3-新建SDS" class="headerlink" title="3.3 新建SDS"></a>3.3 新建SDS</h2><pre><code class="c">#dep/hiredis/sds.c#创建SDS对象　根据字符串指针获取其长度　传给sdsnewlensds sdsnew(const char *init) {    size_t initlen = (init == NULL) ? 0 : strlen(init);    return sdsnewlen(init, initlen);}#被sdsnew调用sds sdsnewlen(const void *init, size_t initlen) {    struct sdshdr *sh;    if (init) {        sh = zmalloc(sizeof(struct sdshdr)+initlen+1);    } else {        sh = zcalloc(sizeof(struct sdshdr)+initlen+1);    }    if (sh == NULL) return NULL;    sh-&gt;len = initlen;  //sds-&gt;len = 字符串长度    sh-&gt;free = 0;　　　　//sds-&gt;free = 0    if (initlen &amp;&amp; init)        memcpy(sh-&gt;buf, init, initlen);    sh-&gt;buf[initlen] = &#39;\0&#39;;    return (char*)sh-&gt;buf;}</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/sdsnew.png" alt=""></p><h2 id="3-4-修改SDS"><a href="#3-4-修改SDS" class="headerlink" title="3.4 修改SDS"></a>3.4 修改SDS</h2><pre><code class="c">#dep/hiredis/sds.csds sdscpy(sds s, const char *t) {    return sdscpylen(s, t, strlen(t));}sds sdscpylen(sds s, const char *t, size_t len) {    struct sdshdr *sh = (void*) (s-(sizeof(struct sdshdr)));    size_t totlen = sh-&gt;free+sh-&gt;len;    if (totlen &lt; len) {        # 特别注意sdsMakeRoomFor函数　是对sds的扩容操作        s = sdsMakeRoomFor(s,len-sh-&gt;len);        if (s == NULL) return NULL;        sh = (void*) (s-(sizeof(struct sdshdr)));        totlen = sh-&gt;free+sh-&gt;len;    }    memcpy(s, t, len);    s[len] = &#39;\0&#39;;    sh-&gt;len = len;    sh-&gt;free = totlen-len;    return s;}</code></pre><p>整体代码写的很清晰,没什么过多解释的,我们特别注意下<code>sdsMakeRoomFor</code>这个函数,是对sds的扩容操作：</p><pre><code class="c">#dep/hiredis/sds.c#define SDS_MAX_PREALLOC (1024*1024)  #1MBsds sdsMakeRoomFor(sds s, size_t addlen) {    struct sdshdr *sh, *newsh;    size_t free = sdsavail(s);    size_t len, newlen;    if (free &gt;= addlen) return s;    len = sdslen(s);    sh = (void*) (s-(sizeof(struct sdshdr)));    newlen = (len+addlen);    if (newlen &lt; SDS_MAX_PREALLOC)        newlen *= 2;    else        newlen += SDS_MAX_PREALLOC;    newsh = zrealloc(sh, sizeof(struct sdshdr)+newlen+1);    if (newsh == NULL) return NULL;    newsh-&gt;free = newlen - len;    return newsh-&gt;buf;}</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/sdsedit.png" alt=""></p><p>我们注意到:</p><ul><li>修改sds时redis会进行<code>空间预分配</code>,用以减少连续字符串增长操作所需的内存重新分配次数</li><li>如果将sds字符串缩短,sds的空间也不会立即释放,采用<code>惰性空间释放的方式</code>使用free属性将这些字节数量记录下来，将来使用<code>sdsRemoveFreeSpace</code>进行释放</li></ul><pre><code class="c">#dep/hiredis/sds.csds sdsRemoveFreeSpace(sds s) {    struct sdshdr *sh;    sh = (void*) (s-(sizeof(struct sdshdr)));    sh = zrealloc(sh, sizeof(struct sdshdr)+sh-&gt;len+1);    sh-&gt;free = 0;    return sh-&gt;buf;}</code></pre><h2 id="3-5-SDS与C字符串区别"><a href="#3-5-SDS与C字符串区别" class="headerlink" title="3.5 SDS与C字符串区别"></a>3.5 SDS与C字符串区别</h2><table><thead><tr><th align="center">序号</th><th>C 字符串</th><th>SDS</th></tr></thead><tbody><tr><td align="center">１</td><td>获取字符串长度的复杂度为 O(N)</td><td>获取字符串长度的复杂度为 O(1) 。</td></tr><tr><td align="center">２</td><td>API 是不安全的，可能会造成缓冲区溢出</td><td>API 是安全的，不会造成缓冲区溢出</td></tr><tr><td align="center">３</td><td>修改字符串长度 N 次必然需要执行 N 次内存重分配</td><td>修改字符串长度 N 次最多需要执行 N 次内存重分配</td></tr><tr><td align="center">４</td><td>只能保存文本数据</td><td>可以保存文本或者二进制数据</td></tr><tr><td align="center">５</td><td>可以使用所有 &lt;string.h&gt; 库中的函数</td><td>可以使用一部分 &lt;string.h&gt; 库中的函数</td></tr></tbody></table><p>区别①②④主要是因为sds结构的<code>len</code>属性,不依靠<code>\0</code>来判断结尾</p><p>区别③主要因为sds的空间预分配算法</p><p>区别⑤sds本质上还是一个封装了的string</p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2.Redis数据操作</title>
      <link href="/2020/02/18/2-Redis%E6%95%B0%E6%8D%AE%E6%93%8D%E4%BD%9C/"/>
      <url>/2020/02/18/2-Redis%E6%95%B0%E6%8D%AE%E6%93%8D%E4%BD%9C/</url>
      
        <content type="html"><![CDATA[<h2 id="2-1-String命令"><a href="#2-1-String命令" class="headerlink" title="2.1 String命令"></a>2.1 String命令</h2><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/string.png" alt=""></p><h2 id="2-2-List命令"><a href="#2-2-List命令" class="headerlink" title="2.2 List命令"></a>2.2 List命令</h2><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/list.png" alt=""></p><h2 id="2-3-Hash命令"><a href="#2-3-Hash命令" class="headerlink" title="2.3 Hash命令"></a>2.3 Hash命令</h2><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/hash.png" alt=""></p><h2 id="2-4-Set命令"><a href="#2-4-Set命令" class="headerlink" title="2.4 Set命令"></a>2.4 Set命令</h2><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/set.png" alt=""></p><h2 id="2-5-ZSet命令"><a href="#2-5-ZSet命令" class="headerlink" title="2.5 ZSet命令"></a>2.5 ZSet命令</h2><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/zset.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>1.Redis简介</title>
      <link href="/2020/02/18/1-Redis%E7%AE%80%E4%BB%8B/"/>
      <url>/2020/02/18/1-Redis%E7%AE%80%E4%BB%8B/</url>
      
        <content type="html"><![CDATA[<h2 id="1-1-Redis特点"><a href="#1-1-Redis特点" class="headerlink" title="1.1 Redis特点"></a>1.1 Redis特点</h2><ul><li>Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用。</li><li>Redis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。</li><li>Redis支持数据的备份，即master-slave模式的数据备份</li><li>Redis有原生的集群模式</li><li>Redis是单线程模式</li></ul><h2 id="1-2-与Memcache对比"><a href="#1-2-与Memcache对比" class="headerlink" title="1.2 与Memcache对比"></a>1.2 与Memcache对比</h2><table><thead><tr><th align="center">名称</th><th align="center">持久化</th><th align="center">数据类型</th><th>集群支持</th></tr></thead><tbody><tr><td align="center">Redis</td><td align="center">可持久化</td><td align="center">五种</td><td>原生支持cluster模式</td></tr><tr><td align="center">Memcached</td><td align="center">不可持久化</td><td align="center">一种</td><td>没有原生的集群模式,需要依靠客户端来实现往集群中分片写入数据</td></tr></tbody></table><h2 id="1-3-Redis线程模型"><a href="#1-3-Redis线程模型" class="headerlink" title="1.3 Redis线程模型"></a>1.3 Redis线程模型</h2><p>redis 基于 <code>reactor 模式</code>开发了网络事件处理器，这个处理器叫做文件事件处理器，file event handler，这个文件事件处理器是单线程的，所以redis 是单线程的模型，采用 io多路复用机制同时监听多个 socket,根据socket上的事件来选择对应的事件处理器来处理这个事件</p><p>文件事件处理器的结构包含 4 个部分：</p><ul><li>多个 Socket</li><li>IO 多路复用程序</li><li>文件事件分派器</li><li>事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）</li></ul><p>多个 Socket 可能会并发产生不同的操作，每个操作对应不同的文件事件，但是 IO 多路复用程序会监听多个 Socket，会将 Socket 产生的事件放入队列中排队，事件分派器每次从队列中取出一个事件，把该事件交给对应的事件处理器进行处理。</p><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/even.png" alt=""></p><h2 id="1-4-Redis为什么效率高"><a href="#1-4-Redis为什么效率高" class="headerlink" title="1.4 Redis为什么效率高"></a>1.4 Redis为什么效率高</h2><ul><li>纯内存操作</li><li>核心是基于非堵塞的IO多路复用机制</li><li>单线程反而避免了多线程的频繁上下文切换问题</li></ul><h2 id="1-5-Redis-数据结构"><a href="#1-5-Redis-数据结构" class="headerlink" title="1.5 Redis 数据结构"></a>1.5 Redis 数据结构</h2><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/datastruct.png" alt=""></p><p>​    </p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>9.MysqlProfile介绍</title>
      <link href="/2020/02/16/9-MysqlProfile%E4%BB%8B%E7%BB%8D/"/>
      <url>/2020/02/16/9-MysqlProfile%E4%BB%8B%E7%BB%8D/</url>
      
        <content type="html"><![CDATA[<h2 id="9-1-相关参数"><a href="#9-1-相关参数" class="headerlink" title="9.1 相关参数"></a>9.1 相关参数</h2><pre><code class="mysql">mysql&gt; show variables like &#39;%profil%&#39;;+------------------------+-------+| Variable_name          | Value |+------------------------+-------+| have_profiling         | YES   || profiling              | OFF   || profiling_history_size | 15    |+------------------------+-------+3 rows in set (0.01 sec)have_profiling： 当前版本是否支持profiling功能profiling： 是否开启profiling功能profiling_history_size： 保留profiling的数目，默认是15，范围为0~100，为0时代表禁用profiling</code></pre><h2 id="9-2-开启profile"><a href="#9-2-开启profile" class="headerlink" title="9.2 开启profile"></a>9.2 开启profile</h2><pre><code class="mysql">session级别开启:mysql&gt; SET profiling = 1;全局开启echo &quot;profiling=1&quot; &gt;&gt; my.cnf</code></pre><h2 id="9-3-help-profile"><a href="#9-3-help-profile" class="headerlink" title="9.3 help profile"></a>9.3 help profile</h2><p>我们可以通过help profile查看profile的用法,官方的解释已经很好了</p><pre><code class="mysql">mysql&gt; help profile;Name: &#39;SHOW PROFILE&#39;Description:Syntax:SHOW PROFILE [type [, type] ... ]    [FOR QUERY n]    [LIMIT row_count [OFFSET offset]]type: {    ALL  | BLOCK IO  | CONTEXT SWITCHES  | CPU  | IPC  | MEMORY  | PAGE FAULTS  | SOURCE  | SWAPS}The SHOW PROFILE and SHOW PROFILES statements display profilinginformation that indicates resource usage for statements executedduring the course of the current session.*Note*:The SHOW PROFILE and SHOW PROFILES statements are deprecated and willbe removed in a future MySQL release. Use the Performance Schemainstead; seehttp://dev.mysql.com/doc/refman/5.7/en/performance-schema-query-profiling.html.To control profiling, use the profiling session variable, which has adefault value of 0 (OFF). Enable profiling by setting profiling to 1 orON:mysql&gt; SET profiling = 1;SHOW PROFILES displays a list of the most recent statements sent to theserver. The size of the list is controlled by theprofiling_history_size session variable, which has a default value of15. The maximum value is 100. Setting the value to 0 has the practicaleffect of disabling profiling.All statements are profiled except SHOW PROFILE and SHOW PROFILES, soyou will find neither of those statements in the profile list.Malformed statements are profiled. For example, SHOW PROFILING is anillegal statement, and a syntax error occurs if you try to execute it,but it will show up in the profiling list.SHOW PROFILE displays detailed information about a single statement.Without the FOR QUERY n clause, the output pertains to the mostrecently executed statement. If FOR QUERY n is included, SHOW PROFILEdisplays information for statement n. The values of n correspond to theQuery_ID values displayed by SHOW PROFILES.The LIMIT row_count clause may be given to limit the output torow_count rows. If LIMIT is given, OFFSET offset may be added to beginthe output offset rows into the full set of rows.By default, SHOW PROFILE displays Status and Duration columns. TheStatus values are like the State values displayed by SHOW PROCESSLIST,although there might be some minor differences in interpretion for thetwo statements for some status values (seehttp://dev.mysql.com/doc/refman/5.7/en/thread-information.html).Optional type values may be specified to display specific additionaltypes of information:o ALL displays all informationo BLOCK IO displays counts for block input and output operationso CONTEXT SWITCHES displays counts for voluntary and involuntary  context switcheso CPU displays user and system CPU usage timeso IPC displays counts for messages sent and receivedo MEMORY is not currently implementedo PAGE FAULTS displays counts for major and minor page faultso SOURCE displays the names of functions from the source code, together  with the name and line number of the file in which the function  occurso SWAPS displays swap countsProfiling is enabled per session. When a session ends, its profilinginformation is lost.URL: http://dev.mysql.com/doc/refman/5.7/en/show-profile.htmlExamples:mysql&gt; SELECT @@profiling;+-------------+| @@profiling |+-------------+|           0 |+-------------+1 row in set (0.00 sec)mysql&gt; SET profiling = 1;Query OK, 0 rows affected (0.00 sec)mysql&gt; DROP TABLE IF EXISTS t1;Query OK, 0 rows affected, 1 warning (0.00 sec)mysql&gt; CREATE TABLE T1 (id INT);Query OK, 0 rows affected (0.01 sec)mysql&gt; SHOW PROFILES;+----------+----------+--------------------------+| Query_ID | Duration | Query                    |+----------+----------+--------------------------+|        0 | 0.000088 | SET PROFILING = 1        ||        1 | 0.000136 | DROP TABLE IF EXISTS t1  ||        2 | 0.011947 | CREATE TABLE t1 (id INT) |+----------+----------+--------------------------+3 rows in set (0.00 sec)mysql&gt; SHOW PROFILE;+----------------------+----------+| Status               | Duration |+----------------------+----------+| checking permissions | 0.000040 || creating table       | 0.000056 || After create         | 0.011363 || query end            | 0.000375 || freeing items        | 0.000089 || logging slow query   | 0.000019 || cleaning up          | 0.000005 |+----------------------+----------+7 rows in set (0.00 sec)mysql&gt; SHOW PROFILE FOR QUERY 1;+--------------------+----------+| Status             | Duration |+--------------------+----------+| query end          | 0.000107 || freeing items      | 0.000008 || logging slow query | 0.000015 || cleaning up        | 0.000006 |+--------------------+----------+4 rows in set (0.00 sec)mysql&gt; SHOW PROFILE CPU FOR QUERY 2;+----------------------+----------+----------+------------+| Status               | Duration | CPU_user | CPU_system |+----------------------+----------+----------+------------+| checking permissions | 0.000040 | 0.000038 |   0.000002 || creating table       | 0.000056 | 0.000028 |   0.000028 || After create         | 0.011363 | 0.000217 |   0.001571 || query end            | 0.000375 | 0.000013 |   0.000028 || freeing items        | 0.000089 | 0.000010 |   0.000014 || logging slow query   | 0.000019 | 0.000009 |   0.000010 || cleaning up          | 0.000005 | 0.000003 |   0.000002 |+----------------------+----------+----------+------------+7 rows in set (0.00 sec)</code></pre><h2 id="9-4-type类型"><a href="#9-4-type类型" class="headerlink" title="9.4 type类型"></a>9.4 type类型</h2><p>这里我们主要关注两个指标　</p><ul><li><code>ALL</code>:显示所性能信息</li><li><code>BLOCK IO</code>:显示块(页)IO的数量<ul><li>BLOCK_OPS_IN:输入页数量</li><li>BLOCK_OPS_OUT:输出页数量</li></ul></li><li><code>CONTEXT SWITCHES</code>:上下文切换相关开销</li><li><code>CPU</code>:显示CPU相关开销信息<ul><li>CPU_user:用户所用时间,秒单位 </li><li>CPU_system:系统所用时间,秒单位 </li></ul></li><li><code>IPC</code>:显示发送和接收相关开销信息</li><li><code>MEMORY</code>:显示内存相关开销信息</li><li><code>PAGE FAULTS</code> :显示页面错误相关开销信息</li><li><code>SOURCE</code> :显示和Source_function，Source_file，Source_line相关的开销信息</li><li><code>SWAPS</code> :显示交换次数相关开销的信息</li></ul><h2 id="9-5-profile过程"><a href="#9-5-profile过程" class="headerlink" title="9.5 profile过程"></a>9.5 profile过程</h2><pre><code class="mysql">mysql&gt; show profile for query 4;+----------------------+-----------+| Status               | Duration  |+----------------------+-----------+| starting             |  0.000083 || checking permissions |  0.000013 || Opening tables       |  0.000019 || init                 |  0.000036 || System lock          |  0.000014 || optimizing           |  0.000012 || statistics           |  0.000021 || preparing            |  0.000018 || executing            |  0.000006 || Sending data         | 87.327560 || end                  |  0.000016 || query end            |  0.000013 || closing tables       |  0.000011 || freeing items        |  0.000027 || logging slow query   |  0.000057 || cleaning up          |  0.000017 |+----------------------+-----------+16 rows in set, 1 warning (0.00 sec)starting：开始checking permissions：检查权限Opening tables：打开表init ： 初始化System lock ：系统锁optimizing ： 优化statistics ： 统计preparing ：准备executing ：执行Sending data ：发送数据Sorting result ：排序end ：结束query end ：查询 结束closing tables ： 关闭表 ／去除TMP 表freeing items ： 释放事件cleaning up ：清理profile只能列出使用到的环节　没有使用的环节不显示</code></pre><h3 id="9-5-1-重点环节"><a href="#9-5-1-重点环节" class="headerlink" title="9.5.1 重点环节"></a>9.5.1 重点环节</h3><ul><li><code>preparing</code> ：准备</li><li><code>executing</code> ：执行</li><li><code>Sending data</code> ：发送数据  一般这个环节时间最长</li><li><code>Sorting result</code> ：排序</li></ul><h3 id="9-5-2-不应-减少出现的环节"><a href="#9-5-2-不应-减少出现的环节" class="headerlink" title="9.5.2 不应/减少出现的环节"></a>9.5.2 不应/减少出现的环节</h3><ul><li><code>converting HEAP to MyISAM</code>： 查询结果太大，内存都不够用了，往磁盘上搬了</li><li><code>creating tmp table</code> ：创建临时表，拷贝数据到临时表，然后再删除</li><li><code>copying to tmp table on disk</code> ：把内存中临时表复制到磁盘</li><li><code>locked</code>: 被锁喉了~</li></ul><h2 id="9-6-日常常用指令"><a href="#9-6-日常常用指令" class="headerlink" title="9.6 日常常用指令"></a>9.6 日常常用指令</h2><pre><code class="mysql">SHOW PROFILE block io,cpu FOR QUERY N;多注意CPU和IOmysql&gt; SHOW PROFILE block io,cpu FOR QUERY 4\G;*************************** 1. row ***************************       Status: starting     Duration: 0.000083     CPU_user: 0.000049   CPU_system: 0.000025 Block_ops_in: 0Block_ops_out: 0*************************** 2. row ***************************       Status: checking permissions     Duration: 0.000013     CPU_user: 0.000006   CPU_system: 0.000003 Block_ops_in: 0Block_ops_out: 0*************************** 3. row ***************************       Status: Opening tables     Duration: 0.000019     CPU_user: 0.000012   CPU_system: 0.000006 Block_ops_in: 0Block_ops_out: 0*************************** 4. row ***************************       Status: init     Duration: 0.000036     CPU_user: 0.000022   CPU_system: 0.000012 Block_ops_in: 0Block_ops_out: 0*************************** 5. row ***************************       Status: System lock     Duration: 0.000014     CPU_user: 0.000008   CPU_system: 0.000004 Block_ops_in: 0Block_ops_out: 0*************************** 6. row ***************************       Status: optimizing     Duration: 0.000012     CPU_user: 0.000007   CPU_system: 0.000003 Block_ops_in: 0Block_ops_out: 0*************************** 7. row ***************************       Status: statistics     Duration: 0.000021     CPU_user: 0.000013   CPU_system: 0.000007 Block_ops_in: 0Block_ops_out: 0*************************** 8. row ***************************       Status: preparing     Duration: 0.000018     CPU_user: 0.000011   CPU_system: 0.000006 Block_ops_in: 0Block_ops_out: 0*************************** 9. row ***************************       Status: executing     Duration: 0.000006     CPU_user: 0.000003   CPU_system: 0.000002 Block_ops_in: 0Block_ops_out: 0*************************** 10. row ***************************       Status: Sending data     Duration: 87.327560     CPU_user: 37.617680   CPU_system: 32.943640 Block_ops_in: 2591264Block_ops_out: 0*************************** 11. row ***************************       Status: end     Duration: 0.000016     CPU_user: 0.000006   CPU_system: 0.000004 Block_ops_in: 0Block_ops_out: 0*************************** 12. row ***************************       Status: query end     Duration: 0.000013     CPU_user: 0.000007   CPU_system: 0.000005 Block_ops_in: 0Block_ops_out: 0*************************** 13. row ***************************       Status: closing tables     Duration: 0.000011     CPU_user: 0.000006   CPU_system: 0.000004 Block_ops_in: 0Block_ops_out: 0*************************** 14. row ***************************       Status: freeing items     Duration: 0.000027     CPU_user: 0.000015   CPU_system: 0.000010 Block_ops_in: 0Block_ops_out: 0*************************** 15. row ***************************       Status: logging slow query     Duration: 0.000057     CPU_user: 0.000032   CPU_system: 0.000021 Block_ops_in: 0Block_ops_out: 8*************************** 16. row ***************************       Status: cleaning up     Duration: 0.000017     CPU_user: 0.000009   CPU_system: 0.000006 Block_ops_in: 0Block_ops_out: 016 rows in set, 1 warning (0.00 sec)ERROR: No query specified</code></pre><h2 id="9-7-使用Performance查看profi"><a href="#9-7-使用Performance查看profi" class="headerlink" title="9.7  使用Performance查看profi"></a>9.7  使用Performance查看profi</h2><p>通过help profile我们知道show proflie相关指令即将废弃,可以使用如下指令进行查询</p><p>在使用以下两个命令前需要做一些设置角色的操作:具体请参考官方文档:</p><p><a href="https://dev.mysql.com/doc/refman/5.7/en/performance-schema-query-profiling.html" target="_blank" rel="noopener">25.19.1 Query Profiling Using Performance Schema</a></p><h3 id="9-7-1-查看所有语句"><a href="#9-7-1-查看所有语句" class="headerlink" title="9.7.1 查看所有语句"></a>9.7.1 查看所有语句</h3><pre><code class="mysql">mysql&gt; SELECT EVENT_ID, TRUNCATE(TIMER_WAIT/1000000000000,6) as Duration, SQL_TEXT        FROM performance_schema.events_statements_history_long\G;*************************** 1. row ***************************EVENT_ID: 146Duration: 0.000842SQL_TEXT: UPDATE performance_schema.setup_consumers       SET ENABLED = &#39;YES&#39;       WHERE NAME LIKE &#39;%events_statements_%&#39;*************************** 2. row ***************************EVENT_ID: 147Duration: 0.000376SQL_TEXT: UPDATE performance_schema.setup_consumers       SET ENABLED = &#39;YES&#39;       WHERE NAME LIKE &#39;%events_stages_%&#39;*************************** 3. row ***************************EVENT_ID: 154Duration: 2.089741SQL_TEXT: select count(*) from t_scrm_pet_info where pet_birthday &gt; &#39;2019-01-01 00:00:01&#39; and pet_birthday &lt; &#39;2019-03-01 00:00:01&#39;*************************** 4. row ***************************EVENT_ID: 171Duration: 0.003488SQL_TEXT: SELECT EVENT_ID, TRUNCATE(TIMER_WAIT/1000000000000,6) as Duration, SQL_TEXT       FROM performance_schema.events_statements_history_long*************************** 5. row ***************************EVENT_ID: 188Duration: 0.000899SQL_TEXT: SELECT event_name AS Stage, TRUNCATE(TIMER_WAIT/1000000000000,6) AS Duration       FROM performance_schema.events_stages_history_long WHERE NESTING_EVENT_ID=154*************************** 6. row ***************************EVENT_ID: 205Duration: 0.000480SQL_TEXT: SELECT event_name AS Stage, TRUNCATE(TIMER_WAIT/1000000000000,6) AS Duration        FROM performance_schema.events_stages_history_long WHERE NESTING_EVENT_ID=154*************************** 7. row ***************************EVENT_ID: 222Duration: 0.000669SQL_TEXT: SELECT EVENT_ID, TRUNCATE(TIMER_WAIT/1000000000000,6) as Duration, SQL_TEXT        FROM performance_schema.events_statements_history_long7 rows in set (0.00 sec)ERROR: No query specified</code></pre><h3 id="9-7-2-查看指定语句"><a href="#9-7-2-查看指定语句" class="headerlink" title="9.7.2 查看指定语句"></a>9.7.2 查看指定语句</h3><pre><code class="mysql">mysql&gt; SELECT event_name AS Stage, TRUNCATE(TIMER_WAIT/1000000000000,6) AS Duration        FROM performance_schema.events_stages_history_long WHERE NESTING_EVENT_ID=154\G;*************************** 1. row ***************************   Stage: stage/sql/startingDuration: 0.000105*************************** 2. row ***************************   Stage: stage/sql/checking permissionsDuration: 0.000008*************************** 3. row ***************************   Stage: stage/sql/Opening tablesDuration: 0.000021*************************** 4. row ***************************   Stage: stage/sql/initDuration: 0.000059*************************** 5. row ***************************   Stage: stage/sql/System lockDuration: 0.000016*************************** 6. row ***************************   Stage: stage/sql/optimizingDuration: 0.000014*************************** 7. row ***************************   Stage: stage/sql/statisticsDuration: 0.000023*************************** 8. row ***************************   Stage: stage/sql/preparingDuration: 0.000017*************************** 9. row ***************************   Stage: stage/sql/executingDuration: 0.000002*************************** 10. row ***************************   Stage: stage/sql/Sending dataDuration: 2.089357*************************** 11. row ***************************   Stage: stage/sql/endDuration: 0.000005*************************** 12. row ***************************   Stage: stage/sql/query endDuration: 0.000012*************************** 13. row ***************************   Stage: stage/sql/closing tablesDuration: 0.000009*************************** 14. row ***************************   Stage: stage/sql/freeing itemsDuration: 0.000027*************************** 15. row ***************************   Stage: stage/sql/logging slow queryDuration: 0.000055*************************** 16. row ***************************   Stage: stage/sql/cleaning upDuration: 0.00000116 rows in set (0.00 sec)ERROR: No query specified</code></pre>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> Mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>8.MysqlExplain介绍</title>
      <link href="/2020/02/16/8-MysqlExplain%E4%BB%8B%E7%BB%8D/"/>
      <url>/2020/02/16/8-MysqlExplain%E4%BB%8B%E7%BB%8D/</url>
      
        <content type="html"><![CDATA[<h2 id="8-1-Explain各列意义"><a href="#8-1-Explain各列意义" class="headerlink" title="8.1 Explain各列意义"></a>8.1 Explain各列意义</h2><p>EXPLAIN 命令的输出内容大致如下:</p><pre><code class="mysql">mysql&gt; explain select *  from t_scrm_user_info where bigdata_user_id &gt; &#39;A1001036&#39; and bigdata_user_id &lt; &#39;A2100000&#39;\G;*************************** 1. row ***************************           id: 1  select_type: SIMPLE        table: t_scrm_user_info   partitions: NULL         type: rangepossible_keys: UQ_CUSTOMER_ID          key: UQ_CUSTOMER_ID      key_len: 130          ref: NULL         rows: 168902     filtered: 100.00        Extra: Using index condition1 row in set, 1 warning (0.00 sec)</code></pre><table><thead><tr><th align="center">列名称</th><th align="center">含义</th></tr></thead><tbody><tr><td align="center">id</td><td align="center">SELECT 查询的标识符. 每个 SELECT 都会自动分配一个唯一的标识符.</td></tr><tr><td align="center">select_type</td><td align="center">SELECT 查询的类型.</td></tr><tr><td align="center">table</td><td align="center">查询的是哪个表</td></tr><tr><td align="center">partitions</td><td align="center">匹配的分区</td></tr><tr><td align="center">type</td><td align="center">join 类型</td></tr><tr><td align="center">possible_keys</td><td align="center">此次查询中可能选用的索引</td></tr><tr><td align="center">key</td><td align="center">此次查询中确切使用到的索引.</td></tr><tr><td align="center">ref</td><td align="center">哪个字段或常数与 key 一起被使用</td></tr><tr><td align="center">rows</td><td align="center">显示此查询一共扫描了多少行. 这个是一个估计值.</td></tr><tr><td align="center">filtered</td><td align="center">表示此查询条件所过滤的数据的百分比</td></tr><tr><td align="center">extra</td><td align="center">额外的信息</td></tr></tbody></table><h2 id="8-2-id"><a href="#8-2-id" class="headerlink" title="8.2 id"></a>8.2 id</h2><p>表示select标识符，同时表明执行顺序，也就是说id是一个查询的序列号，查询序号即为sql语句执行的顺序。</p><ol><li>当id值相同时，按从上到下的顺序执行</li><li>当id全部不同时，按id从大到小执行</li><li>当id部分不同时，先执行id大的，id相同的，按从上到下的顺序执行</li></ol><h2 id="8-3-select-type"><a href="#8-3-select-type" class="headerlink" title="8.3 select_type"></a>8.3 select_type</h2><ol><li>SIMPLE 简单的select查询，查询中不包含子查询或者UNION</li><li>PRIMARY 查询中若包含任何复杂的子部分，最外层查询则被标记为PRIMARY</li><li>SUBQUERY 在SELECT或WHERE列表中包含了子查询</li><li>DERIVED 在FROM列表中包含的子查询被标记为DERIVED（衍生），MySQL会递归执行这些子查询，把结果放在临时表中</li><li>UNION 若第二个SELECT出现在UNION之后，则被标记为UNION：若UNION包含在FROM子句的子查询中，外层SELECT将被标记为：DERIVED</li><li>UNION RESULT 从UNION表获取结果的SELECT</li></ol><pre><code class="mysql">mysql&gt; explain select * from t_scrm_user_info where  id = 1\G;*************************** 1. row ***************************           id: 1  select_type: SIMPLE        table: t_scrm_user_info   partitions: NULL         type: constpossible_keys: PRIMARY,IX_ID_CREATE_TIME          key: PRIMARY      key_len: 4          ref: const         rows: 1     filtered: 100.00        Extra: NULL1 row in set, 1 warning (0.00 sec)ERROR: No query specified==================================================================================mysql&gt; explain select * from (select * from t_scrm_pet_info limit 20) t where  t.id = (select id from t_scrm_map limit 1)\G;*************************** 1. row ***************************           id: 1  select_type: PRIMARY        table: &lt;derived2&gt;   partitions: NULL         type: refpossible_keys: &lt;auto_key0&gt;          key: &lt;auto_key0&gt;      key_len: 4          ref: const         rows: 2     filtered: 100.00        Extra: Using where*************************** 2. row ***************************           id: 3  select_type: SUBQUERY        table: t_scrm_map   partitions: NULL         type: indexpossible_keys: NULL          key: IX_CREATE_TIME      key_len: 5          ref: NULL         rows: 11271619     filtered: 100.00        Extra: Using index*************************** 3. row ***************************           id: 2  select_type: DERIVED        table: t_scrm_pet_info   partitions: NULL         type: ALLpossible_keys: NULL          key: NULL      key_len: NULL          ref: NULL         rows: 4578062     filtered: 100.00        Extra: NULL3 rows in set, 1 warning (0.00 sec)ERROR: No query specified==================================================================================mysql&gt; explain select * from t_scrm_map where id =10 union select * from t_scrm_map where id = 20\G;*************************** 1. row ***************************           id: 1  select_type: PRIMARY        table: t_scrm_map   partitions: NULL         type: constpossible_keys: PRIMARY          key: PRIMARY      key_len: 4          ref: const         rows: 1     filtered: 100.00        Extra: NULL*************************** 2. row ***************************           id: 2  select_type: UNION        table: t_scrm_map   partitions: NULL         type: constpossible_keys: PRIMARY          key: PRIMARY      key_len: 4          ref: const         rows: 1     filtered: 100.00        Extra: NULL*************************** 3. row ***************************           id: NULL  select_type: UNION RESULT        table: &lt;union1,2&gt;   partitions: NULL         type: ALLpossible_keys: NULL          key: NULL      key_len: NULL          ref: NULL         rows: NULL     filtered: NULL        Extra: Using temporary3 rows in set, 1 warning (0.00 sec)</code></pre><h2 id="8-4-table"><a href="#8-4-table" class="headerlink" title="8.4 table"></a>8.4 table</h2><p>这一列表示 explain 的一行正在访问哪个表。</p><p>当 from 子句中有子查询时，table列是 <derivenN> 格式，表示当前查询依赖 id=N 的查询，于是先执行 id=N 的查询。当有 union 时，UNION RESULT 的 table 列的值为 &lt;union1,2&gt;，1和2表示参与 union 的 select 行id。</p><h2 id="8-5-partitions"><a href="#8-5-partitions" class="headerlink" title="8.5 partitions"></a>8.5 partitions</h2><p>使用的哪些分区（对于非分区表值为null）</p><h2 id="8-6-type"><a href="#8-6-type" class="headerlink" title="8.6 type"></a>8.6 type</h2><p>type所显示的是查询使用了哪种类型，type包含的类型包括如下图所示的几种：</p><p>从最好到最差依次是：</p><pre><code>system &gt; const &gt; eq_ref &gt; ref &gt; range &gt; index &gt; all</code></pre><p>一般来说，得保证查询至少达到range级别，最好能达到ref。</p><ul><li><code>const, system</code>：mysql能对查询的某部分进行优化并将其转化成一个常量。用于 primary key 或 unique key 的所有列与常数比较时，所以表最多有一个匹配行，读取1次，速度比较快。</li></ul><pre><code class="mysql">mysql&gt; explain select * from t_scrm_user_info where bigdata_user_id = &#39;B13470427&#39;\G;*************************** 1. row ***************************           id: 1  select_type: SIMPLE        table: t_scrm_user_info   partitions: NULL         type: constpossible_keys: UQ_CUSTOMER_ID          key: UQ_CUSTOMER_ID      key_len: 130          ref: const         rows: 1     filtered: 100.00        Extra: NULL1 row in set, 1 warning (0.00 sec)</code></pre><ul><li><code>eq_ref</code>：primary key 或 unique key 索引的所有部分被连接使用 ，最多只会返回一条符合条件的记录。这可能是在 const 之外最好的<code>联接类型</code>了，简单的 select 查询不会出现这种 type。</li></ul><pre><code class="mysql">mysql&gt; explain select * from t_scrm_user_info u left join t_scrm_map m on u.bigdata_user_id = m.bigdata_id where u.bigdata_user_id = &#39;B13470427&#39;\G;*************************** 1. row ***************************           id: 1  select_type: SIMPLE        table: u   partitions: NULL         type: constpossible_keys: UQ_CUSTOMER_ID          key: UQ_CUSTOMER_ID      key_len: 130          ref: const         rows: 1     filtered: 100.00        Extra: NULL*************************** 2. row ***************************           id: 1  select_type: SIMPLE        table: m   partitions: NULL         type: refpossible_keys: UQ_ID          key: UQ_ID      key_len: 258          ref: const         rows: 1     filtered: 100.00        Extra: Using where2 rows in set, 1 warning (0.00 sec)</code></pre><ul><li>ref：相比 eq_ref，不使用唯一索引，而是使用普通索引或者唯一性索引的部分前缀，索引要和某个值相比较，可能会找到多个符合条件的行。</li></ul><pre><code class="mysql">mysql&gt; explain select * from t_scrm_map where target_id = &#39;11255964&#39;\G;*************************** 1. row ***************************           id: 1  select_type: SIMPLE        table: t_scrm_map   partitions: NULL         type: refpossible_keys: IX_TRAGET_ID          key: IX_TRAGET_ID      key_len: 130          ref: const         rows: 1     filtered: 100.00        Extra: NULL1 row in set, 1 warning (0.00 sec)</code></pre><ul><li><code>ref_or_null</code>：类似ref，但是可以搜索值为NULL的行。</li><li><code>range</code>：范围扫描通常出现在 in(), between ,&gt; ,&lt;, &gt;= 等操作中。使用一个索引来检索给定范围的行。</li></ul><pre><code class="mysql">mysql&gt; explain select * from t_scrm_map where id &gt; 10 and id  &lt;20\G;*************************** 1. row ***************************           id: 1  select_type: SIMPLE        table: t_scrm_map   partitions: NULL         type: rangepossible_keys: PRIMARY          key: PRIMARY      key_len: 4          ref: NULL         rows: 9     filtered: 100.00        Extra: Using where1 row in set, 1 warning (0.00 sec)ERROR: No query specified</code></pre><ul><li><code>index</code>：和ALL一样，不同就是mysql只需扫描索引树，这通常比ALL快一些。</li></ul><pre><code class="mysql">mysql&gt; explain select count(*) from t_scrm_map\G;*************************** 1. row ***************************           id: 1  select_type: SIMPLE        table: t_scrm_map   partitions: NULL         type: indexpossible_keys: NULL          key: IX_CREATE_TIME      key_len: 5          ref: NULL         rows: 11271619     filtered: 100.00        Extra: Using index1 row in set, 1 warning (0.00 sec)ERROR: No query specified</code></pre><ul><li><code>ALL</code>：即全表扫描，意味着mysql需要从头到尾去查找所需要的行。通常情况下这需要增加索引来进行优化了</li></ul><pre><code class="mysql">mysql&gt; explain select * from t_scrm_map\G;*************************** 1. row ***************************           id: 1  select_type: SIMPLE        table: t_scrm_map   partitions: NULL         type: ALLpossible_keys: NULL          key: NULL      key_len: NULL          ref: NULL         rows: 11271619     filtered: 100.00        Extra: NULL1 row in set, 1 warning (0.00 sec)ERROR: No query specified</code></pre><h2 id="8-7-possible-keys"><a href="#8-7-possible-keys" class="headerlink" title="8.7  possible_keys"></a>8.7  possible_keys</h2><p>这一列显示查询可能使用哪些索引来查找。 </p><p>explain 时可能出现 possible_keys 有列，而 key 显示 NULL 的情况，这种情况是因为表中数据不多，mysql认为索引对此查询帮助不大，选择了全表查询。 </p><p>如果该列是NULL，则没有相关的索引。在这种情况下，可以通过检查 where 子句看是否可以创造一个适当的索引来提高查询性能，然后用 explain 查看效果。</p><h2 id="8-8-key"><a href="#8-8-key" class="headerlink" title="8.8 key"></a>8.8 key</h2><p>这一列显示mysql实际采用哪个索引来优化对该表的访问。</p><p>如果没有使用索引，则该列是 NULL。如果想强制mysql使用或忽视possible_keys列中的索引，在查询中使用 force index、ignore index。</p><h2 id="8-9-key-len列"><a href="#8-9-key-len列" class="headerlink" title="8.9 key_len列"></a>8.9 key_len列</h2><p>这一列显示了mysql在索引里使用的字节数，通过这个值可以算出具体使用了索引中的哪些列。 </p><pre><code class="mysql">key_len 的计算规则如下:字符串char(n): n 字节长度varchar(n): 如果是 utf8 编码, 则是 3 n + 2字节; 如果是 utf8mb4 编码, 则是 4n +2 字节.数值类型:TINYINT: 1字节SMALLINT: 2字节MEDIUMINT: 3字节INT: 4字节BIGINT: 8字节时间类型DATE: 3字节TIMESTAMP: 4字节DATETIME: 8字节字段属性: NULL 属性 占用一个字节. 如果一个字段是 NOT NULL 的, 则没有此属性.</code></pre><pre><code class="mysql">mysql&gt; explain select count(*) from t_scrm_map where target_id  = &#39;11255964&#39;\G;*************************** 1. row ***************************           id: 1  select_type: SIMPLE        table: t_scrm_map   partitions: NULL         type: refpossible_keys: IX_TRAGET_ID          key: IX_TRAGET_ID      key_len: 130          ref: const         rows: 1     filtered: 100.00        Extra: Using index1 row in set, 1 warning (0.00 sec)/**| t_scrm_map | CREATE TABLE `t_scrm_map` (  `id` int(10) unsigned NOT NULL AUTO_INCREMENT,  `bigdata_id` varchar(64) NOT NULL COMMENT &#39;唯一ID&#39;,  `type` tinyint(3) NOT NULL COMMENT &#39;关联类型&#39;,  PRIMARY KEY (`id`),  UNIQUE KEY `UQ_ID` (`bigdata_id`,`type`),  KEY `IX_MAP_ID` (`scrm_id`),) ENGINE=InnoDB AUTO_INCREMENT=11962156 DEFAULT CHARSET=utf8mb4 ROW_FORMAT=DYNAMIC COMMENT=&#39;关系表&#39; |*/mysql&gt; explain select count(*) from t_scrm_map where bigdata_id  = &#39;11255964&#39;\G;*************************** 1. row ***************************           id: 1  select_type: SIMPLE        table: t_scrm_map   partitions: NULL         type: refpossible_keys: UQ_ID          key: UQ_ID      key_len: 258          ref: const         rows: 1     filtered: 100.00        Extra: Using index1 row in set, 1 warning (0.04 sec)可以看到key_len = 258---&gt; 64*4+2;即只使用了索引UQ_ID的bigdata_id部分mysql&gt; explain select * from t_scrm_map where bigdata_id  = &#39;B11255964&#39; and type = 1\G;*************************** 1. row ***************************           id: 1  select_type: SIMPLE        table: t_scrm_map   partitions: NULL         type: constpossible_keys: UQ_ID          key: UQ_ID      key_len: 259          ref: const,const         rows: 1     filtered: 100.00        Extra: NULL1 row in set, 1 warning (0.04 sec)可以看到key_len = 258---&gt; 64*4+2+1;即使用了索引UQ_ID的bigdata_id和type部分</code></pre><h2 id="8-10-ref列"><a href="#8-10-ref列" class="headerlink" title="8.10 ref列"></a>8.10 ref列</h2><p>这一列显示了在key列记录的索引中，表查找值所用到的列或常量，常见的有：</p><ul><li><p>const（常量）</p></li><li><p>func</p></li><li><p>NULL</p></li><li><p>字段名</p></li></ul><h2 id="8-11-rows列rows"><a href="#8-11-rows列rows" class="headerlink" title="8.11 rows列rows"></a>8.11 rows列rows</h2><p>rows 也是一个重要的字段. MySQL 查询优化器根据统计信息, 估算 SQL 要查找到结果集需要扫描读取的数据行数. 这个值非常直观显示 SQL 的效率好坏, 原则上 rows 越少越好.</p><h2 id="8-12-Extra列"><a href="#8-12-Extra列" class="headerlink" title="8.12 Extra列"></a>8.12 Extra列</h2><p>这一列展示的是额外信息。常见的重要值如下： </p><h3 id="8-12-1-Using-filesort"><a href="#8-12-1-Using-filesort" class="headerlink" title="8.12.1 Using filesort"></a>8.12.1 Using filesort</h3><p>mysql 会对结果使用一个外部索引排序，而不是按索引次序从表里读取行。此时mysql会根据联接类型浏览所有符合条件的记录，并保存排序关键字和行指针，然后排序关键字并按顺序检索行信息。</p><p><code>这种情况是要考虑使用索引来优化的</code></p><pre><code class="mysql">mysql&gt; explain select * from t_scrm_map order by type asc\G;*************************** 1. row ***************************           id: 1  select_type: SIMPLE        table: t_scrm_map   partitions: NULL         type: ALLpossible_keys: NULL          key: NULL      key_len: NULL          ref: NULL         rows: 11271619     filtered: 100.00        Extra: Using filesort1 row in set, 1 warning (0.00 sec)</code></pre><h3 id="8-12-2-Using-temporary"><a href="#8-12-2-Using-temporary" class="headerlink" title="8.12.2 Using temporary"></a>8.12.2 Using temporary</h3><p>使用临时表保存中间结果，常用于GROUP BY 和 ORDER BY,DISTINCT操作中。</p><p>出现这种情况一般是要进行优化的，首先是想到用索引来优化。</p><pre><code class="mysql">mysql&gt; explain select distinct(type) from t_scrm_map order by type asc\G;*************************** 1. row ***************************           id: 1  select_type: SIMPLE        table: t_scrm_map   partitions: NULL         type: indexpossible_keys: UQ_ID          key: UQ_ID      key_len: 259          ref: NULL         rows: 11271619     filtered: 100.00        Extra: Using index; Using temporary; Using filesort1 row in set, 1 warning (0.00 sec)</code></pre><h3 id="8-12-3-Using-where"><a href="#8-12-3-Using-where" class="headerlink" title="8.12.3 Using where"></a>8.12.3 Using where</h3><p>在查找使用索引的情况下，需要回表去查询所需的数据</p><pre><code class="mysql">mysql&gt; explain select * from t_scrm_map where target_id  = &#39;11255964&#39; and type =2\G;*************************** 1. row ***************************           id: 1  select_type: SIMPLE        table: t_scrm_map   partitions: NULL         type: refpossible_keys: IX_TRAGET_ID          key: IX_TRAGET_ID      key_len: 130          ref: const         rows: 1     filtered: 10.00        Extra: Using where1 row in set, 1 warning (0.00 sec)</code></pre><h3 id="8-12-4-Using-index"><a href="#8-12-4-Using-index" class="headerlink" title="8.12.4 Using index"></a>8.12.4 Using index</h3><p>这发生在对表的请求列都是同一索引的部分的时候，返回的列数据只使用了索引中的信息，而没有再去访问表中的行记录。是性能高的表现。</p><pre><code class="mysql">mysql&gt; explain select count(*) from t_scrm_map\G;*************************** 1. row ***************************           id: 1  select_type: SIMPLE        table: t_scrm_map   partitions: NULL         type: indexpossible_keys: NULL          key: IX_CREATE_TIME      key_len: 5          ref: NULL         rows: 11271619     filtered: 100.00        Extra: Using index1 row in set, 1 warning (0.00 sec)</code></pre><h3 id="8-12-5-Using-index-condition"><a href="#8-12-5-Using-index-condition" class="headerlink" title="8.12.5 Using index condition"></a>8.12.5 Using index condition</h3><p>这是MySQL 5.6出来的新特性，叫做“索引条件推送”。</p><p>简单说一点就是MySQL原来在索引上是不能执行如like这样的操作的，但是现在可以了，这样减少了不必要的IO操作，但是只能用在二级索引上。</p><pre><code class="mysql">mysql&gt; explain select * from t_scrm_map where bigdata_id  = &#39;B11255964&#39; or bigdata_id like &#39;B125294%&#39;\G;*************************** 1. row ***************************           id: 1  select_type: SIMPLE        table: t_scrm_map   partitions: NULL         type: rangepossible_keys: UQ_ID          key: UQ_ID      key_len: 258          ref: NULL         rows: 8     filtered: 100.00        Extra: Using index condition1 row in set, 1 warning (0.00 sec)</code></pre><h3 id="8-12-6-Using-join-buffer"><a href="#8-12-6-Using-join-buffer" class="headerlink" title="8.12.6 Using join buffer"></a>8.12.6 Using join buffer</h3><p>使用了连接缓存：</p><ul><li>Block Nested Loop，连接算法是块嵌套循环连接;</li><li>Batched Key Access，连接算法是批量索引连接</li></ul><h3 id="8-12-7-Using-MRR"><a href="#8-12-7-Using-MRR" class="headerlink" title="8.12.7 Using MRR"></a>8.12.7 Using MRR</h3><p>使用了MRR优化算法</p><pre><code class="mysql">mysql&gt; explain select *  from t_scrm_user_info where bigdata_user_id &gt; &#39;A1001036&#39; and bigdata_user_id &lt; &#39;A2100000&#39;\G;*************************** 1. row ***************************           id: 1  select_type: SIMPLE        table: t_scrm_user_info   partitions: NULL         type: rangepossible_keys: UQ_CUSTOMER_ID          key: UQ_CUSTOMER_ID      key_len: 130          ref: NULL         rows: 168902     filtered: 100.00        Extra: Using index condition; Using MRR1 row in set, 1 warning (0.00 sec)</code></pre>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> Mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>7.Mysql优化器算法</title>
      <link href="/2020/02/16/7-Mysql%E4%BC%98%E5%8C%96%E5%99%A8%E7%AE%97%E6%B3%95/"/>
      <url>/2020/02/16/7-Mysql%E4%BC%98%E5%8C%96%E5%99%A8%E7%AE%97%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<p>除了我们自己手动进行优化外,根据之前的章节,我们可以知道,Mysql内部自己有优化器,对SQL语句进行一些内部的优化,本章介绍几个常用的优化算法:</p><ul><li>MRR</li><li>ICP</li><li>BKA</li></ul><h2 id="7-1-MRR"><a href="#7-1-MRR" class="headerlink" title="7.1 MRR"></a>7.1 MRR</h2><p>MRR——Multi Range Read</p><h3 id="7-1-1作用"><a href="#7-1-1作用" class="headerlink" title="7.1.1作用"></a>7.1.1作用</h3><p>减少磁盘的随机访问，并将随机访问转化为顺序的数据访问</p><h3 id="7-1-2-原理"><a href="#7-1-2-原理" class="headerlink" title="7.1.2 原理"></a>7.1.2 原理</h3><p>在不使用 MRR 时，优化器需要根据二级索引返回的记录来进行“回表”，这个过程一般会有较多的随机 IO, 使用 MRR 时，SQL 语句的执行过程是这样的：</p><ol><li>优化器将二级索引查询到的记录放到一块缓冲区中；</li><li>如果二级索引扫描到文件的末尾或者缓冲区已满，则使用<code>快速排序对缓冲区中的内容按照主键进行排序</code>；</li><li>用户线程调用 MRR 接口取 cluster index，然后根据cluster index 取行数据；</li><li>当根据缓冲区中的 cluster index 取完数据，则继续调用过程 2) 3)，直至扫描结束；</li></ol><p>通过上述过程，优化器将二级索引随机的 IO 进行排序，转化为主键的有序排列，从而实现了随机 IO 到顺序 IO 的转化，提升性能</p><p>在未开启MRR时,查询方式如图所示:</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/no-mrr-access-pattern.png" alt=""></p><p>开启MRR后,查询方式如下图所示:</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/mrr-access-pattern.png" alt=""></p><h3 id="7-1-3-开关MRR"><a href="#7-1-3-开关MRR" class="headerlink" title="7.1.3 开关MRR"></a>7.1.3 开关MRR</h3><p>我们可以通过 以下命令查看和开启MRR,5.6以后默认是开启的</p><pre><code class="mysql">查看MRR是否开启mysql&gt; select @@optimizer_switch\G*************************** 1. row ***************************@@optimizer_switch: index_merge=on,index_merge_union=on,index_merge_sort_union=on,index_merge_intersection=on,engine_condition_pushdown=on,index_condition_pushdown=on,mrr=on,mrr_cost_based=on,block_nested_loop=on,batched_key_access=off,materialization=on,semijoin=on,loosescan=on,firstmatch=on,duplicateweedout=on,subquery_materialization_cost_based=on,use_index_extensions=on,condition_fanout_filter=on,derived_merge=on1 row in set (0.00 sec)注意上面的mrr=on关闭MRRmysql&gt; set optimizer_switch=&#39;mrr=off&#39;;开启MRRmysql&gt; set optimizer_switch=&#39;mrr=on&#39;;相关参数当mrr=on,mrr_cost_based=on，则表示cost base的方式还选择启用MRR优化,当发现优化后的代价过高时就会不使用该项优化当mrr=on,mrr_cost_based=off，则表示总是开启MRR优化尽量设置 mrr_cost_based=ON，毕竟大多数情况下优化器是对的</code></pre><h3 id="7-1-4-开关对比"><a href="#7-1-4-开关对比" class="headerlink" title="7.1.4 开关对比"></a>7.1.4 开关对比</h3><pre><code class="mysql">mysql&gt; explain select *  from t_scrm_user_info where bigdata_user_id &gt; &#39;A1001036&#39; and bigdata_user_id &lt; &#39;A2100000&#39;;</code></pre><p>当<code>mrr=off</code>时</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/mrroffexplain.png" alt=""></p><p>当<code>mrr=on</code>时</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/mrrontime.png" alt=""></p><p>可以看到当mrr开启时, extra 的输出中多了 “Using MRR” 信息，即使用了 MRR Optimization IO 层面进行了优化，减少 IO 方面的开销</p><p>在时间上理论上可以查一个数量级,但是要在缓存池中没有预热以及查询的数据不在缓冲池中才可以</p><p>我测试的时候时间都差不多 (⊙﹏⊙)b</p><h2 id="7-2-ICP"><a href="#7-2-ICP" class="headerlink" title="7.2 ICP"></a>7.2 ICP</h2><p>ICP——Index Condition Pushdown</p><h3 id="7-2-1作用"><a href="#7-2-1作用" class="headerlink" title="7.2.1作用"></a>7.2.1作用</h3><p>在mysql数据库取出索引的同时,判断是否可以进行WHERE条件的过滤,也就是讲WHERE条件的过滤放到了存储引擎层,大大减少了上层SQL层对记录的fetch索取,以提高性能</p><h3 id="7-2-2-原理"><a href="#7-2-2-原理" class="headerlink" title="7.2.2 原理"></a>7.2.2 原理</h3><p>5.6 之前，在 SQL 语句的执行过程中，server 层通过 engine 的 api 获取数据，然后再进行 where_cond 的判断（具体判断逻辑在: evaluate_join_record），每一条数据都需要从engine层返回server层做判断。我们回顾一下上面把 ICP 关掉的测试，可以看到 Handler_read_next 的值陡增，其原因是第 1 个字段区分度不高，且 memo 字段无法使用索引，造成了类似 index 扫描的的情况，性能较低。</p><p>5.6 之后，在利用索引扫描的过程中，如果发现 where_cond 中含有这个 index 相关的条件，则将此条件记录在 handler 接口中，在索引扫描的过程中，只有满足索引与handler接口的条件时，才会返回到 server 层做进一步的处理，在前缀索引区分度不够，其它字段区分度高的情况下可以有效的减少 server &amp; engine之间的开销，提升查询性能。</p><p>开启ICP前查询方式如图所示:</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/index-access-2phases.png" alt=""></p><p>开启ICP后查询方式如图所示:</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/index-access-with-icp.png" alt=""></p><h3 id="7-2-3-开关ICP"><a href="#7-2-3-开关ICP" class="headerlink" title="7.2.3 开关ICP"></a>7.2.3 开关ICP</h3><pre><code class="mysql">默认是开启的查看MRR是否开启mysql&gt; select @@optimizer_switch\G*************************** 1. row ***************************@@optimizer_switch: index_merge=on,index_merge_union=on,index_merge_sort_union=on,index_merge_intersection=on,engine_condition_pushdown=on,index_condition_pushdown=on,mrr=on,mrr_cost_based=on,block_nested_loop=on,batched_key_access=off,materialization=on,semijoin=on,loosescan=on,firstmatch=on,duplicateweedout=on,subquery_materialization_cost_based=on,use_index_extensions=on,condition_fanout_filter=on,derived_merge=on1 row in set (0.00 sec)注意上面的index_condition_pushdown=onSET optimizer_switch=&#39;index_condition_pushdown=on&#39;SET optimizer_switch=&#39;index_condition_pushdown=off&#39;</code></pre><h3 id="7-2-4-开关对比"><a href="#7-2-4-开关对比" class="headerlink" title="7.2.4 开关对比"></a>7.2.4 开关对比</h3><p>开启ICP时,使用explain语句时extra字段有<code>Using index condition</code>关键字</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/mrroffexplain.png" alt=""></p><h3 id="7-2-5-使用场景"><a href="#7-2-5-使用场景" class="headerlink" title="7.2.5 使用场景"></a>7.2.5 使用场景</h3><ul><li><p>只支持 select 语句；</p></li><li><p>MyISAM 与 InnoDB 引擎都起作用;</p></li><li><p>ICP的优化策略可用于range、ref、eq_ref、ref_or_null 类型的访问数据方法；</p></li><li><p>不支持主建索引，只支持辅助索引；</p></li><li><p>涉及子查询的不能起作用</p></li><li><p>作用于多列索引的情况最为明显</p><pre><code class="mysql">SELECT * FROM people  WHERE zipcode=&#39;95054&#39;  AND lastname LIKE &#39;%etrunia%&#39;  AND address LIKE &#39;%Main Street%&#39;;</code></pre></li></ul><h2 id="7-3-BKA"><a href="#7-3-BKA" class="headerlink" title="7.3 BKA"></a>7.3 BKA</h2><p>BKA——Batched Key Access</p><p>BKA的前辈是BNL:</p><h3 id="7-3-1-Block-Nested-Loop-Join算法"><a href="#7-3-1-Block-Nested-Loop-Join算法" class="headerlink" title="7.3.1 Block Nested-Loop Join算法"></a>7.3.1 Block Nested-Loop Join算法</h3><p>将外层循环的行/结果集存入join buffer, 内层循环的每一行与整个buffer中的记录做比较，从而减少内层循环的次数。主要用于当被join的表上无索引。</p><h3 id="7-3-2-Batched-Key-Access算法"><a href="#7-3-2-Batched-Key-Access算法" class="headerlink" title="7.3.2 Batched Key Access算法"></a>7.3.2 Batched Key Access算法</h3><p>当被join的表能够使用索引时，就先好顺序，然后再去检索被join的表。对这些行按照索引字段进行排序，因此减少了随机IO。如果被Join的表上没有索引，则使用老版本的BNL策略(BLOCK Nested-loop)。</p><h3 id="7-3-3-BKA和BNL标识"><a href="#7-3-3-BKA和BNL标识" class="headerlink" title="7.3.3 BKA和BNL标识"></a>7.3.3 BKA和BNL标识</h3><p>Explain下的Extra显示不同：</p><ul><li><p>Using join buffer (Batched Key Access)</p></li><li><p>Using join buffer (Block Nested Loop)</p></li></ul><pre><code class="mysql">相关参数BAK使用了MRR，要想使用BAK必须打开MRR功能，而MRR基于mrr_cost_based的成本估算并不能保证总是使用MRR，官方推荐设置mrr_cost_based=off来总是开启MRR功能。打开BAK功能(BAK默认OFF)：SET optimizer_switch=&#39;mrr=on,mrr_cost_based=off,batched_key_access=on&#39;;BKA使用join buffer size来确定buffer的大小，buffer越大，访问被join的表/内部表就越顺序。BNL默认是开启的，设置BNL相关参数：SET optimizer_switch=’block_nested_loop’支持inner join, outer join, semi-join operations,including nested outer joins</code></pre><p><code>BKA主要适用于join的表上有索引可利用，无索引只能使用BNL</code></p><h3 id="7-3-4-BKA-BNL-MRR的关系"><a href="#7-3-4-BKA-BNL-MRR的关系" class="headerlink" title="7.3.4 BKA BNL MRR的关系"></a>7.3.4 BKA BNL MRR的关系</h3><p>BKA = BNL + MRR</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/bka.jpg" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> Mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>6.Mysql索引介绍</title>
      <link href="/2020/02/16/6-Mysql%E7%B4%A2%E5%BC%95%E4%BB%8B%E7%BB%8D/"/>
      <url>/2020/02/16/6-Mysql%E7%B4%A2%E5%BC%95%E4%BB%8B%E7%BB%8D/</url>
      
        <content type="html"><![CDATA[<p>【注意】主要介绍Innodb的索引结构</p><h2 id="6-1-Innodb索引组织表"><a href="#6-1-Innodb索引组织表" class="headerlink" title="6.1 Innodb索引组织表"></a>6.1 Innodb索引组织表</h2><p>和MyISAM的一个大区别,在Innodb的存储引擎中,表都是根据<code>主键</code>顺序组织存放的.我们把这种存储方式的表成为<code>索引组织表(index origanized table)</code>即大家常说的<code>IOT</code>方式</p><p>Innodb规定每一个表必须需要有主键(PK),主键的选择方式按照如下顺序选择:</p><ol><li>如有有定义主键 则选择此主键</li><li>如果为定义主键 选择<code>第一个定义的非空唯一索引</code>做主键:这里注意有三个条件:<code>非空</code>,<code>唯一</code>,<code>第一个满足以上两个条件的索引</code></li><li>如果以上两个都没有,Innodb会自动创建一个6字节大小的指针:隐式的创建,平时查询不能看到</li></ol><pre><code class="mysql">我们可以通过以下语句查看每一行的主键id,select *,_rowid form table;_rowid表示表的主键 需要注意的是 _rowid只能用于查看单个列为主键的情况 对于多列组成的主键就不好使了</code></pre><h2 id="6-1-Innodb逻辑存储结构"><a href="#6-1-Innodb逻辑存储结构" class="headerlink" title="6.1 Innodb逻辑存储结构"></a>6.1 Innodb逻辑存储结构</h2><p>之间介绍过Innodb库表的文件结构为两个:</p><pre><code>${tablename}.frm   #表结构文件${tablename}.idb   #表索引及数据文件</code></pre><p>所有的数据都被逻辑的存放在一个空间中(.idb文件中),我们称这个空间为<code>表空间(tablespace)</code></p><p>表空间的组成结构如下图所示:</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/innodb_engine_struct.png" alt=""></p><p>这样看可能不明显 再看一个:</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/tablespace.png" alt=""></p><pre><code>可以看到:表空间  ↓段segment  ↓区extent  ↓页page/块block   &lt;---最小储存单元而页里面包含了一个一个的行数据</code></pre><h3 id="6-2-1-表空间"><a href="#6-2-1-表空间" class="headerlink" title="6.2.1 表空间"></a>6.2.1 表空间</h3><p>在5.6以前所有的数据都存在共享表空间ibdata1中，在5.6以后加入了<code>innodb_file_per_table</code>参数默认是开启的,建议也是开启的,开启了这个参数后,每张表内的数据会单独放到一个表空间内</p><p>需要注意的是:每张表空间内存放的只有:</p><ul><li>数据</li><li>索引</li><li>插入缓存Bitmap</li></ul><p>其他的一些信息如:undo操作,插入缓存索引页,失误信息,double write buffer还是存在ibdata里</p><p>ibdata的具体介绍会在innodb索引章节进行介绍说明</p><h3 id="6-2-2-段"><a href="#6-2-2-段" class="headerlink" title="6.2.2 段"></a>6.2.2 段</h3><p>常见的段分类如下:</p><ul><li>数据段</li><li>索引段</li><li>回滚段</li></ul><h3 id="6-2-3-区"><a href="#6-2-3-区" class="headerlink" title="6.2.3 区"></a>6.2.3 区</h3><p>区是由<code>连续的页</code>组成的空间,<code>在任何情况下每个区的大小都为1MB</code></p><p>为了保证区的连续性,每次存储引擎都会从磁盘申请四五个区</p><p>默认情况下,Innodb页的大小为16KB,即一个区共有64个页  =&gt; (2^10) / (2^4)</p><p>页的大小可以在初始化的时候进行调整,但是区的大小总为1MB</p><h3 id="6-2-4-页"><a href="#6-2-4-页" class="headerlink" title="6.2.4 页"></a>6.2.4 页</h3><p>页是InnoDB存储引擎磁盘管理的最小单位，每个页默认16KB</p><p>可以通过参数<code>innodb_page_size</code>将页的大小设置为4K、8K、16K</p><p>若设置完成，则所有表中页的大小都为innodb_page_size，不可以再次对其进行修改</p><p>除非通过mysqldump导入和导出操作来产生新的库</p><p>innodb的所有数据文件（后缀为ibd的文件），他的大小始终都是<code>innodb_page_size</code> (16384(16k))的整数倍</p><pre><code>[root@centos7-1 baseinfo]# ll|grep &#39;ibd&#39; -rw-r-----. 1 mysql mysql 2663383040 xxx.ibd  =&gt; 2663383040 = 16384*162560-rw-r-----. 1 mysql mysql  868220928 ccc.ibd  =&gt; 868220928 = 16384*52992</code></pre><p><code>innodb_page_size</code>的大小限制了tablespace表空间的大小:</p><p>Table 14.25 InnoDB Maximum Tablespace Size</p><table><thead><tr><th>InnoDB Page Size</th><th>Maximum Tablespace Size</th></tr></thead><tbody><tr><td>4KB</td><td>16TB</td></tr><tr><td>8KB</td><td>32TB</td></tr><tr><td>16KB</td><td>64TB</td></tr><tr><td>32KB</td><td>128TB</td></tr><tr><td>64KB</td><td>256TB</td></tr></tbody></table><h3 id="6-2-5-行"><a href="#6-2-5-行" class="headerlink" title="6.2.5 行"></a>6.2.5 行</h3><p>Innodb存储引擎是面向列的,也就是数据是按行存放的,每个页存放行的记录也是有硬性规定的</p><p>最多允许存放16KB/2-200行记录,即7992行</p><p>但实际上互联网公司一行的数据大概为1KB,即一个page可以存放16行数据</p><h2 id="6-3-B-树结构"><a href="#6-3-B-树结构" class="headerlink" title="6.3 B+树结构"></a>6.3 B+树结构</h2><p>无论是MyISAM还是Innodb 他们在存储数据时,都用到了B+树结构</p><h3 id="6-3-1-B-树结构"><a href="#6-3-1-B-树结构" class="headerlink" title="6.3.1 B+树结构"></a>6.3.1 B+树结构</h3><p>(1) 原理图:</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/BTree.png" alt=""></p><p>(2)特点：</p><ul><li>非叶子节点只存储键值信息</li><li>所有叶子节点之间都有一个链指针</li><li>叶子节点也多存储了指向下一个叶子节点的指针，更方便叶子节点的范围遍历</li><li>数据记录都存放在叶子节点中</li><li>所有的叶子节点组成一个循环双向链表</li></ul><h3 id="6-3-2-MyISAM实现B-Tree"><a href="#6-3-2-MyISAM实现B-Tree" class="headerlink" title="6.3.2 MyISAM实现B+Tree"></a>6.3.2 MyISAM实现B+Tree</h3><p>(1)原理图：</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/MtISAMBTree.png" alt=""></p><p>(2)特点：</p><ul><li>索引文件和数据文件是分离的</li><li>索引文件仅保存数据行记录的地址（行指针）</li><li>主索引与二级索引无区别</li><li>二级索引也存储的是行指针</li></ul><h3 id="6-3-3-Innodb实现B-Tree"><a href="#6-3-3-Innodb实现B-Tree" class="headerlink" title="6.3.3 Innodb实现B+Tree"></a>6.3.3 Innodb实现B+Tree</h3><p>(1)原理图：</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/InnodbBtree.png" alt=""></p><p>(2)特点：</p><ul><li>主键索引既存储索引值，又在叶子节点中存储整行的数据</li><li>二级索引存储索引列值+主键信息</li><li>必须有主键 主键的选择如前文所释</li></ul><h2 id="6-4-索引分类"><a href="#6-4-索引分类" class="headerlink" title="6.4 索引分类"></a>6.4 索引分类</h2><p>我们根据索引文件是否和数据文件共同存储,可讲索引分为:</p><ul><li>聚簇索引(聚集索引)</li><li>非聚簇索引(辅助索引)</li></ul><p>不管是聚簇索引还是非聚簇索引我们看到他们内部都是B+树的,即高度平衡的,他们之间的区别是叶子节点是否存放的是一整行数据信息</p><h3 id="6-4-1-聚簇索引"><a href="#6-4-1-聚簇索引" class="headerlink" title="6.4.1 聚簇索引"></a>6.4.1 聚簇索引</h3><p>Innodb的数据页同B+树数据结构一样,每个页都通过一个双向链表来进行链接。</p><p>由于实际的数据页只能按照一颗B+树进行排序,因此每张表只能拥有一个<code>聚簇索引</code></p><p>在多数情况下,查询优化器倾向与采用聚簇索引:</p><ul><li>聚簇索引能够在叶子节点上直接找到数据</li><li>由于定义了数据的逻辑顺序,聚簇索引能够特别快的访问针对范围值的查询</li></ul><p>【注意】聚簇索引的存储并不是物理上连续的,而是逻辑上连续的:</p><ul><li>页通过双向链表链接,页按照主键的顺序排序</li><li>每个页的记录也是通过双向链表进行维护的,物理储存上可以同样不按照主键存储</li></ul><h3 id="6-4-1-非聚集索引"><a href="#6-4-1-非聚集索引" class="headerlink" title="6.4.1 非聚集索引"></a>6.4.1 非聚集索引</h3><p>对于非聚集索引,叶子节点不包含行记录的全部数据。叶子节点除了包含主键值以外,每个叶子节点的索引行还包含了一个书签(bookmark),在Innodb数据引擎中,这个bookmark就代表相应行数据的聚集索引键</p><p>他们之间的关系如下:</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/IndexRelat.jpg" alt=""></p><p>辅助索引的存在并不影响数据在聚集索引中的组织，因此<code>每张表上可以有多个辅助索引，但只能有一个聚集索引</code>。当通过辅助索引来寻找数据时，InnoDB存储引擎会遍历辅助索引并通过叶子级别的指针获得只想主键索引的主键，然后再通过主键索引来找到一个完整的行记录。</p><p>举例来说，如果在一棵高度为3的辅助索引树种查找数据，那需要对这个辅助索引树遍历3次找到指定主键，如果聚集索引树的高度同样为3，那么还需要对聚集索引树进行3次查找，最终找到一个完整的行数据所在的页，因此一共需要6次逻辑IO访问才能得到最终的一个数据页。</p><p>当然后面优化器部分会有相应的优化算法来优化IO次数</p><h2 id="6-4-索引作用"><a href="#6-4-索引作用" class="headerlink" title="6.4 索引作用"></a>6.4 索引作用</h2><blockquote><p>索引是存储引擎用于快速找到记录的一种数据结构,这是索引的基本功能</p></blockquote><h3 id="6-4-1-索引的优点"><a href="#6-4-1-索引的优点" class="headerlink" title="6.4.1 索引的优点"></a>6.4.1 索引的优点</h3><ul><li>索引大大检索了服务器需要扫描的数据量</li><li>索引可以帮助服务器避免排序和临时表</li><li>索引可以将随机IO变为顺序IO</li></ul><h3 id="6-4-2-索引平衡"><a href="#6-4-2-索引平衡" class="headerlink" title="6.4.2 索引平衡"></a>6.4.2 索引平衡</h3><p>索引太多,应用程序的性能可能受到影响,索引太少,对查询性能又会产生影响,要找到一个平衡点至关重要。</p><p>不要总是在事后才想起添加索引,设计表时要知道数据的使用,从一开始就应该在需要处添加索引</p><p>当然索引并不一定是最好的解决方案:</p><ul><li><p>在创建索引，更新数据表的时候，会给数据库带来额外的消耗。总的来说，只有当索引帮助存储引擎快速查找到记录带来的好处大于其带来的额外工作时，索引才是有效的。</p></li><li><p>对于非常小的表，大部分情况下全表扫描更高效。</p></li><li><p>对于中到大型的表，索引特别有效</p></li><li><p>但是对于特大型的表，建立和使用索引带来的代价将随之增长，这种情况下，需要使用一种技术可以直接区分出查询需要的一组数据，而不是一条记录一条记录的匹配。例如分区表技术;</p></li></ul><h2 id="6-5-索引种类"><a href="#6-5-索引种类" class="headerlink" title="6.5 索引种类"></a>6.5 索引种类</h2><ul><li>聚簇索引<ul><li>主键索引</li></ul></li><li>非聚簇索引<ul><li>普通单列索引</li><li>唯一索引</li><li>前缀索引</li><li>多列索引</li></ul></li></ul><h3 id="6-5-1-主键索引"><a href="#6-5-1-主键索引" class="headerlink" title="6.5.1 主键索引"></a>6.5.1 主键索引</h3><p>必须要有的索引，用于构建聚簇索引的基本条件</p><p>一个表只能有一个主键，不允许有空值。一般是在建表的时候同时创建主键索引。</p><p>关键字及创建方式:</p><pre><code class="mysql">  PRIMARY KEY (`id`)</code></pre><h3 id="6-5-2-普通单列索引"><a href="#6-5-2-普通单列索引" class="headerlink" title="6.5.2 普通单列索引"></a>6.5.2 普通单列索引</h3><p>普通索引是最基本的索引类型，唯一的任务是加快对数据的访问速度，没有任何限制。</p><p>关键字及创建方式:</p><pre><code class="mysql">CREATE INDEX index_name ON TABLE(column_name);ALTER TABLE table_name ADD INDEX index_name(column_name);INDEX index_name (name(length))</code></pre><h3 id="6-5-3-唯一索引"><a href="#6-5-3-唯一索引" class="headerlink" title="6.5.3 唯一索引"></a>6.5.3 唯一索引</h3><p>索引列的值必须唯一，但允许有空值。如果是组合索引，则列值的组合必须唯一。</p><p>关键字及创建方式:</p><pre><code class="mysql">UNIQUE INDEX index_name (column_name)CREATE UNIQUE INDEX index_name ON mytable(column_name)ALTER TABLE table_name ADD UNIQUE indexName(column_name)</code></pre><h3 id="6-5-4-前缀索引"><a href="#6-5-4-前缀索引" class="headerlink" title="6.5.4 前缀索引"></a>6.5.4 前缀索引</h3><p>有时候需要索引很长的字符列，这会让索引变得大且慢。</p><p>通常可以索引开始的部分字符，这样可以大大节约索引空间，从而提高索引效率。但这样也会降低索引的选择性。索引的选择性是指不重复的索引值（也称为基数，cardinality)和数据表的记录总数的比值，范围从1/#T到1之间。索引的选择性越高则查询效率越高，因为选择性高的索引可以让MySQL在查找时过滤掉更多的行。唯一索引的选择性是1，这是最好的索引选择性，性能也是最好的。</p><p>一般情况下某个前缀的选择性也是足够高的，足以满足查询性能。对于BLOB，TEXT，或者很长的VARCHAR类型的列，必须使用前缀索引，因为MySQL不允许索引这些列的完整长度。</p><p>诀窍在于要选择足够长的前缀以保证较高的选择性，同时又不能太长（以便节约空间）。前缀应该足够长，以使得前缀索引的选择性接近于索引的整个列。</p><p>换句话说，<code>前缀的”基数“应该接近于完整的列的”基数“</code>。</p><p>【注意】前缀索引只能作用在普通索引上 不能作用在唯一索引上</p><p>那就是计算完整列的选择性，并使其前缀的选择性接近于完整列的选择性。下面显示如何计算完整列的选择性：</p><pre><code class="mysql">mysql&gt; select count(distinct city) / count(*) from city_demo;+---------------------------------+| count(distinct city) / count(*) |+---------------------------------+|                          0.4283 |+---------------------------------+1 row in set (0.05 sec)</code></pre><p>可以在一个查询中针对不同前缀长度的选择性进行计算，这对于大表非常有用，下面给出如何在同一个查询中计算不同前缀长度的选择性：</p><pre><code class="mysql">mysql&gt; select count(distinct left(city,3))/count(*) as sel3,    -&gt; count(distinct left(city,4))/count(*) as sel4,    -&gt; count(distinct left(city,5))/count(*) as sel5,     -&gt; count(distinct left(city,6))/count(*) as sel6     -&gt; from city_demo;+--------+--------+--------+--------+| sel3   | sel4   | sel5   | sel6   |+--------+--------+--------+--------+| 0.3367 | 0.4075 | 0.4208 | 0.4267 |+--------+--------+--------+--------+1 row in set (0.01 sec)</code></pre><p>可以看见当索引前缀为6时的基数是0.4267，已经接近完整列选择性0.4283。</p><p>在上面的示例中，已经找到了合适的前缀长度，下面创建前缀索引：</p><pre><code class="mysql">mysql&gt; alter table city_demo add key (city(6));Query OK, 0 rows affected (0.19 sec)Records: 0  Duplicates: 0  Warnings: 0</code></pre><p>前缀索引是一种能使索引更小，更快的有效办法，但另一方面也有其<code>缺点</code>：</p><ul><li>mysql无法使用其前缀索引做ORDER BY和GROUP BY</li><li>无法使用前缀索引做覆盖扫描。</li></ul><h3 id="6-5-5-多列索引"><a href="#6-5-5-多列索引" class="headerlink" title="6.5.5 多列索引"></a>6.5.5 多列索引</h3><p>指多个字段上创建的索引，只有在查询条件中使用了创建索引时的第一个字段，索引才会被使用。使用组合索引时遵循最左前缀集合。</p><p>关键字及创建方式:</p><pre><code class="mysql">ALTER TABLE table ADD INDEX name_city_age (name,city,age);</code></pre><p>联合索引在内部的结构图如下图所示:</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/unionindex.png" alt=""></p><p>对于联合索引（a,b），where a =xxx and b =xxx，和where a=xxx 可以使用此联合索引，但是对于where b = xxx不能使用，因为b列数据在此联合索引上不是有序的。具体的索引是否生效会在以后章节介绍。</p><h2 id="6-6-覆盖索引"><a href="#6-6-覆盖索引" class="headerlink" title="6.6 覆盖索引"></a>6.6 覆盖索引</h2><h3 id="6-6-1-定义"><a href="#6-6-1-定义" class="headerlink" title="6.6.1 定义"></a>6.6.1 定义</h3><p>SQL只需要通过索引就可以返回查询所需要的数据，而不必通过二级索引查到主键之后再去查询数据。</p><p>这样可以减少大量的IO操作,无需进行回表操作。</p><h3 id="6-6-2-判断标准"><a href="#6-6-2-判断标准" class="headerlink" title="6.6.2 判断标准"></a>6.6.2 判断标准</h3><p>使用explain，可以通过输出的extra列来判断，对于一个索引覆盖查询，显示为<code>using index</code>,MySQL查询优化器在执行查询前会决定是否有索引覆盖查询</p><h3 id="6-6-3-优点"><a href="#6-6-3-优点" class="headerlink" title="6.6.3 优点"></a>6.6.3 优点</h3><p>覆盖索引是一种非常强大的工具，能大大提高查询性能，只需要读取索引而不用读取数据有以下一些优点<br>1、索引项通常比记录要小，所以MySQL访问更少的数据<br>2、索引都按值的大小顺序存储，相对于随机访问记录，需要更少的I/O<br>3、大多数据引擎能更好的缓存索引，比如MyISAM只缓存索引<br>4、覆盖索引对于InnoDB表尤其有用，因为InnoDB使用聚集索引组织数据，如果二级索引中包含查询所需的数据，就不再需要在聚集索引中查找了</p><h2 id="6-7-索引管理"><a href="#6-7-索引管理" class="headerlink" title="6.7 索引管理"></a>6.7 索引管理</h2><p>我们可以通过<code>SHOW INDEX FROM table</code>查看表的索引情况</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/showindex.png" alt=""></p><p>具体每个字段的含义如下:</p><p>下面我们一起了解下返回的这张表的含义：</p><ol><li>Table: 表名</li><li>Non_unique: 如果索引不能包括重复值则为0，如果可以则为1。也就是平时所说的唯一索引。</li><li>Key_name 索引名称，如果名字相同则表明是同一个索引，而并不是重复，比如上图中的而三条数据，其实是一个联合索引。</li><li>Seq_in_index 索引中的列序列号，从1开始。上图中的二、三数据，Seq_in_index一个是1一个是2，就是表明在联合索引中的顺序，我们就能推断出联合索引中索引的前后顺序。</li><li>Column_name 索引的列名。</li><li>Collation指的是列以什么方式存储在索引中，可是A或NULL,Btree总是A,即排序的。</li><li>Cardinality 是基数的意思，表示索引中唯一值的数目的估计值。我们知道某个字段的重复值越少越适合建索引，所以我们一般都是根据Cardinality来判断索引是否具有高选择性，如果这个值非常小，那就需要重新评估这个字段是否适合建立索引。</li><li>Sub_part 前置索引的意思，如果列只是被部分地编入索引，则为被编入索引的字符的数目。如果整列被编入索引，则为NULL。</li><li>Packed 指示关键字如何被压缩。如果没有被压缩，则为NULL。压缩一般包括压缩传输协议、压缩列解决方案和压缩表解决方案。</li><li>.Null 如果列含有NULL，则含有YES。</li><li>.Index_type表示索引类型，Mysql目前主要有以下几种索引类型：FULLTEXT，HASH，BTREE，RTREE。</li><li>.Comment Index_comment 注释的意思。</li></ol><h3 id="6-7-1-什么是Cardinality"><a href="#6-7-1-什么是Cardinality" class="headerlink" title="6.7.1 什么是Cardinality"></a>6.7.1 什么是Cardinality</h3><p>不是所有的查询条件出现的列都需要添加索引。对于什么时候添加B+树索引。一般的经验是，在访问表中很少一部分时使用B+树索引才有意义。对于性别字段、地区字段、类型字段，他们可取值范围很小，称为低选择性。如</p><pre><code class="mysql">SELECT * FROM student WHERE sex=&#39;M&#39;</code></pre><p>按性别进行查询时，可取值一般只有M、F。</p><p>因此SQL语句得到的结果可能是该表50%的数据(加入男女比例1:1)这时添加B+树索引是完全没有必要的。</p><p>相反，如果某个字段的取值范围很广，几乎没有重复，属于高选择性。则此时使用B+树的索引是最合适的。</p><p>例如对于姓名字段，基本上在一个应用中不允许重名的出现</p><h3 id="6-7-2-查看高选择性"><a href="#6-7-2-查看高选择性" class="headerlink" title="6.7.2 查看高选择性"></a>6.7.2 查看高选择性</h3><p>怎样查看索引是否有高选择性？通过SHOW INDEX结果中的列Cardinality来观察。非常关键，表示所以中不重复记录的预估值，需要注意的是Cardinality是一个预估值，而不是一个准确值基本上用户也不可能得到一个准确的值</p><p>在实际应用中，<code>Cardinality/n_row_in_table应尽可能的接近1</code>，如果非常小,那用户需要考虑是否还有必要创建这个索引。故在访问高选择性属性的字段并从表中取出很少一部分数据时，对于字段添加B+树索引是非常有必要的。如</p><pre><code class="mysql">SELECT * FROM member WHERE usernick=&#39;David&#39;;</code></pre><p>表member大约有500W行数据,usernick字段上有一个唯一索引。这也符号提到的高选择性</p><h3 id="6-7-3-Cardinality统计"><a href="#6-7-3-Cardinality统计" class="headerlink" title="6.7.3 Cardinality统计"></a>6.7.3 Cardinality统计</h3><p>Cardinality统计时放在存储引擎层进行的</p><p>在生成环境中，索引的更新操作可能非常频繁。如果每次索引在发生操作时就对其进行Cardinality统计，那么将会对数据库带来很大的负担。另外需要考虑的是，如果一张表的数据非常大，如一张表有50G的数据，那么统计一次Cardinality信息所需要的时间可能非常长。这样的环境下，是不能接受的。因此，数据库对于Cardinality信息的统计都是通过采样的方法完成</p><p>在InnoDB存储引擎中，Cardinality统计信息的更新发生在两个操作中：insert和update。InnoDB存储引擎内部对更新Cardinality信息的策略为:</p><ul><li>表中1/16的数据已发生了改变</li><li>stat_modified_counter&gt;2000 000 000</li></ul><p>接着考虑InnoDB存储引擎内部是怎样进行Cardinality信息统计和更新操作呢？同样是通过采样的方法。默认的InnoDB存储引擎对8个叶子节点Leaf Page进行采用。采用过程如下</p><ol><li>取得B+树索引中叶子节点的数量，记为A</li><li>随机取得B+树索引中的8个叶子节点，统计每个页不同记录的个数，即为P1，P2….P8</li><li>通过采样信息给出Cardinality的预估值:Cardinality=(P1+P2+…+P8)*A/8</li></ol><p>根据上述的说明可以发现，在InnoDB存储引擎中，Cardinality值通过对8个叶子节点预估而得的。而<code>不是一个实际精确的值</code>。再者，每次对Cardinality值的统计，都是通过随机取8个叶子节点得到的，这同时有暗示了另外一个Cardinality现象，即每次得到的Cardinality值可能不同的;</p><p>当然，有一种情况可以使得用户每次观察到的索引Cardinality值是一样的。那就是表足够小，表的叶子节点树小于或者等于8个</p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> Mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>4.MySQL体系结构</title>
      <link href="/2020/02/15/4-Mysql%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/"/>
      <url>/2020/02/15/4-Mysql%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/</url>
      
        <content type="html"><![CDATA[<h2 id="4-1-Mysql整体结构图"><a href="#4-1-Mysql整体结构图" class="headerlink" title="4. 1 Mysql整体结构图"></a>4. 1 Mysql整体结构图</h2><p>下图是Mysql官方给出的结构图:</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/Mysql%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84.png" alt="Mysql体系结构"></p><p>从上图可以发现Mysql由以下几部分组成</p><ul><li>客户端</li><li>连接层</li><li>SQL层</li><li>存储引擎层</li><li>文件系统</li><li>服务管理(非必须)</li></ul><h3 id="4-1-1-客户端"><a href="#4-1-1-客户端" class="headerlink" title="4.1.1 客户端"></a>4.1.1 客户端</h3><p>即Mysql提供给不同语言的API链接方式,支持的语言有很过Go,PHP,Java等等 没啥好说的哈</p><h3 id="4-1-2-连接层"><a href="#4-1-2-连接层" class="headerlink" title="4.1.2 连接层"></a>4.1.2 连接层</h3><p>主要负责以下功能:</p><ul><li>提供链接协议,两种: <code>socket连接&amp;TCP/IP连接</code></li><li>授权认证</li><li>提供专用的连接线程</li><li>最大连接数限制</li></ul><h3 id="4-1-3-SQL层"><a href="#4-1-3-SQL层" class="headerlink" title="4.1.3  SQL层"></a>4.1.3  SQL层</h3><p>主要负责以下功能:</p><ul><li>SQL语法检查</li><li>语义检查(DML,DCL,DQL,DTL)</li><li>权限判断</li><li>解析器:解析预处理,执行计划(是全表扫描还是走哪个索引)</li><li>优化分析器:帮我们选择最优的方案</li><li>执行器:执行SQL语句</li><li>查询缓存(QC)<ul><li>【注】这个不要开启,在许多情况下它会失效并且会拉低数据库性能</li><li>可以使用Redis来替代</li></ul></li></ul><h3 id="4-1-4-存储引擎层"><a href="#4-1-4-存储引擎层" class="headerlink" title="4.1.4 存储引擎层"></a>4.1.4 存储引擎层</h3><p>提供不同的存储引擎以供选择,类似于Linux的文件系统,和磁盘模块进行数据交互</p><p>我们可以通过show engine指令查看目前数据库支持的存储引擎</p><pre><code>[root@centos7-1 3306]# mysql -e&#39;show engines&#39;|awk &#39;{print $1}&#39;EngineCSVMRG_MYISAMMyISAM        ***BLACKHOLEPERFORMANCE_SCHEMAMEMORY          ARCHIVEInnoDB          *****FEDERATED</code></pre><p>经常提到的存储引擎有两个:</p><ul><li>InnoDB</li><li>MyISAM</li></ul><p>在早期使用的默认存储引擎为MyISAM,目前默认都是用InnoDB,他们之间的区别稍后会在存储引擎一篇中详细介绍</p><h3 id="4-1-5-文件系统"><a href="#4-1-5-文件系统" class="headerlink" title="4.1.5 文件系统"></a>4.1.5 文件系统</h3><p>用于存储数据文件和不同类型的日志</p><h2 id="4-2-MySQL文件结构"><a href="#4-2-MySQL文件结构" class="headerlink" title="4.2 MySQL文件结构"></a>4.2 MySQL文件结构</h2><p>目前我们的Mysql数据库下有以下几个库:</p><pre><code>mysql&gt; show databases;+--------------------+| Database           |+--------------------+| information_schema || baseinfo           || mysql              || performance_schema || sys                || test               |+--------------------+6 rows in set (0.00 sec)</code></pre><p>我们查看MySQL的数据存储文件夹下会看到如下文件:</p><pre><code>[root@centos7-1 3306]# tree -L 1.├── auto.cnf├── baseinfo├── centos7-1.err├── centos7-1.pid├── ib_buffer_pool├── ibdata1├── ib_logfile0├── ib_logfile1├── ibtmp1├── mysql├── performance_schema├── sys└── test</code></pre><p>意义如下:</p><pre><code>[root@centos7-1 3306]# tree -L 1.├── auto.cnf               #Mysql自动生成的一些配置文件├── baseinfo            #baseinfo库里的文件【自建库】├── centos7-1.err       #数据库错误日志 命名方式为 主机名+“.err”├── centos7-1.pid       #数据里的进程id文件├── ib_buffer_pool      #一些持久化了的buffer pool文件├── ibdata1             #ibddata文件存储临时表数据+用户数据├── ib_logfile0         #ib_logfile0～N为 redo log日志├── ib_logfile1├── ibtmp1              #临时表空间文件├── mysql               #Mysql库文件├── performance_schema  #performance_schema库文件夹【系统库】├── sys                    #sys库文件夹【系统库】└── test                #自建test库文件夹【自建库】</code></pre><p>我们看到baseinfo库为Innodb存储引擎库,而test为MyISAM存储引擎库, 他们在文件存储上又有不同之处:</p><pre><code>[root@centos7-1 3306]# tree testtest├── db.opt├── t1.frm├── t1.MYD└── t1.MYI0 directories, 4 files[root@centos7-1 3306]# tree baseinfo/baseinfo/├── db.opt├── t_scrm_map.frm├── t_scrm_map.ibd├── t_scrm_pet_info.frm├── t_scrm_pet_info.ibd├── t_scrm_user_info.frm└── t_scrm_user_info.ibd[root@centos7-1 test]# cat db.opt default-character-set=utf8mb4default-collation=utf8mb4_general_ci#db.opt的作用1、create database时会自动生成一个文件db.opt，存放的数据库的默认字符集，show create database时显示数据库默认字符集即db.opt中字符集2、这个文件丢失不影响数据库运行，该文件丢失之后新建表时，找不到数据库的默认字符集，就把character_set_server当成数据库的默认字符集，show create database时显示character_set_server字符集</code></pre><p>可以看到MyISAM库表的文件结构为三个:</p><pre><code>${tablename}.frm   #表结构文件${tablename}.MYI   #表索引文件 MyISAM Index${tablename}.MYD   #表数据文件 MyISAM Data</code></pre><p>而Innodb库表的文件结构为两个:</p><pre><code>${tablename}.frm   #表结构文件${tablename}.idb   #表索引及数据文件</code></pre><p>可以看到在文件存储上 MyISAM和Innodb就有截然不同的结构 从而造成了数据引擎上的巨大差异</p><h2 id="4-3-MySQL运行模式"><a href="#4-3-MySQL运行模式" class="headerlink" title="4.3  MySQL运行模式"></a>4.3  MySQL运行模式</h2><p>MySQL被设计成一个单进程多线程架构的数据库,这一点与SQL Server比较类似,但与Oracle多进程的架构不同</p><p><code>MySQL数据库实例在系统上表现就是一个进程</code></p><p>已Innodb存储引擎为例,包含的后台线程主要有四种（具体含义会在存储引擎章节做解释）:</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/Mysqld%E8%BF%9B%E7%A8%8B.png" alt=""></p><p>我们可以在mysql中执行以下语句看查看所有mysql的进程数,具体含义在innodb章节解释吧:</p><pre><code class="mysql">mysql&gt; select thread_id,name,type FROM performance_schema.threads;+-----------+----------------------------------------+------------+| thread_id | name                                   | type       |+-----------+----------------------------------------+------------+|         1 | thread/sql/main                        | BACKGROUND ||         2 | thread/sql/thread_timer_notifier       | BACKGROUND ||         3 | thread/innodb/io_ibuf_thread           | BACKGROUND ||         4 | thread/innodb/io_log_thread            | BACKGROUND ||         5 | thread/innodb/io_read_thread           | BACKGROUND ||         6 | thread/innodb/io_read_thread           | BACKGROUND ||         7 | thread/innodb/io_read_thread           | BACKGROUND ||         8 | thread/innodb/io_read_thread           | BACKGROUND ||         9 | thread/innodb/io_write_thread          | BACKGROUND ||        10 | thread/innodb/io_write_thread          | BACKGROUND ||        11 | thread/innodb/io_write_thread          | BACKGROUND ||        12 | thread/innodb/io_write_thread          | BACKGROUND ||        13 | thread/innodb/page_cleaner_thread      | BACKGROUND ||        16 | thread/innodb/srv_lock_timeout_thread  | BACKGROUND ||        17 | thread/innodb/srv_error_monitor_thread | BACKGROUND ||        18 | thread/innodb/srv_monitor_thread       | BACKGROUND ||        19 | thread/innodb/srv_master_thread        | BACKGROUND ||        20 | thread/innodb/srv_worker_thread        | BACKGROUND ||        21 | thread/innodb/srv_purge_thread         | BACKGROUND ||        22 | thread/innodb/srv_worker_thread        | BACKGROUND ||        23 | thread/innodb/srv_worker_thread        | BACKGROUND ||        24 | thread/innodb/buf_dump_thread          | BACKGROUND ||        25 | thread/innodb/dict_stats_thread        | BACKGROUND ||        26 | thread/sql/signal_handler              | BACKGROUND ||        27 | thread/sql/compress_gtid_table         | FOREGROUND ||        36 | thread/sql/one_connection              | FOREGROUND |+-----------+----------------------------------------+------------+26 rows in set (0.00 sec)</code></pre>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> Mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>5.MysqlSQL基础</title>
      <link href="/2020/02/15/5-MysqlSQL%E5%9F%BA%E7%A1%80/"/>
      <url>/2020/02/15/5-MysqlSQL%E5%9F%BA%E7%A1%80/</url>
      
        <content type="html"><![CDATA[<h2 id="5-1-常用数据类型"><a href="#5-1-常用数据类型" class="headerlink" title="5.1 常用数据类型"></a>5.1 常用数据类型</h2><h3 id="5-1-1-整型"><a href="#5-1-1-整型" class="headerlink" title="5.1.1 整型"></a>5.1.1 整型</h3><table><thead><tr><th align="center">类型</th><th align="center">字节</th><th align="center">范围(有符号位)</th></tr></thead><tbody><tr><td align="center">TINYINT</td><td align="center">1Byte</td><td align="center">0~2^8 OR  -2^7 ~ 2^7-1</td></tr><tr><td align="center">INT</td><td align="center">4Byte</td><td align="center">0~2^32 OR  -2^31 ~ 2^31-1</td></tr><tr><td align="center">BIGINT</td><td align="center">8Byte</td><td align="center">0~2^64 OR -2^63 ~ 2^63-1</td></tr></tbody></table><ul><li>int(M)  M表示总位数<ul><li>如果某个数不够定义字段时设置的位数，则前面以0补填，zerofill 属性修改</li><li>例：int(5)   插入一个数’123’，补填后为’00123’</li></ul></li><li>默认存在符号位，unsigned 属性修改</li><li>在满足要求的情况下，越小越好</li><li>1表示bool值真，0表示bool值假。MySQL没有布尔类型，通过整型0和1表示。常用tinyint(1)表示布尔型</li></ul><h3 id="5-1-2-小数"><a href="#5-1-2-小数" class="headerlink" title="5.1.2 小数"></a>5.1.2 小数</h3><table><thead><tr><th align="center">类型</th><th align="center">字节</th><th align="center">范围(有符号位)</th></tr></thead><tbody><tr><td align="center">float(单精度)</td><td align="center">4Byte</td><td align="center">自定义，表示近似值</td></tr><tr><td align="center">double(双精度)</td><td align="center">8Byte</td><td align="center">自定义，表示近似值</td></tr><tr><td align="center">decimal</td><td align="center">自定义</td><td align="center">自定义,表示精确数值</td></tr></tbody></table><ul><li><p>浮点型既支持符号位 unsigned 属性，也支持显示宽度 zerofill 属性，不同于整型，前后均会补填0</p></li><li><p>支持科学计数法表示。</p></li><li><p>定义浮点型时，需指定总位数和小数位数。</p><blockquote><p>float(M, D)     double(M, D)</p><p>M表示总位数，D表示小数位数</p><p>M和D的大小会决定浮点数的范围 不同于整型的固定范围</p><p>M既表示总位数（不包括小数点和正负号），也表示显示宽度（所有显示符号均包括）</p><p>decimal(M, D)   M也表示总位数，D表示小数位数</p><p>保存一个精确的数值，不会发生数据的改变，不同于浮点数的四舍五入<br>将浮点数转换为字符串来保存，每9位数字保存为4个字节</p></blockquote></li></ul><h3 id="5-1-3-字符"><a href="#5-1-3-字符" class="headerlink" title="5.1.3 字符"></a>5.1.3 字符</h3><table><thead><tr><th align="center">类型</th><th align="left">说明</th></tr></thead><tbody><tr><td align="center">CHAR</td><td align="left">定长字符串最多255个字符</td></tr><tr><td align="center">VARCHAR</td><td align="left">变长字符串最多65535个字符</td></tr><tr><td align="center">TEXT</td><td align="left">变长字符串最多65535个字符类型，在定义时,不需要定义长度<br/>也不会计算总长度不可给default值</td></tr><tr><td align="center">BLOB</td><td align="left">二进制字符串（字节字符串）</td></tr><tr><td align="center">ENUM</td><td align="left">枚举类型 smallint 存储</td></tr><tr><td align="center">SET</td><td align="left">集合类型 bigint存储</td></tr></tbody></table><pre><code>char(11) ：定长字符串类型,在存储字符串时，最大字符长度11个，立即分配11个字符长度的存储空间，如果存不满，空格填充varchar(11):变长的字符串类型看，最大字符长度11个。在存储字符串时，自动判断字符长度，按需分配存储空间。M表示能存储的最大长度，此长度是字符数，非字节数。不同的编码，所占用的空间不同。char,最多255个字符，与编码无关。varchar,最多65535字符，与编码有关。一条有效记录最大不能超过65535个字节。utf8 最大为21844个字符，gbk 最大为32766个字符，latin1 最大为65532个字符【注】varchar 是变长的，需要利用存储空间保存 varchar 的长度，如果数据小于255个字节，则采用一个字节来保存长度，反之需要两个字节来保存。varchar 的最大有效长度由最大行大小和使用的字符集确定。最大有效长度是65532字节，因为在varchar存字符串时，第一个字节是空的，不存在任何数据，然后还需两个字节来存放字符串的长度，所以有效长度是64432-1-2=65532字节。例：若一个表定义为 CREATE TABLE tb(c1 int, c2 char(30), c3 varchar(N)) charset=utf8; 问N的最大值是多少？答：(65535-1-2-4-30*3)/3</code></pre><pre><code>枚举类型说明enum(val1, val2, val3...)在已知的值中进行单选。最大数量为65535.枚举值在保存时，以2个字节的整型(smallint)保存。每个枚举值，按保存的位置顺序，从1开始逐一递增。表现为字符串类型，存储却是整型。NULL值的索引是NULL。空字符串错误值的索引值是0枚举类型，比较适合于将来此列的值是固定范围内的特点，可以使用enum,可以很大程度的优化我们的索引结构</code></pre><pre><code class="mysql">集合类型说明set(val1, val2, val3...)create table tab ( gender set(&#39;男&#39;, &#39;女&#39;, &#39;无&#39;) );insert into tab values (&#39;男, 女&#39;);最多可以有64个不同的成员。以bigint存储，共8个字节。采取位运算的形式当创建表时，SET成员值的尾部空格将自动被删除</code></pre><h3 id="5-1-4-时间"><a href="#5-1-4-时间" class="headerlink" title="5.1.4 时间"></a>5.1.4 时间</h3><table><thead><tr><th align="center">类型</th><th align="center">字节</th><th align="center">说明</th><th align="center">范围</th></tr></thead><tbody><tr><td align="center">datetime</td><td align="center">8Byte</td><td align="center">日期及时间</td><td align="center">1000-01-01 00:00:00 到 9999-12-31 23:59:59</td></tr><tr><td align="center">date</td><td align="center">3Byte</td><td align="center">日期</td><td align="center">1000-01-01 到 9999-12-31</td></tr><tr><td align="center">timestamp</td><td align="center">4Byte</td><td align="center">时间戳</td><td align="center">19700101000000 到 2038-01-19 03:14:07</td></tr><tr><td align="center">time</td><td align="center">3Byte</td><td align="center">时间</td><td align="center">-838:59:59 到 838:59:59</td></tr><tr><td align="center">year</td><td align="center">1Byte</td><td align="center">年份</td><td align="center">1901 - 2155</td></tr></tbody></table><h2 id="5-2-列属性"><a href="#5-2-列属性" class="headerlink" title="5.2 列属性"></a>5.2 列属性</h2><h3 id="5-2-1-PRIMARY"><a href="#5-2-1-PRIMARY" class="headerlink" title="5.2.1 PRIMARY"></a>5.2.1 PRIMARY</h3><ul><li>能唯一标识记录的字段，可以作为主键。</li><li>一个表只能有一个主键。</li><li>主键具有唯一性。</li><li>声明字段时，用 primary key 标识。</li><li>也可以在字段列表之后声明：create table tab ( id int, stu varchar(10), primary key (id));</li><li>主键字段的值不能为null。</li><li>主键可以由多个字段共同组成。此时需要在字段列表后声明的方法。<br>  例：create table tab ( id int, stu varchar(10), age int, primary key (stu, age));</li></ul><h3 id="5-2-2-UNIQUE"><a href="#5-2-2-UNIQUE" class="headerlink" title="5.2.2 UNIQUE"></a>5.2.2 UNIQUE</h3><p>唯一索引,使得某字段的值也不能重复。</p><h3 id="5-2-3-NULL"><a href="#5-2-3-NULL" class="headerlink" title="5.2.3 NULL"></a>5.2.3 NULL</h3><ul><li>null不是数据类型，是列的一个属性。</li><li>表示当前列是否可以为null，表示什么都没有。</li><li>null, 允许为空。默认；not null, 不允许为空。</li><li>insert into tab values (null, ‘val’); – 此时表示将第一个字段的值设为null, 取决于该字段是否允许为null</li></ul><h3 id="5-2-4-DEFAULT"><a href="#5-2-4-DEFAULT" class="headerlink" title="5.2.4 DEFAULT"></a>5.2.4 DEFAULT</h3><ul><li>当前字段的默认值。<pre><code class="mysql">#表示强制使用默认值insert into tab values (default, &#39;val&#39;);#表示将当前时间的时间戳 设为默认值create table tab ( add_time timestamp default current_timestamp )</code></pre></li></ul><h3 id="5-2-5-AUTO-INCREMENT"><a href="#5-2-5-AUTO-INCREMENT" class="headerlink" title="5.2.5 AUTO_INCREMENT"></a>5.2.5 AUTO_INCREMENT</h3><ul><li>自动增长约束</li><li>自动增长必须为索引（主键或unique）</li><li>只能存在一个字段为自动增长。</li><li>默认为1开始自动增长。可以通过表属性 auto_increment = x进行设置，或 alter table tbl auto_increment = x;</li></ul><h3 id="5-2-6-COMMENT"><a href="#5-2-6-COMMENT" class="headerlink" title="5.2.6 COMMENT"></a>5.2.6 COMMENT</h3><p>注释<br>例：create table tab ( id int ) comment ‘注释内容’;</p><h3 id="5-2-7-FOREIGN-KEY"><a href="#5-2-7-FOREIGN-KEY" class="headerlink" title="5.2.7 FOREIGN KEY"></a>5.2.7 FOREIGN KEY</h3><p>外键约束 高并发下不建议使用 ERP中常用</p><h2 id="5-3-表属性"><a href="#5-3-表属性" class="headerlink" title="5.3 表属性"></a>5.3 表属性</h2><h3 id="5-3-1-engine"><a href="#5-3-1-engine" class="headerlink" title="5.3.1 engine"></a>5.3.1 engine</h3><p>使用的存储引擎 建议都是用Innodb</p><h3 id="5-3-2-charset"><a href="#5-3-2-charset" class="headerlink" title="5.3.2 charset"></a>5.3.2 charset</h3><p>使用的字符集 这个参数也可以在列属性里设置,但是不建议这样做,整表设置相同字符集即可</p><p>常用的有:</p><ul><li>utf8 推荐使用** </li><li>utf8mb4 推荐使用***</li><li>gbk</li></ul><p>建议默认使用utf8mb4格式:</p><blockquote><p>MySQL在5.5.3之后增加了utf8mb4的编码，mb4即4-Byte UTF-8 Unicode Encoding，专门用来兼容四字节的unicode。utf8mb4为utf8的超集并兼容utf8，比utf8能表示更多的字符。</p><p>低版本的MySQL支持的utf8编码，最大字符长度为 3 字节，如果遇到 4 字节的字符就会出现错误了。</p><p>常见的四字节就是Emoji 表情（Emoji 是一种特殊的 Unicode 编码，常见于 ios 和 android 手机上），和一些不常用的汉字，以及任何新增的 Unicode 字符等等。</p></blockquote><h2 id="5-4-常用SQL分类"><a href="#5-4-常用SQL分类" class="headerlink" title="5.4 常用SQL分类"></a>5.4 常用SQL分类</h2><ul><li>DDL：数据定义语言</li><li>DML：数据操作语言</li><li>DCL：数据控制语言</li><li>DQL：数据的查询语言</li></ul><h2 id="5-5-DDL语句"><a href="#5-5-DDL语句" class="headerlink" title="5.5 DDL语句"></a>5.5 DDL语句</h2><h3 id="5-5-1-数据库操作"><a href="#5-5-1-数据库操作" class="headerlink" title="5.5.1 数据库操作"></a>5.5.1 数据库操作</h3><pre><code class="mysql"># 创建demo数据库mysql&gt; create database demo charset utf8mb4mysql&gt; create database if not exists demo charset utf8mb4;# 删除demo数据库mysql&gt; drop database demo;mysql&gt; drop database if exists demo;# 修改database字符集mysql&gt; alter database demo charset=utf8;</code></pre><h3 id="5-5-2-表操作"><a href="#5-5-2-表操作" class="headerlink" title="5.5.2 表操作"></a>5.5.2 表操作</h3><pre><code class="mysql"># 创建表CREATE TABLE `t_scrm_user_info`(  `id`          INT(10) UNSIGNED NOT NULL AUTO_INCREMENT,  `user_id`     VARCHAR(32)      NOT NULL COMMENT &#39;用户ID作为唯一标示&#39;,  `user_name`   VARCHAR(32)      NOT NULL DEFAULT &#39;&#39; COMMENT &#39;用户姓名&#39;,  `user_sex`    TINYINT(3)       NOT NULL DEFAULT 0 COMMENT &#39;用户性别 0未知 1男 2女&#39;,  `user_mobile` VARCHAR(16)      NOT NULL DEFAULT &#39;&#39; COMMENT &#39;用户手机号&#39;,  `user_status` TINYINT(3)       NOT NULL DEFAULT 0 COMMENT &#39;用户状态 0正常 1锁定 -1删除&#39;,  `user_avatar` varchar(256)     NOT NULL DEFAULT &#39;&#39; COMMENT &#39;用户头像&#39;,  `create_time` DATETIME         NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#39;创建时间&#39;,  PRIMARY KEY (`id`),  UNIQUE KEY `UQ_USER_ID` (`user_id`)) ENGINE = InnoDB  DEFAULT CHARSET = utf8mb4 COMMENT =&#39;用户信息表&#39;;# 删除表mysql&gt; drop table t_scrm_user_info;# 重命名表mysql&gt; RENAME TABLE t_scrm_user_info to demo;# 复制表mysql&gt; CREATE table t_scrm_user_info like demo;# 清空表mysql&gt; truncate table t_scrm_user_info;# 添加列——添加update_time列ALTER TABLE t_scrm_user_info ADD update_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT &#39;更新时间&#39;;# 添加列——在user_avatar列后添加user_remark列ALTER TABLE t_scrm_user_info ADD `user_remark` VARCHAR(128) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;用户备注&#39; AFTER user_avatar;# 更新列mysql&gt; ALTER TABLE t_scrm_user_info MODIFY user_name VARCHAR(64);注意上面语句更新的时候 会把user_name列上的其他属性更新没 如not null属性和comment属性所以建议写成如下：mysql&gt; ALTER TABLE t_scrm_user_info MODIFY user_name VARCHAR(32)      NOT NULL DEFAULT &#39;&#39; COMMENT &#39;用户姓名&#39;;# 更新列名mysql&gt; ALTER TABLE t_scrm_user_info CHANGE user_name u_name VARCHAR(32)      NOT NULL DEFAULT &#39;&#39; COMMENT &#39;用户姓名&#39;;# 删除列ALTER TABLE t_scrm_user_info DROP user_avatar;#添加索引ALTER TABLE tbl_name ADD INDEX index_name (column_list): 添加普通索引，索引值可出现多次。#删除索引DROP INDEX [indexName] ON mytable;</code></pre><h2 id="5-6-DML语句"><a href="#5-6-DML语句" class="headerlink" title="5.6 DML语句"></a>5.6 DML语句</h2><pre><code class="mysql"># 插入INSERT INTO t_scrm_user_info(user_id,user_name,user_sex,user_mobile,user_status) VALUES(&quot;123&quot;,&#39;nihao&#39;,1,&#39;18611111111&#39;,&#39;0&#39;),(&quot;345&quot;,&#39;hahah&#39;,1,&#39;18611111111&#39;,&#39;0&#39;);# 更新UPDATE t_scrm_user_info set user_id=&quot;444&quot; WHERE user_id=&quot;123&quot;;# 删除mysql&gt; DELETE FROM t_scrm_user_info where user_id =&quot;444&quot;;# 全表删除mysql&gt; DELETE FROM t_scrm_user_info;与truncate区别delete:         DML操作, 是逻辑性质删除,逐行进行删除,速度慢. 还在文件里 文件大小不会改变        主键继续原来的增长计数truncate:         DDL操作,对与表段中的数据页进行清空,速度快. 从文件里删除 文件大小改变        主键从1开始计数</code></pre><h2 id="5-7-DCL语句"><a href="#5-7-DCL语句" class="headerlink" title="5.7 DCL语句"></a>5.7 DCL语句</h2><pre><code class="mysql"># 管理用户通配符：%表示可以在任意主机使用用户登录数据库【注意】在mysql里面用户的定义为:用户名+主机名【注意】在mysql8.0中添加用户和授权必须是两步进行 不能用一条语句# 添加用户mysql&gt; CREATE USER &#39;read&#39;@&#39;10.15.2.%&#39; identified by &#39;123&#39;;# 删除用户mysql&gt; DROP USER &#39;read&#39;@&#39;10.15.2.%&#39;;#修改用户密码mysql&gt; set password for &#39;read&#39;@&#39;10.15.2.%&#39; = password(&#39;456&#39;);# 授权# 查看授权mysql&gt; show grants for &#39;read&#39;@&#39;10.15.2.%&#39;;+------------------------------------------+| Grants for read@10.15.2.%                |+------------------------------------------+| GRANT USAGE ON *.* TO &#39;read&#39;@&#39;10.15.2.%&#39; |+------------------------------------------+1 row in set (0.00 sec)# 添加授权grant 权限列表 on 数据库.表名  to  &#39;用户名&#39;@&#39;主机名&#39;;mysql&gt; GRANT CREATE,ALTER,DROP,INSERT,UPDATE,DELETE,SELECT ON demo.* TO &#39;read&#39;@&#39;10.15.2.%&#39;;# 授权所有权限mysql&gt; grant all privileges on demo.* to &#39;read&#39;@&#39;10.15.2.%&#39;;# 删除授权revoke 权限列表  on  数据库.表名  from  &#39;用户名&#39;@&#39;主机名&#39;;mysql&gt; revoke DROP,DELETE  on  demo.* from &#39;read&#39;@&#39;10.15.2.%&#39;;# 让授权生效FLUSH PRIVILEGES;</code></pre><h2 id="5-8-DQL语句"><a href="#5-8-DQL语句" class="headerlink" title="5.8 DQL语句"></a>5.8 DQL语句</h2><h3 id="5-8-1-SELECT"><a href="#5-8-1-SELECT" class="headerlink" title="5.8.1 SELECT"></a>5.8.1 SELECT</h3><pre><code class="mysql">SELECT [ALL|DISTINCT] select_expr FROM -&gt; WHERE -&gt; GROUP BY [合计函数] -&gt; HAVING -&gt; ORDER BY -&gt; LIMITa. select_expr    -- 可以用 * 表示所有字段。        select * from tb;    -- 可以使用表达式（计算公式、函数调用、字段也是个表达式）        select stu, 29+25, now() from tb;    -- 可以为每个列使用别名。适用于简化列标识，避免多个列标识符重复。        - 使用 as 关键字，也可省略 as.        select stu+10 as add10 from tb;b. FROM 子句    用于标识查询来源。    -- 可以为表起别名。使用as关键字。        SELECT * FROM tb1 AS tt, tb2 AS bb;    -- from子句后，可以同时出现多个表。        -- 多个表会横向叠加到一起，而数据会形成一个笛卡尔积。        SELECT * FROM tb1, tb2;    -- 向优化符提示如何选择索引        USE INDEX、IGNORE INDEX、FORCE INDEX        SELECT * FROM table1 USE INDEX (key1,key2) WHERE key1=1 AND key2=2 AND key3=3;        SELECT * FROM table1 IGNORE INDEX (key3) WHERE key1=1 AND key2=2 AND key3=3;c. WHERE 子句    -- 从from获得的数据源中进行筛选。    -- 整型1表示真，0表示假。    -- 表达式由运算符和运算数组成。        -- 运算数：变量（字段）、值、函数返回值        -- 运算符：            =, &lt;=&gt;, &lt;&gt;, !=, &lt;=, &lt;, &gt;=, &gt;, !, &amp;&amp;, ||,            in (not) null, (not) like, (not) in, (not) between and, is (not), and, or, not, xor            is/is not 加上ture/false/unknown，检验某个值的真假            &lt;=&gt;与&lt;&gt;功能相同，&lt;=&gt;可用于null比较d. GROUP BY 子句, 分组子句    GROUP BY 字段/别名 [排序方式]    分组后会进行排序。升序：ASC，降序：DESC    以下[合计函数]需配合 GROUP BY 使用：    count 返回不同的非NULL值数目  count(*)、count(字段)    sum 求和    max 求最大值    min 求最小值    avg 求平均值    group_concat 返回带有来自一个组的连接的非NULL值的字符串结果。组内字符串连接。e. HAVING 子句，条件子句    与 where 功能、用法相同，执行时机不同。    where 在开始时执行检测数据，对原数据进行过滤。    having 对筛选出的结果再次进行过滤。    having 字段必须是查询出来的，where 字段必须是数据表存在的。    where 不可以使用字段的别名，having 可以。因为执行WHERE代码时，可能尚未确定列值。    where 不可以使用合计函数。一般需用合计函数才会用 having    SQL标准要求HAVING必须引用GROUP BY子句中的列或用于合计函数中的列。f. ORDER BY 子句，排序子句    order by 排序字段/别名 排序方式 [,排序字段/别名 排序方式]...    升序：ASC，降序：DESC    支持多个字段的排序。g. LIMIT 子句，限制结果数量子句    仅对处理好的结果进行数量限制。将处理好的结果的看作是一个集合，按照记录出现的顺序，索引从0开始。    limit 起始位置, 获取条数    省略第一个参数，表示从索引0开始。limit 获取条数h. DISTINCT, ALL 选项    distinct 去除重复记录    默认为 all, 全部记录</code></pre><h3 id="5-8-2-多表查询"><a href="#5-8-2-多表查询" class="headerlink" title="5.8.2 多表查询"></a>5.8.2 多表查询</h3><p>多表查询使用join关键字进行连接</p><p>连接方式分为四种:</p><ul><li>INNER JOIN：如果表中有至少一个匹配，则返回行</li><li>LEFT JOIN：即使右表中没有匹配，也从左表返回所有的行</li><li>RIGHT JOIN：即使左表中没有匹配，也从右表返回所有的行</li><li>FULL JOIN：只要其中一个表中存在匹配，则返回行</li></ul><p>这里不详细介绍 看图理解</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/sql-join.png" alt=""></p><p>也可参考此篇<a href="https://www.runoob.com/sql/sql-join.html" target="_blank" rel="noopener">文档</a></p><h3 id="5-8-3-SHOW"><a href="#5-8-3-SHOW" class="headerlink" title="5.8.3 SHOW"></a>5.8.3 SHOW</h3><pre><code class="mysql">show  databases;                          #查看所有数据库show tables;                              #查看当前库的所有表SHOW TABLES FROM                          #查看某个指定库下的表show create database world                #查看建库语句show create table world.city              #查看建表语句show  grants for  root@&#39;localhost&#39;        #查看用户的权限信息show  charset；                            #查看字符集show collation                             #查看校对规则show processlist;                          #查看数据库连接情况show index from                            #表的索引情况show status                                 #数据库状态查看SHOW STATUS LIKE &#39;%lock%&#39;;                 #模糊查询数据库某些状态SHOW VARIABLES                             #查看所有配置信息SHOW variables LIKE &#39;%lock%&#39;;              #查看部分配置信息show engines                                #查看支持的所有的存储引擎show engine innodb status                  #查看InnoDB引擎相关的状态信息show binary logs                            #列举所有的二进制日志show master status                           #查看数据库的日志位置信息show binlog events;                          #查看二进制日志事件show slave status                           #查看从库状态SHOW RELAYLOG EVENTS                        #查看从库relaylog事件信息desc  (show colums from city)               #查看表的列定义信息</code></pre><h3 id="5-8-4其它关键字"><a href="#5-8-4其它关键字" class="headerlink" title="5.8.4其它关键字"></a>5.8.4其它关键字</h3><pre><code class="mysql"># distinct：去重复SELECT countrycode FROM city ;SELECT DISTINCT(countrycode) FROM city  ;# 联合查询- union allSELECT * FROM city WHERE countrycode IN (&#39;CHN&#39; ,&#39;USA&#39;);SELECT * FROM city WHERE countrycode=&#39;CHN&#39;UNION ALLSELECT * FROM city WHERE countrycode=&#39;USA&#39;# 联合查询- union SELECT * FROM city WHERE countrycode=&#39;CHN&#39;UNION SELECT * FROM city WHERE countrycode=&#39;USA&#39;说明:一般情况下,我们会将 IN 或者 OR 语句 改写成 UNION (ALL),来提高性能UNION     去重复UNION ALL 不去重复</code></pre>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> Mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>3.Mysql安装及初始化</title>
      <link href="/2020/02/14/3-Mysql%E5%AE%89%E8%A3%85%E5%8F%8A%E5%88%9D%E5%A7%8B%E5%8C%96/"/>
      <url>/2020/02/14/3-Mysql%E5%AE%89%E8%A3%85%E5%8F%8A%E5%88%9D%E5%A7%8B%E5%8C%96/</url>
      
        <content type="html"><![CDATA[<p>环境:Centos8 64位<br>版本:5.7.26 通用二级制版本<br>下载地址:   <a href="https://downloads.mysql.com/archives/get/p/23/file/mysql-5.7.26-linux-glibc2.12-x86_64.tar.gz" target="_blank" rel="noopener">https://downloads.mysql.com/archives/get/p/23/file/mysql-5.7.26-linux-glibc2.12-x86_64.tar.gz</a></p><h2 id="3-1-下载通用二进制包"><a href="#3-1-下载通用二进制包" class="headerlink" title="3.1 下载通用二进制包"></a>3.1 下载通用二进制包</h2><pre><code class="shell">[root@localhost Downloads]# wget  https://downloads.mysql.com/archives/get/p/23/file/mysql-5.7.26-linux-glibc2.12-x86_64.tar.gz</code></pre><h2 id="3-2-创建用户用户"><a href="#3-2-创建用户用户" class="headerlink" title="3.2 创建用户用户"></a>3.2 创建用户用户</h2><pre><code>[root@localhost ken]# useradd mysql</code></pre><h2 id="3-3-创建相应文件夹"><a href="#3-3-创建相应文件夹" class="headerlink" title="3.3 创建相应文件夹"></a>3.3 创建相应文件夹</h2><pre><code>#创建数据存放目录[root@localhost ken]# mkdir -p /data/3306#创建mysql程序存放的目录[root@localhost ken]# mkdir -p /app/database#创建日志存放的目录[root@localhost ken]# mkdir -p /log/3306</code></pre><h2 id="3-4-更改所属目录"><a href="#3-4-更改所属目录" class="headerlink" title="3.4 更改所属目录"></a>3.4 更改所属目录</h2><pre><code>[root@localhost ken]# chown -R mysql.mysql /data/3306  /app/database/ /log/3306/</code></pre><h2 id="3-5-解压mysql并放到指定目录"><a href="#3-5-解压mysql并放到指定目录" class="headerlink" title="3.5 解压mysql并放到指定目录"></a>3.5 解压mysql并放到指定目录</h2><pre><code>[ken@localhost Downloads]$ tar -zxvf mysql-5.7.26-linux-glibc2.12-i686.tar.gz [ken@localhost Downloads]$ lsmysql-5.7.26-linux-glibc2.12-i686  mysql-5.7.26-linux-glibc2.12-i686.tar.gz[ken@localhost Downloads]$ sudo mv mysql-5.7.26-linux-glibc2.12-i686 /app/database/mysql[ken@localhost Downloads]$ sudo chown -R mysql.mysql /app/database/mysql</code></pre><h2 id="3-6设置环境变量"><a href="#3-6设置环境变量" class="headerlink" title="3.6设置环境变量"></a>3.6设置环境变量</h2><pre><code>[ken@localhost ~]$ suPassword: [root@localhost ken]# echo &quot;export PATH=/app/database/mysql/bin:$PATH&quot; &gt;&gt; /etc/profile[root@localhost ken]# exitexit[ken@localhost ~]$ source /etc/profile#显示以下内容即可完成此安装步骤[ken@localhost bin]$ mysql -Vmysql  Ver 14.14 Distrib 5.7.26, for linux-glibc2.12 (x86_64) using  EditLine wrapper【注意】在centos8中 经常会报libncurses.so.5这个文件不存在 但是已经安装了libncurses库还是有报错的话主要是再ceontos中有它的升级版文件/lib64/libncurses.so.6.1 我们做一个软连接即可ln -s /lib64/libncurses.so.6.1 /lib64/libncurses.so.5</code></pre><h2 id="3-7-初始化Mysql"><a href="#3-7-初始化Mysql" class="headerlink" title="3.7 初始化Mysql"></a>3.7 初始化Mysql</h2><pre><code>[root@localhost ken]# mysqld --initialize-insecure --user=mysql --basedir=/app/database/mysql --datadir=/data/3306</code></pre><h2 id="3-8-配置文件设置"><a href="#3-8-配置文件设置" class="headerlink" title="3.8 配置文件设置"></a>3.8 配置文件设置</h2><pre><code>cat &gt; /etc/my.cnf &lt;&lt;EOF[mysqld]user=mysqlbasedir=/app/database/mysqldatadir=/data/3306socket=/tmp/mysql3306.sock[mysql]socket=/tmp/mysql3306.sockEOF</code></pre><h2 id="3-9-准备Mysql启动脚本"><a href="#3-9-准备Mysql启动脚本" class="headerlink" title="3.9 准备Mysql启动脚本"></a>3.9 准备Mysql启动脚本</h2><pre><code>root@localhost support-files]# pwd/app/database/mysql/support-files[root@localhost support-files]# cp mysql.server /etc/init.d/mysqld[root@localhost support-files]# service mysqld startStarting MySQL. SUCCESS! </code></pre><h2 id="3-10-验证是否可以连接成功"><a href="#3-10-验证是否可以连接成功" class="headerlink" title="3.10 验证是否可以连接成功"></a>3.10 验证是否可以连接成功</h2><pre><code>[root@localhost support-files]# mysqlWelcome to the MySQL monitor.  Commands end with ; or \g.Your MySQL connection id is 2Server version: 5.7.26 MySQL Community Server (GPL)Copyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type &#39;help;&#39; or &#39;\h&#39; for help. Type &#39;\c&#39; to clear the current input statement.mysql&gt; </code></pre>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> Mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2.Mysql产品线</title>
      <link href="/2020/02/13/2-Mysql%E4%BA%A7%E5%93%81%E7%BA%BF/"/>
      <url>/2020/02/13/2-Mysql%E4%BA%A7%E5%93%81%E7%BA%BF/</url>
      
        <content type="html"><![CDATA[<h2 id="2-1-Mysql主流厂家"><a href="#2-1-Mysql主流厂家" class="headerlink" title="2.1 Mysql主流厂家"></a>2.1 Mysql主流厂家</h2><ul><li>Oracle:MySQL官方版</li><li>红帽 :MariaDB</li><li>Percona: PerconaDB</li><li>阿里云做的也很好</li></ul><h2 id="2-2-Mysql主流版本"><a href="#2-2-Mysql主流版本" class="headerlink" title="2.2 Mysql主流版本"></a>2.2 Mysql主流版本</h2><ul><li>5.6—–5.6.36 5.6.38 5.6.40 5.6.46</li><li>5.7—–5.7.20 5.7.22 5.7.24 5.7.28</li><li>8.0—–8.0.11</li></ul><p><code>建议选择GA稳定版下半年发布的产品</code></p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> Mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>1.数据库分类</title>
      <link href="/2020/02/12/1-%E6%95%B0%E6%8D%AE%E5%BA%93%E5%88%86%E7%B1%BB/"/>
      <url>/2020/02/12/1-%E6%95%B0%E6%8D%AE%E5%BA%93%E5%88%86%E7%B1%BB/</url>
      
        <content type="html"><![CDATA[<p>我们可以从 <a href="https://db-engines.com/en/ranking" target="_blank" rel="noopener">https://db-engines.com/en/ranking</a>  这个网站查看数据库在互联网上的<code>流行程度</code>:<br><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/database.png" alt="数据库流行程度"></p><h2 id="1-1-关系型数据库"><a href="#1-1-关系型数据库" class="headerlink" title="1.1 关系型数据库"></a>1.1 关系型数据库</h2><p>英文简称为RDMS,最常见的数据库,其核心思想是将复杂的数据结构归结成简单的二元关系<br>常见的关系型数据库为:Mysql,SqlServer,Oracle</p><h2 id="1-2-键值存储数据库"><a href="#1-2-键值存储数据库" class="headerlink" title="1.2  键值存储数据库"></a>1.2  键值存储数据库</h2><p>键值数据库是一种非关系数据库，它使用简单的键值方法来存储数据<br>键值数据库将数据存储为键值对集合，其中键作为唯一标识符<br>常见的键值存储数据库为：Redis和memcached</p><h2 id="1-3-列存储数据库"><a href="#1-3-列存储数据库" class="headerlink" title="1.3 列存储数据库"></a>1.3 列存储数据库</h2><p>列式存储(column-based)是相对于传统关系型数据库的行式存储(Row-basedstorage)来说的<br>简单来说两者的区别就是对表中数据的存储形式的差异<br>常见的列存储数据库为：HBase</p><h2 id="1-4-面向文档数据库"><a href="#1-4-面向文档数据库" class="headerlink" title="1.4 面向文档数据库"></a>1.4 面向文档数据库</h2><p>此类数据库可存放并获取文档，可以是XML、JSON、BSON等格式，这些文档具备可述性（self-describing），呈现分层的树状结构（hierarchical tree data structure），可以包含映射表、集合和纯量值。数据库中的文档彼此相似，但不必完全相同。文档数据库所存放的文档，就相当于键值数据库所存放的“值”。文档数据库可视为其值可查的键值数据库。<br>常见的面向文档数据库为：MongoDB</p><h2 id="1-5-图形数据库"><a href="#1-5-图形数据库" class="headerlink" title="1.5 图形数据库"></a>1.5 图形数据库</h2><p>故名思意就是存储图形关系的数据库,也是Nosql的一种<br>常见的图形数据库为:Neo4J、ArangoDB、OrientDB、FlockDB、GraphDB、InfiniteGraph、Titan和Cayley等</p><h2 id="1-6-搜索引擎存储"><a href="#1-6-搜索引擎存储" class="headerlink" title="1.6 搜索引擎存储"></a>1.6 搜索引擎存储</h2><p>搜索引擎数据库是应用在搜索引擎领域的数据存储形式，由于搜索引擎会爬取大量的数据，并以特定的格式进行存储，这样在检索的时候才能保证性能最优。<br>常见的搜索引擎存储为:Elasticsearch,solr</p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> Mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mysql </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
