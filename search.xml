<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Go并发channel</title>
      <link href="/2020/05/06/Go%E5%B9%B6%E5%8F%91channel/"/>
      <url>/2020/05/06/Go%E5%B9%B6%E5%8F%91channel/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Go make和new的区别</title>
      <link href="/2020/05/06/Gomake%E5%92%8Cnew%E7%9A%84%E5%8C%BA%E5%88%AB/"/>
      <url>/2020/05/06/Gomake%E5%92%8Cnew%E7%9A%84%E5%8C%BA%E5%88%AB/</url>
      
        <content type="html"><![CDATA[<p>new 和 make 是 Go 语言中两种内存分配原语。</p><p>二者所做的事情和针对的类型都不一样。</p><p> new 和其他编程语言中的关键字功能类似，都是向系统申请一段内存空间来存储对应类型的数据，但又有些区别，区别在于它会将该片空间置零。也就是说 new(T) 会根据类型 T 在堆上 申请一片置零的内存空间，并返回指针 *T。</p><p> <strong>make 只针对切片，映射和信道三种数据类型 T 的构建，并返回类型为 T 的一个已经初始化（而非零）的值</strong>。原因是这三种数据类型都是引用数据类型，在使用前必须初始化。就像切片是一个具有三项内容的描述符，包含一个指向数组的指针，长度和容量。通过 make 创建对应类型的变量过程是先分配一段空间，接着根据对应的描述符来创建对应的类型变量</p>]]></content>
      
      
      <categories>
          
          <category> 语言 </category>
          
          <category> go </category>
          
      </categories>
      
      
        <tags>
            
            <tag> go </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Go 函数参数slice和map的区别</title>
      <link href="/2020/05/06/Go%E5%87%BD%E6%95%B0%E5%8F%82%E6%95%B0slice%E5%92%8Cmap%E7%9A%84%E5%8C%BA%E5%88%AB/"/>
      <url>/2020/05/06/Go%E5%87%BD%E6%95%B0%E5%8F%82%E6%95%B0slice%E5%92%8Cmap%E7%9A%84%E5%8C%BA%E5%88%AB/</url>
      
        <content type="html"><![CDATA[<p><strong>从变量本身来说，go只有值传递</strong></p><h2 id="1-slice"><a href="#1-slice" class="headerlink" title="1.slice"></a>1.slice</h2><p><strong>slice本身是传递给func的时候是结构体传递,后对外部的slice生成一个副本</strong></p><p>但是slice的结构体如下:</p><pre><code class="go">type slice struct {    array unsafe.Pointer    len   int    cap   int}</code></pre><p>slice结构体中真正指向数组array的是一个指针,所以修改了func里面的slice可能会影响外面的slice:</p><pre><code class="go">func main() {    arr := []int{1, 2, 3, 4, 5, 6}    fmt.Println(&quot;main函数:arr&quot;, arr)    fmt.Printf(&quot;main函数:arr的地址%p\n&quot;, arr)    fmt.Println(&quot;=====================&quot;)    test1(arr)    fmt.Println(&quot;=====================&quot;)    fmt.Println(&quot;执行过test1函数后,main函数:arr&quot;, arr)    fmt.Printf(&quot;执行过test1函数后,main函数:arr的地址%p\n&quot;, arr)    test2(arr)    fmt.Println(&quot;=====================&quot;)    fmt.Println(&quot;执行过test2函数后,main函数:arr&quot;, arr)    fmt.Printf(&quot;执行过test2函数后,main函数:arr的地址%p\n&quot;, arr)}func test1(arr []int) {    //arr = append(arr,111,111,111,1111,1111,1111,1111,1111)    arr = append(arr,111)    arr[0] = 1111    fmt.Println(&quot;test1函数:arr&quot;, arr)    fmt.Printf(&quot;test1函数:arr的地址%p\n&quot;, arr)}func test2(arr []int) {    arr[0] = 1111    arr = append(arr,111)    fmt.Println(&quot;test2函数:arr&quot;, arr)    fmt.Printf(&quot;test2函数:arr的地址%p\n&quot;, arr)}</code></pre><p>输出:</p><pre><code>main函数:arr [1 2 3 4 5 6]main函数:arr的地址0x94b0020=====================test1函数:arr [1111 2 3 4 5 6 111]test1函数:arr的地址0x94aa030=====================执行过test1函数后,main函数:arr [1 2 3 4 5 6]执行过test1函数后,main函数:arr的地址0x94b0020test2函数:arr [1111 2 3 4 5 6 111]test2函数:arr的地址0x94aa060=====================执行过test2函数后,main函数:arr [1111 2 3 4 5 6]执行过test2函数后,main函数:arr的地址0x94b0020</code></pre><p>解释:</p><pre><code class="go">append的操作会返回一个新的结构体func append(slice []Type, elems ...Type) []Type替换掉原来外部的指针地址,因此不会以外部的变量产生影响了而先进行arr[0]修改操作还是会影响原来的指针</code></pre><p><strong>以上对于slice的坑需要额外注意,说出来都是泪T T</strong></p><h2 id="2-map"><a href="#2-map" class="headerlink" title="2.map"></a>2.map</h2><p>map相比slice简单了很多</p><pre><code class="go">func makemap(t *maptype, hint int, h *hmap) *hmap</code></pre><p><strong>创建map的时候会返回一个指针</strong></p><p><strong>传入到func之后就是对原地址进行操作,一般不会有其他的坑,除了map不支持并发以外= =</strong></p><p><strong>还有尽量不要用浮点数做key值,会有精度丢失的问题</strong></p><p>demo:</p><pre><code class="go">func main() {    tMap := make(map[string]string)    tMap[&quot;aaaa&quot;] = &quot;aaaa&quot;    fmt.Println(&quot;main函数:tMap&quot;, tMap)    fmt.Printf(&quot;main函数:tMap的地址%p\n&quot;, tMap)    test1(tMap)    fmt.Println(&quot;执行过test1后main函数:tMap&quot;, tMap)    fmt.Printf(&quot;执行过test1后main函数:tMap的地址%p\n&quot;, tMap)}func test1(tMap map[string]string) {    tMap[&quot;aaaa&quot;] = &quot;vvvvv&quot;    tMap[&quot;bbbb&quot;] = &quot;bbbbb&quot;    fmt.Println(&quot;test1函数:tMap&quot;, tMap)    fmt.Printf(&quot;test1函数:tMap的地址%p\n&quot;, tMap)}</code></pre><p>输出:</p><pre><code>main函数:tMap map[aaaa:aaaa]main函数:tMap的地址0xa058100test1函数:tMap map[aaaa:vvvvv bbbb:bbbbb]test1函数:tMap的地址0xa058100执行过test1后main函数:tMap map[aaaa:vvvvv bbbb:bbbbb]执行过test1后main函数:tMap的地址0xa058100</code></pre>]]></content>
      
      
      <categories>
          
          <category> 语言 </category>
          
          <category> go </category>
          
      </categories>
      
      
        <tags>
            
            <tag> go </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>访问者模式</title>
      <link href="/2020/05/03/%E8%AE%BF%E9%97%AE%E8%80%85%E6%A8%A1%E5%BC%8F/"/>
      <url>/2020/05/03/%E8%AE%BF%E9%97%AE%E8%80%85%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h2 id="1-模式动机"><a href="#1-模式动机" class="headerlink" title="1 模式动机"></a>1 模式动机</h2><p><strong>意图：主要将数据结构与数据操作分离。</strong></p><h2 id="2-模式定义"><a href="#2-模式定义" class="headerlink" title="2 模式定义"></a>2 模式定义</h2><p>访问者（Visitor）模式的定义：将作用于某种数据结构中的各元素的操作分离出来封装成独立的类，使其在不改变数据结构的前提下可以添加作用于这些元素的新的操作，为数据结构中的每个元素提供多种访问方式。它将对数据的操作与数据结构进行分离是行为类模式中最复杂的一种模式。</p><h2 id="3-Demo"><a href="#3-Demo" class="headerlink" title="3 Demo"></a>3 Demo</h2><pre><code class="go">#===================ObjectStruct.go====================package maintype ObjectStruct struct {    list []*Element}func NewObjectStruct() *ObjectStruct {    return &amp;ObjectStruct{list: make([]*Element, 0)}}func (ob *ObjectStruct) Add(element *Element) {    ob.list = append(ob.list, element)}func (ob *ObjectStruct) Remove(element *Element) {    for i, e := range ob.list {        if element == e {            ob.list = append(ob.list[:i], ob.list[i+1:]...)        }    }}func (ob *ObjectStruct) Accept(visitor *Visitor) {    for _,e := range ob.list {        e.Accept(visitor)    }}#=================Element.go===================package mainimport &quot;fmt&quot;type elementInter interface {    Accept(visitor Visitor)    Operation()}type Element struct {    visitor *Visitor    name    string}func NewElement(name string) *Element {    return &amp;Element{        visitor: nil,        name:    name,    }}func (e *Element) Accept(visitor *Visitor) {    visitor.Visit(e)}func (e *Element) Operation() {    fmt.Println(e.name + &quot;Operation&quot;)}#=================Visitor.go===================package maintype visitorInter interface {    Visit(element Element)}type Visitor struct {    name string}func NewVisitor(name string) *Visitor {    return &amp;Visitor{name: name}}func (v *Visitor) Visit(element *Element) {    element.Operation()}#===================main.go====================package main//访问者（Visitor）模式的定义：将作用于某种数据结构中的各元素的操作分离出来封装成独立的类，//使其在不改变数据结构的前提下可以添加作用于这些元素的新的操作，//为数据结构中的每个元素提供多种访问方式。它将对数据的操作与数据结构进行分离//是行为类模式中最复杂的一种模式。func main()  {    os := NewObjectStruct()    e1 := NewElement(&quot;A&quot;)    e2 := NewElement(&quot;B&quot;)    os.Add(e1)    os.Add(e2)    v := NewVisitor(&quot;v&quot;)    os.Accept(v)}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 设计模式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>模板模式</title>
      <link href="/2020/05/03/%E6%A8%A1%E6%9D%BF%E6%A8%A1%E5%BC%8F/"/>
      <url>/2020/05/03/%E6%A8%A1%E6%9D%BF%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h2 id="1-模式动机"><a href="#1-模式动机" class="headerlink" title="1 模式动机"></a>1 模式动机</h2><p>定义一个操作中的算法的骨架，而<strong>将一些步骤延迟到子类中。模板方法使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤。</strong></p><h2 id="2-模式定义"><a href="#2-模式定义" class="headerlink" title="2 模式定义"></a>2 模式定义</h2><p>在模板模式（Template Pattern）中，一个抽象类公开定义了执行它的方法的方式/模板。它的子类可以按需要重写方法实现，但调用将以抽象类中定义的方式进行。这种类型的设计模式属于行为型模式。</p><h2 id="3-Demo"><a href="#3-Demo" class="headerlink" title="3 Demo"></a>3 Demo</h2><pre><code class="go">#===================Person.go====================package mainimport &quot;fmt&quot;type DressInter interface {    Dress()}type PersonInter interface {    SetName(name string)    BeforeOut()    Out()}type Person struct {    Specific DressInter    name     string}func (p *Person) SetName(name string) {    p.name = name}func (p *Person) Out() {    p.BeforeOut()    fmt.Println(p.name + &quot; go out...&quot;)}func (p *Person) BeforeOut() {    if p.Specific == nil {        return    }    p.Specific.Dress()}#=================Boy.go===================package mainimport &quot;fmt&quot;type Boy struct {    Person}func (_ *Boy) Dress() {    fmt.Println(&quot;wash face&quot;)}#===================main.go====================package main//定义一个操作中的算法骨架，而将算法的一些步骤延迟到子类中，//使得子类可以不改变该算法结构的情况下重定义该算法的某些特定步骤。它是一种类行为型模式。//系统的组件都是按照一定的流程执行//并且不同的组件的实现方式不同,需要我们延迟到子类来实现.func main() {    p := &amp;Person{}    p.Specific = &amp;Boy{}    p.SetName(&quot;Ken&quot;)    p.Out()}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 设计模式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>策略模式</title>
      <link href="/2020/05/03/%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F/"/>
      <url>/2020/05/03/%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h2 id="1-模式动机"><a href="#1-模式动机" class="headerlink" title="1 模式动机"></a>1 模式动机</h2><p>完成一项任务，往往可以有多种不同的方式，每一种方式称为一个策略，我们可以根据环境或者条件的不同选择不同的策略来完成该项任务。</p><h2 id="2-模式定义"><a href="#2-模式定义" class="headerlink" title="2 模式定义"></a>2 模式定义</h2><p>策略（Strategy）模式的定义：该模式定义了一系列算法，并将每个算法封装起来，使它们可以相互替换，且算法的变化不会影响使用算法的客户。策略模式属于对象行为模式，它通过对算法进行封装，把使用算法的责任和算法的实现分割开来，并委派给不同的对象对这些算法进行管理。</p><h2 id="3-Demo"><a href="#3-Demo" class="headerlink" title="3 Demo"></a>3 Demo</h2><pre><code class="go">#===================Strategy.go====================package maintype strategyInter interface {    strategyMethod()}type contextInter interface {    setStrategy(inter strategyInter)    strategyMethod()}type Context struct {    strategy strategyInter}func (c *Context) setStrategy(inter strategyInter) {    c.strategy = inter}func (c *Context) strategyMethod() {    c.strategy.strategyMethod()}#=================Concrete.go===================package mainimport &quot;fmt&quot;type ConcreteA struct {}func (c *ConcreteA) strategyMethod() {    fmt.Println(&quot;ConcreteA strategyMethod&quot;)}type ConcreteB struct {}func (c *ConcreteB) strategyMethod() {    fmt.Println(&quot;ConcreteB strategyMethod&quot;)}#===================main.go====================package main//策略（Strategy）模式的定义：该模式定义了一系列算法，//并将每个算法封装起来，使它们可以相互替换，//且算法的变化不会影响使用算法的客户。策略模式属于对象行为模式，//它通过对算法进行封装，把使用算法的责任和算法的实现分割开来，并//委派给不同的对象对这些算法进行管理。//模板方法模式的主要思想：定义一个算法流程，将一些特定步骤的具体实现、延迟到子类//。使得可以在不改变算法流程的情况下，通过不同的子类、来实现“定制”流程中的特定的步骤。////策略模式的主要思想：使不同的算法可以被相互替换，而不影响客户端的使用。func main()  {    c := &amp;Context{}    sa := &amp;ConcreteA{}    sb := &amp;ConcreteB{}    c.setStrategy(sa)    c.strategyMethod()    c.setStrategy(sb)    c.strategyMethod()}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 设计模式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>状态模式</title>
      <link href="/2020/05/01/%E7%8A%B6%E6%80%81%E6%A8%A1%E5%BC%8F/"/>
      <url>/2020/05/01/%E7%8A%B6%E6%80%81%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h2 id="1-模式动机"><a href="#1-模式动机" class="headerlink" title="1 模式动机"></a>1 模式动机</h2><p>在很多情况下<strong>，一个对象的行为取决于一个或多个动态变化的属性</strong>，这样的属性叫做状态，这样的对象叫做有状态的(stateful)对象，这样的对象状态是从事先定义好的一系列值中取出的。当一个这样的对象与外部事件产生互动时，其内部状态就会改变，从而使得系统的行为也随之发生变化。</p><h2 id="2-模式定义"><a href="#2-模式定义" class="headerlink" title="2 模式定义"></a>2 模式定义</h2><p>状态模式(State Pattern) ：允许一个对象在其内部状态改变时改变它的行为，对象看起来似乎修改了它的类。其别名为状态对象(Objects for States)，状态模式是一种对象行为型模式。</p><h2 id="3-Demo"><a href="#3-Demo" class="headerlink" title="3 Demo"></a>3 Demo</h2><pre><code class="go">#===================State.go====================package mainimport &quot;fmt&quot;type Account struct {    State       ActionState    HealthValue int}func NewAccount(health int) *Account {    a := &amp;Account{        HealthValue: health,    }    a.changeState()    return a}func (a *Account) View() {    a.State.View()}func (a *Account) Comment() {    a.State.Comment()}func (a *Account) Post() {    a.State.Post()}func (a *Account) changeState() {    if a.HealthValue &lt;= -10 {        a.State = &amp;CloseState{}    } else if a.HealthValue &gt; -10 &amp;&amp; a.HealthValue &lt;= 0 {        a.State = &amp;RestrictedState{}    } else if a.HealthValue &gt; 0 {        a.State = &amp;NormalState{}    }}///给账户设定健康值func (a *Account) SetHealth(value int) {    a.HealthValue = value    a.changeState()}//===========================================================================type ActionState interface {    View()    Comment()    Post()}type CloseState struct {}func (c *CloseState) View() {    fmt.Println(&quot;账号被封，无法看帖&quot;)}func (c *CloseState) Comment() {    fmt.Println(&quot;抱歉，你的健康值小于-10，不能评论&quot;)}func (c *CloseState) Post() {    fmt.Println(&quot;抱歉，你的健康值小于0，不能发帖&quot;)}type RestrictedState struct {}func (r *RestrictedState) View() {    fmt.Println(&quot;正常看帖&quot;)}func (r *RestrictedState) Comment() {    fmt.Println(&quot;正常评论&quot;)}func (r *RestrictedState) Post() {    fmt.Println(&quot;抱歉，你的健康值小于0，不能发帖&quot;)}type NormalState struct {}func (n *NormalState) View() {    fmt.Println(&quot;正常看帖&quot;)}func (n *NormalState) Comment() {    fmt.Println(&quot;正常评论&quot;)}func (n *NormalState) Post() {    fmt.Println(&quot;正常发帖&quot;)}#===================main.go====================package main//状态模式(State)：当一个对象的内部状态发生改变时，会导致其行为的改变，//对象看起来似乎修改了它的类。其别名为状态对象(Objects for States)//状态模式是一种对象行为型模式。状态模式用于解决系统中复杂对象的状态转换以及不同状态下行为的封装问题//当系统中某个对象存在多个状态，这些状态之间可以进行转换，而且对象在不同状态下行为不相同时可以使用状态模式。//Context（环境类）：环境类又称为上下文类，它是拥有多种状态的对象。由于环境类的状态存在多样性且在不同状态下对象的行为有所不同，因此将状态独立出去形成单独的状态类。在环境类中维护一个抽象状态类State的实例，这个实例定义当前状态，在具体实现时，它是一个State子类的对象。//State（抽象状态类）：它用于定义一个接口以封装与环境类的一个特定状态相关的行为，在抽象状态类中声明了各种不同状态对应的方法，而在其子类中实现类这些方法，由于不同状态下对象的行为可能不同，因此在不同子类中方法的实现可能存在不同，相同的方法可以写在抽象状态类中。//ConcreteState（具体状态类）：它是抽象状态类的子类，每一个子类实现一个与环境类的一个状态相关的行为，每一个具体状态类对应环境的一个具体状态，不同的具体状态类其行为有所不同func main() {    account := NewAccount(11)    account.Comment()    account.Post()    account.View()    account.SetHealth(-1)    account.Comment()    account.Post()    account.View()}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 设计模式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>观察者模式</title>
      <link href="/2020/05/01/%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F/"/>
      <url>/2020/05/01/%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h2 id="1-模式动机"><a href="#1-模式动机" class="headerlink" title="1 模式动机"></a>1 模式动机</h2><p>建立一种对象与对象之间的依赖关系，一个对象发生改变时将自动通知其他对象，其他对象将相应做出反应。在此，发生改变的对象称为观察目标，而被通知的对象称为观察者，一个观察目标可以对应多个观察者，而且这些观察者之间没有相互联系，<strong>可以根据需要增加和删除观察者，使得系统更易于扩展</strong>，这就是观察者模式的模式动机。</p><h2 id="2-模式定义"><a href="#2-模式定义" class="headerlink" title="2 模式定义"></a>2 模式定义</h2><p>观察者（Observer）模式的定义：指多个对象间存在一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新。这种模式有时又称作发布-订阅模式、模型-视图模式，它是对象行为型模式。</p><h2 id="3-Demo"><a href="#3-Demo" class="headerlink" title="3 Demo"></a>3 Demo</h2><pre><code class="go">#===================Observer.go====================package mainimport &quot;fmt&quot;type observerInter interface {    Response()}type Observer struct {    name string}func (o *Observer) Response() {}type AObserver struct {    Observer}func NewAObserver(name string) *Observer {    return &amp;Observer{name: name}}func (o *AObserver) Response() {    fmt.Println(&quot;AObserver Response&quot;)}type BObserver struct {    Observer}func NewBObserver(name string) *Observer {    return &amp;Observer{name: name}}func (o *BObserver) Response() {    fmt.Println(&quot;BObserver Response&quot;)}#=================Subject.go===================package mainimport &quot;fmt&quot;type subjectInter interface {    Add(o *Observer)    Remove(o *Observer)    Notify()}type Subject struct {    name      string    observers map[string]*Observer}func NewSubject(name string) *Subject {    return &amp;Subject{        name:      name,        observers: make(map[string]*Observer),    }}func (s *Subject) Add(o *Observer) {    s.observers[o.name] = o}func (s *Subject) Remove(o *Observer) {    delete(s.observers, o.name)}func (s *Subject) Notify() {    fmt.Println(&quot;主题:&quot;+s.name)    for name, object := range s.observers {        fmt.Println(&quot;通知:&quot; + name)        object.Response()    }}#===================main.go====================package main//观察者（Observer）模式的定义：指多个对象间存在一对多的依赖关系，当一个对象的状态发生改变时，//所有依赖于它的对象都得到通知并被自动更新。这种模式有时又称作发布-订阅模式、模型-视图模式，它是对象行为型模式。//观察者模式的主要角色如下。//抽象主题（Subject）角色：也叫抽象目标类，它提供了一个用于保存观察者对象的聚集类和增加、删除观察者对象的方法，以及通知所有观察者的抽象方法。//具体主题（Concrete    Subject）角色：也叫具体目标类，它实现抽象目标中的通知方法，当具体主题的内部状态发生改变时，通知所有注册过的观察者对象。//抽象观察者（Observer）角色：它是一个抽象类或接口，它包含了一个更新自己的抽象方法，当接到具体主题的更改通知时被调用。//具体观察者（Concrete Observer）角色：实现抽象观察者中定义的抽象方法，以便在得到目标的更改通知时更新自身的状态。func main()  {    subject := NewSubject(&quot;SubA&quot;)    oa := NewAObserver(&quot;A&quot;)    ob := NewBObserver(&quot;B&quot;)    subject.Add(oa)    subject.Add(ob)    subject.Notify()    subject.Remove(oa)    subject.Notify()}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 设计模式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>备忘录模式</title>
      <link href="/2020/05/01/%E5%A4%87%E5%BF%98%E5%BD%95%E6%A8%A1%E5%BC%8F/"/>
      <url>/2020/05/01/%E5%A4%87%E5%BF%98%E5%BD%95%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h2 id="1-模式动机"><a href="#1-模式动机" class="headerlink" title="1 模式动机"></a>1 模式动机</h2><p>很多时候我们总是需要<strong>记录一个对象的内部状态</strong>，这样做的目的就是为了允许用户取消不确定或者错误的操作，<strong>能够恢复到他原先的状态</strong>，使得他有”后悔药”可吃。</p><h2 id="2-模式定义"><a href="#2-模式定义" class="headerlink" title="2 模式定义"></a>2 模式定义</h2><p>备忘录（Memento）模式的定义：在不破坏封装性的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态，以便以后当需要时能将该对象恢复到原先保存的状态。该模式又叫快照模式。</p><h2 id="3-Demo"><a href="#3-Demo" class="headerlink" title="3 Demo"></a>3 Demo</h2><pre><code class="go">#===================Originator.go====================package maintype Originator struct {    state string}func NewOriginator() *Originator {    return new(Originator)}func (o *Originator) SetState(state string) {    o.state = state}func (o *Originator) GetState() string {    return o.state}func (o *Originator) CreateMemento() *Memento {    return NewMemento(o.state)}func (o *Originator) RestoreMemento(m *Memento) {    o.SetState(m.GetState())}#=================Memento.go===================package maintype Memento struct {    state string}func NewMemento(state string) *Memento {    return &amp;Memento{state: state}}func (m *Memento) GetState() string {    return m.state}#=================Caretaker.go===================package maintype Caretaker struct {    memento *Memento}func NewCaretaker() *Caretaker {    return new(Caretaker)}func (c *Caretaker) SetMemento(memento *Memento) {    c.memento = memento}func (c *Caretaker) GetMemento() *Memento {    return c.memento}#===================main.go====================package mainimport &quot;fmt&quot;//备忘录（Memento）模式的定义：在不破坏封装性的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态，//以便以后当需要时能将该对象恢复到原先保存的状态。该模式又叫快照模式。//备忘录模式的主要角色如下。//发起人（Originator）角色：记录当前时刻的内部状态信息，提供创建备忘录和恢复备忘录数据的功能，实现其他业务功能，它可以访问备忘录里的所有信息。//备忘录（Memento）角色：负责存储发起人的内部状态，在需要的时候提供这些内部状态给发起人。//管理者（Caretaker）角色：对备忘录进行管理，提供保存与获取备忘录的功能，但其不能对备忘录的内容进行访问与修改。func main()  {    o := NewOriginator()    o.SetState(&quot;S1&quot;)    fmt.Println(o.GetState())    c := NewCaretaker()    c.SetMemento(o.CreateMemento())    o.SetState(&quot;S2&quot;)    fmt.Println(o.GetState())    o.RestoreMemento(c.GetMemento())    fmt.Println(o.GetState())}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 设计模式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>中介者模式</title>
      <link href="/2020/04/29/%E4%B8%AD%E4%BB%8B%E8%80%85%E6%A8%A1%E5%BC%8F/"/>
      <url>/2020/04/29/%E4%B8%AD%E4%BB%8B%E8%80%85%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h2 id="1-模式动机"><a href="#1-模式动机" class="headerlink" title="1 模式动机"></a>1 模式动机</h2><p>在用户与用户直接聊天的设计方案中，用户对象之间存在很强的关联性，将导致系统出现如下问题：</p><ul><li>系统结构复杂：对象之间存在大量的相互关联和调用，若有一个对象发生变化，则需要跟踪和该对象关联的其他所有对象，并进行适当处理。</li><li>对象可重用性差：由于一个对象和其他对象具有很强的关联，若没有其他对象的支持，一个对象很难被另一个系统或模块重用，这些对象表现出来更像一个不可分割的整体，职责较为混乱。</li><li>系统扩展性低：增加一个新的对象需要在原有相关对象上增加引用，增加新的引用关系也需要调整原有对象，系统耦合度很高，对象操作很不灵活，扩展性差。</li><li>在面向对象的软件设计与开发过程中，根据“单一职责原则”，我们应该尽量将对象细化，使其只负责或呈现单一的职责。</li><li>对于一个模块，可能由很多对象构成，而且这些对象之间可能存在相互的引用，为了<strong>减少对象两两之间复杂的引用关系，使之成为一个松耦合的系统</strong>，我们需要使用中介者模式，这就是中介者模式的模式动机。</li></ul><h2 id="2-模式定义"><a href="#2-模式定义" class="headerlink" title="2 模式定义"></a>2 模式定义</h2><p>中介者模式(Mediator Pattern)定义：用一个中介对象来封装一系列的对象交互，中介者使各对象不需要显式地相互引用，从而使其耦合松散，而且可以独立地改变它们之间的交互。中介者模式又称为调停者模式，它是一种对象行为型模式。</p><h2 id="3-Demo"><a href="#3-Demo" class="headerlink" title="3 Demo"></a>3 Demo</h2><pre><code class="go">#===================Mediator.go====================package maintype MediatorInter interface {    Register(c *Collage)    Relay(c *Collage)}type ConcreteMediator struct {    name     string    collages map[string]*Collage}func NewConcreteMediator(name string) *ConcreteMediator {    return &amp;ConcreteMediator{        name:     name,        collages: make(map[string]*Collage),    }}func (c *ConcreteMediator) Register(coll *Collage) {    c.collages[coll.name] = coll}func (c *ConcreteMediator) Relay(coll *Collage) {    for name, collage := range c.collages {        if name != coll.name {            collage.Receive()        }    }}#=================Collage.go===================package mainimport &quot;fmt&quot;type CollageInter interface {    SetMedium(m MediatorInter)    Receive()    Send()}type Collage struct {    name     string    mediator MediatorInter}func NewCollage(name string) *Collage {    return &amp;Collage{        name: name,    }}func (coll *Collage) SetMedium(m MediatorInter) {    coll.mediator = m    coll.mediator.Register(coll)}func (coll *Collage) Receive() {    fmt.Println(coll.name + &quot;收到消息&quot;)}func (coll *Collage) Send() {    fmt.Println(coll.name + &quot;发送消息&quot;)    coll.mediator.Relay(coll)}#===================main.go====================package mainfunc main()  {    lianjia := NewConcreteMediator(&quot;链家&quot;)    collA := NewCollage(&quot;中介从业者1&quot;)    collA.SetMedium(lianjia)    collB := NewCollage(&quot;中介从业者2&quot;)    collB.SetMedium(lianjia)    collC := NewCollage(&quot;买房人A&quot;)    collC.SetMedium(lianjia)    collC.Send()    woaiwojia := NewConcreteMediator(&quot;我爱我家&quot;)    collA1 := NewCollage(&quot;中介从业者11&quot;)    collA1.SetMedium(woaiwojia)    collB1 := NewCollage(&quot;中介从业者21&quot;)    collB1.SetMedium(woaiwojia)    collC1 := NewCollage(&quot;买房人A1&quot;)    collC1.SetMedium(woaiwojia)    collC1.Send()}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 设计模式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>迭代器模式</title>
      <link href="/2020/04/29/%E8%BF%AD%E4%BB%A3%E5%99%A8%E6%A8%A1%E5%BC%8F/"/>
      <url>/2020/04/29/%E8%BF%AD%E4%BB%A3%E5%99%A8%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h2 id="1-模式动机"><a href="#1-模式动机" class="headerlink" title="1 模式动机"></a>1 模式动机</h2><p>意图：提供一种方法顺序访问一个聚合对象中各个元素, 而又无须暴露该对象的内部表示。</p><p>主要解决：不同的方式来遍历整个整合对象。</p><h2 id="2-模式定义"><a href="#2-模式定义" class="headerlink" title="2 模式定义"></a>2 模式定义</h2><p>迭代器（Iterator）模式：提供一种方法来顺序访问聚合对象中的一系列数据，而不暴露聚合对象的内部表示。</p><h2 id="3-Demo"><a href="#3-Demo" class="headerlink" title="3 Demo"></a>3 Demo</h2><pre><code class="go">#===================Iterator.go====================package maintype iteratorInter interface {    First() interface{}    Next() interface{}    HasNext() bool}type iterator struct {    index int    list  []interface{}}func NewIterator(list []interface{}) *iterator {    return &amp;iterator{        index: 0,        list:  list,    }}func (i *iterator) First() interface{} {    return i.list[0]}func (i *iterator) Next() interface{} {    if i.HasNext() {        i.index = i.index + 1        return i.list[i.index-1]    }    return nil}func (i *iterator) HasNext() bool {    return i.index &lt; len(i.list)}#=================Aggregate.go===================package maintype aggregateInter interface {    Add(o interface{})    Remove()    GetIterator() *iterator}type Aggregate struct {    list []interface{}}func NewAggregate() aggregateInter {    return &amp;Aggregate{list: make([]interface{}, 0)}}func (a *Aggregate) Add(o interface{}) {    a.list = append(a.list, o)}func (a *Aggregate) Remove() {    a.list = a.list[:len(a.list)-1]}func (a *Aggregate) GetIterator() *iterator {    return NewIterator(a.list)}#===================main.go====================package mainimport &quot;fmt&quot;func main() {    agg := NewAggregate()    agg.Add(&quot;甲&quot;)    agg.Add(&quot;已&quot;)    agg.Add(&quot;丙&quot;)    agg.Add(&quot;丁&quot;)    agg.Remove()    i := agg.GetIterator()    for i.HasNext() {        fmt.Println(i.Next())    }}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 设计模式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>解释器模式</title>
      <link href="/2020/04/29/%E8%A7%A3%E9%87%8A%E5%99%A8%E6%A8%A1%E5%BC%8F/"/>
      <url>/2020/04/29/%E8%A7%A3%E9%87%8A%E5%99%A8%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h2 id="1-模式动机"><a href="#1-模式动机" class="headerlink" title="1 模式动机"></a>1 模式动机</h2><p>给定一个语言，定义它的文法表示，并定义一个解释器，这个解释器使用该标识来解释语言中的句子。</p><p>业务上使用较少</p><h2 id="2-模式定义"><a href="#2-模式定义" class="headerlink" title="2 模式定义"></a>2 模式定义</h2><p>解释器模式（Interpreter Pattern）提供了评估语言的语法或表达式的方式，它属于行为型模式。这种模式实现了一个表达式接口，该接口解释一个特定的上下文。这种模式被用在 SQL 解析、符号处理引擎等。</p><h2 id="3-Demo"><a href="#3-Demo" class="headerlink" title="3 Demo"></a>3 Demo</h2><pre><code class="go">#===================Parse.go====================package mainimport (    &quot;strconv&quot;    &quot;strings&quot;)type Parser struct {    exp   []string    index int    prev  Node}func (p *Parser) Parse(exp string) {    p.exp = strings.Split(exp, &quot; &quot;)    for {        if p.index &gt;= len(p.exp) {            return        }        switch p.exp[p.index] {        case &quot;+&quot;:            p.prev = p.newAddNode()        case &quot;-&quot;:            p.prev = p.newSubNode()        default:            p.prev = p.newValNode()        }    }}func (p *Parser) newAddNode() Node {    p.index++    return &amp;AddNode{p.prev, p.newValNode()}}func (p *Parser) newSubNode() Node {    p.index++    return &amp;SubNode{p.prev, p.newValNode()}}func (p *Parser) newValNode() Node {    v, _ := strconv.Atoi(p.exp[p.index]) //转换类型    p.index++    return &amp;ValNode{v}}func (p *Parser) Result() Node {    return p.prev}#=================Node.go===================package main//节点，返回一个数据type Node interface {    Interpret () int}type ValNode struct {    val int}func (valn *ValNode)Interpret () int {    return valn.val}#=================AddNode.go===================package maintype AddNode struct {    left, right Node}func (a *AddNode) Interpret() int {    return a.left.Interpret() + a.right.Interpret()}#=================SubNode.go===================package maintype SubNode struct {    left, right Node}func (a *SubNode) Interpret() int {    return a.left.Interpret() - a.right.Interpret()}#===================main.go====================package mainimport &quot;fmt&quot;//解释器（Interpreter）模式的定义：给分析对象定义一个语言，并定义该语言的文法表示，//再设计一个解析器来解释语言中的句子。也就是说，//用编译语言的方式来分析应用中的实例。这种模式实现了文法表达式处理的接口，该接口解释一个特定的上下文。func main() {    p := &amp;Parser{}    fmt.Print(&quot;start\n&quot;)    p.Parse(&quot;1 + 3 - 2 + 5 - 6 + 7 + 21&quot;)    fmt.Println(p.Result().Interpret())}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 设计模式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>命令模式</title>
      <link href="/2020/04/29/%E5%91%BD%E4%BB%A4%E6%A8%A1%E5%BC%8F/"/>
      <url>/2020/04/29/%E5%91%BD%E4%BB%A4%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h2 id="1-模式动机"><a href="#1-模式动机" class="headerlink" title="1 模式动机"></a>1 模式动机</h2><p><strong>将一个请求封装成一个对象，从而使您可以用不同的请求对客户进行参数化。</strong></p><p><strong>调用者只关系调用的命令　不用关心调用的接收者</strong></p><h2 id="2-模式定义"><a href="#2-模式定义" class="headerlink" title="2 模式定义"></a>2 模式定义</h2><p>命令模式（Command Pattern）是一种数据驱动的设计模式，它属于行为型模式。请求以命令的形式包裹在对象中，并传给调用对象。调用对象寻找可以处理该命令的合适的对象，并把该命令传给相应的对象，该对象执行命令。</p><h2 id="3-Demo"><a href="#3-Demo" class="headerlink" title="3 Demo"></a>3 Demo</h2><pre><code class="go">#===================Command.go====================package maintype ReceiverInter interface {    action()}type InvokerInter interface {    setCommand(inter commandInter)    call()}type commandInter interface {    execute()}type command struct {    receiver Receiver}func NewCommand() *command {    receiver := Receiver{}    c := &amp;command{}    c.receiver = receiver    return c}func (c *command) execute() {    c.receiver.action()}#=================Invoker.go===================package maintype Invoker struct {    command commandInter}func NewInvoker() *Invoker {    return &amp;Invoker{}}func (i *Invoker) setCommand(command commandInter) {    i.command = command}func (i *Invoker) call() () {    i.command.execute()}#===================Receiver.go====================package mainimport &quot;fmt&quot;type Receiver struct {}func (r *Receiver) action() {    fmt.Print(&quot;Receiver action&quot;)}#===================main.go====================package mainfunc main()  {    invoker := NewInvoker()    command := NewCommand()    invoker.setCommand(command)    invoker.call()}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 设计模式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>责任链模式</title>
      <link href="/2020/04/29/%E8%B4%A3%E4%BB%BB%E9%93%BE%E6%A8%A1%E5%BC%8F/"/>
      <url>/2020/04/29/%E8%B4%A3%E4%BB%BB%E9%93%BE%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h2 id="1-模式动机"><a href="#1-模式动机" class="headerlink" title="1 模式动机"></a>1 模式动机</h2><p><strong>避免请求发送者与接收者耦合在一起</strong>，让多个对象都有可能接收请求，将这些对象连接成一条链，并且沿着这条链传递请求，直到有对象处理它为止。</p><p><strong>在不明确指定接收者的情况下，向多个对象中的一个提交一个请求</strong></p><h2 id="2-模式定义"><a href="#2-模式定义" class="headerlink" title="2 模式定义"></a>2 模式定义</h2><p>顾名思义，责任链模式（Chain of Responsibility Pattern）为请求创建了一个接收者对象的链。这种模式给予请求的类型，对请求的发送者和接收者进行解耦。这种类型的设计模式属于行为型模式。</p><p>在这种模式中，通常每个接收者都包含对另一个接收者的引用。如果一个对象不能处理该请求，那么它会把相同的请求传给下一个接收者，依此类推。</p><h2 id="3-Demo"><a href="#3-Demo" class="headerlink" title="3 Demo"></a>3 Demo</h2><pre><code class="go">#===================Handler.go====================package mainimport &quot;fmt&quot;type handlerInter interface {    setNext(handler handlerInter)    getNext() handlerInter    handleRequest(request int)}type handlerBase struct {    next handlerInter}func (h *handlerBase) setNext(base handlerInter) {    h.next = base}func (h *handlerBase) getNext() handlerInter {    return h.next}func (h *handlerBase) handleRequest(request int) {}type AHandler struct {    handlerBase}func (h *AHandler) handleRequest(request int) {    if request &lt; 100 {        fmt.Println(&quot;AHandler 处理了请求&quot;)        return    }    if h.getNext() != nil {        h.getNext().handleRequest(request)        return    }    fmt.Println(&quot;没有人能处理该请求&quot;)}type BHandler struct {    handlerBase}func (h *BHandler) handleRequest(request int) {    if request &lt; 200 {        fmt.Println(&quot;BHandler 处理了请求&quot;)        return    }    if h.getNext() != nil {        h.getNext().handleRequest(request)        return    }    fmt.Println(&quot;没有人能处理该请求&quot;)}#===================main.go====================package mainfunc main()  {    ha := new(AHandler)    hb := new(BHandler)    ha.setNext(hb)    ha.handleRequest(100)}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 设计模式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>组合模式</title>
      <link href="/2020/04/28/%E7%BB%84%E5%90%88%E6%A8%A1%E5%BC%8F/"/>
      <url>/2020/04/28/%E7%BB%84%E5%90%88%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h2 id="1-模式动机"><a href="#1-模式动机" class="headerlink" title="1 模式动机"></a>1 模式动机</h2><p><strong>使用场景：部分、整体场景，如树形菜单，文件、文件夹的管理。</strong></p><h2 id="2-模式定义"><a href="#2-模式定义" class="headerlink" title="2 模式定义"></a>2 模式定义</h2><p>组合模式（Composite Pattern），又叫部分整体模式，是用于把一组相似的对象当作一个单一的对象。组合模式依据树形结构来组合对象，用来表示部分以及整体层次。这种类型的设计模式属于结构型模式，它创建了对象组的树形结构。</p><p>这种模式创建了一个包含自己对象组的类。该类提供了修改相同对象组的方式。</p><h2 id="3-Demo"><a href="#3-Demo" class="headerlink" title="3 Demo"></a>3 Demo</h2><pre><code class="go">#=================Composite.go===================package mainimport &quot;fmt&quot;type Composite struct {    component    children []Component //叶子集合}//创建一个组合结构体func NewComposite() *Composite {    return &amp;Composite{children: make([]Component, 0)}}func (c *Composite) AddChild(child Component) {    child.SetParent(c)    c.children = append(c.children, child) //加入孩子节点}func (c *Composite) Print(pre string) { //打印显示每一个节点    fmt.Println(pre, c.name)    pre += &quot;  &quot;    for _, leaf := range c.children {        leaf.Print(pre)    }}#===================Component.go====================package main//有的时候是父节点，叶子type Component interface {    Parent() Component    SetParent(Component)    Name() string    SetName(string)    AddChild(Component)    Print(string)}const (    LeafNode = iota    CompositeNode)type component struct {    parent Component    name   string}func NewComponent(kind int, name string) Component {    var c Component    switch kind {    case LeafNode: //根据不同的类型        c = NewLeaf()    case CompositeNode:        c = NewComposite()    }    c.SetName(name)    return c}func (c *component) Parent() Component {    return c.parent}func (c *component) SetParent(parent Component) {    c.parent = parent}func (c *component) Name() string {    return c.name}func (c *component) SetName(name string) {    c.name = name}func (c *component) AddChild(Component) {}func (c *component) Print(string) {}#===================leaf.go====================package mainimport &quot;fmt&quot;type Leaf struct {    component}func NewLeaf() *Leaf { //开辟一个叶子    return &amp;Leaf{}}func (c *Leaf) Print(pre string) {    fmt.Println(pre, c.Name())}#===================main.go====================package main//组合（Composite）模式的定义：有时又叫作部分-整体模式，//它是一种将对象组合成树状的层次结构的模式，用来表示“部分-整体”的关系，//使用户对单个对象和组合对象具有一致的访问性。//组合模式包含以下主要角色。//抽象构件（Component）角色：它的主要作用是为树叶构件和树枝构件声明公共接口，并实现它们的默认行为。在透明式的组合模式中抽象构件还声明访问和管理子类的接口；在安全式的组合模式中不声明访问和管理子类的接口，管理工作由树枝构件完成。//树叶构件（Leaf）角色：是组合中的叶节点对象，它没有子节点，用于实现抽象构件角色中 声明的公共接口。//树枝构件（Composite）角色：是组合中的分支节点对象，它有子节点。它实现了抽象构件角色中声明的接口，它的主要作用是存储和管理子部件，通常包含 Add()、Remove()、GetChild() 等方法。func main()  {    root := NewComponent(CompositeNode,&quot;root&quot;)    l1 := NewComponent(LeafNode,&quot;l1&quot;)    l2 := NewComponent(LeafNode,&quot;l2&quot;)    l3 := NewComponent(LeafNode,&quot;l3&quot;)    l4 := NewComponent(CompositeNode,&quot;l4&quot;)    ll1 := NewComponent(LeafNode,&quot;ll1&quot;)    ll2 := NewComponent(LeafNode,&quot;ll2&quot;)    ll3 := NewComponent(LeafNode,&quot;ll3&quot;)    root.AddChild(l1)    root.AddChild(l2)    root.AddChild(l3)    root.AddChild(l4)    l4.AddChild(ll1)    l4.AddChild(ll2)    l4.AddChild(ll3)    root.Print(&quot;&quot;)}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 设计模式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>享元模式</title>
      <link href="/2020/04/28/%E4%BA%AB%E5%85%83%E6%A8%A1%E5%BC%8F/"/>
      <url>/2020/04/28/%E4%BA%AB%E5%85%83%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h2 id="1-模式动机"><a href="#1-模式动机" class="headerlink" title="1 模式动机"></a>1 模式动机</h2><p>面向对象技术可以很好地解决一些灵活性或可扩展性问题，但在很多情况下需要在系统中增加类和对象的个数。当对象数量太多时，将导致运行代价过高，带来性能下降等问题。</p><ul><li>享元模式正是为解决这一类问题而诞生的。<strong>享元模式通过共享技术实现相同或相似对象的重用</strong>。</li><li>在享元模式中可以共享的相同内容称为内部状态(IntrinsicState)，而那些需要外部环境来设置的不能共享的内容称为外部状态(Extrinsic State)，由于区分了内部状态和外部状态，因此可以通过设置不同的外部状态使得相同的对象可以具有一些不同的特征，而相同的内部状态是可以共享的。</li><li><strong>在享元模式中通常会出现工厂模式，需要创建一个享元工厂来负责维护一个享元池(Flyweight Pool)用于存储具有相同内部状态的享元对象</strong>。</li><li>在享元模式中共享的是享元对象的内部状态，外部状态需要通过环境来设置。在实际使用中，能够共享的内部状态是有限的，因此享元对象一般都设计为较小的对象，它所包含的内部状态较少，这种对象也称为细粒度对象。享元模式的目的就是使用共享技术来实现大量细粒度对象的复用。</li></ul><h2 id="2-模式定义"><a href="#2-模式定义" class="headerlink" title="2 模式定义"></a>2 模式定义</h2><p>享元模式(Flyweight Pattern)：运用共享技术有效地支持大量细粒度对象的复用。系统只使用少量的对象，而这些对象都很相似，状态变化很小，可以实现对象的多次复用。由于享元模式要求能够共享的对象必须是细粒度对象，因此它又称为轻量级模式，它是一种对象结构型模式。</p><h2 id="3-Demo"><a href="#3-Demo" class="headerlink" title="3 Demo"></a>3 Demo</h2><pre><code class="go">#===================ImageFlyWeightFactory.go====================package mainimport &quot;sync&quot;type ImageFlyWeightFactory struct {    maps map[string]*ImageFlyWeight}var imageFlyWeightFactory *ImageFlyWeightFactoryvar mux sync.Oncefunc NewImageFlyWeightFactory() *ImageFlyWeightFactory {    mux.Do(func() {        imageFlyWeightFactory = &amp;ImageFlyWeightFactory{maps: make(map[string]*ImageFlyWeight)}    })    return imageFlyWeightFactory}func (imf *ImageFlyWeightFactory) Get(filename string) *ImageFlyWeight {    image := imf.maps[filename]    if image == nil {        image = NewImageFlyWeight(filename)        imf.maps[filename] = image    }    return image}func (imf *ImageFlyWeightFactory) GetMapCount() int {    return len(imf.maps)}#=================ImageFlyWeight.go===================package maintype ImageFlyWeight struct {    data string}func NewImageFlyWeight(filename string) *ImageFlyWeight {    return &amp;ImageFlyWeight{data: filename}}func (imw *ImageFlyWeight) GetData() string {    return imw.data}#===================main.go====================package mainimport &quot;fmt&quot;//运用共享技术来有効地支持大量细粒度对象的复用。它通过共享已经存在的对象来大幅度减少需要创建的对象数量、//避免大量相似类的开销，从而提高系统资源的利用率。func main()  {    imf := NewImageFlyWeightFactory()    f1 := imf.Get(&quot;fA&quot;)    fmt.Println(imf.GetMapCount())    imf.Get(&quot;fB&quot;)    fmt.Println(imf.GetMapCount())    f3 := imf.Get(&quot;fA&quot;)    fmt.Println(imf.GetMapCount())    if f1 == f3{        println(&quot;没有消耗多余内存&quot;)    }}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 设计模式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>外观模式</title>
      <link href="/2020/04/28/%E5%A4%96%E8%A7%82%E6%A8%A1%E5%BC%8F/"/>
      <url>/2020/04/28/%E5%A4%96%E8%A7%82%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h2 id="1-模式动机"><a href="#1-模式动机" class="headerlink" title="1 模式动机"></a>1 模式动机</h2><p><strong>建造者模式的目的是希望用同样的生产过程，根据不同的生产者得到不同的产品。</strong><br><strong>外观模式是将多个对象组合起来，它不需要生产者，也不需要得到不同的结果。</strong></p><h2 id="2-模式定义"><a href="#2-模式定义" class="headerlink" title="2 模式定义"></a>2 模式定义</h2><p>外观模式(Facade Pattern)：外部与一个子系统的通信必须通过一个统一的外观对象进行，为子系统中的一组接口提供一个一致的界面，外观模式定义了一个高层接口，这个接口使得这一子系统更加容易使用。外观模式又称为门面模式，它是一种对象结构型模式。</p><h2 id="3-Demo"><a href="#3-Demo" class="headerlink" title="3 Demo"></a>3 Demo</h2><pre><code class="go">#===================Facade.go====================package maintype Facade struct {    Japanese *Japanese    Chinese  *Chinese    English  *English}func NewFacade() *Facade {    Japanese := new(Japanese)    Chinese := new(Chinese)    English := new(English)    return &amp;Facade{        Japanese: Japanese,        Chinese:  Chinese,        English:  English,    }}func (f *Facade) SayHello() {    f.Chinese.SayHello()    f.Japanese.SayHello()    f.English.SayHello()}#=================SubSystem.go===================package mainimport &quot;fmt&quot;type Chinese struct {}func (c *Chinese) SayHello() {    fmt.Println(&quot;你好&quot;)}type Japanese struct {}func (j *Japanese) SayHello() {    fmt.Println(&quot;库尼奇瓦&quot;)}type English struct {}func (e *English) SayHello() {    fmt.Println(&quot;Hello&quot;)}#===================main.go====================package main//外观（Facade）模式的定义：是一种通过为多个复杂的子系统提供一个一致的接口，//而使这些子系统更加容易被访问的模式。该模式对外有一个统一接口，//外部应用程序不用关心内部子系统的具体的细节，//这样会大大降低应用程序的复杂度，提高了程序的可维护性。//建造者模式的目的是希望用同样的生产过程，根据不同的生产者得到不同的产品。//外观模式是将多个对象组合起来，它不需要生产者，也不需要得到不同的结果。func main() {    f := NewFacade()    f.SayHello()}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 设计模式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>装饰模式</title>
      <link href="/2020/04/28/%E8%A3%85%E9%A5%B0%E6%A8%A1%E5%BC%8F/"/>
      <url>/2020/04/28/%E8%A3%85%E9%A5%B0%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h2 id="1-模式动机"><a href="#1-模式动机" class="headerlink" title="1 模式动机"></a>1 模式动机</h2><p>一般有两种方式可以实现给一个类或对象增加行为：</p><ul><li>继承机制，使用继承机制是给现有类添加功能的一种有效途径，通过继承一个现有类可以使得子类在拥有自身方法的同时还拥有父类的方法。但是这种方法是静态的，用户不能控制增加行为的方式和时机。</li><li><strong>关联机制，即将一个类的对象嵌入另一个对象中，由另一个对象来决定是否调用嵌入对象的行为以便扩展自己的行为，我们称这个嵌入的对象为装饰器(Decorator)</strong></li></ul><p>装饰模式以对客户透明的方式动态地给一个对象附加上更多的责任，换言之，客户端并不会觉得对象在装饰前和装饰后有什么不同。<strong>装饰模式可以在不需要创造更多子类的情况下，将对象的功能加以扩展</strong>。这就是装饰模式的模式动机。</p><h2 id="2-模式定义"><a href="#2-模式定义" class="headerlink" title="2 模式定义"></a>2 模式定义</h2><p>装饰模式(Decorator Pattern) ：动态地给一个对象增加一些额外的职责(Responsibility)，就增加对象功能来说，装饰模式比生成子类实现更为灵活。其别名也可以称为包装器(Wrapper)，与适配器模式的别名相同，但它们适用于不同的场合。根据翻译的不同，装饰模式也有人称之为“油漆工模式”，它是一种对象结构型模式。</p><h2 id="3-Demo"><a href="#3-Demo" class="headerlink" title="3 Demo"></a>3 Demo</h2><pre><code class="go">#===================Component.go====================package mainimport &quot;fmt&quot;type CarInter interface {    Run()}type Car struct {}func (c *Car) Run() {    fmt.Print(&quot;行驶&quot;)}#=================Decorator.go===================package mainimport &quot;fmt&quot;type DecoCar struct {    car Car}func NewDecoCar() *DecoCar {    return new(DecoCar)}func (d *DecoCar) Run() {    fmt.Print(&quot;加速&quot;)    d.car.Run()}#===================main.go====================package main//为让自己的能力增强，使得增强后的自己能够使用更多的方法，拓展在自己基础之上的功能的，就是装饰器模式//让别人帮助你做你并不关心的事情，这是代理模式func main() {    d := NewDecoCar()    d.Run()}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 设计模式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>代理模式</title>
      <link href="/2020/04/27/%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F/"/>
      <url>/2020/04/27/%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h2 id="1-模式动机"><a href="#1-模式动机" class="headerlink" title="1 模式动机"></a>1 模式动机</h2><p>在某些情况下，一个客户不想或者不能直接引用一个对 象，此时可以通过一个称之为“代理”的第三者来实现 间接引用。<strong>代理对象可以在客户端和目标对象之间起到 中介的作用，并且可以通过代理对象去掉客户不能看到 的内容和服务或者添加客户需要的额外服务</strong>。</p><p>通过引入一个新的对象（如小图片和远程代理 对象）来实现对真实对象的操作或者将新的对 象作为真实对象的一个替身，这种实现机制即 为代理模式，通过引入代理对象来间接访问一 个对象，这就是代理模式的模式动机。</p><h2 id="2-模式定义"><a href="#2-模式定义" class="headerlink" title="2 模式定义"></a>2 模式定义</h2><p>代理模式(Proxy Pattern) ：给某一个对象提供一个代 理，并由代理对象控制对原对象的引用。代理模式的英 文叫做Proxy或Surrogate，它是一种对象结构型模式。</p><h2 id="3-Demo"><a href="#3-Demo" class="headerlink" title="3 Demo"></a>3 Demo</h2><pre><code class="go">#===================Origin.go====================package mainimport &quot;fmt&quot;type Origin struct {}func NewOrigin() *Origin {    return new(Origin)}func (o *Origin) Request() {    fmt.Println(&quot;Origin Request Method&quot;)}#=================Proxy.go===================package mainimport &quot;fmt&quot;type Proxy struct {    origin *Origin}func NewProxy() *Proxy {    origin := NewOrigin()    return &amp;Proxy{origin: origin}}func (p *Proxy) Request() {    p.PreRequest()    p.origin.Request()    p.PostRequest()}func (p *Proxy) PreRequest() {    fmt.Println(&quot;Proxy PreRequest&quot;)}func (p *Proxy) PostRequest() {    fmt.Println(&quot;Proxy PostRequest&quot;)}#===================main.go====================package main//代理模式的定义：由于某些原因需要给某对象提供一个代理以控制对该对象的访问//这时，访问对象不适合或者不能直接引用目标对象，代理对象作为访问对象和目标对象之间的中介。//相比于适配器的应用场景，代理就不一样了，虽然代理也同样是增加了一层//但是，代理提供的接口和原本的接口是一样的，代理模式的作用是不把实现直接暴露给client//而是通过代理这个层，代理能够做一些处理；func main()  {    p := NewProxy()    p.Request()}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 设计模式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>桥接模式</title>
      <link href="/2020/04/27/%E6%A1%A5%E6%8E%A5%E6%A8%A1%E5%BC%8F/"/>
      <url>/2020/04/27/%E6%A1%A5%E6%8E%A5%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h2 id="1-模式动机"><a href="#1-模式动机" class="headerlink" title="1 模式动机"></a>1 模式动机</h2><p>设想如果要绘制矩形、圆形、椭圆、正方形，我们至少需要4个形状类，但是如果绘制的图形需要具有不同的颜色，如红色、绿色、蓝色等，此时至少有如下两种设计方案：</p><ul><li>第一种设计方案是为每一种形状都提供一套各种颜色的版本。</li><li>第二种设计方案是<strong>根据实际需要对形状和颜色进行组合</strong></li></ul><p>对于有两个变化维度（即两个变化的原因）的系统，采用方案二来进行设计系统中类的个数更少，且系统扩展更为方便。设计方案二即是桥接模式的应用。桥接模式将继承关系转换为关联关系，从而降低了类与类之间的耦合，减少了代码编写量。</p><h2 id="2-模式定义"><a href="#2-模式定义" class="headerlink" title="2 模式定义"></a>2 模式定义</h2><p>桥接模式(Bridge Pattern)：将抽象部分与它的实现部分分离，使它们都可以独立地变化。它是一种对象结构型模式，又称为柄体(Handle and Body)模式或接口(Interface)模式。</p><h2 id="3-Demo"><a href="#3-Demo" class="headerlink" title="3 Demo"></a>3 Demo</h2><pre><code class="go">#===================Species.go====================package maintype Animal interface {    SayHi()}type Color interface {    SayColor()}type Size interface {    SaySize()}type Species struct {    animal Animal    color  Color    size   Size}func NewSpecies() *Species {    return new(Species)}func (s *Species) SetAnimal(animal Animal) {    s.animal = animal}func (s *Species) SetColor(color Color) {    s.color = color}func (s *Species) SetSize(size Size) {    s.size = size}func (s *Species) show() {    s.animal.SayHi()    s.color.SayColor()    s.size.SaySize()}#=================Animal.go===================package mainimport &quot;fmt&quot;type Dog struct {}func (d *Dog) SayHi() {    fmt.Print(&quot;我是一只狗&quot;)}type Cat struct {}func (c *Cat) SayHi() {    fmt.Print(&quot;我是一只猫&quot;)}#=================Color.go===================package mainimport &quot;fmt&quot;type Red struct {}func (r *Red) SayColor() {    fmt.Print(&quot;我的颜色是红色&quot;)}type Black struct {}func (b *Black) SayColor() {    fmt.Print(&quot;我的颜色是黑色&quot;)}#=================Size.go===================package mainimport &quot;fmt&quot;type Big struct {}func (b *Big) SaySize() {    fmt.Print(&quot;我是个大号的&quot;)}type Small struct {}func (s *Small) SaySize() {    fmt.Print(&quot;我是个小号的&quot;)}#===================main.go====================package main//桥接（Bridge）模式的定义如下：将抽象与实现分离，使它们可以独立变化。//它是用组合关系代替继承关系来实现，从而降低了抽象和实现这两个可变维度的耦合度func main() {    color := new(Red)    size := new(Big)    animal := new(Dog)    species := NewSpecies()    species.SetAnimal(animal)    species.SetColor(color)    species.SetSize(size)    species.show()}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 设计模式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>适配器模式</title>
      <link href="/2020/04/27/%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F/"/>
      <url>/2020/04/27/%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h2 id="1-模式动机"><a href="#1-模式动机" class="headerlink" title="1 模式动机"></a>1 模式动机</h2><ul><li>在软件开发中采用类似于电源适配器的设计和编码技巧被称为适配器模式。</li><li>通常情况下，客户端可以通过目标类的接口访问它所提供的服务。有时，现有的类可以满足客户类的功能需要，但是它所提供的接口不一定是客户类所期望的，这可能是因为现有类中方法名与目标类中定义的方法名不一致等原因所导致的。</li><li>在这种情况下，现有的接口需要转化为客户类期望的接口，这样保证了对现有类的重用。如果不进行这样的转化，客户类就不能利用现有类所提供的功能，适配器模式可以完成这样的转化。</li><li><strong>在适配器模式中可以定义一个包装类，包装不兼容接口的对象</strong>，这个包装类指的就是适配器(Adapter)，它所包装的对象就是适配者(Adaptee)，即被适配的类。</li><li>适配器提供客户类需要的接口，适配器的实现就是把客户类的请求转化为对适配者的相应接口的调用。也就是说：当客户类调用适配器的方法时，在适配器类的内部将调用适配者类的方法，而这个过程对客户类是透明的，客户类并不直接访问适配者类。因此，适配器可以使由于接口不兼容而不能交互的类可以一起工作。这就是适配器模式的模式动机。</li></ul><h2 id="2-模式定义"><a href="#2-模式定义" class="headerlink" title="2 模式定义"></a>2 模式定义</h2><p>适配器模式(Adapter Pattern) ：将一个接口转换成客户希望的另一个接口，适配器模式使接口不兼容的那些类可以一起工作，其别名为包装器(Wrapper)。适配器模式既可以作为类结构型模式，也可以作为对象结构型模式。</p><h2 id="3-Demo"><a href="#3-Demo" class="headerlink" title="3 Demo"></a>3 Demo</h2><pre><code class="go">#===================SMS.go====================package mainimport &quot;fmt&quot;type SMS struct {    context  string    sender   string    receiver string}func NewSMS(context string, sender string, receiver string) *SMS {    return &amp;SMS{        context:  context,        sender:   sender,        receiver: receiver,    }}func (s *SMS) SendSms() {    fmt.Println(s.sender + &quot; send to &quot; + s.receiver + &quot; message:&quot; + s.context)}#=================AdapterSMS.go===================package maintype AdapterSMS struct {    context  string    receiver string}func NewAdapterSMS(context string, receiver string) *SMS {    sender := &quot;Default sender&quot;    return NewSMS(context, sender, receiver)}#===================main.go====================package main//适配器模式（Adapter):将一个类的接口转换成客户希望的另外一个接口//使得原本由于接口不兼容而不能一起工作的那些类能一起工作func main() {    sms := NewAdapterSMS(&quot;你好北京&quot;, &quot;北京土著&quot;)    sms.SendSms()}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 设计模式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>建造者模式</title>
      <link href="/2020/04/26/%E5%BB%BA%E9%80%A0%E8%80%85%E6%A8%A1%E5%BC%8F/"/>
      <url>/2020/04/26/%E5%BB%BA%E9%80%A0%E8%80%85%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h2 id="1-模式动机"><a href="#1-模式动机" class="headerlink" title="1 模式动机"></a>1 模式动机</h2><p>无论是在现实世界中还是在软件系统中，都存在一些复杂的对象，它们拥有多个组成部分，如汽车，它包括车轮、方向盘、发送机等各种部件。而对于大多数用户而言，无须知道这些部件的装配细节，也几乎不会使用单独某个部件，而是使用一辆完整的汽车，可以通过建造者模式对其进行设计与描述，建造者模式可以将部件和其组装过程分开，一步一步创建一个复杂的对象。用户只需要指定复杂对象的类型就可以得到该对象，而无须知道其内部的具体构造细节。</p><p>在软件开发中，也存在大量类似汽车一样的复杂对象，它们拥有一系列成员属性，这些成员属性中有些是引用类型的成员对象。而且在这些复杂对象中，还可能存在一些限制条件，如某些属性没有赋值则复杂对象不能作为一个完整的产品使用；有些属性的赋值必须按照某个顺序，一个属性没有赋值之前，另一个属性可能无法赋值等。</p><p>复杂对象相当于一辆有待建造的汽车，而对象的属性相当于汽车的部件，建造产品的过程就相当于组合部件的过程。<strong>由于组合部件的过程很复杂，因此，这些部件的组合过程往往被“外部化”到一个称作建造者的对象里，建造者返还给客户端的是一个已经建造完毕的完整产品对象，而用户无须关心该对象所包含的属性以及它们的组装方式，这就是建造者模式的模式动机</strong>。</p><h2 id="2-模式定义"><a href="#2-模式定义" class="headerlink" title="2 模式定义"></a>2 模式定义</h2><p>造者模式(Builder Pattern)：将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。</p><p>建造者模式是一步一步创建一个复杂的对象，它允许用户只通过指定复杂对象的类型和内容就可以构建它们，用户不需要知道内部的具体构建细节。建造者模式属于对象创建型模式。根据中文翻译的不同，建造者模式又可以称为生成器模式。</p><h2 id="3-Demo"><a href="#3-Demo" class="headerlink" title="3 Demo"></a>3 Demo</h2><pre><code class="go">#===================Builder.go====================package maintype Builder interface {    NewProduct()    BuildWheels()    BuildChassis()    BuildSeat()    GetResult() interface{}}#=================BusBuilder.go===================package mainimport &quot;fmt&quot;type Bus struct {    Wheels  string    Chassis string    Seat    string}func (b *Bus) Show() {    fmt.Println(b.Wheels + &quot;---&quot; + b.Chassis + &quot;---&quot; + b.Seat)}type BusBuilder struct {    bus *Bus}func (bb *BusBuilder) NewProduct() {    bb.bus = new(Bus)}func (bb *BusBuilder) BuildWheels() {    bb.bus.Wheels = &quot;Bus Wheels&quot;}func (bb *BusBuilder) BuildChassis() {    bb.bus.Chassis = &quot;Bus Chassis&quot;}func (bb *BusBuilder) BuildSeat() {    bb.bus.Seat = &quot;Bus Seat&quot;}func (bb *BusBuilder) GetResult() interface{} {    return bb.bus}#==================Director.go====================package maintype Director struct {    builder Builder}func (d *Director) SetBuilder(builder Builder) {    d.builder = builder}func (d *Director) Generate() interface{} {    d.builder.NewProduct()    d.builder.BuildWheels()    d.builder.BuildChassis()    d.builder.BuildSeat()    return d.builder.GetResult()}#===================main.go====================package mainfunc main() {    director := new(Director)    builder := new(BusBuilder)    director.SetBuilder(builder)    bus := director.Generate().(*Bus)    bus.Show()}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 设计模式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>原型模式</title>
      <link href="/2020/04/26/%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F/"/>
      <url>/2020/04/26/%E5%8E%9F%E5%9E%8B%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h2 id="1-模式动机"><a href="#1-模式动机" class="headerlink" title="1 模式动机"></a>1 模式动机</h2><p>这是一个十分简单的设计模式,<strong>可以看做是其他语言中的克隆方法</strong><br>例如 JAVA/PHP 中都有相关方法，从一个内存中已经存在的对象中，<br>拷贝出一个一模一样的对象来，针对复杂对象或比较大的对象，要比使用各种设计模式new出来的对象要快的多<br><strong>相当于对原始对象进行深拷贝</strong></p><p>这种模式是实现了一个原型接口，该接口用于创建当前对象的克隆。当直接创建对象的代价比较大时，则采用这种模式。例如，一个对象需要在一个高代价的数据库操作之后被创建。我们可以缓存该对象，在下一个请求时返回它的克隆，在需要的时候更新数据库，以此来减少数据库调用。</p><h2 id="2-模式定义"><a href="#2-模式定义" class="headerlink" title="2 模式定义"></a>2 模式定义</h2><p>原型模式（Prototype Pattern）是用于创建重复的对象，同时又能保证性能。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。</p><h2 id="3-Demo"><a href="#3-Demo" class="headerlink" title="3 Demo"></a>3 Demo</h2><pre><code class="go">#===================Prototype.go====================package maintype Example struct {    name string}func (e *Example) clone() *Example {    cloneExample := *e    return &amp;cloneExample}#===================main.go====================package mainimport &quot;fmt&quot;//这是一个十分简单的设计模式,可以看做是其他语言中的克隆方法，//例如 JAVA/PHP 中都有相关方法，从一个内存中已经存在的对象中，//拷贝出一个一模一样的对象来，针对复杂对象或比较大的对象，要比使用各种设计模式new出来的对象要快的多//深拷贝func main() {    t1 := new(Example)    t1.name = &quot;t1&quot;    t2 := t1.clone()    fmt.Printf(&quot;type t1 = %T\n&quot;, t1)    fmt.Printf(&quot;type t2 = %T\n&quot;, t2)    fmt.Printf(&quot;type t1 = %p\n&quot;, t1)    fmt.Printf(&quot;type t1 = %p\n&quot;, t2)    fmt.Println(t1.name)    fmt.Println(t2.name)    if t1 == t2 {        fmt.Println(&quot;浅拷贝&quot;)    } else {        fmt.Println(&quot;深拷贝&quot;)    }}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 设计模式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>单例模式</title>
      <link href="/2020/04/26/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/"/>
      <url>/2020/04/26/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h2 id="1-模式动机"><a href="#1-模式动机" class="headerlink" title="1 模式动机"></a>1 模式动机</h2><p>对于系统中的某些类来说，只有一个实例很重要，例如，一个系统中可以存在多个打印任务，但是只能有一个正在工作的任务；一个系统只能有一个窗口管理器或文件系统；一个系统只能有一个计时工具或ID（序号）生成器。</p><p>如何保证一个类只有一个实例并且这个实例易于被访问呢？定义一个全局变量可以确保对象随时都可以被访问，但不能防止我们实例化多个对象。</p><p><strong>一个更好的解决办法是让类自身负责保存它的唯一实例。这个类可以保证没有其他实例被创建，并且它可以提供一个访问该实例的方法。这就是单例模式的模式动机。</strong></p><h2 id="2-模式定义"><a href="#2-模式定义" class="headerlink" title="2 模式定义"></a>2 模式定义</h2><p>单例模式(Singleton Pattern)：单例模式确保某一个类只有一个实例，而且自行实例化并向整个系统提供这个实例，这个类称为单例类，它提供全局访问的方法。</p><p>单例模式的要点有三个：<strong>一是某个类只能有一个实例；二是它必须自行创建这个实例；三是它必须自行向整个系统提供这个实例</strong>。单例模式是一种对象创建型模式。单例模式又名单件模式或单态模式。</p><h2 id="3-Demo"><a href="#3-Demo" class="headerlink" title="3 Demo"></a>3 Demo</h2><pre><code class="go">#===================Singleton.go====================package mainimport &quot;sync&quot;type Single struct {    data int}var singleton *Singlevar once sync.Oncevar mux sync.Mutex//最好func GetInstance() *Single {    once.Do(func() {        singleton = &amp;Single{data: 100}    })    return singleton}//次好 双重检查机制func GetInstance2() *Single {    if singleton == nil {        mux.Lock()        defer mux.Unlock()        if singleton == nil {            singleton = new(Single)            singleton.data = 100        }    }    return singleton}//最差 并发下有问题func GetInstance3() *Single {    if singleton == nil {        singleton = new(Single)        singleton.data = 100    }    return singleton}#===================main.go====================package mainimport &quot;fmt&quot;func main() {    t11 := GetInstance()    t12 := GetInstance()    t21 := GetInstance2()    t22 := GetInstance2()    t31 := GetInstance3()    t32 := GetInstance3()    if t11 == t12 {        fmt.Println(&quot;相等&quot;)    } else {        fmt.Println(&quot;不相等&quot;)    }    if t21 == t22 {        fmt.Println(&quot;相等&quot;)    } else {        fmt.Println(&quot;不相等&quot;)    }    if t31 == t32 {        fmt.Println(&quot;相等&quot;)    } else {        fmt.Println(&quot;不相等&quot;)    }}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 设计模式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>抽象工厂模式</title>
      <link href="/2020/04/24/%E6%8A%BD%E8%B1%A1%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F/"/>
      <url>/2020/04/24/%E6%8A%BD%E8%B1%A1%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h2 id="1-模式动机"><a href="#1-模式动机" class="headerlink" title="1 模式动机"></a>1 模式动机</h2><p><strong>抽象工厂模式与工厂方法模式最大的区别在于，工厂方法模式针对的是一个产品等级结构，而抽象工厂模式则需要面对多个产品等级结构，一个工厂等级结构可以负责多个不同产品等级结构中的产品对象的创建</strong> 。当一个工厂等级结构可以创建出分属于不同产品等级结构的一个产品族中的所有对象时，抽象工厂模式比工厂方法模式更为简单、有效率。</p><p><strong>工厂模式只创建一种产品,抽象工厂创建多种产品</strong></p><h2 id="2-模式定义"><a href="#2-模式定义" class="headerlink" title="2 模式定义"></a>2 模式定义</h2><p>抽象工厂模式(Abstract Factory Pattern)：提供一个创建一系列相关或相互依赖对象的接口，而无须指定它们具体的类。抽象工厂模式又称为Kit模式，属于对象创建型模式。</p><h2 id="3-Demo"><a href="#3-Demo" class="headerlink" title="3 Demo"></a>3 Demo</h2><pre><code class="go">#===================AbstractFactory.go====================package mainconst (    DELL = iota    HP)type KeyBoInter interface {    SayHi()}type MouseInter interface {    SayHi()}type PcFactoryInter interface {    CreateMouse() MouseInter    CreateKeyBo() KeyBoInter}#===================DellFactory.go====================package maintype DellKeyBo struct {}func (dell *DellKeyBo) SayHi() {    println(&quot;DellKeyBo&quot;)}type DellMouse struct {}func (dell *DellMouse) SayHi() {    println(&quot;DellMouse&quot;)}type DellFactory struct {}func (df *DellFactory) CreateMouse() MouseInter {    return new(DellMouse)}func (df *DellFactory) CreateKeyBo() KeyBoInter {    return new(DellKeyBo)}#===================HpFactory.go====================package maintype HpKeyBo struct {}func (hp *HpKeyBo) SayHi() {    println(&quot;HpKeyBo&quot;)}type HpMouse struct {}func (hp *HpMouse) SayHi() {    println(&quot;HpMouse&quot;)}type HpFactory struct {}func (hf *HpFactory) CreateMouse() MouseInter {    return new(HpMouse)}func (hf *HpFactory) CreateKeyBo() KeyBoInter {    return new(HpKeyBo)}#===================main.go====================package main//抽象工厂模式//提供一个创建一系列相关或相互以来的对象的接口//当产品只有一个的时候抽象工厂模式变成工厂模式//当工厂模式的产品变为多个的时,工厂模式变为抽象工厂模式func main()  {    var pcFactory PcFactoryInter    pcFactory = new(HpFactory)    pcFactory.CreateMouse().SayHi()    pcFactory.CreateKeyBo().SayHi()    pcFactory = new(DellFactory)    pcFactory.CreateMouse().SayHi()    pcFactory.CreateKeyBo().SayHi()}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 设计模式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>普通工厂模式</title>
      <link href="/2020/04/24/%E6%99%AE%E9%80%9A%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F/"/>
      <url>/2020/04/24/%E6%99%AE%E9%80%9A%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h2 id="1-模式动机"><a href="#1-模式动机" class="headerlink" title="1 模式动机"></a>1 模式动机</h2><p>现在对该系统进行修改，<strong>不再设计一个按钮工厂类来统一负责所有产品的创建，而是将具体按钮的创建过程交给专门的工厂子类去完成</strong>，我们先定义一个抽象的按钮工厂类，再定义具体的工厂类来生成圆形按钮、矩形按钮、菱形按钮等，它们实现在抽象按钮工厂类中定义的方法。这种抽象化的结果使这种结构可以在不修改具体工厂类的情况下引进新的产品，如果出现新的按钮类型，只需要为这种新类型的按钮创建一个具体的工厂类就可以获得该新按钮的实例，这一特点无疑使得工厂方法模式具有超越简单工厂模式的优越性，更加符合“开闭原则”。</p><h2 id="2-模式定义"><a href="#2-模式定义" class="headerlink" title="2 模式定义"></a>2 模式定义</h2><p>工厂方法模式(Factory Method Pattern)它属于类创建型模式。在工厂方法模式中，工厂父类负责定义创建产品对象的公共接口，而工厂子类则负责生成具体的产品对象，这样做的目的是将产品类的实例化操作延迟到工厂子类中完成，即通过工厂子类来确定究竟应该实例化哪一个具体产品类</p><h2 id="3-Demo"><a href="#3-Demo" class="headerlink" title="3 Demo"></a>3 Demo</h2><pre><code class="go">#===================MouseFactory.go====================package mainconst (    DELL = iota    HP)type MouseInter interface {    SayHi()}type FactoryInter interface {    CreateMouse() MouseInter}#===================DellMouseFactory.go====================package mainimport &quot;fmt&quot;type DellMouse struct {}func (dell *DellMouse) SayHi() {    fmt.Println(&quot;DellMouse&quot;)}type DellMouseFactory struct {}func (df *DellMouseFactory) CreateMouse() MouseInter {    return &amp;DellMouse{}}#===================HpMouseFactory.go====================package mainimport &quot;fmt&quot;type HpMouse struct {}func (hp *HpMouse) SayHi() {    fmt.Println(&quot;HpMouse&quot;)}type HpMouseFactory struct {}func (hf *HpMouseFactory) CreateMouse() MouseInter {    return &amp;HpMouse{}}#===================mainpackage main.go====================package main//工厂模式:定义一个用于创建对象的接口//让子类决定实例化哪一个类//使一个类的实例化延迟到其子类func main() {    var mf FactoryInter    mf = new(DellMouseFactory)    mouse := mf.CreateMouse()    mouse.SayHi()    mf = new(HpMouseFactory)    mouse = mf.CreateMouse()    mouse.SayHi()}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 设计模式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>简单工厂模式</title>
      <link href="/2020/04/24/%E7%AE%80%E5%8D%95%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F/"/>
      <url>/2020/04/24/%E7%AE%80%E5%8D%95%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h2 id="1-模式动机"><a href="#1-模式动机" class="headerlink" title="1 模式动机"></a>1 模式动机</h2><p>考虑一个简单的软件应用场景，一个软件系统可以提供多个外观不同的按钮（如圆形按钮、矩形按钮、菱形按钮等）， 这些按钮都源自同一个基类，不过在继承基类后不同的子类修改了部分属性从而使得它们可以呈现不同的外观，如果<strong>我们希望在使用这些按钮时，不需要知道这些具体按钮类的名字，只需要知道表示该按钮类的一个参数，并提供一个调用方便的方法，把该参数传入方法即可返回一个相应的按钮对象，此时，就可以使用简单工厂模式</strong>。</p><h2 id="2-模式定义"><a href="#2-模式定义" class="headerlink" title="2 模式定义"></a>2 模式定义</h2><p>简单工厂模式(Simple Factory Pattern)：又称为静态工厂方法(Static Factory Method)模式，它属于类创建型模式。在简单工厂模式中，可以根据参数的不同返回不同类的实例。简单工厂模式专门定义一个类来负责创建其他类的实例，被创建的实例通常都具有共同的父类。</p><h2 id="3-Demo"><a href="#3-Demo" class="headerlink" title="3 Demo"></a>3 Demo</h2><pre><code class="go">#===================MouseFactory.go====================package mainconst (    Dell = iota    HP)type MouseInter interface {    SayHi()}func newMouseFactory(mCase int) MouseInter {    switch mCase {    case Dell:        return &amp;DellMouse{}    case HP:        return &amp;HpMouse{}    default:        return &amp;HpMouse{}    }}#===================DellMouse.go====================package mainimport &quot;fmt&quot;type DellMouse struct {}func (dell *DellMouse) SayHi() {    fmt.Println(&quot;DellMouse&quot;)}#===================HpMouse.go====================package mainimport &quot;fmt&quot;type HpMouse struct {}func (hp *HpMouse) SayHi() {    fmt.Println(&quot;HpMouse&quot;)}#===================main.go====================package mainfunc main() {    f1 := newMouseFactory(Dell)    f2 := newMouseFactory(HP)    f1.SayHi()    f2.SayHi()}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 设计模式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>设计模式概述</title>
      <link href="/2020/04/24/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E6%A6%82%E8%BF%B0/"/>
      <url>/2020/04/24/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E6%A6%82%E8%BF%B0/</url>
      
        <content type="html"><![CDATA[<h2 id="1-设计模式分类"><a href="#1-设计模式分类" class="headerlink" title="1 设计模式分类"></a>1 设计模式分类</h2><ul><li><p>创建型模式</p><ul><li><a href="DesignPattern/CreationalPatterns/SimpleFactory">简单工厂模式（Simple Factory）</a></li><li><a href="DesignPattern/CreationalPatterns/Factory">工厂方法模式（Factory Method）</a></li><li><a href="DesignPattern/CreationalPatterns/AbstractFactory">抽象工厂模式（Abstract Factory）</a></li><li><a href="DesignPattern/CreationalPatterns/Builder">创建者模式（Builder）</a></li><li><a href="DesignPattern/CreationalPatterns/Prototype">原型模式（Prototype）</a></li><li><a href="DesignPattern/CreationalPatterns/Singleton">单例模式（Singleton）</a></li></ul></li><li><p>结构型模式</p><ul><li><a href="DesignPattern/StructuralPatterns/Facade">外观模式（Facade）</a></li><li><a href="DesignPattern/StructuralPatterns/Adapter">适配器模式（Adapter）</a></li><li><a href="DesignPattern/StructuralPatterns/Proxy">代理模式（Proxy）</a></li><li><a href="DesignPattern/StructuralPatterns/Composite">组合模式（Composite）</a></li><li><a href="DesignPattern/StructuralPatterns/FlyWeight">享元模式（Flyweight）</a></li><li><a href="DesignPattern/StructuralPatterns/Decorator">装饰模式（Decorator）</a></li><li><a href="DesignPattern/StructuralPatterns/Bridge">桥模式（Bridge）</a></li></ul></li><li><p>行为型模式</p><ul><li><a href="DesignPattern/BehavioralPatterns/Mediator">中介者模式（Mediator）</a></li><li><a href="DesignPattern/BehavioralPatterns/Observer">观察者模式（Observer）</a></li><li><a href="DesignPattern/BehavioralPatterns/Command">命令模式（Command）</a></li><li><a href="DesignPattern/BehavioralPatterns/Iterator">迭代器模式（Iterator）</a></li><li><a href="DesignPattern/BehavioralPatterns/Template">模板方法模式（Template Method）</a></li><li><a href="DesignPattern/BehavioralPatterns/Strategy">策略模式（Strategy）</a></li><li><a href="DesignPattern/BehavioralPatterns/State">状态模式（State）</a></li><li><a href="DesignPattern/BehavioralPatterns/Memento">备忘录模式（Memento）</a></li><li><a href="DesignPattern/BehavioralPatterns/Interpreter">解释器模式（Interpreter）</a></li><li><a href="DesignPattern/BehavioralPatterns/Chain">职责链模式（Chain of Responsibility）</a></li><li><a href="DesignPattern/BehavioralPatterns/Vistor">访问者模式（Visitor）</a></li></ul></li></ul><h2 id="2-设计模式功能介绍"><a href="#2-设计模式功能介绍" class="headerlink" title="2 设计模式功能介绍"></a>2 设计模式功能介绍</h2><ul><li><strong>单例（Singleton）模式</strong>：某个类只能生成一个实例，该类提供了一个全局访问点供外部获取该实例，其拓展是有限多例模式。</li><li><strong>原型（Prototype）模式</strong>：将一个对象作为原型，通过对其进行复制而克隆出多个和原型类似的新实例。</li><li><strong>工厂方法（Factory Method）模式</strong>：定义一个用于创建产品的接口，由子类决定生产什么产品。</li><li><strong>抽象工厂（AbstractFactory）模式</strong>：提供一个创建产品族的接口，其每个子类可以生产一系列相关的产品。</li><li><strong>建造者（Builder）模式</strong>：将一个复杂对象分解成多个相对简单的部分，然后根据不同需要分别创建它们，最后构建成该复杂对象。</li><li><strong>代理（Proxy）模式</strong>：为某对象提供一种代理以控制对该对象的访问。即客户端通过代理间接地访问该对象，从而限制、增强或修改该对象的一些特性。</li><li><strong>适配器（Adapter）模式</strong>：将一个类的接口转换成客户希望的另外一个接口，使得原本由于接口不兼容而不能一起工作的那些类能一起工作。</li><li><strong>桥接（Bridge）模式</strong>：将抽象与实现分离，使它们可以独立变化。它是用组合关系代替继承关系来实现，从而降低了抽象和实现这两个可变维度的耦合度。</li><li><strong>装饰（Decorator）模式</strong>：动态的给对象增加一些职责，即增加其额外的功能。</li><li><strong>外观（Facade）模式</strong>：为多个复杂的子系统提供一个一致的接口，使这些子系统更加容易被访问。</li><li><strong>享元（Flyweight）模式</strong>：运用共享技术来有效地支持大量细粒度对象的复用。</li><li><strong>组合（Composite）模式</strong>：将对象组合成树状层次结构，使用户对单个对象和组合对象具有一致的访问性。</li><li><strong>模板方法（TemplateMethod）模式</strong>：定义一个操作中的算法骨架，而将算法的一些步骤延迟到子类中，使得子类可以不改变该算法结构的情况下重定义该算法的某些特定步骤。</li><li><strong>策略（Strategy）模式</strong>：定义了一系列算法，并将每个算法封装起来，使它们可以相互替换，且算法的改变不会影响使用算法的客户。</li><li><strong>命令（Command）模式</strong>：将一个请求封装为一个对象，使发出请求的责任和执行请求的责任分割开。</li><li><strong>职责链（Chain of Responsibility）模式</strong>：把请求从链中的一个对象传到下一个对象，直到请求被响应为止。通过这种方式去除对象之间的耦合。</li><li><strong>状态（State）模式</strong>：允许一个对象在其内部状态发生改变时改变其行为能力。</li><li><strong>观察者（Observer）模式</strong>：多个对象间存在一对多关系，当一个对象发生改变时，把这种改变通知给其他多个对象，从而影响其他对象的行为。</li><li><strong>中介者（Mediator）模式</strong>：定义一个中介对象来简化原有对象之间的交互关系，降低系统中对象间的耦合度，使原有对象之间不必相互了解。</li><li><strong>迭代器（Iterator）模式</strong>：提供一种方法来顺序访问聚合对象中的一系列数据，而不暴露聚合对象的内部表示。</li><li><strong>访问者（Visitor）模式</strong>：在不改变集合元素的前提下，为一个集合中的每个元素提供多种访问方式，即每个元素有多个访问者对象访问。</li><li><strong>备忘录（Memento）模式</strong>：在不破坏封装性的前提下，获取并保存一个对象的内部状态，以便以后恢复它。</li><li><strong>解释器（Interpreter）模式</strong>：提供如何定义语言的文法，以及对语言句子的解释方法，即解释器。</li></ul><h2 id="3-六大原则"><a href="#3-六大原则" class="headerlink" title="3 六大原则"></a>3 六大原则</h2><h3 id="3-1-单一职责原则-Single-Responsibility-Principle"><a href="#3-1-单一职责原则-Single-Responsibility-Principle" class="headerlink" title="3.1 单一职责原则(Single Responsibility Principle)"></a>3.1 单一职责原则(Single Responsibility Principle)</h3><p>定义：就一个类而言， 应该仅有一个引起它变化的原因。</p><p>单一职责的划分界限并不是那么清晰，很多时候需要靠个人经验界定。当然最大的问题就是对职责的定义，什么是类的职责，以及怎么划分类的职责。</p><h3 id="3-2-开放封闭原则（Open-Close-Principle）"><a href="#3-2-开放封闭原则（Open-Close-Principle）" class="headerlink" title="3.2 开放封闭原则（Open Close Principle）"></a>3.2 开放封闭原则（Open Close Principle）</h3><p>定义：类、模块、函数等应该是可以拓展的，但是不可修改。</p><p>开闭原则指导我们，当软件需要变化时，应该尽量通过拓展的方式来实现变化，而不是通过修改已有代码来实现。这里的“应该尽量”4个字说明OCP原则并不是说绝对不可以修改原始类的。当我们嗅到原来的代码“腐化气味”时，应该尽早地重构，以便使代码恢复到正常的“进化”过程，而不是通过集成等方式添加新的实现，这会导致类型的膨胀以及历史遗留代码的冗余。因此，在开发过程中需要自己结合具体情况进行考量，是通过修改旧代码还是通过继承使得软件系统更稳定、更灵活，在保证去除“代码腐化”的同时，也保证原有模块的正确性。</p><h3 id="3-3-里氏替换原则（Liskov-Substitution-Principle）"><a href="#3-3-里氏替换原则（Liskov-Substitution-Principle）" class="headerlink" title="3.3 里氏替换原则（Liskov Substitution Principle）"></a>3.3 里氏替换原则（Liskov Substitution Principle）</h3><p>注：它是开闭原则的具体实现手段之一，它的核心原理是抽象</p><p>定义：所有引用基类的地方必须能透明地使用其子类的对象。</p><p>里氏替换原则的核心原理是抽象，抽象又依赖于继承这个特性，在OOP中，继承的优缺点相当明显，有点如下：</p><ul><li>代码重用，减少创建类成本，每个子类拥有父类的属性和方法；</li><li>子类和父类基本相似，但又与父类有所区别；</li><li>提高代码的可拓展性。</li></ul><p>继承的缺点：</p><ul><li>继承是侵入性的，只要继承就必须拥有弗雷的所有属性和方法</li><li>可能造成子类代码的冗余、灵活性降低，因为子类必须拥有弗雷的属性和方法。</li></ul><p>开闭原则和里氏替换原则往往是生死相依、不离不弃的，通过里氏替换来达到对扩展的开发，对修改的关闭效果。</p><h3 id="3-4-依赖倒置原则（Dependence-Inversion-Principle）"><a href="#3-4-依赖倒置原则（Dependence-Inversion-Principle）" class="headerlink" title="3.4 依赖倒置原则（Dependence Inversion Principle）"></a>3.4 依赖倒置原则（Dependence Inversion Principle）</h3><p>注：关系到系统的可拓展性、拥抱变化的能力、开闭原则</p><p>定义：高层模块不应该依赖于低层模块，两者都应该依赖于抽象。抽象不应该依赖于细节，细节应该依赖于抽象。</p><p>java中抽象指接口或抽象类，两者都不能直接被实例化的；细节就是实现类，实现接口或者集成抽象类而产生的也就细节，也就是可以可以加上yige 关键字new产生的对象。高层模块就是调用端，低层模块就是具体实现类。依赖倒置原则在java中表现就是，模块间依赖通过抽象发生，实现类之间不发生直接依赖关系，其依赖关系是通过接口或者抽象类产生的。如果类与类直接依赖细节，那么久会直接耦合。如此一来当修改时，就会同时修改依赖者代码，这样限制了可拓展性。</p><h3 id="3-5-接口隔离原则（InterfaceSegregation-Principles）"><a href="#3-5-接口隔离原则（InterfaceSegregation-Principles）" class="headerlink" title="3.5 接口隔离原则（InterfaceSegregation Principles）"></a>3.5 接口隔离原则（InterfaceSegregation Principles）</h3><p>注：最小化， 减少依赖从而降低变更的风险。</p><p>定义：一个类对另一个类的依赖应该建立在最小的接口上。</p><p>建立单一接口，不要建立庞大臃肿接口；尽量细化接口，接口中方法尽量少。也就是说，我们要为各个类建立专用的接口，而不要试图建立一个很庞大的接口供所有依赖它的类调用。</p><ul><li>接口尽量小，但是要有限度。对接口进行细化可以提高程序设计的灵活性；但是如果过小，则会造成接口数量过多，使设计复杂化。所以，一定要适度。</li><li>为依赖接口的类定制服务，只暴露给调用的类需要的方法，它不需要的方法则隐蔽起来。只有专注得为一个模块提供定制服务，才能建立最小的依赖关系。</li><li>提高内聚，减少对外交互。接口方法尽量少用public修饰。接口是对外的承诺，承诺越少对系统开发越有利，变更风险也会越少。</li></ul><p>以上（单一职责、开闭原则、里氏替换、接口隔离、依赖倒置）五个原则被Bob大叔在21世纪早期定义为SOLID原则。作为面向对象编程的5个基本原则，当这些原则被一起使用时，它们使得一个软件系统更清晰、简单，最大程度地拥抱变化。</p><h3 id="3-6-迪米特原则（Law-of-Demeter）-最少知识原则"><a href="#3-6-迪米特原则（Law-of-Demeter）-最少知识原则" class="headerlink" title="3.6  迪米特原则（Law of Demeter）/最少知识原则"></a>3.6  迪米特原则（Law of Demeter）/最少知识原则</h3><p>注：通过引入一个合理的第三者降低现有对象之间的耦合度。</p><p>定义：一个软件实体应当尽可能少地与其他实体发生相互作用。</p><p>一个类应该对自己需要耦合或者调用的类知道最少， 类的内部如何实现与调用者或者依赖关系越密切，耦合度越大，当一个类发生变化时，对另一个类的影响也越大。</p><ul><li>在类的划分上，应当尽量创建松耦合的类。类之间的耦合度约低，就越有利于服用。一个处于松耦合中的类一旦被修改，则不会对关联的类造成太大的波及。</li><li>在类的机构设计上， 每一个类都应当尽量降低其成员变量和成员函数的访问权限。</li><li>在对其他类的引用上， 一个类对其他对象的引用应当降到最低。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 设计模式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 设计模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>提测流程规范</title>
      <link href="/2020/04/21/%E6%8F%90%E6%B5%8B%E6%B5%81%E7%A8%8B%E8%A7%84%E8%8C%83/"/>
      <url>/2020/04/21/%E6%8F%90%E6%B5%8B%E6%B5%81%E7%A8%8B%E8%A7%84%E8%8C%83/</url>
      
        <content type="html"><![CDATA[<p><img src="http://base422.oss-cn-beijing.aliyuncs.com/tice.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 基础 </category>
          
          <category> 规范 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 规范 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>上线流程规范</title>
      <link href="/2020/04/21/%E4%B8%8A%E7%BA%BF%E6%B5%81%E7%A8%8B%E8%A7%84%E8%8C%83/"/>
      <url>/2020/04/21/%E4%B8%8A%E7%BA%BF%E6%B5%81%E7%A8%8B%E8%A7%84%E8%8C%83/</url>
      
        <content type="html"><![CDATA[<p><img src="http://base422.oss-cn-beijing.aliyuncs.com/online.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 基础 </category>
          
          <category> 规范 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 规范 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>日志等级规范</title>
      <link href="/2020/04/21/%E6%97%A5%E5%BF%97%E7%AD%89%E7%BA%A7%E8%A7%84%E8%8C%83/"/>
      <url>/2020/04/21/%E6%97%A5%E5%BF%97%E7%AD%89%E7%BA%A7%E8%A7%84%E8%8C%83/</url>
      
        <content type="html"><![CDATA[<h2 id="1-日志等级"><a href="#1-日志等级" class="headerlink" title="1 日志等级"></a>1 日志等级</h2><table><thead><tr><th align="center">日志级别</th><th align="center">要求</th><th align="center">打印场景</th><th align="left">示例</th></tr></thead><tbody><tr><td align="center">DEBUG</td><td align="center">强制</td><td align="center">debug信息、细粒度信息事件</td><td align="left">调试信息</td></tr><tr><td align="center">INFO</td><td align="center">强制</td><td align="center">重要事件、强调应用程序的运行过程</td><td align="left">用户登录的SQL信息、创建任务时的执行过程</td></tr><tr><td align="center">NOTICE</td><td align="center">推荐</td><td align="center">一般重要性事件、执行过程中较INFO级别更为重要的信息</td><td align="left">调用外部API时的过程日志</td></tr><tr><td align="center">WARNING</td><td align="center">推荐</td><td align="center">出现了非错误性的异常信息、潜在异常信息、需要关注并且需要修</td><td align="left">调用了已经被弃用的API、用户请求参数中包含了非法字符但经过处理无害</td></tr><tr><td align="center">ERROR</td><td align="center">强制</td><td align="center">运行时出现的错误、不必要立即进行修复、不影响整个逻辑的运行、需要记录并做检测</td><td align="left">调用预期存在的Cache出现未命中进而查询DB、调用某首选API不通进而调用候选API</td></tr><tr><td align="center">CRITICAL/FATAL</td><td align="center">强制</td><td align="center">紧急情况、需要立刻进行修复、程序组件不可用</td><td align="left">程序组件异常退出、用户注册逻辑不能发送邮件</td></tr><tr><td align="center">ALERT</td><td align="center">推荐</td><td align="center">必须立即采取行动的紧急事件、需要立即通知相关人员紧急修复</td><td align="left">整个网站垮掉、DB/Cache无法连接</td></tr><tr><td align="center">EMERGENCY</td><td align="center">推荐</td><td align="center">系统不可用</td><td align="left">磁盘不可写</td></tr></tbody></table><p><strong>【注】请慎用日志级别,避免所有信息写到ERROR及以上级别,警惕“狼来了”带来的运维麻痹</strong></p><h2 id="2-报警频率"><a href="#2-报警频率" class="headerlink" title="2 报警频率"></a>2 报警频率</h2><p>系统会根据日志等级的不同,报警频率不同:</p><table><thead><tr><th align="center">日志级别</th><th align="center">报警频率</th><th align="center">报警方式</th></tr></thead><tbody><tr><td align="center">DEBUG</td><td align="center">-</td><td align="center">-</td></tr><tr><td align="center">INFO</td><td align="center">-</td><td align="center">-</td></tr><tr><td align="center">NOTICE</td><td align="center">-</td><td align="center">-</td></tr><tr><td align="center">WARNING</td><td align="center">每天报警</td><td align="center">邮件</td></tr><tr><td align="center">ERROR</td><td align="center">每半小时报警</td><td align="center">邮件</td></tr><tr><td align="center">CRITICAL/FATAL</td><td align="center">每10分钟报警</td><td align="center">邮件+钉钉</td></tr><tr><td align="center">ALERT</td><td align="center">每5分钟报警</td><td align="center">邮件+钉钉+短信</td></tr><tr><td align="center">EMERGENCY</td><td align="center">每分钟报警</td><td align="center">邮件+钉钉+短信+电话</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> 基础 </category>
          
          <category> 规范 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 规范 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>版本命名规范</title>
      <link href="/2020/04/20/%E7%89%88%E6%9C%AC%E5%91%BD%E5%90%8D%E8%A7%84%E8%8C%83/"/>
      <url>/2020/04/20/%E7%89%88%E6%9C%AC%E5%91%BD%E5%90%8D%E8%A7%84%E8%8C%83/</url>
      
        <content type="html"><![CDATA[<h2 id="1-命名规范"><a href="#1-命名规范" class="headerlink" title="1  命名规范"></a>1  命名规范</h2><p>版本号由三部分组成:</p><pre><code>1. 主版本号2. 次版本号3. 修订版本号4. 希腊字母版本号</code></pre><p>这三部分之间通过<code>.</code>连接:<code>主版本号.次版本号.修订版本号.希腊字符版本号</code></p><pre><code>      次版本号　希腊字母版本号       ↓       ↓       =       =    1. 2. 3. beta    =     =            ↑     ↑           主版本号 修订版本号  </code></pre><h2 id="2-修改规则"><a href="#2-修改规则" class="headerlink" title="2 修改规则"></a>2 修改规则</h2><ul><li><p>主版本号</p><ul><li>当功能模块有较大的变动(如增加模块或是整体架构发生变化)时,主版本号升级,次版本号和修订版本号归零</li></ul></li><li><p>次版本号</p><ul><li>相对于主版本号而言,次版本号的升级(优化)对应的只是局部的变动,功能的新增,次版本号升级时,修订版本号归零</li></ul></li><li><ul><li>修订版本号<ul><li>一般是Bug的修复或是一些小的变动时,要对修订版本号进行升级</li></ul></li></ul></li><li><p>希腊字母版本号</p><ul><li><strong>Alpha版</strong>: 此版本表示该软件在此阶段主要是以实现软件功能为主，通常只在软件开发者内部交流，一般而言，该版本软件的Bug较多，需要继续修改。 <strong>用在开发环境上</strong></li><li><strong>Beta版</strong>: 该版本相对于α版已有了很大的改进，消除了严重的错误，但还是存在着一些缺陷，需要经过多次测试来进一步消除，此版本主要的修改对像是软件的UI。　<strong>用在测试环境上</strong></li><li><strong>RC版</strong>: 该版本已经相当成熟了，基本上不存在导致错误的BUG，与即将发行的正式版相差无几。<strong>用在预发环境上</strong></li><li><strong>Release版</strong>: 该版本意味“最终版本”,　<strong>用在线上环境上,给客户的安装包不带希腊字母版本号</strong></li></ul></li></ul><pre><code class="ini">例:目前储值卡系统版本号是1.2.31. 当储值卡系统底层结构发生变化时,修改主版本号,由1.2.3.release=&gt;2.0.0.Release2. 当储值卡系统新增密码支付功能时,修改次版本号,由1.2.3.release=&gt;1.3.0.Release3. 当储值卡系统修复分摊、统计等Bug时,修改修订版本号,由1.2.3.release=&gt;1.2.4.Release4. 完成测试且已在预发版本完成验证, 由1.2.4.RC=&gt;1.2.4.Release</code></pre><h2 id="3-版本记录"><a href="#3-版本记录" class="headerlink" title="3  版本记录"></a>3  版本记录</h2><p>要在GIT仓中的<code>README.md</code>中记录版本更新历史,紧记录Release版本</p><p>例:</p><table><thead><tr><th align="center">版本</th><th align="center">更新日期</th><th align="center">更新说明</th></tr></thead><tbody><tr><td align="center">2.0.0</td><td align="center">17年12月14日</td><td align="center">底层结构进行了大挑战更加稳定了</td></tr><tr><td align="center">1.1.0</td><td align="center">17年10月14日</td><td align="center">加入了密码支付功能</td></tr><tr><td align="center">1.0.1</td><td align="center">17年08月14日</td><td align="center">修复了分摊、统计的bug</td></tr><tr><td align="center">1.0.0</td><td align="center">17年07月14日</td><td align="center">初版储值卡</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> 基础 </category>
          
          <category> 规范 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 规范 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SQL开发规范</title>
      <link href="/2020/04/20/SQL%E5%BC%80%E5%8F%91%E8%A7%84%E8%8C%83/"/>
      <url>/2020/04/20/SQL%E5%BC%80%E5%8F%91%E8%A7%84%E8%8C%83/</url>
      
        <content type="html"><![CDATA[<h2 id="1-基础规范"><a href="#1-基础规范" class="headerlink" title="1 基础规范"></a>1 基础规范</h2><ul><li>【强制】使用INNODB存储引擎</li><li>【强制】表字符集使用UTF8mb4</li><li>【强制】所有表都需要添加注释</li><li>【建议】单表数据量建议控制在5000W以内</li><li>【强制】不在数据库中存储图、文件等大数据</li><li>【强制】 禁止使用外键、触发器、存储过程</li></ul><h2 id="2-命名规范"><a href="#2-命名规范" class="headerlink" title="2 命名规范"></a>2 命名规范</h2><ul><li>【强制】库名、表名、字段名必须使用小写字母，“_”分割</li><li>【强制】库名以”_db”结尾,eg:crm_db;</li><li>【建议】表名以”t_”开头,eg:t_crm_user_info;</li><li>【强制】表名由两部分组成:表前缀+表意名</li><li>【建议】库名、表名、字段名见名知意,建议使用名词而不是动词。</li><li>【建议】库名、表名、字段名不超过12个字符。</li><li>【强制】临时库、临时表名必须以tmp为前缀,并以日期为后缀</li><li>【强制】备份库、表必须以bak为前缀,并以日期为后缀</li><li>【强制】非唯一索引按照<code>IX_表简写_字段简写</code>命名</li><li>【强制】唯一索引按照<code>UQ_表简写_字段简写</code>命名</li></ul><h2 id="3-库、表、字段开发设计规范"><a href="#3-库、表、字段开发设计规范" class="headerlink" title="3 库、表、字段开发设计规范"></a>3 库、表、字段开发设计规范</h2><ul><li>【强制】单实例表数目必须小于500</li><li>【强制】大字段、访问频率低的字段拆分到单独的表中存储,分离冷热数据</li><li>【强制】单表列数目必须小于30</li><li>【强制】表必须有主键,且与业务无关，例如自增主键</li><li>【强制】禁止使用外键,如果有外键完整性约束,需要应用程序控制</li><li>【强制】字段名采用规范的英文小写格式,并且以下划线”_”分割,长度不能超过3个单词长 度,单个单词长度超过10个字母的应当使用缩写,禁止使用mysql的关键字作为字段名</li><li>【禁止】在数据库中存储明文密码,把密码加密后存储</li><li>【建议】字段定义为NOT NULL,需为空字段可定义为NOT NULL DEFAULT ‘’或0(0不要赋予实际意义)</li><li>【强制】存储精确浮点数必须使用DECIMAL替代FLOAT和DOUBLE</li><li>【建议】使用UNSIGNED存储非负数值</li><li>【建议】整形定义中建议采用INT(10),而不是INT(1),INT(11)或其他</li><li>【强制】存储状态，性别等，用TINYINT，如果不需要负数加UNSIGNED。使用TINYINT UNSIGNED</li><li>【强制】尽可能不使用TEXT、BLOB类型</li><li>【禁止】数据库中使用VARBINARY、BLOB存储图片、文件等</li><li>VARCHAR(N)，N尽可能小</li><li>存储年使用YEAR类型</li><li>存储时间（精确到秒）建议使用TIMESTAMP类型</li></ul><h2 id="4-索引规范"><a href="#4-索引规范" class="headerlink" title="4  索引规范"></a>4  索引规范</h2><ul><li>索引的数量控制<ul><li>单张表中索引数量不超过5个</li><li>单个索引中的字段数不超过5个</li></ul></li><li>主键准则<ul><li>表必须有主键</li><li>不使用更新频繁的列作为主键</li><li>尽量不选择字符串列作为主键</li><li>不使用UUID MD5 HASH这些作为主键(数值太离散了)</li><li>建议选择自增</li></ul></li><li>重要的SQL必须被索引，比如：<ul><li>UPDATE、DELETE语句的WHERE条件列</li><li>ORDER BY、GROUP BY、DISTINCT的字段</li></ul></li><li>多表JOIN的字段注意以下：<ul><li>区分度最大的字段放在前面</li><li>优先考虑覆盖索引</li><li>避免冗余和重复索引</li><li>索引要综合评估数据密度和分布以及考虑查询和更新比例</li></ul></li><li>索引禁忌<ul><li>不在低基数列上建立索引，例如“性别”</li><li>不在索引列进行数学运算和函数运算</li></ul></li><li>新建的唯一索引必须不能和主键重复</li><li>引字段的默认值不能为NULL，要改为其他的default或者空。NULL非常影响索引的查询效率</li><li>反复查看与表相关的SQL，符合最左前缀的特点建立索引。多条字段重复的语句，要修改语句条件字段的顺序，为其建立一条联合索引，减少索引数量</li><li>能使用唯一索引就要使用唯一索引，提高查询效率</li></ul><h2 id="5-语句规范"><a href="#5-语句规范" class="headerlink" title="5 语句规范"></a>5 语句规范</h2><ul><li>UPDATE、DELETE语句不使用LIMIT。</li><li>SELECT语句只获取需要的字段,减少select *。</li><li>WHERE条件中必须使用合适的类型，避免MySQL进行隐式类型转化。</li><li>避免在SQL语句进行数学运算或者函数运算。</li><li>避免使用存储过程、触发器、函数等，容易将业务逻辑和DB耦合在一起，并且MySQL的存储过程、触发器、函数中存在一定的bug</li><li>避免使用JOIN。</li><li>使用合理的SQL语句减少与数据库的交互次数。</li><li>不使用ORDER BY RAND()，使用其他方法替换。</li><li>WHERE条件中的非等值条件（IN、BETWEEN、&lt;、&lt;=、&gt;、&gt;=）会导致后面的条件使用不了索引。</li><li>SQL语句中IN包含的值不应过多。</li><li>SELECT、INSERT语句必须显式的指明字段名称，不使用SELECT *，不使用INSERT INTO table()。</li><li>使用SELECT column_1, column_2 FROM table WHERE[]而不是SELECT column_1 FROM table WHERE[]和SELECT column_2 FROM table WHERE []。</li><li>limit分页注意效率。Limit越大，效率越低。可以改写limit，比如例子改写：select id from tlimit 10000, 10;  =&gt;  select id from t where id &gt; 10000 limit10;</li></ul><h2 id="6-FAQ"><a href="#6-FAQ" class="headerlink" title="6 FAQ"></a>6 FAQ</h2><ul><li>建议使用UNSIGNED存储非负数值，同样的字节数，存储的数值范围更大。如tinyint 有符号为 -128-127，无符号为0-255。</li><li>尽可能不使用TEXT、BLOB类型<ul><li>索引排序问题，只能使用max_sort_length的长度或者手工指定ORDER BY SUBSTRING(column,length)的长度来排序</li><li>Memory引擘不支持text,blog类型，会在磁盘上生成临时表</li><li>可能浪费更多的空间</li><li>可能无法使用adaptive hash index</li><li>导致使用where没有索引的语句变慢</li></ul></li><li>建议字段定义为NOT NULL<ul><li>如果null字段被索引，需要额外的1字节</li><li>使索引，索引统计，值的比较变得更复杂</li><li>可用’’，0代替</li><li>如果是索引字段，一定要定义为not null 例如：NOT NULL default ‘’</li></ul></li><li>禁止在数据库中使用VARBINARY、BLOB存储图片、文件等。采用分布式文件系统更高效</li><li>VARCHAR(N)，N尽可能小，N表示的是字符数不是字节数，比如VARCHAR(255)，可以最大可存储255个汉字，需要根据实际的宽度来选择N。VARCHAR(N)，因为MySQL一个表中所有的VARCHAR字段最大长度是65535个字节21845个汉字，进行排序和创建临时表一类的内存操作时，会使用N的长度申请内存。</li><li>为什么建议使用TIMESTAMP来存储时间而不是DATETIME？<ul><li>DATETIME和TIMESTAMP都是精确到秒，优先选择TIMESTAMP，因为TIMESTAMP只有4个字节，而DATETIME8个字节。同时TIMESTAMP具有自动赋值以及自动更新的特性。</li></ul></li><li>为什么一张表中不能存在过多的索引？<ul><li>InnoDB的secondaryindex使用b+tree来存储，因此在UPDATE、DELETE、INSERT的时候需要对b+tree进行调整，过多的索引会减慢更新的速度。</li></ul></li><li>不建议使用%前缀模糊查询，例如LIKE “%weibo”。会导致全表扫描</li><li>UPDATE、DELETE语句不使用LIMIT。<ul><li>可能导致主从数据不一致</li><li>会记录到错误日志，导致日志占用大量空间</li></ul></li><li>为什么需要避免MySQL进行隐式类型转化？<ul><li>因为MySQL进行隐式类型转化之后，可能会将索引字段类型转化成=号右边值的类型，导致使用不到索引。</li></ul></li><li>为什么不建议使用SELECT *?<ul><li>增加很多不必要的消耗（cpu、io、内存、网络带宽）</li></ul></li><li>为什么不能使用ORDER BY rand()？<ul><li>因为ORDER BYrand()会将数据从磁盘中读取，进行排序，会消耗大量的IO和CPU，可以在程序中获取一个rand值，然后通过在从数据库中获取对应的值</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> 基础 </category>
          
          <category> 规范 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mysql </tag>
            
            <tag> 规范 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis使用规范</title>
      <link href="/2020/04/20/Redis%E4%BD%BF%E7%94%A8%E8%A7%84%E8%8C%83/"/>
      <url>/2020/04/20/Redis%E4%BD%BF%E7%94%A8%E8%A7%84%E8%8C%83/</url>
      
        <content type="html"><![CDATA[<h2 id="1-键值设计"><a href="#1-键值设计" class="headerlink" title="1 键值设计"></a>1 键值设计</h2><h3 id="1-1-key名设计"><a href="#1-1-key名设计" class="headerlink" title="1.1 key名设计"></a>1.1 key名设计</h3><ul><li>可读性与可管理性，建议业务名为前缀（防止key冲突）,用冒号分隔，比如业务名:表名:id</li><li>禁止包含特殊字符（比如空格、换行、单双引号以及其他转义字符）</li><li>简洁性，保证语义的前提下尽量控制key长度，降低内存占用</li></ul><h3 id="1-2-value设计"><a href="#1-2-value设计" class="headerlink" title="1.2 value设计"></a>1.2 value设计</h3><ul><li>拒绝大key操作string类型控制在10KB以内，hash、list、set、zset元素个数不要超过5000</li><li>设计时选择合适的数据类型</li><li>控制key的生命周期</li></ul><h2 id="2-存储设计"><a href="#2-存储设计" class="headerlink" title="2 存储设计"></a>2 存储设计</h2><ul><li>冷热数据分离，不要将所有数据全部放入Redis中</li><li>不同业务数据建议分开存储，Redis为单线程处理，独立存储降低业务间相互影响</li><li>存储key需设置超时时间，防止内存长期占用</li><li>对于必须存储的大文本数据需压缩处理后进行存储</li><li>程序端需处理Redis数据丢失时的重新加载过程</li></ul><h2 id="3-命令使用"><a href="#3-命令使用" class="headerlink" title="3 命令使用"></a>3 命令使用</h2><ul><li><strong>禁止</strong>使用keys、flushall、flushdb等操作命令</li><li>合理使用select命令</li></ul>]]></content>
      
      
      <categories>
          
          <category> 基础 </category>
          
          <category> 规范 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 规范 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GIT分支规范</title>
      <link href="/2020/04/19/git%E5%88%86%E6%94%AF%E8%A7%84%E8%8C%83/"/>
      <url>/2020/04/19/git%E5%88%86%E6%94%AF%E8%A7%84%E8%8C%83/</url>
      
        <content type="html"><![CDATA[<h2 id="1分支类型"><a href="#1分支类型" class="headerlink" title="1分支类型"></a>1分支类型</h2><h3 id="1-1-主分支-master"><a href="#1-1-主分支-master" class="headerlink" title="1.1 主分支 master"></a>1.1 主分支 master</h3><blockquote><p>概念：代码库应该有一个、且仅有一个主分支。所有提供给用户使用的正式版本，都在这个主分支上发布。</p></blockquote><h3 id="1-2-开发分支-develop"><a href="#1-2-开发分支-develop" class="headerlink" title="1.2 开发分支 develop"></a>1.2 开发分支 develop</h3><blockquote><p>概念：主分支只用来分布重大版本，日常开发应该在另一条分支上完成。我们把开发用的分支，叫做Develop。</p></blockquote><h3 id="1-3-临时性分支"><a href="#1-3-临时性分支" class="headerlink" title="1.3 临时性分支"></a>1.3 临时性分支</h3><blockquote><p>概念：除了常设分支以外，还有一些临时性分支，用于应对一些特定目的的版本开发。临时性分支主要有三种：</p></blockquote><ul><li><p>功能（feature）分支,它是为了开发某种特定功能，从develop分支上面分出来的。开发完成后，要再并入develop。</p></li><li><p>预发布（release）分支，它是指发布正式版本之前（即合并到Master分支之前），我们可能需要有一个预发布的版本进行测试。<br>   预发布分支是从Develop分支上面分出来的，预发布结束以后，必须合并进Develop和Master分支。</p></li><li><p>修补bug（hotfix）分支，软件正式发布以后，难免会出现bug。这时就需要创建一个分支，进行bug修补。<br>   它是从Master分支上面分出来的。修补结束以后，再合并进Master和Develop分支</p></li></ul><h2 id="2-分支命名规范"><a href="#2-分支命名规范" class="headerlink" title="2  分支命名规范"></a>2  分支命名规范</h2><ul><li><p>feature分支命名规范</p><blockquote><p>feature/#+简要说明，简要说明尽量用1到3个单词描述本次修改的功能。如：feature/#send_coupon</p></blockquote></li><li><p>release分支命名规范</p><blockquote><p>release/版本号，需要修改主版本号和次版本号，修订版本号为0。如：release/2.1.0</p></blockquote></li><li><p>hotfix分支命名规范</p><blockquote><p>hotfix/版本号，需要修改修订版本号，主版本号和次版本号不变。如：hotfix/2.1.1</p></blockquote></li></ul><h2 id="3-分支使用规范"><a href="#3-分支使用规范" class="headerlink" title="3 分支使用规范"></a>3 分支使用规范</h2><ul><li>新建仓库时只有一个master分支（用于发布），在master的基础上创建develop分支（开发主分支，主要用于合并其他分支）。</li></ul><pre><code>    git checkout -b develop master    git push origin develop</code></pre><ul><li>每开发一个新功能时<code>必须</code>从develop上创建一个feature分支。</li></ul><pre><code>    git checkout -b feature/#send_coupon develop    git push origin feature/#send_coupon</code></pre><ul><li>新功能开发完成后<code>必须</code>将feature分支合并回develop分支，并在此develop上<code>创建</code>release分支（用于测试和修改bug）。</li></ul><pre><code>    git checkout develop    git merge --no-ff feature/#send_coupon    git checkout -b release/2.1.0 develop    git push origin release/2.1.0</code></pre><ul><li>完成测试并即将上线的时候<code>必须</code>将release分支合并到develop分支和master分支。</li></ul><pre><code>    git checkout develop    git merge --no-ff release/2.1.0    git checkout master    git merge --no-ff release/2.1.0</code></pre><ul><li>遇到线上bug需要修复的时候<code>必须</code>从master上创建hotfix分支，测试完成后需将hotfix分支合并到develop分支和master分支。</li></ul><pre><code>    git checkout -b hotfix/2.1.1 master    git push origin hotfix/2.1.1    git checkout develop    git merge --no-ff hotfix/2.1.1    git checkout master    git merge --no-ff hotfix/2.1.1</code></pre><ul><li><p><strong>禁止</strong>在master分支上进行开发。</p></li><li><p><strong>禁止</strong>将master分支和develop分支向其他分支合并。</p></li><li><p>在进行合并分支之前，<code>必须</code>对即将合并过去的分支（develop或master）进行拉取</p></li></ul><pre><code>    git pull origin develop    git pull origin master</code></pre><ul><li>分支合并之后需要将<code>合并修改提交到远程</code></li></ul><pre><code>    git push origin</code></pre><ul><li>临时性分支在确定没有用处的时候需要删除分支。</li></ul><pre><code>    git branch -d feature/coupon-171212</code></pre><ul><li>git flow 图解：</li></ul><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/git_branch.png" alt=""></p><h2 id="4-分支使用最佳实践（参考）"><a href="#4-分支使用最佳实践（参考）" class="headerlink" title="4 分支使用最佳实践（参考）"></a>4 分支使用最佳实践（参考）</h2><ul><li><a href="https://www.cnblogs.com/cnblogsfans/p/5075073.html" target="_blank" rel="noopener">git在团队中的最佳实践</a></li><li><a href="http://www.ruanyifeng.com/blog/2012/07/git.html" target="_blank" rel="noopener">git分支管理策略</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 基础 </category>
          
          <category> 规范 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 规范 </tag>
            
            <tag> Git </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GIT使用规范</title>
      <link href="/2020/04/19/git%E4%BD%BF%E7%94%A8%E8%A7%84%E8%8C%83/"/>
      <url>/2020/04/19/git%E4%BD%BF%E7%94%A8%E8%A7%84%E8%8C%83/</url>
      
        <content type="html"><![CDATA[<ul><li><strong>每日进行开发工作之前必须更新代码，下班时提交代码。</strong></li><li><strong>各员工需牢记各自的账户和密码，一定不得向他人透漏，严禁使用他人账户进行GIT各项操作</strong></li><li><strong>文件提交时要求必须提交注释，注明相关修改信息，日志信息描述的越详细越好，让项目组其他成员在看到标注后不用详细看代码就能了解你所做的修改</strong></li><li><strong>对提交的信息采用明晰的标注</strong></li></ul><pre><code class="ini">标注方法    +)表示增加了功能     *) 表示对某些功能进行了更改     -) 表示删除了文件，或者对某些功能进行了裁剪，删除，屏蔽。     b) 表示修正了具体的某个bug</code></pre><pre><code class="ini">demo+)  实现需求T2331*)  优化FooUtil方法-)  删除多余文件b)  修复Bug1213</code></pre><ul><li><strong>文件提交前必须先update代码再commit,如果遇到冲突,严禁删除原版本后直接上传新版本</strong></li><li><strong>文件提交前必须检查是否有语法错误,php文件要使用php -l ［文件名］通过检测</strong></li><li><strong>提前宣布修改计划。当你计划进行修改，需要影响到git里的许多文件时，先通过邮件或者当面通知其他开发者 例如，修改底层数据库模块时，有可能影响到业务逻辑层调用数据库模块的地方。这样其他开发者会有准备，也会对修改提出意见和建议</strong></li><li><strong>原子性提交代码(即一个小功能提交一次)</strong></li><li><strong>提交前请自行进行单元测试,严禁上传未测试的代码!</strong></li></ul>]]></content>
      
      
      <categories>
          
          <category> 基础 </category>
          
          <category> 规范 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 规范 </tag>
            
            <tag> Git </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GIT仓库命名规范</title>
      <link href="/2020/04/19/git%E4%BB%93%E5%BA%93%E5%91%BD%E5%90%8D%E8%A7%84%E8%8C%83/"/>
      <url>/2020/04/19/git%E4%BB%93%E5%BA%93%E5%91%BD%E5%90%8D%E8%A7%84%E8%8C%83/</url>
      
        <content type="html"><![CDATA[<ul><li><strong>【强制】</strong>对于存放微服务代码的GIT仓库,采用以Avatar为前缀的命名规范,命名风格采用大驼峰式风格,例:AvatarCoupon,AvatarWallet</li><li><strong>【强制】</strong>对于存放中间件代码的GIT仓库,采用以middleware为后缀的命名规范,命名风格以 - 为分割符,如是管理后台中间件,前接backend,如是TO C端中间件,前接frontend,例:coupon-backend-middleware,coupon-frontend-middleware</li><li><strong>【强制】</strong>对应存放前端代码的Git仓库，采用fe-<code>${项目名}-${endpoint}</code>格式进行命名，项目名称多个单词之间使用分割线(-)连接，<code>endpoint</code>可选值为有<code>pc</code>（默认PC端应用）、<code>mob</code>（移动端应用）、<code>wechat</code>（小程序）</li></ul>]]></content>
      
      
      <categories>
          
          <category> 基础 </category>
          
          <category> 规范 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 规范 </tag>
            
            <tag> Git </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>11.错误处理机制</title>
      <link href="/2020/04/18/11-%E9%94%99%E8%AF%AF%E5%A4%84%E7%90%86%E6%9C%BA%E5%88%B6/"/>
      <url>/2020/04/18/11-%E9%94%99%E8%AF%AF%E5%A4%84%E7%90%86%E6%9C%BA%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<p>很多系统函数在错误返回时将错误原因记录在libc定义的全局变量errno中，每种错误原因对应一个错误码。</p><p>errno在头文件errno.h中声明，是一个整型变量，所有错误码都是正整数。</p><p><strong>然后我们可以用perror或strerror函数将errno解释成字符串</strong></p><ul><li>perror是将errno对应的错误消息的字符串打印到标准错误输出上，即stderr或2上，若你的程序将标准错误输出重定向到/dev/null，那就看不到了，就不能用perror了。</li><li>strerror的作用只是将errno对应的错误消息字符串返回.你可以自己决定咋样处理字符串，比如可以存到日志，也可以直接printf出来。</li></ul><h2 id="11-1-errno"><a href="#11-1-errno" class="headerlink" title="11.1 errno"></a>11.1 errno</h2><pre><code class="c">#/usr/include/asm-generic/errno-base.h#define EPERM 1 /* Operation not permitted */#define ENOENT 2 /* No such file or directory */#define ESRCH 3 /* No such process */#define EINTR 4 /* Interrupted system call */#define EIO 5 /* I/O error */#define ENXIO 6 /* No such device or address */#define E2BIG 7 /* Argument list too long */#define ENOEXEC 8 /* Exec format error */#define EBADF 9 /* Bad file number */#define ECHILD 10 /* No child processes */#define EAGAIN 11 /* Try again */#define ENOMEM 12 /* Out of memory */#define EACCES 13 /* Permission denied */#define EFAULT 14 /* Bad address */#define ENOTBLK 15 /* Block device required */#define EBUSY 16 /* Device or resource busy */#define EEXIST 17 /* File exists */#define EXDEV 18 /* Cross-device link */#define ENODEV 19 /* No such device */#define ENOTDIR 20 /* Not a directory */#define EISDIR 21 /* Is a directory */#define EINVAL 22 /* Invalid argument */#define ENFILE 23 /* File table overflow */#define EMFILE 24 /* Too many open files */#define ENOTTY 25 /* Not a typewriter */#define ETXTBSY 26 /* Text file busy */#define EFBIG 27 /* File too large */#define ENOSPC 28 /* No space left on device */#define ESPIPE 29 /* Illegal seek */#define EROFS 30 /* Read-only file system */#define EMLINK 31 /* Too many links */#define EPIPE 32 /* Broken pipe */#define EDOM 33 /* Math argument out of domain of func */#define ERANGE 34 /* Math result not representable */</code></pre><h2 id="11-2-perror"><a href="#11-2-perror" class="headerlink" title="11.2 perror"></a>11.2 perror</h2><pre><code class="c">#include &lt;stdio.h&gt;void perror(const char *s);#include &lt;errno.h&gt;const char *sys_errlist[];int sys_nerr;int errno;</code></pre><h2 id="11-3-strerror"><a href="#11-3-strerror" class="headerlink" title="11.3 strerror"></a>11.3 strerror</h2><pre><code class="c">#include &lt;string.h&gt;char *strerror(int errnum);int strerror_r(int errnum, char *buf, size_t buflen);/* XSI-compliant */char *strerror_r(int errnum, char *buf, size_t buflen);/* GNU-specific */             </code></pre>]]></content>
      
      
      <categories>
          
          <category> 基础 </category>
          
          <category> Linux系统编程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> 系统编程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>10.多路IO转接服务器</title>
      <link href="/2020/04/18/10-%E5%A4%9A%E8%B7%AFIO%E8%BD%AC%E6%8E%A5%E6%9C%8D%E5%8A%A1%E5%99%A8/"/>
      <url>/2020/04/18/10-%E5%A4%9A%E8%B7%AFIO%E8%BD%AC%E6%8E%A5%E6%9C%8D%E5%8A%A1%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<h2 id="10-1-多路复用机制"><a href="#10-1-多路复用机制" class="headerlink" title="10.1 多路复用机制"></a>10.1 多路复用机制</h2><p>select，poll，epoll都是IO多路复用的机制。<strong>I/O多路复用就是通过一种机制，一个进程可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作</strong>。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。</p><h2 id="10-2-三种模型"><a href="#10-2-三种模型" class="headerlink" title="10.2 三种模型"></a>10.2 三种模型</h2><h3 id="10-2-1-select"><a href="#10-2-1-select" class="headerlink" title="10.2.1 select"></a>10.2.1 select</h3><p>　　select能监听的文件描述符个数受限于FD_SETSIZE,一般为1024，单纯改变进程打开的文件描述符个数并不能改变select监听文件个数</p><p>　　select目前几乎在所有的平台上支持，其良好跨平台支持也是它的一个优点</p><p>　　<strong>select的一 个缺点在于单个进程能够监视的文件描述符的数量存在最大限制</strong>，在Linux上一般为1024，可以通过修改宏定义甚至重新编译内核的方式提升这一限制，但是这样也会造成效率的降低。</p><h3 id="10-2-2-poll"><a href="#10-2-2-poll" class="headerlink" title="10.2.2 poll"></a>10.2.2 poll</h3><p>pollfd结构包含了要监视的event和发生的event，不再使用select“参数-值”传递的方式。同时，<strong>pollfd并没有最大数量限制（但是数量过大后性能也是会下降）。 和select函数一样，poll返回后，需要轮询pollfd来获取就绪的描述符。</strong></p><p>从上面看，select和poll都需要在返回后，通过遍历文件描述符来获取已经就绪的socket。<strong>事实上，同时连接的大量客户端在一时刻可能只有很少的处于就绪状态，因此随着监视的描述符数量的增长，其效率也会线性下降。</strong></p><h3 id="10-2-3-epoll"><a href="#10-2-3-epoll" class="headerlink" title="10.2.3 epoll"></a>10.2.3 epoll</h3><p><strong>在 select/poll中，进程只有在调用一定的方法后，内核才对所有监视的文件描述符进行扫描，而epoll事先通过epoll_ctl()来注册一个文件描述符，一旦基于某个文件描述符就绪时，内核会采用类似callback的回调机制，迅速激活这个文件描述符，当进程调用epoll_wait() 时便得到通知。</strong></p><p><strong>此处去掉了遍历文件描述符，而是通过监听回调的的机制。这正是epoll的魅力所在。</strong></p><h2 id="10-3-epoll"><a href="#10-3-epoll" class="headerlink" title="10.3 epoll"></a>10.3 epoll</h2><h3 id="10-3-1-适用场景"><a href="#10-3-1-适用场景" class="headerlink" title="10.3.1 适用场景"></a>10.3.1 适用场景</h3><p><strong>连接数多,活跃数少的网络模型下</strong></p><h3 id="10-3-2-操作过程"><a href="#10-3-2-操作过程" class="headerlink" title="10.3.2 操作过程"></a>10.3.2 操作过程</h3><p>epoll操作过程需要三个接口，分别如下：</p><pre><code class="c">int epoll_create(int size)；//创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)；int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);</code></pre><h4 id="10-3-2-1-epoll-create"><a href="#10-3-2-1-epoll-create" class="headerlink" title="10.3.2.1 epoll_create"></a>10.3.2.1 epoll_create</h4><p>​        创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大，这个参数不同于select()中的第一个参数，给出最大监听的fd+1的值，<strong>参数size并不是限制了epoll所能监听的描述符最大个数，只是对内核初始分配内部数据结构的一个建议</strong>。<br>        当创建好epoll句柄后，它就会占用一个fd值，在linux下如果查看/proc/进程id/fd/，是能够看到这个fd的，所以在使用完epoll后，必须调用close()关闭，否则可能导致fd被耗尽。</p><h4 id="10-3-2-2-epoll-ctl"><a href="#10-3-2-2-epoll-ctl" class="headerlink" title="10.3.2.2  epoll_ctl"></a>10.3.2.2  epoll_ctl</h4><p>函数是对指定描述符fd执行op操作。</p><ul><li>epfd：是epoll_create()的返回值。</li><li>op：表示op操作，用三个宏来表示：添加EPOLL_CTL_ADD，删除EPOLL_CTL_DEL，修改EPOLL_CTL_MOD。分别添加、删除和修改对fd的监听事件。</li><li>fd：是需要监听的fd（文件描述符）</li><li>epoll_event：是告诉内核需要监听什么事，struct epoll_event结构如下：</li></ul><pre><code class="c">struct epoll_event {  __uint32_t events;  /* Epoll events */  epoll_data_t data;  /* User data variable */};//events可以是以下几个宏的集合：EPOLLIN ：表示对应的文件描述符可以读（包括对端SOCKET正常关闭）；EPOLLOUT：表示对应的文件描述符可以写；EPOLLPRI：表示对应的文件描述符有紧急的数据可读（这里应该表示有带外数据到来）；EPOLLERR：表示对应的文件描述符发生错误；EPOLLHUP：表示对应的文件描述符被挂断；EPOLLET： 将EPOLL设为边缘触发(Edge Triggered)模式，这是相对于水平触发(Level Triggered)来说的。EPOLLONESHOT：只监听一次事件，当监听完这次事件之后，如果还需要继续监听这个socket的话，需要再次把这个socket加入到EPOLL队列里</code></pre><h4 id="10-3-2-3-epoll-wait"><a href="#10-3-2-3-epoll-wait" class="headerlink" title="10.3.2.3 epoll_wait"></a>10.3.2.3 epoll_wait</h4><p><strong>等待epfd上的io事件，最多返回maxevents个事件</strong><br>参数events用来从内核得到事件的集合，maxevents告之内核这个events有多大，这个maxevents的值不能大于创建epoll_create()时的size，参数timeout是超时时间（毫秒，0会立即返回，-1将不确定，也有说法说是永久阻塞）。该函数返回需要处理的事件数目，如返回0表示已超时。</p><h3 id="10-3-3-demo"><a href="#10-3-3-demo" class="headerlink" title="10.3.3 demo"></a>10.3.3 demo</h3><pre><code class="c">#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;netinet/in.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;sys/epoll.h&gt;#include &lt;errno.h&gt;#include &quot;wrap.h&quot;#define MAXLINE 80#define SERV_PORT 8000#define OPEN_MAX 1024int main(int argc, char *argv[]) {    int i, j, maxi, listenfd, connfd, sockfd;    int nready, efd, res;    ssize_t n;    char buf[MAXLINE], str[INET_ADDRSTRLEN];    socklen_t clilen;    int client[OPEN_MAX];    struct sockaddr_in cliaddr, servaddr;    struct epoll_event tep, ep[OPEN_MAX];    listenfd = Socket(AF_INET, SOCK_STREAM, 0);    bzero(&amp;servaddr, sizeof(servaddr));    servaddr.sin_family = AF_INET;    servaddr.sin_addr.s_addr = htonl(INADDR_ANY);    servaddr.sin_port = htons(SERV_PORT);    Bind(listenfd, (struct sockaddr *) &amp;servaddr, sizeof(servaddr));    Listen(listenfd, 20);    for (i = 0; i &lt; OPEN_MAX; i++)        client[i] = -1;    maxi = -1;    efd = epoll_create(OPEN_MAX);    if (efd == -1)        perr_exit(&quot;epoll_create&quot;);    tep.events = EPOLLIN;    tep.data.fd = listenfd;    res = epoll_ctl(efd, EPOLL_CTL_ADD, listenfd, &amp;tep);    if (res == -1)        perr_exit(&quot;epoll_ctl&quot;);    for (;;) {        nready = epoll_wait(efd, ep, OPEN_MAX, -1); /* 阻塞监听 */        if (nready == -1)            perr_exit(&quot;epoll_wait&quot;);        for (i = 0; i &lt; nready; i++) {            if (!(ep[i].events &amp; EPOLLIN))                continue;            if (ep[i].data.fd == listenfd) {                clilen = sizeof(cliaddr);                connfd = Accept(listenfd, (struct sockaddr *) &amp;cliaddr, &amp;clilen);                printf(&quot;received from %s at PORT %d\n                       &quot;, inet_ntop(AF_INET, &amp;cliaddr.sin_addr, str, sizeof(str)), ntohs(cliaddr.sin_port));                for (j = 0; j &lt; OPEN_MAX; j++)                    if (client[j] &lt; 0) {                        client[j] = connfd; /* save descriptor */                        break;                    }                if (j == OPEN_MAX)                    perr_exit(&quot;too many clients&quot;);                if (j &gt; maxi)                    maxi = j; /* max index in client[] array */                tep.events = EPOLLIN;                tep.data.fd = connfd;                res = epoll_ctl(efd, EPOLL_CTL_ADD, connfd, &amp;tep);                if (res == -1)                    perr_exit(&quot;epoll_ctl&quot;);            } else {                sockfd = ep[i].data.fd;                n = Read(sockfd, buf, MAXLINE);                if (n == 0) {                    for (j = 0; j &lt;= maxi; j++) {                        if (client[j] == sockfd) {                            client[j] = -1;                            break;                        }                    }                    res = epoll_ctl(efd, EPOLL_CTL_DEL, sockfd, NULL);                    if (res == -1)                        perr_exit(&quot;epoll_ctl&quot;);                    Close(sockfd);                    printf(&quot;client[%d] closed connection\n&quot;, j);                } else {                    for (j = 0; j &lt; n; j++)                        buf[j] = toupper(buf[j]);                    Writen(sockfd, buf, n);                }            }        }    }    close(listenfd);    close(efd);    return 0;}</code></pre><h3 id="10-3-4-工作模式"><a href="#10-3-4-工作模式" class="headerlink" title="10.3.4 工作模式"></a>10.3.4 工作模式</h3><p>epoll对文件描述符的操作有两种模式:</p><ul><li><p><strong>LT(level trigger)水平触发(默认模式)</strong></p><p>LT(level triggered)是缺省的工作方式，并且<strong>同时支持block和no-block socket</strong>.在这种做法中，内核告诉你一个文件描述符是否就绪了，然后你可以对这个就绪的fd进行IO操作。如果你不作任何操作，<strong>内核还是会继续通知你的</strong></p></li><li><p><strong>ET(edge trigger)边缘触发</strong></p><p>ET(edge-triggered)是高速工作方式，<strong>只支持no-block socket</strong>。在这种模式下，当描述符从未就绪变为就绪时，内核通过epoll告诉你。然后它会假设你知道文件描述符已经就绪，并且不会再为那个文件描述符发送更多的就绪通知，直到你做了某些操作导致那个文件描述符不再为就绪状态了(比如，你在发送，接收或者接收请求，或者发送接收的数据少于一定量时导致了一个EWOULDBLOCK 错误）。但是<strong>请注意，如果一直不对这个fd作IO操作(从而导致它再次变成未就绪)，内核不会发送更多的通知(only once)</strong></p></li></ul><h4 id="10-3-4-1-区别"><a href="#10-3-4-1-区别" class="headerlink" title="10.3.4.1 区别"></a>10.3.4.1 区别</h4><ul><li><strong>LT模式</strong>：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，<strong>应用程序可以不立即处理该事件</strong>。下次调用epoll_wait时，会再次响应应用程序并通知此事件。</li><li><strong>ET模式</strong>：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，<strong>应用程序必须立即处理该事件</strong>。如果不处理，下次调用epoll_wait时，不会再次响应应用程序并通知此事件。</li></ul><p><strong>ET模式在很大程度上减少了epoll事件被重复触发的次数，因此效率要比LT模式高。epoll工作在ET模式的时候，必须使用非阻塞套接口，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。</strong></p><h3 id="10-3-5-epoll的优点"><a href="#10-3-5-epoll的优点" class="headerlink" title="10.3.5 epoll的优点"></a>10.3.5 epoll的优点</h3><p>​        <strong>监视的描述符数量不受限制，它所支持的FD上限是最大可以打开文件的数目</strong>，这个数字一般远大于2048,举个例子,在1GB内存的机器上大约是10万左 右，具体数目可以cat /proc/sys/fs/file-max察看,一般来说这个数目和系统内存关系很大。select的最大缺点就是进程打开的fd是有数量限制的。这对于连接数量比较大的服务器来说根本不能满足。虽然也可以选择多进程的解决方案( Apache就是这样实现的)，不过虽然linux上面创建进程的代价比较小，但仍旧是不可忽视的，加上进程间数据同步远比不上线程间同步的高效，所以也不是一种完美的方案。</p><p>​        <strong>IO的效率不会随着监视fd的数量的增长而下降。epoll不同于select和poll轮询的方式，而是通过每个fd定义的回调函数来实现的。只有就绪的fd才会执行回调函数</strong>。<br>        <strong>如果没有大量的非活跃连接，epoll的效率并不会比select/poll高很多，但是当遇到大量的非活跃连接时，就会发现epoll的效率大大高于select/poll。</strong></p>]]></content>
      
      
      <categories>
          
          <category> 基础 </category>
          
          <category> Linux系统编程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> 系统编程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>9.Socket编程</title>
      <link href="/2020/04/18/9-socket%E7%BC%96%E7%A8%8B/"/>
      <url>/2020/04/18/9-socket%E7%BC%96%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<h2 id="9-1-什么是Socket"><a href="#9-1-什么是Socket" class="headerlink" title="9.1 什么是Socket　　"></a>9.1 什么是Socket　　</h2><p>socket这个词可以表示很多概念：<br>　　<strong>在TCP/IP协议中，“IP地址+TCP或UDP端口号”唯一标识网络通讯中的一个进程，“IP地址+端口号”就称为socket。</strong></p><p>​    在TCP协议中，建立连接的两个进程各自有一个socket来标识，那么这两个socket组成的socket pair就唯一标识一个连接。socket本身有“插座”的意思，因此用来描述网络连接的一对一关系。</p><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/syssocket.png" alt=""></p><h2 id="9-2-socket"><a href="#9-2-socket" class="headerlink" title="9.2 socket"></a>9.2 socket</h2><pre><code class="c">#include &lt;sys/types.h&gt; /* See NOTES */#include &lt;sys/socket.h&gt;int socket(int domain, int type, int protocol);domain:    AF_INET 这是大多数用来产生socket的协议，使用TCP或UDP来传输，用IPv4的地址    AF_INET6 与上面类似，不过是来用IPv6的地址    AF_UNIX 本地协议，使用在Unix和Linux系统上，一般都是当客户端和服务器在同一台及其上的时候使用type:    SOCK_STREAM 这个协议是按照顺序的、可靠的、数据完整的基于字节流的连接。这是一个使用最多的socket类    型，这个socket是使用TCP来进行传输。    SOCK_DGRAM 这个协议是无连接的、固定长度的传输调用。该协议是不可靠的，使用UDP来进行它的连接。    SOCK_SEQPACKET 这个协议是双线路的、可靠的连接，发送固定长度的数据包进行传输。必须把这个包完整的接受才能进行读取。    SOCK_RAW 这个socket类型提供单一的网络访问，这个socket类型使用ICMP公共协议。（ping、traceroute使用该协议）    SOCK_RDM 这个类型是很少使用的，在大部分的操作系统上没有实现，它是提供给数据链路层使用，不保证数据包的顺序protocol:    0 默认协议返回值：    成功返回一个新的文件描述符，失败返回-1，设置errno</code></pre><p>socket()打开一个网络通讯端口，如果成功的话，就像open()一样返回一个文件描述符，应用程序可以像读写文件一样用read/write在网络上收发数据，如果socket()调用出错则返回-1。<strong>对于IPv4，domain参数指定为AF_INET。对于TCP协议，type参数指定为SOCK_STREAM，表示面向流的传输协议</strong>。如果是UDP协议，则type参数指定为SOCK_DGRAM，表示面向数据报的传输协议。protocol参数的介绍从略，指定为0即可。</p><h2 id="9-3-bind"><a href="#9-3-bind" class="headerlink" title="9.3 bind"></a>9.3 bind</h2><pre><code class="c">#include &lt;sys/types.h&gt; /* See NOTES */#include &lt;sys/socket.h&gt;int bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen);sockfd：    socket文件描述符addr:    构造出IP地址加端口号addrlen:    sizeof(addr)长度返回值：    成功返回0，失败返回-1, 设置errno    </code></pre><p>​        服务器程序所监听的网络地址和端口号通常是固定不变的，客户端程序得知服务器程序的地址和端口号后就可以向服务器发起连接，因此服务器需要调用bind绑定一个固定的网络地址和端口号。<br>        <strong>bind()的作用是将参数sockfd和addr绑定在一起</strong>，使sockfd这个用于网络通讯的文件描述符监听addr所描述的地址和端口号。</p><h2 id="9-4-listen"><a href="#9-4-listen" class="headerlink" title="9.4 listen"></a>9.4 listen</h2><pre><code class="c">#include &lt;sys/types.h&gt; /* See NOTES */#include &lt;sys/socket.h&gt;int listen(int sockfd, int backlog);sockfd:    socket文件描述符backlog:    排队建立3次握手队列和刚刚建立3次握手队列的链接数和</code></pre><p>　　<strong>典型的服务器程序可以同时服务于多个客户端，当有客户端发起连接时，服务器调用的accept()返回并接受这个连接，如果有大量的客户端发起连接而服务器来不及处理，尚未accept的客户端就处于连接等待状态，listen()声明sockfd处于监听状态，并且最多允许有backlog个客户端处于连接待状态，如果接收到更多的连接请求就忽略。listen()成功返回0，失败返回-1。</strong></p><p>查看系统默认backlog</p><pre><code class="shell">cat /proc/sys/net/ipv4/tcp_max_syn_backlog</code></pre><h2 id="9-5-accept"><a href="#9-5-accept" class="headerlink" title="9.5 accept"></a>9.5 accept</h2><pre><code class="c">#include &lt;sys/types.h&gt; /* See NOTES */#include &lt;sys/socket.h&gt;int accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen);sockdf:    socket文件描述符addr:    传出参数，返回链接客户端地址信息，含IP地址和端口号addrlen:    传入传出参数（值-结果）,传入sizeof(addr)大小，函数返回时返回真正接收到地址结构体的大小返回值：    成功返回一个新的socket文件描述符，用于和客户端通信，失败返回-1，设置errno</code></pre><p>　　<strong>三方握手完成后，服务器调用accept()接受连接，如果服务器调用accept()时还没有客户端的连接请求，就阻塞等待直到有客户端连接上来</strong>。addr是一个传出参数，accept()返回时传出客户端的地址和端口号。addrlen参数是一个传入传出参数（value-result argument），传入的是调用者提供的缓冲区addr的长度以避免缓冲区溢出问题，传出的是客户端地址结构体的实际长度（有可能没有占满调用者提供的缓冲区）。如果给addr参数传NULL，表示不关心客户端的地址</p><h2 id="9-6-connect"><a href="#9-6-connect" class="headerlink" title="9.6 connect"></a>9.6 connect</h2><pre><code class="c">#include &lt;sys/types.h&gt; /* See NOTES */#include &lt;sys/socket.h&gt;int connect(int sockfd, const struct sockaddr *addr, socklen_t addrlen);sockdf:    socket文件描述符addr:    传入参数，指定服务器端地址信息，含IP地址和端口号addrlen:    传入参数,传入sizeof(addr)大小返回值：    成功返回0，失败返回-1，设置errno</code></pre><p>　　客户端需要调用connect()连接服务器，connect和bind的参数形式一致，区别在于bind的参数是自己的地址，而connect的参数是对方的地址。connect()成功返回0，出错返回-1。</p><h2 id="9-7-连接流程"><a href="#9-7-连接流程" class="headerlink" title="9.7 连接流程"></a>9.7 连接流程</h2><p>下图是基于TCP协议的客户端/服务器程序的一般流程：</p><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/systcpsocket.png" alt=""></p><p>　　<strong>服务器调用socket()、bind()、listen()完成初始化后，调用accept()阻塞等待，处于监听端口的状态，客户端调用socket()初始化后，调用connect()发出SYN段并阻塞等待服务器应答，服务器应答一个SYN-ACK段，客户端收到后从connect()返回，同时应答一个ACK段，服务器收到后从accept()返回。</strong></p><p>　　建立连接后，TCP协议提供全双工的通信服务，但是一般的客户端/服务器程序的流程是由客户端主动发起请求，服务器被动处理请求，一问一答的方式。因此，服务器从accept()返回后立刻调用read()，读socket就像读管道一样，如果没有数据到达就阻塞等待，这时客户端调用write()发送请求给服务器，服务器收到后从read()返回，对客户端的请求进行处理，在此期间客户端调用read()阻塞等待服务器的应答，服务器调用write()将处理结果发回给客户端，再次调用read()阻塞等待下一条请求，客户端收到后从read()返回，发送下一条请求，如此循环下去。</p><p>　　如果客户端没有更多的请求了，就调用close()关闭连接，就像写端关闭的管道一样，服务器的read()返回0，这样服务器就知道客户端关闭了连接，也调用close()关闭连接。注意，任何一方调用close()后，连接的两个传输方向都关闭，不能再发送数据了。如果一方调用shutdown()则连接处于半关闭状态，仍可接收对方发来的数据。</p><h2 id="9-7-server-demo"><a href="#9-7-server-demo" class="headerlink" title="9.7 server demo"></a>9.7 server demo</h2><p>　　下面通过最简单的客户端/服务器程序的实例来学习socket API。<br>　　server.c的作用是从客户端读字符，然后将每个字符转换为大写并回送给客户端。</p><pre><code class="c">/* server.c */#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/socket.h&gt;#include &lt;netinet/in.h&gt;#include &lt;arpa/inet.h&gt;#define MAXLINE 80#define SERV_PORT 8000int main(void) {    struct sockaddr_in servaddr, cliaddr;    socklen_t cliaddr_len;    int listenfd, connfd;    char buf[MAXLINE];    char str[INET_ADDRSTRLEN];    int i, n;    listenfd = socket(AF_INET, SOCK_STREAM, 0);    bzero(&amp;servaddr, sizeof(servaddr));    servaddr.sin_family = AF_INET;    servaddr.sin_addr.s_addr = htonl(INADDR_ANY);    servaddr.sin_port = htons(SERV_PORT);    bind(listenfd, (struct sockaddr *) &amp;servaddr, sizeof(servaddr));    listen(listenfd, 20);    printf(&quot;Accepting connections ...\n&quot;);    while (1) {        cliaddr_len = sizeof(cliaddr);        connfd = accept(listenfd, (struct sockaddr *) &amp;cliaddr, &amp;cliaddr_len);        n = read(connfd, buf, MAXLINE);        printf(&quot;received from %s at PORT %d\n&quot;,               inet_ntop(AF_INET, &amp;cliaddr.sin_addr, str, sizeof(str)),               ntohs(cliaddr.sin_port));        for (i = 0; i &lt; n; i++)            buf[i] = toupper(buf[i]);        write(connfd, buf, n);        close(connfd);    }}</code></pre><h2 id="9-8-client-demo"><a href="#9-8-client-demo" class="headerlink" title="9.8 client demo"></a>9.8 client demo</h2><pre><code class="c">/* client.c */#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/socket.h&gt;#include &lt;netinet/in.h&gt;#define MAXLINE 80#define SERV_PORT 8000int main(int argc, char *argv[]) {    struct sockaddr_in servaddr;    char buf[MAXLINE];    int sockfd, n;    char *str;    if (argc != 2) {        fputs(&quot;usage: ./client message\n&quot;, stderr);        exit(1);    }    str = argv[1];    sockfd = socket(AF_INET, SOCK_STREAM, 0);    bzero(&amp;servaddr, sizeof(servaddr));    servaddr.sin_family = AF_INET;    inet_pton(AF_INET, &quot;127.0.0.1&quot;, &amp;servaddr.sin_addr);    servaddr.sin_port = htons(SERV_PORT);    connect(sockfd, (struct sockaddr *) &amp;servaddr, sizeof(servaddr));    write(sockfd, str, strlen(str));    n = read(sockfd, buf, MAXLINE);    printf(&quot;Response from server:\n&quot;);    write(STDOUT_FILENO, buf, n);    close(sockfd);    return 0;}</code></pre><p>　　由于客户端不需要固定的端口号，<strong>因此不必调用bind()，客户端的端口号由内核自动分配</strong>。注意，客户端不是不允许调用bind()，只是没有必要调用bind()固定一个端口号，服务器也不是必须调用bind()，但如果服务器不调用bind()，内核会自动给服务器分配监听端口，每次启动服务器时端口号都不一样，客户端要连接服务器就会遇到麻烦。</p>]]></content>
      
      
      <categories>
          
          <category> 基础 </category>
          
          <category> Linux系统编程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> 系统编程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>8.线程同步</title>
      <link href="/2020/04/18/8-%E7%BA%BF%E7%A8%8B%E5%90%8C%E6%AD%A5/"/>
      <url>/2020/04/18/8-%E7%BA%BF%E7%A8%8B%E5%90%8C%E6%AD%A5/</url>
      
        <content type="html"><![CDATA[<p><strong>多个线程同时访问共享数据时可能会冲突</strong>。比如两个线程都要把某个全局变量增加1，这个操作在某平台需要三条指令完成：</p><ul><li>从内存读变量值到寄存器</li><li>寄存器的值加1</li><li>将寄存器的值写回内存</li></ul><p>假设两个线程在多处理器平台上同时执行这三条指令，则可能导致下图所示的结果，最后变量只加了一次而非两次。</p><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/systhread.corrupt.png" alt=""></p><h2 id="9-1-线程为什么要同步"><a href="#9-1-线程为什么要同步" class="headerlink" title="9.1 线程为什么要同步"></a>9.1 线程为什么要同步</h2><ul><li>多个线程都可对共享资源操作</li><li>线程操作共享资源的先后顺序不确定</li><li>处理器对存储器的操作一般不是原子操作</li></ul><h2 id="9-2-互斥量"><a href="#9-2-互斥量" class="headerlink" title="9.2 互斥量"></a>9.2 互斥量</h2><h3 id="7-2-1-临界区（Critical-Section）"><a href="#7-2-1-临界区（Critical-Section）" class="headerlink" title="7.2.1 临界区（Critical Section）"></a>7.2.1 临界区（Critical Section）</h3><p><strong>保证在某一时刻只有一个线程能访问数据的简便办法。在任意时刻只允许一个线程对共享资源进行访问</strong>。如果有多个线程试图同时访问临界区，那么 在有一个线程进入后其他所有试图访问此临界区的线程将被挂起，并一直持续到进入临界区的线程离开。临界区在被释放后，其他线程可以继续抢占，并以此达到用原子方式操作共享资源的目的。</p><h3 id="7-2-2-临界区的选定"><a href="#7-2-2-临界区的选定" class="headerlink" title="7.2.2 临界区的选定"></a>7.2.2 临界区的选定</h3><p><strong>临界区的选定因尽可能小，如果选定太大会影响程序的并行处理性能。</strong></p><h3 id="7-2-3-mute函数"><a href="#7-2-3-mute函数" class="headerlink" title="7.2.3 mute函数"></a>7.2.3 mute函数</h3><pre><code class="c">#include &lt;pthread.h&gt;pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;int pthread_mutex_destroy(pthread_mutex_t *mutex);int pthread_mutex_init(pthread_mutex_t *restrict mutex, const pthread_mutexattr_t *restrict attr);int pthread_mutex_lock(pthread_mutex_t *mutex);int pthread_mutex_trylock(pthread_mutex_t *mutex); 尝试拿锁 不堵塞int pthread_mutex_unlock(pthread_mutex_t *mutex);</code></pre><h4 id="7-2-3-1-demo"><a href="#7-2-3-1-demo" class="headerlink" title="7.2.3.1 demo"></a>7.2.3.1 demo</h4><pre><code class="c">#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;pthread.h&gt;#define NLOOP 5000int counter; /* incremented by threads */pthread_mutex_t counter_mutex = PTHREAD_MUTEX_INITIALIZER;void *doit(void *);int main(int argc, char **argv){    pthread_t tidA, tidB;    pthread_create(&amp;tidA, NULL, doit, NULL);    pthread_create(&amp;tidB, NULL, doit, NULL);/* wait for both threads to terminate */    pthread_join(tidA, NULL);    pthread_join(tidB, NULL);    return 0;}void *doit(void *vptr){    int i, val;    for (i = 0; i &lt; NLOOP; i++) {        pthread_mutex_lock(&amp;counter_mutex);//加锁        val = counter;        printf(&quot;%x: %d\n&quot;, (unsigned int)pthread_self(), val + 1);        counter = val + 1;        pthread_mutex_unlock(&amp;counter_mutex);//解锁    }    return NULL;}</code></pre><h3 id="7-2-4-死锁"><a href="#7-2-4-死锁" class="headerlink" title="7.2.4 死锁"></a>7.2.4 死锁</h3><ul><li>同一个线程在拥有A锁的情况下再次请求获得A锁</li><li>线程一拥有A锁，请求获得B锁；线程二拥有B锁，请求获得A锁</li></ul><h3 id="7-2-5-读写锁"><a href="#7-2-5-读写锁" class="headerlink" title="7.2.5 读写锁"></a>7.2.5 读写锁</h3><p><strong>读共享，写独占</strong></p><pre><code class="c">pthread_rwlock_tpthread_rwlock_initpthread_rwlock_destroypthread_rwlock_rdlockpthread_rwlock_wrlockpthread_rwlock_tryrdlockpthread_rwlock_trywrlockpthread_rwlock_unlock</code></pre><h4 id="7-2-5-1-demo"><a href="#7-2-5-1-demo" class="headerlink" title="7.2.5.1 demo"></a>7.2.5.1 demo</h4><pre><code class="c">#include &lt;stdio.h&gt;#include &lt;pthread.h&gt;int counter;pthread_rwlock_t rwlock;//3个线程不定时写同一全局资源，5个线程不定时读同一全局资源void *th_write(void *arg) {    int t;    while (1) {        pthread_rwlock_wrlock(&amp;rwlock);        t = counter;        usleep(100);        printf(&quot;write %x : counter=%d ++counter=%d\n&quot;, (int) pthread_self(), t, ++counter);        pthread_rwlock_unlock(&amp;rwlock);        usleep(100);    }}void *th_read(void *arg) {    while (1) {        pthread_rwlock_rdlock(&amp;rwlock);        printf(&quot;read %x : %d\n&quot;, (int) pthread_self(), counter);        pthread_rwlock_unlock(&amp;rwlock);        usleep(100);    }}int main(void) {    int i;    pthread_t tid[8];    pthread_rwlock_init(&amp;rwlock, NULL);    for (i = 0; i &lt; 3; i++)        pthread_create(&amp;tid[i], NULL, th_write, NULL);    for (i = 0; i &lt; 5; i++)        pthread_create(&amp;tid[i + 3], NULL, th_read, NULL);    pthread_rwlock_destroy(&amp;rwlock);    for (i = 0; i &lt; 8; i++)        pthread_join(tid[i], NULL);    return 0;}</code></pre><h2 id="9-3-条件变量"><a href="#9-3-条件变量" class="headerlink" title="9.3 条件变量"></a>9.3 条件变量</h2><p>　　线程间的同步还有这样一种情况：线程A需要等某个条件成立才能继续往下执行，现在这个条件不成立，线程A就阻塞等待，而线程B在执行过程中使这个条件成立了，就唤醒线程A继续执行。在pthread库中通过条件变量（Condition Variable）来阻塞等待一个条件，或者唤醒等待这个条件的线程。Condition Variable用pthread_cond_t类型的变量表示，可以这样初始化和销毁：</p><pre><code class="c">#include &lt;pthread.h&gt;int pthread_cond_destroy(pthread_cond_t *cond);int pthread_cond_init(pthread_cond_t *restrict cond,const pthread_condattr_t *restrict attr);pthread_cond_t cond = PTHREAD_COND_INITIALIZER;</code></pre><p><strong>返回值：成功返回0，失败返回错误号。</strong></p><p>和Mutex的初始化和销毁类似，pthread_cond_init函数初始化一个Condition Variable，attr参数为NULL则表示缺省属性，pthread_cond_destroy函数销毁一个Condition Variable。如果Condition Variable是静态分配的，也可以用宏定义PTHEAD_COND_INITIALIZER初始化，相当于用pthread_cond_init函数初始化并且attr参数为NULL。Condition Variable的操作可以用下列函数：</p><pre><code class="c">#include &lt;pthread.h&gt;int pthread_cond_timedwait(pthread_cond_t *restrict cond,pthread_mutex_t *restrict mutex,const struct timespec *restrict abstime);int pthread_cond_wait(pthread_cond_t *restrict cond,pthread_mutex_t *restrict mutex);int pthread_cond_broadcast(pthread_cond_t *cond);int pthread_cond_signal(pthread_cond_t *cond);</code></pre><p><strong>返回值：成功返回0，失败返回错误号。</strong></p><p><strong>可见，一个Condition Variable总是和一个Mutex搭配使用的</strong>。一个线程可以调用pthread_cond_wait在一个Condition Variable上阻塞等待，这个函数做以下三步操作：</p><ul><li>释放Mutex</li><li>阻塞等待</li><li>当被唤醒时，重新获得Mutex并返回</li></ul><p>pthread_cond_timedwait函数还有一个额外的参数可以设定等待超时，如果到达了abstime所指定的时刻仍然没有别的线程来唤醒当前线程，就返回ETIMEDOUT。一个线程可以调用pthread_cond_signal唤醒在某个Condition Variable上等待的另一个线程，也可以调用pthread_cond_broadcast唤醒在这个Condition Variable上等待的所有线程。</p><p>下面的程序演示了一个生产者-消费者的例子，生产者生产一个结构体串在链表的表头上，消费者从表头取走结构体。</p><h3 id="9-3-1-demo"><a href="#9-3-1-demo" class="headerlink" title="9.3.1 demo"></a>9.3.1 demo</h3><pre><code class="c">#include &lt;stdlib.h&gt;#include &lt;pthread.h&gt;#include &lt;stdio.h&gt;struct msg {    struct msg *next;    int num;};struct msg *head;pthread_cond_t has_product = PTHREAD_COND_INITIALIZER;pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER;void *consumer(void *p){    struct msg *mp;    for (;;) {        pthread_mutex_lock(&amp;lock);        while (head == NULL)            pthread_cond_wait(&amp;has_product, &amp;lock);        mp = head;        head = mp-&gt;next;        pthread_mutex_unlock(&amp;lock);        printf(&quot;Consume %d\n&quot;, mp-&gt;num);        free(mp);        sleep(rand() % 5);    }}void *producer(void *p){    struct msg *mp;    for (;;) {        mp = malloc(sizeof(struct msg));        mp-&gt;num = rand() % 1000 + 1;        printf(&quot;Produce %d\n&quot;, mp-&gt;num);        pthread_mutex_lock(&amp;lock);        mp-&gt;next = head;        head = mp;        pthread_mutex_unlock(&amp;lock);        pthread_cond_signal(&amp;has_product);        sleep(rand() % 5);    }}int main(int argc, char *argv[]) {    pthread_t pid, cid;      srand(time(NULL));    pthread_create(&amp;pid, NULL, producer, NULL);    pthread_create(&amp;cid, NULL, consumer, NULL);    pthread_join(pid, NULL);    pthread_join(cid, NULL);    return 0;}</code></pre><h2 id="9-4-信号量"><a href="#9-4-信号量" class="headerlink" title="9.4 信号量"></a>9.4 信号量</h2><p>Mutex变量是非0即1的，可看作一种资源的可用数量，初始化时Mutex是1，表示有一个可用资源，加锁时获得该资源，将Mutex减到0，表示不再有可用资源，解锁时释放该资源，将Mutex重新加到1，表示又有了一个可用资源。</p><p><strong>信号量（Semaphore）和Mutex类似，表示可用资源的数量，和Mutex不同的是这个数量可以大于1。</strong></p><pre><code class="c">#include &lt;semaphore.h&gt;int sem_init(sem_t *sem, int pshared, unsigned int value);int sem_wait(sem_t *sem);int sem_trywait(sem_t *sem);int sem_post(sem_t * sem);int sem_destroy(sem_t * sem);</code></pre><p>semaphore变量的类型为sem_t，sem_init()初始化一个semaphore变量，value参数表示可用资源的数量，pshared参数为0表示信号量用于同一进程的线程间同步。</p><p>在用完semaphore变量之后应该调用sem_destroy()释放与semaphore相关的资源。</p><p><strong>调用sem_wait()可以获得资源，使semaphore的值减1，如果调用sem_wait()时semaphore的值已经是0，则挂起等待</strong>。如果不希望挂起等待，可以调用sem_trywait()。调用sem_post()可以释放资源，使semaphore的值加1，同时唤醒挂起等待的线程。</p><h3 id="9-4-1-demo"><a href="#9-4-1-demo" class="headerlink" title="9.4.1 demo"></a>9.4.1 demo</h3><p>上一节生产者－消费者的例子是基于链表的，其空间可以动态分配，现在基于固定大小的环形队列重写这个程序</p><pre><code class="c">#include &lt;stdlib.h&gt;#include &lt;pthread.h&gt;#include &lt;stdio.h&gt;#include &lt;semaphore.h&gt;#include &lt;time.h&gt;#include &lt;zconf.h&gt;#define NUM 5int queue[NUM];sem_t blank_number, product_number;void *producer(void *arg){    int p = 0;    while (1) {        sem_wait(&amp;blank_number);        queue[p] = rand() % 1000 + 1;        printf(&quot;Produce %d\n&quot;, queue[p]);        sem_post(&amp;product_number);        p = (p+1)%NUM;        sleep(rand()%5);    }}void *consumer(void *arg){    int c = 0;    while (1) {        sem_wait(&amp;product_number);        printf(&quot;Consume %d\n&quot;, queue[c]);        queue[c] = 0;        sem_post(&amp;blank_number);        c = (c+1)%NUM;        sleep(rand()%5);    }}int main(int argc, char *argv[]){    pthread_t pid, cid;    printf(&quot;Hello&quot;);    sem_init(&amp;blank_number, 0, NUM);    sem_init(&amp;product_number, 0, 0);    pthread_create(&amp;pid, NULL, producer, NULL);    pthread_create(&amp;cid, NULL, consumer, NULL);    pthread_join(pid, NULL);    pthread_join(cid, NULL);    sem_destroy(&amp;blank_number);    sem_destroy(&amp;product_number);    return 0;}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 基础 </category>
          
          <category> Linux系统编程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> 系统编程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>7.线程</title>
      <link href="/2020/04/16/7-%E7%BA%BF%E7%A8%8B/"/>
      <url>/2020/04/16/7-%E7%BA%BF%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<h2 id="7-1-什么是线程"><a href="#7-1-什么是线程" class="headerlink" title="7.1 什么是线程"></a>7.1 什么是线程</h2><ul><li><strong>轻量级进程(light-weight process)，也有PCB,创建线程使用的底层函数和进程一样，都是clone</strong></li><li><strong>从内核里看进程和线程是一样的，都有各自不同的PCB，但是PCB中指向内存资源的三级页表是相同的 公用虚拟地址页面</strong></li><li><strong>在linux下，线程最是小的执行单位；进程是最小的分配资源单位</strong></li></ul><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/systhread.png" alt=""></p><h2 id="7-2-线程间共享资源"><a href="#7-2-线程间共享资源" class="headerlink" title="7.2 线程间共享资源"></a>7.2 线程间共享资源</h2><ul><li><strong>文件描述符表</strong></li><li><strong>每种信号的处理方式</strong></li><li><strong>当前工作目录</strong></li><li><strong>用户ID和组ID</strong></li><li><strong>堆内存地址空间</strong></li></ul><h2 id="7-3-线程间非共享资源"><a href="#7-3-线程间非共享资源" class="headerlink" title="7.3 线程间非共享资源"></a>7.3 线程间非共享资源</h2><ul><li><strong>线程id</strong></li><li><strong>处理器现场和栈指针(内核栈)</strong></li><li><strong>独立的栈空间(用户空间栈)</strong></li><li><strong>errno变量</strong></li><li><strong>信号屏蔽字</strong></li><li><strong>调度优先级</strong></li></ul><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/systhread1.png" alt=""></p><h2 id="7-4-优缺点"><a href="#7-4-优缺点" class="headerlink" title="7.4 优缺点"></a>7.4 优缺点</h2><h3 id="7-4-1-优点"><a href="#7-4-1-优点" class="headerlink" title="7.4.1 优点"></a>7.4.1 优点</h3><ul><li>提高程序的并发性</li><li>开销小，不用重新分配内存</li><li>通信和共享数据方便</li></ul><h3 id="7-4-2-缺点"><a href="#7-4-2-缺点" class="headerlink" title="7.4.2 缺点"></a>7.4.2 缺点</h3><ul><li>线程不稳定（库函数实现）</li><li>线程调试比较困难（gdb支持不好）</li><li>线程无法使用unix经典事件，例如信</li></ul><h2 id="7-5-相关函数"><a href="#7-5-相关函数" class="headerlink" title="7.5 相关函数"></a>7.5 相关函数</h2><h3 id="7-5-1-创建线程"><a href="#7-5-1-创建线程" class="headerlink" title="7.5.1 创建线程"></a>7.5.1 创建线程</h3><p> <strong>pthread_create 创建线程</strong></p><pre><code class="c">#include &lt;pthread.h&gt;int pthread_create(pthread_t *thread, const pthread_attr_t *attr,void (start_routine) (void *), void *arg);pthread_t *thread:传递一个pthread_t变量地址进来，用于保存新线程的tid（线程ID）const pthread_attr_t *attr:线程属性设置，如使用默认属性，则传NULLvoid (start_routine) (void *):函数指针，指向新线程应该加载执行的函数模块void *arg:指定线程将要加载调用的那个函数的参数</code></pre><p><strong>返回值:成功返回0，失败返回错误号。</strong></p><h4 id="7-5-1-1-demo"><a href="#7-5-1-1-demo" class="headerlink" title="7.5.1.1 demo"></a>7.5.1.1 demo</h4><pre><code class="c">#include &lt;stdio.h&gt;#include &lt;string.h&gt;#include &lt;stdlib.h&gt;#include &lt;pthread.h&gt;#include &lt;unistd.h&gt;pthread_t ntid;void printids(const char *s){    pid_t      pid;    pthread_t  tid;    pid = getpid();    tid = pthread_self();    printf(&quot;%s pid %u tid %u (0x%x)\n&quot;, s, (unsigned int)pid,           (unsigned int)tid, (unsigned int)tid);}void *thr_fn(void *arg){    printids(arg);    return NULL;}int main(void){    int err;    err = pthread_create(&amp;ntid, NULL, thr_fn, &quot;new thread: &quot;);    if (err != 0) {        fprintf(stderr, &quot;can&#39;t create thread: %s\n&quot;, strerror(err));        exit(1);    }    printids(&quot;main thread:&quot;);    sleep(1);    return 0;}</code></pre><h3 id="7-5-2-终止线程"><a href="#7-5-2-终止线程" class="headerlink" title="7.5.2 终止线程"></a>7.5.2 终止线程</h3><p>如果需要只终止某个线程而不终止整个进程，可以有三种方法：</p><ul><li><strong>从线程函数return。这种方法对主线程不适用，从main函数return相当于调用exit</strong></li><li><strong>一个线程可以调用pthread_cancel终止同一进程中的另一个线程。</strong></li><li><strong>线程可以调用pthread_exit终止自己。</strong></li></ul><h4 id="7-5-2-1-pthread-join"><a href="#7-5-2-1-pthread-join" class="headerlink" title="7.5.2.1 pthread_join"></a>7.5.2.1 pthread_join</h4><pre><code class="c">#include &lt;pthread.h&gt;int pthread_join(pthread_t thread, void **value_ptr);</code></pre><p><strong>返回值：成功返回0，失败返回错误号</strong></p><p><strong>调用该函数的线程将挂起等待，直到id为thread的线程终止</strong>。thread线程以不同的方法终止，通过pthread_join得到的终止状态是不同的，总结如下：</p><ul><li>如果thread线程通过return返回，value_ptr所指向的单元里存放的是thread线程函数的返回值。</li><li>如果thread线程被别的线程调用pthread_cancel异常终止掉，value_ptr所指向的单元里存放的是常数PTHREAD_CANCELED。</li><li>如果thread线程是自己调用pthread_exit终止的，value_ptr所指向的单元存放的是传给pthread_exit的参数。</li></ul><p>如果对thread线程的终止状态不感兴趣，可以传NULL给value_ptr参数。</p><h4 id="7-5-2-2-demo"><a href="#7-5-2-2-demo" class="headerlink" title="7.5.2.2 demo"></a>7.5.2.2 demo</h4><pre><code class="c">#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;pthread.h&gt;#include &lt;unistd.h&gt;void *thr_fn1(void *arg){    printf(&quot;thread 1 returning\n&quot;);    return (void *)1;}void *thr_fn2(void *arg){    printf(&quot;thread 2 exiting\n&quot;);    pthread_exit((void *)2);}void *thr_fn3(void *arg){    while(1) {        printf(&quot;thread 3 writing\n&quot;);        sleep(1);    }}int main(void){    pthread_t   tid;    void        *tret;    pthread_create(&amp;tid, NULL, thr_fn1, NULL);    pthread_join(tid, &amp;tret);    printf(&quot;thread 1 exit code %d\n&quot;, (int)tret);    pthread_create(&amp;tid, NULL, thr_fn2, NULL);    pthread_join(tid, &amp;tret);    printf(&quot;thread 2 exit code %d\n&quot;, (int)tret);    pthread_create(&amp;tid, NULL, thr_fn3, NULL);    sleep(3);    pthread_cancel(tid);    pthread_join(tid, &amp;tret);    printf(&quot;thread 3 exit code %d\n&quot;, (int)tret);    return 0;}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 基础 </category>
          
          <category> Linux系统编程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> 系统编程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>6.信号</title>
      <link href="/2020/04/16/6-%E4%BF%A1%E5%8F%B7/"/>
      <url>/2020/04/16/6-%E4%BF%A1%E5%8F%B7/</url>
      
        <content type="html"><![CDATA[<h2 id="6-1-信号概念"><a href="#6-1-信号概念" class="headerlink" title="6.1 信号概念"></a>6.1 信号概念</h2><p><strong>处理时间时发送的不同类型的通知</strong></p><h3 id="6-1-1-编号"><a href="#6-1-1-编号" class="headerlink" title="6.1.1 编号"></a>6.1.1 编号</h3><pre><code class="shell">ken@Ken:~$ kill -l 1) SIGHUP     2) SIGINT     3) SIGQUIT     4) SIGILL     5) SIGTRAP 6) SIGABRT     7) SIGBUS     8) SIGFPE     9) SIGKILL    10) SIGUSR111) SIGSEGV    12) SIGUSR2    13) SIGPIPE    14) SIGALRM    15) SIGTERM16) SIGSTKFLT    17) SIGCHLD    18) SIGCONT    19) SIGSTOP    20) SIGTSTP21) SIGTTIN    22) SIGTTOU    23) SIGURG    24) SIGXCPU    25) SIGXFSZ26) SIGVTALRM    27) SIGPROF    28) SIGWINCH    29) SIGIO    30) SIGPWR31) SIGSYS    34) SIGRTMIN    35) SIGRTMIN+1    36) SIGRTMIN+2    37) SIGRTMIN+338) SIGRTMIN+4    39) SIGRTMIN+5    40) SIGRTMIN+6    41) SIGRTMIN+7    42) SIGRTMIN+843) SIGRTMIN+9    44) SIGRTMIN+10    45) SIGRTMIN+11    46) SIGRTMIN+12    47) SIGRTMIN+1348) SIGRTMIN+14    49) SIGRTMIN+15    50) SIGRTMAX-14    51) SIGRTMAX-13    52) SIGRTMAX-1253) SIGRTMAX-11    54) SIGRTMAX-10    55) SIGRTMAX-9    56) SIGRTMAX-8    57) SIGRTMAX-758) SIGRTMAX-6    59) SIGRTMAX-5    60) SIGRTMAX-4    61) SIGRTMAX-3    62) SIGRTMAX-263) SIGRTMAX-1    64) SIGRTMAX    </code></pre><h3 id="6-1-2-动作类型"><a href="#6-1-2-动作类型" class="headerlink" title="6.1.2 动作类型"></a>6.1.2 动作类型</h3><ul><li><strong>Term表示终止当前进程.</strong></li><li><strong>Core表示终止当前进程并且Core Dump（Core Dump 用于gdb调试）.</strong></li><li><strong>Ign表示忽略该信号.</strong></li><li><strong>Stop表示停止,暂停当前进程.</strong> </li><li><strong>Cont表示继续执行先前停止的进程,继续</strong></li></ul><h4 id="6-1-2-1-默认动作"><a href="#6-1-2-1-默认动作" class="headerlink" title="6.1.2.1 默认动作"></a>6.1.2.1 默认动作</h4><table><thead><tr><th align="center">Signal</th><th align="center">Value</th><th align="center">Action</th><th align="center">Comment</th></tr></thead><tbody><tr><td align="center">SIGHUP</td><td align="center">1</td><td align="center">Term</td><td align="center">Hangup detected on controlling terminal or death of controlling process</td></tr><tr><td align="center">SIGINT</td><td align="center">2</td><td align="center">Term</td><td align="center">Interrupt from keyboard</td></tr><tr><td align="center">SIGQUIT</td><td align="center">3</td><td align="center">Core</td><td align="center">Quit from keyboard</td></tr><tr><td align="center">SIGILL</td><td align="center">4</td><td align="center">Core</td><td align="center">Illegal Instruction</td></tr><tr><td align="center">SIGABRT</td><td align="center">6</td><td align="center">Core</td><td align="center">Abort signal from abort(3)</td></tr><tr><td align="center">SIGFPE</td><td align="center">8</td><td align="center">Core</td><td align="center">Floating point exception</td></tr><tr><td align="center">SIGKILL</td><td align="center">9</td><td align="center">Term</td><td align="center">Kill signal</td></tr><tr><td align="center">SIGSEGV</td><td align="center">11</td><td align="center">Core</td><td align="center">Invalid memory reference</td></tr><tr><td align="center">SIGPIPE</td><td align="center">13</td><td align="center">Term</td><td align="center">Broken pipe: write to pipe with no readers</td></tr><tr><td align="center">SIGALRM</td><td align="center">14</td><td align="center">Term</td><td align="center">Timer signal from alarm(2)</td></tr><tr><td align="center">SIGTERM</td><td align="center">15</td><td align="center">Term</td><td align="center">Termination signal</td></tr><tr><td align="center">SIGUSR1</td><td align="center">30,10,16</td><td align="center">Term</td><td align="center">User-defined signal 1</td></tr><tr><td align="center">SIGUSR2</td><td align="center">31,12,17</td><td align="center">Term</td><td align="center">User-defined signal 2</td></tr><tr><td align="center">SIGCHLD</td><td align="center">20,17,18</td><td align="center">Ign</td><td align="center">Child stopped or terminated</td></tr><tr><td align="center">SIGCONT</td><td align="center">19,18,25</td><td align="center">Cont</td><td align="center">Continue if stopped</td></tr><tr><td align="center">SIGSTOP</td><td align="center">17,19,23</td><td align="center">Stop</td><td align="center">Stop process</td></tr><tr><td align="center">SIGTSTP</td><td align="center">18,20,24</td><td align="center">Stop</td><td align="center">Stop typed at tty</td></tr><tr><td align="center">SIGTTIN</td><td align="center">21,21,26</td><td align="center">Stop</td><td align="center">tty input for background process</td></tr><tr><td align="center">SIGTTOU</td><td align="center">22,22,27</td><td align="center">Stop</td><td align="center">tty output for background process</td></tr></tbody></table><h3 id="6-1-2-详细说明"><a href="#6-1-2-详细说明" class="headerlink" title="6.1.2 详细说明"></a>6.1.2 详细说明</h3><pre><code class="c">1) SIGHUP:当用户退出shell时，由该shell启动的所有进程将收到这个信号，默认动作为终止进程2）SIGINT：当用户按下了&lt;Ctrl+C&gt;组合键时，用户终端向正在运行中的由该终端启动的程序发出此信号。默认动作为终止里程。3）SIGQUIT：当用户按下&lt;ctrl+\&gt;组合键时产生该信号，用户终端向正在运行中的由该终端启动的程序发出些信号。默认动作为终止进程。4）SIGILL：CPU检测到某进程执行了非法指令。默认动作为终止进程并产生core文件5）SIGTRAP：该信号由断点指令或其他 trap指令产生。默认动作为终止里程 并产生core文件。6) SIGABRT:调用abort函数时产生该信号。默认动作为终止进程并产生core文件。7）SIGBUS：非法访问内存地址，包括内存对齐出错，默认动作为终止进程并产生core文件。8）SIGFPE：在发生致命的运算错误时发出。不仅包括浮点运算错误，还包括溢出及除数为0等所有的算法错误。默认动作为终止进程并产生core文件。9）SIGKILL：无条件终止进程。本信号不能被忽略，处理和阻塞。默认动作为终止进程。它向系统管理员提供了可以杀死任何进程的方法。10）SIGUSE1：用户定义 的信号。即程序员可以在程序中定义并使用该信号。默认动作为终止进程。11）SIGSEGV：指示进程进行了无效内存访问。默认动作为终止进程并产生core文件。12）SIGUSR2：这是另外一个用户自定义信号 ，程序员可以在程序中定义 并使用该信号。默认动作为终止进程。113）SIGPIPE：Broken pipe向一个没有读端的管道写数据。默认动作为终止进程。14) SIGALRM:定时器超时，超时的时间 由系统调用alarm设置。默认动作为终止进程。15）SIGTERM：程序结束信号，与SIGKILL不同的是，该信号可以被阻塞和终止。通常用来要示程序正常退出。执行shell命令Kill时，缺省产生这个信号。默认动作为终止进程。16）SIGCHLD：子进程结束时，父进程会收到这个信号。默认动作为忽略这个信号。17）SIGCONT：停止进程的执行。信号不能被忽略，处理和阻塞。默认动作为终止进程。18）SIGTTIN：后台进程读终端控制台。默认动作为暂停进程。19）SIGSTOP：停止进程的运行。按下&lt;ctrl+z&gt;组合键时发出这个信号。默认动作为暂停进程。21）SIGTTOU:该信号类似于SIGTTIN，在后台进程要向终端输出数据时发生。默认动作为暂停进程。22）SIGURG：套接字上有紧急数据时，向当前正在运行的进程发出些信号，报告有紧急数据到达。如网络带外数据到达，默认动作为忽略该信号。23）SIGXFSZ：进程执行时间超过了分配给该进程的CPU时间 ，系统产生该信号并发送给该进程。默认动作为终止进程。24）SIGXFSZ：超过文件的最大长度设置。默认动作为终止进程。25）SIGVTALRM：虚拟时钟超时时产生该信号。类似于SIGALRM，但是该信号只计算该进程占用CPU的使用时间。默认动作为终止进程。26）SGIPROF：类似于SIGVTALRM，它不公包括该进程占用CPU时间还包括执行系统调用时间。默认动作为终止进程。27）SIGWINCH：窗口变化大小时发出。默认动作为忽略该信号。28）SIGIO：此信号向进程指示发出了一个异步IO事件。默认动作为忽略。29）SIGPWR：关机。默认动作为终止进程。30）SIGSYS：无效的系统调用。默认动作为终止进程并产生core文件。31）SIGRTMIN～（64）SIGRTMAX：LINUX的实时信号，它们没有固定的含义（可以由用户自定义）。所有的实时信号的默认动作都为终止进程。</code></pre><h2 id="6-2-kill"><a href="#6-2-kill" class="headerlink" title="6.2 kill"></a>6.2 kill</h2><p><strong>kill信号原型</strong></p><pre><code class="c">int kill(pid_t pid, int sig)pid &gt; 0sig发送给ID为pid的进程        pid == 0sig发送给与发送进程同组的所有进程        pid &lt; 0sig发送给组ID为|-pid|的进程，并且发送进程具有向其发送信号的权限        pid == -1sig发送给发送进程有权限向他们发送信号的系统上的所有进程        sig为0时，用于检测，特定为pid进程是否存在，如不存在，返回-1。sig:信号3种处理方式：    SIG_IGN 忽略    SIG_DFL 默认处理动作    a signal handling function 捕捉</code></pre><h2 id="6-3-阻塞信号"><a href="#6-3-阻塞信号" class="headerlink" title="6.3 阻塞信号"></a>6.3 阻塞信号</h2><h3 id="6-3-1-信号在内核中的表示"><a href="#6-3-1-信号在内核中的表示" class="headerlink" title="6.3.1 信号在内核中的表示"></a>6.3.1 信号在内核中的表示</h3><p><strong>实际执行信号的处理动作称为信号递达（Delivery），信号从产生到递达之间的状态，称为信号未决（Pending）</strong></p><p><strong>进程可以选择阻塞（Block）某个信号。被阻塞的信号产生时将保持在未决状态，直到进程解除对此信号的阻塞，才执行递达的动作。</strong></p><p><strong>注意，阻塞和忽略是不同的，只要信号被阻塞就不会递达，而忽略是在递达之后可选的一种处理动作。信号在内核中的表示可以看作是这样的</strong></p><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/syssign.png" alt=""></p><p><strong>每个信号都有两个标志位分别表示阻塞和未决，还有一个函数指针表示处理动作</strong>。信号产生时，内核在进程控制块中设置该信号的未决标志，直到信号递达才清除该标志。在上图的例子中，</p><ul><li><strong>SIGHUP信号未阻塞也未产生过，当它递达时执行默认处理动作。</strong></li><li><strong>SIGINT信号产生过，但正在被阻塞，所以暂时不能递达。虽然它的处理动作是忽略，但在没有解除阻塞之前不能忽略这个信号，因为进程仍有机会改变处理动作之后再解除阻塞。</strong></li><li><strong>SIGQUIT信号未产生过，一旦产生SIGQUIT信号将被阻塞，它的处理动作是用户自定义函数sighandler。</strong></li></ul><h3 id="6-3-2-信号集操作函数"><a href="#6-3-2-信号集操作函数" class="headerlink" title="6.3.2 信号集操作函数"></a>6.3.2 信号集操作函数</h3><p>sigset_t类型对于每种信号用一个bit表示“有效”或“无效”状态，至于这个类型内部如何存储这些bit则依赖于系统实现，从使用者的角度是不必关心的，使用者只能调用以下函数来操作sigset_t变量，而不应该对它的内部数据做任何解释，比如用printf直接打印sigset_t变量是没有意义的。</p><pre><code class="c">int sigemptyset(sigset_t *set)int sigfillset(sigset_t *set)int sigaddset(sigset_t *set, int signo)int sigdelset(sigset_t *set, int signo)int sigismember(const sigset_t *set, int signo)</code></pre><p><strong>这四个函数都是成功返回0，出错返回-1。</strong></p><p><strong>注意，在使用sigset_t类型的变量之前，一定要调用sigemptyset或sigfillset做初始化，使信号集处于确定的状态。初始化sigset_t变量之后就可以在调用sigaddset和sigdelset在该信号集中添加或删除某种有效信号。</strong></p><h3 id="6-3-3-sigprocmask"><a href="#6-3-3-sigprocmask" class="headerlink" title="6.3.3 sigprocmask"></a>6.3.3 sigprocmask</h3><p>调用函数sigprocmask可以读取或更改进程的信号屏蔽字。</p><pre><code>#include &lt;signal.h&gt;int sigprocmask(int how, const sigset_t *set, sigset_t *oset);</code></pre><p><strong>返回值：若成功则为0，若出错则为-1</strong></p><p>如果oset是非空指针，则读取进程的当前信号屏蔽字通过oset参数传出。如果set是非空指针，则更改进程的信号屏蔽字，参数how指示如何更改。如果oset和set都是非空指针，则先将原来的信号屏蔽字备份到oset里，然后根据set和how参数更改信号屏蔽字。假设当前的信号屏蔽字为mask，下表说明了how参数的可选值。</p><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/syssgnmask.png" alt=""></p><h3 id="6-3-4-sigpending"><a href="#6-3-4-sigpending" class="headerlink" title="6.3.4 sigpending"></a>6.3.4 sigpending</h3><p>sigpending读取当前进程的未决信号集，通过set参数传出。</p><pre><code class="c">#include &lt;signal.h&gt;int sigpending(sigset_t *set);</code></pre><p><strong>调用成功则返回0，出错则返回-1</strong></p><h3 id="6-3-5-demo"><a href="#6-3-5-demo" class="headerlink" title="6.3.5 demo"></a>6.3.5 demo</h3><pre><code class="c">#include &lt;signal.h&gt;#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;void printsigset(const sigset_t *set){    int i;    for (i = 1; i &lt; 32; i++)        if (sigismember(set, i) == 1)            putchar(&#39;1&#39;);        else            putchar(&#39;0&#39;);    puts(&quot;&quot;);}int main(void){    sigset_t s, p;    sigemptyset(&amp;s);    sigaddset(&amp;s, SIGINT);    sigprocmask(SIG_BLOCK, &amp;s, NULL);    while (1) {        sigpending(&amp;p);        printsigset(&amp;p);        sleep(1);    }    return 0;}</code></pre><p>程序运行时，每秒钟把各信号的未决状态打印一遍，由于我们阻塞了SIGINT信号，按Ctrl-C将会使SIGINT信号处于未决状态，按Ctrl-\仍然可以终止程序，因为SIGQUIT信号没有阻塞。</p><pre><code class="shell">$ ./a.out 00000000000000000000000000000000000000000000000000000000000000（这时按Ctrl-C）01000000000000000000000000000000100000000000000000000000000000（这时按Ctrl-\）Quit (core dumped)</code></pre><h2 id="6-4-信号捕捉"><a href="#6-4-信号捕捉" class="headerlink" title="6.4 信号捕捉"></a>6.4 信号捕捉</h2><h3 id="6-4-1-内核如何实现信号的捕捉"><a href="#6-4-1-内核如何实现信号的捕捉" class="headerlink" title="6.4.1 内核如何实现信号的捕捉"></a>6.4.1 内核如何实现信号的捕捉</h3><p>​        如果信号的处理动作是用户自定义函数，在信号递达时就调用这个函数，这称为捕捉信号。由于信号处理函数的代码是在用户空间的，处理过程比较复杂，举例如下：</p><ol><li>用户程序注册了SIGQUIT信号的处理函数sighandler。</li><li>当前正在执行main函数，这时发生中断或异常切换到内核态。</li><li>在中断处理完毕后要返回用户态的main函数之前检查到有信号SIGQUIT递达。</li><li>内核决定返回用户态后不是恢复main函数的上下文继续执行，而是执行sighandler函数，sighandler和main函数使用不同的堆栈空间，它们之间不存在调用和被调用的关系，是两个独立的控制流程。</li><li>sighandler函数返回后自动执行特殊的系统调用sigreturn再次进入内核态。</li><li>如果没有新的信号要递达，这次再返回用户态就是恢复main函数的上下文继续执行了。</li></ol><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/syssignalcatch.png" alt=""></p><h3 id="6-4-2-signaction"><a href="#6-4-2-signaction" class="headerlink" title="6.4.2 signaction"></a>6.4.2 signaction</h3><p>sigaction函数可以读取和修改与指定信号相关联的处理动作</p><pre><code class="c">#include &lt;signal.h&gt;int sigaction(int signo, const struct sigaction *act, struct sigaction *oact);</code></pre><p><strong>调用成功则返回0，出错则返回-1。</strong></p><p>signo是指定信号的编号。若act指针非空，则根据act修改该信号的处理动作。若oact指针非空，则通过oact传出该信号原来的处理动作。act和oact指向sigaction结构体：</p><pre><code class="c">struct sigaction {   void      (*sa_handler)(int);   /* addr of signal handler, */                                       /* or SIG_IGN, or SIG_DFL */   sigset_t sa_mask;               /* additional signals to block */   int      sa_flags;              /* signal options, Figure 10.16 */   /* alternate handler */   void     (*sa_sigaction)(int, siginfo_t *, void *);};</code></pre><p>​        将sa_handler赋值为常数SIG_IGN传给sigaction表示忽略信号，赋值为常数SIG_DFL表示执行系统默认动作，赋值为一个函数指针表示用自定义函数捕捉信号，或者说向内核注册了一个信号处理函数，该函数返回值为void，可以带一个int参数，通过参数可以得知当前信号的编号，这样就可以用同一个函数处理多种信号。显然，这也是一个回调函数，不是被main函数调用，而是被系统所调用。</p><p>​        当某个信号的处理函数被调用时，内核自动将当前信号加入进程的信号屏蔽字，当信号处理函数返回时自动恢复原来的信号屏蔽字，这样就保证了在处理某个信号时，如果这种信号再次产生，那么它会被阻塞到当前处理结束为止。如果在调用信号处理函数时，除了当前信号被自动屏蔽之外，还希望自动屏蔽另外一些信号，则用sa_mask字段说明这些需要额外屏蔽的信号，当信号处理函数返回时自动恢复原来的信号屏蔽字。</p><h3 id="6-4-3-pause"><a href="#6-4-3-pause" class="headerlink" title="6.4.3 pause"></a>6.4.3 pause</h3><p>pause函数使调用进程挂起直到有信号递达。</p><pre><code class="c">#include &lt;unistd.h&gt;int pause(void);</code></pre><p>如果信号的处理动作是终止进程，则进程终止，pause函数没有机会返回；如果信号的处理动作是忽略，则进程继续处于挂起状态，pause不返回；如果信号的处理动作是捕捉，则调用了信号处理函数之后pause返回-1，errno设置为EINTR，所以pause只有出错的返回值。错误码EINTR表示“被信号中断”</p><h3 id="6-4-4-demo"><a href="#6-4-4-demo" class="headerlink" title="6.4.4 demo"></a>6.4.4 demo</h3><pre><code class="c">#include &lt;unistd.h&gt;#include &lt;signal.h&gt;#include &lt;stdio.h&gt;void sig_alrm(int signo){    /* nothing to do */}unsigned int mysleep(unsigned int nsecs){    struct sigaction newact, oldact;    unsigned int unslept;    newact.sa_handler = sig_alrm;    sigemptyset(&amp;newact.sa_mask);    newact.sa_flags = 0;    sigaction(SIGALRM, &amp;newact, &amp;oldact);    alarm(nsecs);    pause();    unslept = alarm(0);    sigaction(SIGALRM, &amp;oldact, NULL);    return unslept;}int main(void){    while(1){        mysleep(2);        printf(&quot;Two seconds passed\n&quot;);    }    return 0;}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 基础 </category>
          
          <category> Linux系统编程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> 系统编程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>5.进程间关系</title>
      <link href="/2020/04/16/5-%E8%BF%9B%E7%A8%8B%E9%97%B4%E5%85%B3%E7%B3%BB/"/>
      <url>/2020/04/16/5-%E8%BF%9B%E7%A8%8B%E9%97%B4%E5%85%B3%E7%B3%BB/</url>
      
        <content type="html"><![CDATA[<h2 id="5-1-进程组"><a href="#5-1-进程组" class="headerlink" title="5.1 进程组"></a>5.1 进程组</h2><p><strong>一个或多个进程的集合,进程组ID是一个正整数</strong>。 用来获得当前进程进程组ID的函数</p><pre><code class="c">pid_t getpgid(pid_t pid)pid_t getpgrp(void)</code></pre><ul><li><strong>组长进程标识:其进程组ID==其进程ID</strong></li><li><strong>组长进程可以创建一个进程组，创建该进程组中的进程，然后终止,只要进程组中有一个进程存在，进程组就存在，与组长进程是否终止无关</strong></li><li><strong>进程组生存期:进程组创建到最后一个进程离开(终止或转移到另一个进程组)</strong></li><li><strong>一个进程可以为自己或子进程设置进程组ID</strong></li></ul><h3 id="5-1-1-设置进程组"><a href="#5-1-1-设置进程组" class="headerlink" title="5.1.1 设置进程组"></a>5.1.1 设置进程组</h3><pre><code class="c">int setpgid(pid_t pid, pid_t pgid)如改变子进程为新的组，应在fork后，exec前使用非root进程只能改变自己创建的子进程，或有权限操作的进程</code></pre><h4 id="5-1-1-1-demo"><a href="#5-1-1-1-demo" class="headerlink" title="5.1.1.1 demo"></a>5.1.1.1 demo</h4><pre><code class="c">#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;int main(void) {    pid_t pid;    if ((pid = fork()) &lt; 0) {        perror(&quot;fork&quot;);        exit(1);    } else if (pid == 0) {        printf(&quot;child process PID is %d\n&quot;, getpid());        printf(&quot;Group ID of child is %d\n&quot;, getpgid(0)); // 返回组id        sleep(5);        printf(&quot;Group ID of child is changed to %d\n&quot;, getpgid(0));        exit(0);    }    sleep(1);    setpgid(pid, pid); // 父进程改变子进程的组id为子进程本身    sleep(5);    printf(&quot;parent process PID is %d\n&quot;, getpid());    printf(&quot;parent of parent process PID is %d\n&quot;, getppid());    printf(&quot;Group ID of parent is %d\n&quot;, getpgid(0));    setpgid(getpid(), getppid()); // 改变父进程的组id为父进程的父进程    printf(&quot;Group ID of parent is changed to %d\n&quot;, getpgid(0));    return 0;}</code></pre><h2 id="5-2-会话"><a href="#5-2-会话" class="headerlink" title="5.2 会话"></a>5.2 会话</h2><h3 id="5-2-1-设置会话"><a href="#5-2-1-设置会话" class="headerlink" title="5.2.1 设置会话"></a>5.2.1 设置会话</h3><pre><code class="c">pid_t setsid(void)</code></pre><ul><li><strong>调用进程不能是进程组组长,该进程变成新会话首进程(session header)</strong> </li><li><strong>该进程成为一个新进程组的组长进程。</strong> </li><li><strong>需有root权限</strong> </li><li><strong>新会话丢弃原有的控制终端,该会话没有控制终端</strong> </li><li>*<em>该调用进程是组长进程，则出错返回 *</em></li><li><strong>建立新会话时，先调用fork, 父进程终止，子进程调用</strong></li></ul><h3 id="5-2-1-demo"><a href="#5-2-1-demo" class="headerlink" title="5.2.1 demo"></a>5.2.1 demo</h3><pre><code class="c">#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;int main(void){    pid_t pid;    if ((pid = fork())&lt;0) {        perror(&quot;fork&quot;);        exit(1);    } else if (pid == 0) {        printf(&quot;child process PID is %d\n&quot;, getpid());        printf(&quot;Group ID of child is %d\n&quot;, getpgid(0));        printf(&quot;Session ID of child is %d\n&quot;, getsid(0));        sleep(10);        setsid(); // 子进程非组长进程，故其成为新会话首进程，且成为组长进程。该进程组id即为会话进程        printf(&quot;Changed:\n&quot;);        printf(&quot;child process PID is %d\n&quot;, getpid());        printf(&quot;Group ID of child is %d\n&quot;, getpgid(0));        printf(&quot;Session ID of child is %d\n&quot;, getsid(0));        sleep(20);        exit(0);    }    return 0;}</code></pre><h2 id="5-3-守护进程"><a href="#5-3-守护进程" class="headerlink" title="5.3 守护进程"></a>5.3 守护进程</h2><h3 id="5-3-1-概念"><a href="#5-3-1-概念" class="headerlink" title="5.3.1 概念"></a>5.3.1 概念</h3><p><strong>Daemon(精灵)进程,是Linux 的后台服务进程,生存期较长的进程，通常独立于控制终 端并且周期性地执行某种任务或等待处理某些发生的事件。</strong></p><h3 id="5-3-2-模型"><a href="#5-3-2-模型" class="headerlink" title="5.3.2 模型"></a>5.3.2 模型</h3><pre><code>1. 创建子进程，父进程退出   所有工作在子进程中进行　　形式上脱离了控制终端2. 在子进程中创建新会话　　setsid()函数　　使子进程完全独立出来，脱离控制3. 改变当前目录为根目录　　chdir()函数　　防止占用可卸载的文件系统　　也可以换成其它路径4. 重设文件权限掩码　　umask()函数　　防止继承的文件创建屏蔽字拒绝某些权限　　增加守护进程灵活性5. 关闭文件描述符　　继承的打开文件不会用到，浪费系统资源，无法卸载6. 开始执行守护进程核心工作7. 守护进程退出处理</code></pre><h3 id="5-3-3-demo"><a href="#5-3-3-demo" class="headerlink" title="5.3.3 demo"></a>5.3.3 demo</h3><pre><code class="c">#include &lt;stdlib.h&gt;#include &lt;stdio.h&gt;#include &lt;fcntl.h&gt;void daemonize(void){    pid_t pid;/** 成为一个新会话的首进程，失去控制终端*/    if ((pid = fork()) &lt; 0) {        perror(&quot;fork&quot;);        exit(1);    } else if (pid != 0) /* parent */        exit(0);    setsid();/** 改变当前工作目录到/目录下.*/    if (chdir(&quot;/&quot;) &lt; 0) {        perror(&quot;chdir&quot;);        exit(1);    }/* 设置umask为0 */    umask(0);/** 重定向0，1，2文件描述符到 /dev/null，因为已经失去控制终端，再操作0，1，2没有意义.*/    close(0);    open(&quot;/dev/null&quot;, O_RDWR);    dup2(0, 1);    dup2(0, 2);}int main(void){    daemonize();    while(1); /* 在此循环中可以实现守护进程的核心工作 */}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 基础 </category>
          
          <category> Linux系统编程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> 系统编程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>4.进程间通信</title>
      <link href="/2020/04/14/4-%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/"/>
      <url>/2020/04/14/4-%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1/</url>
      
        <content type="html"><![CDATA[<p>　　每个进程各自有不同的用户地址空间，任何一个进程的全局变量在另一个进程中都看不到，所以<strong>进程之间要交换数据必须通过内核，在内核中开辟一块缓冲区，进程1把数据从用户空间拷到内核缓冲区，进程2再从内核缓冲区把数据读走，内核提供的这种机制称为进程间通信（IPC，InterProcess Communication）</strong></p><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/sysconnect.png" alt=""></p><h2 id="4-1-进程通信的方式"><a href="#4-1-进程通信的方式" class="headerlink" title="4.1 进程通信的方式"></a>4.1 进程通信的方式</h2><ul><li><strong>pipe管道</strong></li><li><strong>fifo管道</strong></li><li><strong>内存共享映射</strong></li><li><strong>socket(后面会细说)</strong></li></ul><h2 id="4-2-pipe管道"><a href="#4-2-pipe管道" class="headerlink" title="4.2 pipe管道"></a>4.2 pipe管道</h2><p>管道是一种最基本的IPC机制，<strong>管道作用于有血缘关系的进程之间,通过fork来传递</strong></p><p>由pipe函数创建：</p><pre><code class="c">#include &lt;unistd.h&gt;int pipe(int filedes[2]);</code></pre><p><strong>pipe函数调用成功返回0，调用失败返 -1。</strong></p><p>调用pipe函数时在内核中开辟一块缓冲区（称为管道）用于通信，它有一个读端一个写端，然后通过filedes参数传出给用户程序两个文件描述符，<strong>filedes[0]指向管道的读端，filedes[1]指向管道的写端</strong>(很好记，就像0是标准输入1是标准输出一样) 。所以管道 在用户程序看起来就像一个打开的文件，通过read(filedes[0]);或者write(filedes[1]);向这个文件读写数据其实是在读写内核缓冲区。</p><h3 id="4-2-1-通信步骤"><a href="#4-2-1-通信步骤" class="headerlink" title="4.2.1 通信步骤"></a>4.2.1 通信步骤</h3><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/syspipe.png" alt=""></p><ol><li>父进程调用pipe开辟管道，得到两个文件描述符指向管道的两端。</li><li>父进程调用fork创建子进程，那么子进程也有两个文件描述符指向同一管道。</li><li><strong>父进程关闭管道读端，子进程关闭管道写端</strong>。父进程可以往管道里写，子进程可以从管道里读，管道是用环形队列实现的，数据从写端流入从读端流出，这样就实现了进程间通信。</li></ol><h3 id="4-2-2-demo"><a href="#4-2-2-demo" class="headerlink" title="4.2.2 demo"></a>4.2.2 demo</h3><pre><code class="c">#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#define MAXLINE 80int main(void){    int n;    int fd[2];    pid_t pid;    char line[MAXLINE];    if (pipe(fd) &lt; 0) {        perror(&quot;pipe&quot;);        exit(1);    }    if ((pid = fork()) &lt; 0) {        perror(&quot;fork&quot;);        exit(1);    }    if (pid &gt; 0) { /* parent */        close(fd[0]);        write(fd[1], &quot;hello world\n&quot;, 12);        wait(NULL);    } else { /* child */        close(fd[1]);        n = read(fd[0], line, MAXLINE);        write(STDOUT_FILENO, line, n);    }    return 0;}</code></pre><h3 id="4-2-3-使用限制"><a href="#4-2-3-使用限制" class="headerlink" title="4.2.3 使用限制"></a>4.2.3 使用限制</h3><p><strong>两个进程通过一个管道只能实现单向通信</strong>，比如上面的例子，父进程写子进程读，如果有时候也需要子进程写父进程读，<strong>就必须另开一个管道</strong>。</p><h3 id="4-2-4-特殊情况"><a href="#4-2-4-特殊情况" class="headerlink" title="4.2.4 特殊情况"></a>4.2.4 特殊情况</h3><p><strong>使用管道需要注意以下4种特殊情况（假设都是阻塞I/O操作，没有设置O_NONBLOCK标志）：</strong></p><ul><li>如果所有指向管道写端的文件描述符都关闭了（<strong>管道写端的引用计数等于0</strong>），<strong>而仍然有进程从管道的读端读数据，那么管道中剩余的数据都被读取后，再次read会返回0，就像读到文件末尾一样</strong>。</li><li>如果有指向管道写端的文件描述符没关闭（<strong>管道写端的引用计数大于0</strong>），而持<strong>有管道写端的进程也没有向管道中写数据，这时有进程从管道读端读数据，那么管道中剩余的数据都被读取后，再次read会阻塞</strong>，直到管道中有数据可读了才读取数据并返回。</li><li>如果所有指向管道读端的文件描述符都关闭了（<strong>管道读端的引用计数等于0</strong>），<strong>这时有进程向管道的写端write，那么该进程会收到信号SIGPIPE，通常会导致进程异常终止</strong>。讲信号时会讲到怎样使SIGPIPE信号不终止进程。</li><li>如果有指向管道读端的文件描述符没关闭（<strong>管道读端的引用计数大于0</strong>），而<strong>持有管道读端的进程也没有从管道中读数据，这时有进程向管道写端写数据，那么在管道被写满时再次write会阻塞</strong>，直到管道中有空位置了才写入数据并返回。</li></ul><h2 id="4-3-fifo有名管道"><a href="#4-3-fifo有名管道" class="headerlink" title="4.3 fifo有名管道"></a>4.3 fifo有名管道</h2><p><strong>创建一个有名管道，解决无血缘关系的进程通信</strong></p><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/sysfifo.png" alt=""></p><pre><code class="c">#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;int mkfifo(const char *pathname, mode_t mode);</code></pre><ul><li><strong>当只写打开FIFO管道时，如果没有FIFO没有读端打开，则open写打开会阻塞。</strong></li><li><strong>FIFO内核实现时可以支持双向通信。（pipe单向通信，因为父子进程共享同一个file结构体）</strong></li><li><strong>FIFO可以一个读端，多个写端；也可以一个写端，多个读端。</strong></li></ul><h2 id="4-4-内存共享映射"><a href="#4-4-内存共享映射" class="headerlink" title="4.4 内存共享映射"></a>4.4 内存共享映射</h2><h3 id="4-4-1-mmap-munmap"><a href="#4-4-1-mmap-munmap" class="headerlink" title="4.4.1 mmap/munmap"></a>4.4.1 mmap/munmap</h3><p>mmap可以把磁盘文件的一部分直接映射到内存，这样文件中的位置直接就有对应的内存地址，对文件的读写可以直接用指针来做而不需要read/write函数。</p><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/sysmmap.png" alt=""></p><pre><code class="c">#include &lt;sys/mman.h&gt;void *mmap(void *addr, size_t length, int prot, int flags, int fd, off_t offset);int munmap(void *addr, size_t length);#addr:#如果addr参数为NULL，内核会自己在进程地址空间中选择合适的地址建立映射。如果addr不是NULL，则给内核一个提示，应该从什么地址开始映射，内核会选择addr之上的某个合适的地址开始映射。建立映射后，真正的映射首地址通过返回值可以得到#len参数是需要映射的那一部分文件的长度。#off参数是从文件的什么位置开始映射，必须是页大小的整数倍（在32位体系统结构上通常是4K）。##fd是代表该文件的描述符。#prot取值#- PROT_EXEC表示映射的这一段可执行，例如映射共享库#- PROT_READ表示映射的这一段可读#- PROT_WRITE表示映射的这一段可写#- PROT_NONE表示映射的这一段不可访问#flag参数取值#- MAP_SHARED多个进程对同一个文件的映射是共享的，一个进程对映射的内存做了修改，另一个进程也会看到这种变化。#- MAP_PRIVATE多个进程对同一个文件的映射不是共享的，一个进程对映射的内存做了修改，另一个进程并不会看到这种变化，也不会真的写到文件中去。</code></pre><p><strong>如果mmap成功则返回映射首地址，如果出错则返回常数MAP_FAILED。当进程终止时，该进程的映射内存会自动解除，也可以调用munmap解除映射。munmap成功返回0，出错返回-1。</strong></p><h3 id="4-4-2-demo"><a href="#4-4-2-demo" class="headerlink" title="4.4.2 demo"></a>4.4.2 demo</h3><h4 id="4-4-2-1-写进程"><a href="#4-4-2-1-写进程" class="headerlink" title="4.4.2.1 写进程"></a>4.4.2.1 写进程</h4><pre><code class="c">#include &lt;stdio.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;sys/mman.h&gt;#include &lt;unistd.h&gt;#include &lt;stdlib.h&gt;#include &lt;fcntl.h&gt;#define MAPLEN 0x1000struct STU {    int id;    char name[20];    char sex;};void sys_err(char *str, int exitno){    perror(str);    exit(exitno);}int main(int argc, char *argv[]){    struct STU *mm;    int fd, i = 0;    if (argc &lt; 2) {        printf(&quot;./a.out filename\n&quot;);        exit(1);    }    fd = open(argv[1], O_RDWR | O_CREAT, 0777);    if (fd &lt; 0)        sys_err(&quot;open&quot;, 1);    if (lseek(fd, MAPLEN-1, SEEK_SET) &lt; 0)        sys_err(&quot;lseek&quot;, 3);    if (write(fd, &quot;\0&quot;, 1) &lt; 0)        sys_err(&quot;write&quot;, 4);    mm = mmap(NULL, MAPLEN, PROT_READ|PROT_WRITE, MAP_SHARED, fd, 0);    if (mm == MAP_FAILED)        sys_err(&quot;mmap&quot;, 2);    close(fd);    while (1) {        mm-&gt;id = i;        sprintf(mm-&gt;name, &quot;zhang-%d&quot;, i);        if (i % 2 == 0)            mm-&gt;sex = &#39;m&#39;;        else            mm-&gt;sex = &#39;w&#39;;        i++;        sleep(1);    }    munmap(mm, MAPLEN);    return 0;}</code></pre><h4 id="4-4-2-2-读进程"><a href="#4-4-2-2-读进程" class="headerlink" title="4.4.2.2 读进程"></a>4.4.2.2 读进程</h4><pre><code class="c">#include &lt;stdio.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;sys/mman.h&gt;#include &lt;unistd.h&gt;#include &lt;stdlib.h&gt;#include &lt;fcntl.h&gt;#define MAPLEN 0x1000struct STU {    int id;    char name[20];    char sex;};void sys_err(char *str, int exitno){    perror(str);    exit(exitno);}int main(int argc, char *argv[]){    struct STU *mm;    int fd, i = 0;    if (argc &lt; 2) {        printf(&quot;./a.out filename\n&quot;);        exit(1);    }    fd = open(argv[1], O_RDWR);    if (fd &lt; 0)        sys_err(&quot;open&quot;, 1);    mm = mmap(NULL, MAPLEN, PROT_READ|PROT_WRITE, MAP_SHARED, fd, 0);    if (mm == MAP_FAILED)        sys_err(&quot;mmap&quot;, 2);    close(fd);    unlink(argv[1]);    while (1) {        printf(&quot;%d\n&quot;, mm-&gt;id);        printf(&quot;%s\n&quot;, mm-&gt;name);        printf(&quot;%c\n&quot;, mm-&gt;sex);        sleep(1);    }    munmap(mm, MAPLEN);    return 0;}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 基础 </category>
          
          <category> Linux系统编程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> 系统编程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>3.进程</title>
      <link href="/2020/04/14/3-%E8%BF%9B%E7%A8%8B/"/>
      <url>/2020/04/14/3-%E8%BF%9B%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<h2 id="3-1-PCB结构体"><a href="#3-1-PCB结构体" class="headerlink" title="3.1 PCB结构体"></a>3.1 PCB结构体</h2><p>我们知道，每个进程在内核中都有一个进程控制块（PCB）来维护进程相关的信息，Linux内核的进程控制块是task_struct结构体。现在我们全面了解一下其中都有哪些信息。</p><ul><li>进程id。系统中每个进程有唯一的id，在C语言中用pid_t类型表示，其实就是一个非负整数。</li><li>进程的状态，有运行、挂起、停止、僵尸等状态。</li><li>进程切换时需要保存和恢复的一些CPU寄存器。</li><li>描述虚拟地址空间的信息。</li><li>描述控制终端的信息。</li><li>当前工作目录（Current Working Directory）。</li><li>umask掩码。</li><li>文件描述符表，包含很多指向file结构体的指针。</li><li>和信号相关的信息。</li><li>用户id和组id。</li><li>控制终端、Session和进程组。</li><li>进程可以使用的资源上限（Resource Limit）。</li></ul><p><strong>fork和exec是本章要介绍的两个重要的系统调用。fork的作用是根据一个现有的进程复制出一个新进程，原来的进程称为父进程（Parent Process），新进程称为子进程（Child Process）。</strong></p><p>系统中同时运行着很多进程，这些进程都是从最初只有一个进程开始一个一个复制出来的。在Shell下输入命令可以运行一个程序，是因为Shell进程在读取用户输入的命令之后会调用fork复制出一个新的Shell进程，然后新的Shell进程调用exec执行新的程序。<br>我们知道一个程序可以多次加载到内存，成为同时运行的多个进程，例如可以同时开多个终端窗口运行/bin/bash，另一方面，一个进程在调用exec前后也可以分别执行两个不同的程序，例如在Shell提示符下输入命令ls，首先fork创建子进程，这时子进程仍在执行/bin/bash程序，然后子进程调用exec执行新的程序/bin/ls</p><p><strong>由于父进程在调用fork创建子进程时会把自己的环境变量表也复制给子进程</strong></p><h2 id="3-2-fork"><a href="#3-2-fork" class="headerlink" title="3.2 fork"></a>3.2 fork</h2><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/sysfork.png" alt=""></p><pre><code class="c">#include &lt;unistd.h&gt;pid_t fork(void);</code></pre><p><strong>子进程复制父进程的0到3g空间和父进程内核中的PCB，但id号不同。</strong><br><strong>fork调用一次返回两次</strong></p><ul><li><strong>父进程中返回子进程ID</strong></li><li><strong>子进程中返回0</strong></li></ul><p><strong>读时共享，写时复制</strong></p><h3 id="3-2-1-demo"><a href="#3-2-1-demo" class="headerlink" title="3.2.1 demo"></a>3.2.1 demo</h3><pre><code class="c">#include &lt;sys/types.h&gt;#include &lt;unistd.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;int main(void){    pid_t pid;    char *message;    int n;    pid = fork();    if (pid &lt; 0) {        perror(&quot;fork failed&quot;);        exit(1);    }    if (pid == 0) {        message = &quot;This is the child\n&quot;;        n = 6;    } else {        message = &quot;This is the parent\n&quot;;        n = 3;    }    for(; n &gt; 0; n--) {        printf(message);        sleep(1);    }    return 0;}</code></pre><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/sysforkdetail.png" alt=""></p><h2 id="3-2-相关进程函数"><a href="#3-2-相关进程函数" class="headerlink" title="3.2 相关进程函数"></a>3.2 相关进程函数</h2><h3 id="3-2-1-getpid-getppid"><a href="#3-2-1-getpid-getppid" class="headerlink" title="3.2.1 getpid/getppid"></a>3.2.1 getpid/getppid</h3><pre><code class="c">#include &lt;sys/types.h&gt;#include &lt;unistd.h&gt;pid_t getpid(void); //返回调用进程的PID号pid_t getppid(void); //返回调用进程父进程的PID号</code></pre><h3 id="3-2-2-getgid"><a href="#3-2-2-getgid" class="headerlink" title="3.2.2 getgid"></a>3.2.2 getgid</h3><pre><code class="c">#include &lt;unistd.h&gt;#include &lt;sys/types.h&gt;gid_t getgid(void); //返回实际用户组IDgid_t getegid(void); //返回有效用户组ID</code></pre><h3 id="3-2-3-getuid"><a href="#3-2-3-getuid" class="headerlink" title="3.2.3 getuid"></a>3.2.3 getuid</h3><pre><code class="c">#include &lt;unistd.h&gt;#include &lt;sys/types.h&gt;uid_t getuid(void); //返回实际用户IDuid_t geteuid(void); //返回有效用户ID</code></pre><h2 id="3-3-exec"><a href="#3-3-exec" class="headerlink" title="3.3 exec"></a>3.3 exec</h2><p>​       用fork创建子进程后执行的是和父进程相同的程序（但有可能执行不同的代码分支），子进程往往要调用一种exec函数以执行另一个程序。当进程调用一种exec函数时，该进程的用户空间代码和数据完全被新程序替换，从新程序的启动例程开始执行。调用exec并不创建新进程，所以调用exec前后该进程的id并未改变。<br>        其实有六种以exec开头的函数，统称exec函数：</p><pre><code class="c">#include &lt;unistd.h&gt;int execl(const char *path, const char *arg, ...);int execlp(const char *file, const char *arg, ...);int execle(const char *path, const char *arg, ..., char *const envp[]);int execv(const char *path, char *const argv[]);int execvp(const char *file, char *const argv[]);int execve(const char *path, char *const argv[], char *const envp[]);不带字母 p（表示path）的exec函数第一个参数必须是程序的相对路径或绝对路径，例如“/bin/ls”或“./a.out”，而不能是“ls”或“a.out”。对于带字母p的函数：如果参数中包含/，则将其视为路径名。否则视为不带路径的程序名，在PATH环境变量的目录列表中搜索这个程序。带有字母l（表示list）的exec函数要求将新程序的每个命令行参数都当作一个参数传给它，命令行参数的个数是可变的，因此函数原型中有…，…中的最后一个可变参数应该是NULL，起sentinel的作用。对于带有字母v（表示vector）的函数，则应该先构造一个指向各参数的指针数组，然后将该数组的首地址当作参数传给它，数组中的最后一个指针也应该是NULL，就像main函数的argv参数或者环境变量表一样。对于以e（表示environment）结尾的exec函数，可以把一份新的环境变量表传给它，其他exec函数仍使用当前的环境变量表执行新程序</code></pre><p>如果调用成功则加载新的程序从启动代码开始执行，不再返回，如果<strong>调用出错则返回-1</strong>，所以<strong>exec函数只有出错的返回值而没有成功的返回值。</strong></p><p><strong>由于exec函数只有错误返回值，只要返回了一定是出错了，所以不需要判断它的返回值，直接在后面调用perror即可。</strong></p><h3 id="3-3-1-demo"><a href="#3-3-1-demo" class="headerlink" title="3.3.1 demo"></a>3.3.1 demo</h3><pre><code class="c">char *const ps_argv[] ={&quot;ps&quot;, &quot;-o&quot;, &quot;pid,ppid,pgrp,session,tpgid,comm&quot;, NULL};char *const ps_envp[] ={&quot;PATH=/bin:/usr/bin&quot;, &quot;TERM=console&quot;, NULL};execl(&quot;/bin/ps&quot;, &quot;ps&quot;, &quot;-o&quot;, &quot;pid,ppid,pgrp,session,tpgid,comm&quot;, NULL);execv(&quot;/bin/ps&quot;, ps_argv);execle(&quot;/bin/ps&quot;, &quot;ps&quot;, &quot;-o&quot;, &quot;pid,ppid,pgrp,session,tpgid,comm&quot;, NULL, ps_envp);execve(&quot;/bin/ps&quot;, ps_argv, ps_envp);execlp(&quot;ps&quot;, &quot;ps&quot;, &quot;-o&quot;, &quot;pid,ppid,pgrp,session,tpgid,comm&quot;, NULL);execvp(&quot;ps&quot;, ps_argv);</code></pre><h2 id="3-4-wait-waitpid"><a href="#3-4-wait-waitpid" class="headerlink" title="3.4 wait/waitpid"></a>3.4 wait/waitpid</h2><h3 id="3-4-1-僵尸-孤儿进程"><a href="#3-4-1-僵尸-孤儿进程" class="headerlink" title="3.4.1 僵尸/孤儿进程"></a>3.4.1 僵尸/孤儿进程</h3><p><strong>僵尸进程: 子进程退出，父进程没有回收子进程资源（PCB），则子进程变成僵尸进程</strong><br><strong>孤儿进程: 父进程先于子进程结束，则子进程成为孤儿进程,子进程的父进程成为1号进程init进程，称为init进程领养孤儿进程</strong></p><h3 id="3-4-2-函数"><a href="#3-4-2-函数" class="headerlink" title="3.4.2 函数"></a>3.4.2 函数</h3><pre><code class="c">#include &lt;sys/types.h&gt;#include &lt;sys/wait.h&gt;pid_t wait(int *status);pid_t waitpid(pid_t pid, int *status, int options);传入值pid&lt; -1 回收指定进程组内的任意子进程-1 回收任意子进程0 回收和当前调用waitpid一个组的所有子进程&gt; 0 回收指定ID的子进程</code></pre><p>​    <strong>一个进程在终止时会关闭所有文件描述符，释放在用户空间分配的内存，但它的PCB还保留着，内核在其中保存了一些信息：如果是正常终止则保存着退出状态，如果是异常终止则保存着导致该进程终止的信号是哪个。这个进程的父进程可以调用wait或waitpid获取这些信息，然后彻底清除掉这个进程。</strong>我们知道一个进程的退出状态可以在Shell中用特殊变量$?查看，因为Shell是它的父进程，当它终止时Shell调用wait或waitpid得到它的退出状态同时彻底清除掉这个进程。</p><p>​        <strong>如果一个进程已经终止，但是它的父进程尚未调用wait或waitpid对它进行清理，这时</strong><br><strong>的进程状态称为僵尸（Zombie）进程</strong>。任何进程在刚终止时都是僵尸进程，正常情况下，僵<br>尸进程都立刻被父进程清理了</p><p>​        <strong>若调用成功则返回清理掉的子进程 id，若调用出错则返回-1。父进程调用 wait或</strong><br><strong>waitpid时可能会：</strong></p><ul><li><strong>阻塞（如果它的所有子进程都还在运行）。</strong></li><li><strong>带子进程的终止信息立即返回（如果一个子进程已终止，正等待父进程读取其终止信息）。</strong></li><li><strong>出错立即返回（如果它没有任何子进程）。</strong></li></ul><p><strong>这两个函数的区别是：</strong></p><ul><li><strong>如果父进程的所有子进程都还在运行，调用wait将使父进程阻塞，而调用waitpid时如果在options参数中指定WNOHANG可以使父进程不阻塞而立即返回0。</strong></li><li><strong>wait等待第一个终止的子进程，而waitpid可以通过pid参数指定等待哪一个子进程。</strong></li></ul>]]></content>
      
      
      <categories>
          
          <category> 基础 </category>
          
          <category> Linux系统编程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> 系统编程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2.文件系统</title>
      <link href="/2020/04/14/2-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"/>
      <url>/2020/04/14/2-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/</url>
      
        <content type="html"><![CDATA[<h2 id="2-1-ext2文件系统"><a href="#2-1-ext2文件系统" class="headerlink" title="2.1 ext2文件系统"></a>2.1 ext2文件系统</h2><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/sysfileext2.png" alt=""></p><p><strong>文件系统中存储的最小单位是块（Block）</strong></p><p><strong>上图中启动块（BootBlock）的大小是确定的，就是1KB，启动块是由PC标准规定的，用来存储磁盘分区信息和启动信息，任何文件系统都不能使用启动块。</strong></p><p><strong>启动块之后才是ext2文件系统的开始</strong>，ext2文件系统将整个分区划成若干个同样大小的<strong>块组（Block Group）</strong>，每个块组都由<strong>以下六部分组成</strong>:</p><ul><li><strong>超级块</strong></li><li><strong>块组描述符表</strong></li><li><strong>块位图</strong></li><li><strong>inode位图</strong></li><li><strong>inode表</strong></li><li><strong>数据块</strong></li></ul><h3 id="2-1-1-超级块"><a href="#2-1-1-超级块" class="headerlink" title="2.1.1 超级块"></a>2.1.1 超级块</h3><p><strong>超级块（Super Block） 描述整个分区的文件系统信息，例如块大小、文件系统版本号、上次mount的时间等等。超级块在每个块组的开头都有一份拷贝。</strong></p><h3 id="2-1-2-块组描述表"><a href="#2-1-2-块组描述表" class="headerlink" title="2.1.2 块组描述表"></a>2.1.2 块组描述表</h3><p><strong>块组描述符表（GDT，Group Descriptor Table） 由很多块组描述符组成，整个分区分成多少个块组就对应有多少个块组描述符。</strong></p><p><strong>每个块组描述符（Group Descriptor）存储一个块组的描述信息，例如在这个块组中从哪里开始是inode表，从哪里开始是数据块，空闲的inode和数据块还有多少个等等</strong></p><h3 id="2-1-3-块位图"><a href="#2-1-3-块位图" class="headerlink" title="2.1.3 块位图"></a>2.1.3 块位图</h3><p>块位图（Block Bitmap） 一个块组中的块是这样利用的：数据块存储所有文件的数据，比如某个分区的块大小是1024字节，某个文件是2049字节，那么就需要三个数据块来存，即使第三个块只存了一个字节也需要占用一个整块；</p><p><strong>块位图就是用来描述整个块组中哪些块已用哪些块空闲的，它本身占一个块，其中的每个bit代表本块组中的一个块，这个bit为1表示该块已用，这个bit为0表示该块空闲可用。</strong></p><h4 id="2-1-3-1-为什么用df命令统计整个磁盘的已用空间非常快"><a href="#2-1-3-1-为什么用df命令统计整个磁盘的已用空间非常快" class="headerlink" title="2.1.3.1 为什么用df命令统计整个磁盘的已用空间非常快"></a>2.1.3.1 为什么用df命令统计整个磁盘的已用空间非常快</h4><blockquote><p>因为只需要查看每个块组的块位图即可，而不需要搜遍整个分区。相反，用du命令查看一个较大目录的已用空间就非常慢，因为不可避免地要搜遍整个目录的所有文件。</p></blockquote><h3 id="2-1-4-inode位图"><a href="#2-1-4-inode位图" class="headerlink" title="2.1.4 inode位图"></a>2.1.4 inode位图</h3><p><strong>inode位图（inode Bitmap） 和块位图类似，本身占一个块，其中每个bit表示一个inode是否空闲可用。</strong></p><h3 id="2-1-5-inode表"><a href="#2-1-5-inode表" class="headerlink" title="2.1.5 inode表"></a>2.1.5 inode表</h3><p>inode表（inode Table） 我们知道，一个文件除了数据需要存储之外，一些<strong>描述信息也需要存储，例如文件类型（常规、目录、符号链接等），权限，文件大小，创建/修改/访问时间，数据地址</strong>等，也就是ls -l命令看到的那些信息，这些信息存在inode中而不是数据块中。</p><p><strong>每个文件都有一个inode，一个块组中的所有inode组成了inode表</strong></p><h3 id="2-1-6-数据块"><a href="#2-1-6-数据块" class="headerlink" title="2.1.6 数据块"></a>2.1.6 数据块</h3><p>数据块（Data Block） 根据不同的文件类型有以下几种情况</p><ul><li><strong>对于常规文件，文件的数据存储在数据块中。</strong></li><li><strong>对于目录，该目录下的所有文件名和目录名存储在数据块中，注意文件名保存在它所在目录的数据块中，除文件名之外，ls -l命令看到的其它信息都保存在该文件的inode中。</strong></li></ul><p><strong>注意这个概念：目录也是一种文件，是一种特殊类型的文件。</strong></p><p><strong>对于符号链接，如果目标路径名较短则直接保存在inode中以便更快地查找，如果目标路径名较长则分配一个数据块来保存。</strong></p><h3 id="2-1-7-文件类型"><a href="#2-1-7-文件类型" class="headerlink" title="2.1.7 文件类型"></a>2.1.7 文件类型</h3><table><thead><tr><th align="center">编码</th><th align="center">文件类型</th></tr></thead><tbody><tr><td align="center">0</td><td align="center">Unknown</td></tr><tr><td align="center">1</td><td align="center">Regular file</td></tr><tr><td align="center">2</td><td align="center">Directory</td></tr><tr><td align="center">3</td><td align="center">Character device 字符设备</td></tr><tr><td align="center">4</td><td align="center">Block device 块设备</td></tr><tr><td align="center">5</td><td align="center">Named pipe 管道</td></tr><tr><td align="center">6</td><td align="center">Socket</td></tr><tr><td align="center">7</td><td align="center">Symbolic link 符号链接</td></tr></tbody></table><h3 id="2-1-8-数据库寻址"><a href="#2-1-8-数据库寻址" class="headerlink" title="2.1.8 数据库寻址"></a>2.1.8 数据库寻址</h3><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/sysfilefind.png" alt=""></p><p>从上图可以看出，索引项Blocks[13]指向两级的间接寻址块，最多可表示(b/4)2+b/4+12个数据块，对于1K的块大小最大可表示64.26MB的文件。索引项Blocks[14]指向三级的间接寻址块，最多可表示(b/4)3+(b/4)2+b/4+12个数据块，对于1K的块大小最大可表示16.06GB的文件。</p><p>可见，这种寻址方式对于访问不超过12个数据块的小文件是非常快的，访问文件中的任意数据只需要两次读盘操作，一次读inode（也就是读索引项）一次读数据块。而访问大文件中的数据则需要最多五次读盘操作：inode、一级间接寻址块、二级间接寻址块、三级间接寻址块、数据块。</p><p><strong>实际上，磁盘中的inode和数据块往往已经被内核缓存了，读大文件的效率也不会太低。</strong></p><h2 id="2-2-相关函数"><a href="#2-2-相关函数" class="headerlink" title="2.2 相关函数"></a>2.2 相关函数</h2><h3 id="2-2-1-stat"><a href="#2-2-1-stat" class="headerlink" title="2.2.1 stat"></a>2.2.1 stat</h3><pre><code class="c">#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;unistd.h&gt;int stat(const char *path, struct stat *buf);int fstat(int fd, struct stat *buf);int lstat(const char *path, struct stat *buf);struct stat {    dev_t st_dev; /* ID of device containing file */    ino_t st_ino; /* inode number */    mode_t st_mode; /* protection */    nlink_t st_nlink; /* number of hard links */    uid_t st_uid; /* user ID of owner */    gid_t st_gid; /* group ID of owner */    dev_t st_rdev; /* device ID (if special file) */    off_t st_size; /* total size, in bytes */    blksize_t st_blksize; /* blocksize for file system I/O */    blkcnt_t st_blocks; /* number of 512B blocks allocated */    time_t st_atime; /* time of last access */    time_t st_mtime; /* time of last modification */    time_t st_ctime; /* time of last status change */};</code></pre><p>stat既有命令也有同名函数，用来获取文件 Inode里主要信息，stat 跟踪符号链接，lstat不跟踪符号链接</p><h4 id="2-2-1-1-stat里面时间辨析"><a href="#2-2-1-1-stat里面时间辨析" class="headerlink" title="2.2.1.1 stat里面时间辨析"></a>2.2.1.1 stat里面时间辨析</h4><ul><li><p><strong>atime(最近访问时间)</strong></p></li><li><p><strong>mtime(最近更改时间):指最近修改文件内容的时间</strong> </p></li><li><p><strong>ctime(最近改动时间)：指最近改动Inode的时间,比如改文件权限,这个时间也会更新</strong></p></li></ul><h3 id="2-2-2-access"><a href="#2-2-2-access" class="headerlink" title="2.2.2 access"></a>2.2.2 access</h3><p>判断是否有权限</p><pre><code class="c">#include &lt;unistd.h&gt;int access(const char *pathname, int mode);R_OK 是否有读权限W_OK 是否有写权限X_OK 是否有执行权限F_OK 测试一个文件是否存在</code></pre><h3 id="2-2-3-chmod"><a href="#2-2-3-chmod" class="headerlink" title="2.2.3 chmod"></a>2.2.3 chmod</h3><pre><code class="c">#include &lt;sys/stat.h&gt;int chmod(const char *path, mode_t mode);int fchmod(int fd, mode_t mode);</code></pre><h3 id="2-2-4-chown"><a href="#2-2-4-chown" class="headerlink" title="2.2.4 chown"></a>2.2.4 chown</h3><p><strong>chown使用时必须拥有root权限。</strong></p><pre><code class="c">#include &lt;unistd.h&gt;int chown(const char *path, uid_t owner, gid_t group);int fchown(int fd, uid_t owner, gid_t group);int lchown(const char *path, uid_t owner, gid_t group);</code></pre><h3 id="2-2-5-link"><a href="#2-2-5-link" class="headerlink" title="2.2.5 link"></a>2.2.5 link</h3><h4 id="2-2-5-1-link"><a href="#2-2-5-1-link" class="headerlink" title="2.2.5.1 link"></a>2.2.5.1 link</h4><p><strong>创建一个硬链接</strong></p><p><strong>当rm删除文件时，只是删除了目录下的记录项和把inode硬链接计数减1，当硬链接计数减为0时，才会正的删除文件。</strong></p><pre><code class="c">#include &lt;unistd.h&gt;int link(const char *oldpath, const char *newpath);</code></pre><h4 id="2-2-5-2-unlink"><a href="#2-2-5-2-unlink" class="headerlink" title="2.2.5.2 unlink"></a>2.2.5.2 unlink</h4><pre><code class="c">int unlink(const char *pathname)1. 如果是符号链接，删除符号链接2. 如果是硬链接，硬链接数减1，当减为0时，释放数据块和inode3. 如果文件硬链接数为0，但有进程已打开该文件，并持有文件描述符，则等该进程关闭该文件时，kernel才真正去删除该文件4. 利用该特性创建临时文件，先open或creat创建一个文件，马上unlink此文件</code></pre><h3 id="2-2-6-rename"><a href="#2-2-6-rename" class="headerlink" title="2.2.6 rename"></a>2.2.6 rename</h3><p>文件重命名</p><pre><code class="c">#include &lt;stdio.h&gt;int rename(const char *oldpath, const char *newpath);</code></pre><h3 id="2-2-7-chdir"><a href="#2-2-7-chdir" class="headerlink" title="2.2.7 chdir"></a>2.2.7 chdir</h3><p>改变当前进程的工作目录</p><pre><code class="c">#include &lt;unistd.h&gt;int chdir(const char *path);int fchdir(int fd);</code></pre><h3 id="2-2-8-getcwd"><a href="#2-2-8-getcwd" class="headerlink" title="2.2.8 getcwd"></a>2.2.8 getcwd</h3><p>获取当前进程的工作目录</p><pre><code class="c">#include &lt;unistd.h&gt;char *getcwd(char *buf, size_t size);</code></pre><h3 id="2-2-9-目录操作"><a href="#2-2-9-目录操作" class="headerlink" title="2.2.9 目录操作"></a>2.2.9 目录操作</h3><h4 id="2-2-9-1-mkdir"><a href="#2-2-9-1-mkdir" class="headerlink" title="2.2.9.1 mkdir"></a>2.2.9.1 mkdir</h4><pre><code class="c">#include &lt;sys/stat.h&gt;#include &lt;sys/types.h&gt;int mkdir(const char *pathname, mode_t mode);</code></pre><h4 id="2-2-9-2-rmdir"><a href="#2-2-9-2-rmdir" class="headerlink" title="2.2.9.2 rmdir"></a>2.2.9.2 rmdir</h4><pre><code class="c">#include &lt;unistd.h&gt;int rmdir(const char *pathname);</code></pre><h4 id="2-2-9-3-opendir-fdopendir"><a href="#2-2-9-3-opendir-fdopendir" class="headerlink" title="2.2.9.3 opendir/fdopendir"></a>2.2.9.3 opendir/fdopendir</h4><pre><code class="c">#include &lt;sys/types.h&gt;#include &lt;dirent.h&gt;DIR *opendir(const char *name);DIR *fdopendir(int fd)</code></pre><h4 id="2-2-9-4-closedir"><a href="#2-2-9-4-closedir" class="headerlink" title="2.2.9.4 closedir"></a>2.2.9.4 closedir</h4><pre><code class="c">#include &lt;sys/types.h&gt;#include &lt;dirent.h&gt;int closedir(DIR *dirp);</code></pre>]]></content>
      
      
      <categories>
          
          <category> 基础 </category>
          
          <category> Linux系统编程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> 系统编程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>1.文件系统IO</title>
      <link href="/2020/04/14/1-%E6%96%87%E4%BB%B6IO/"/>
      <url>/2020/04/14/1-%E6%96%87%E4%BB%B6IO/</url>
      
        <content type="html"><![CDATA[<h2 id="1-1-C标准函数与系统函数的区别"><a href="#1-1-C标准函数与系统函数的区别" class="headerlink" title="1.1 C标准函数与系统函数的区别"></a>1.1 C标准函数与系统函数的区别</h2><p>C函数进行文件操作的时候,是调用的系统内核函数,中间经过一层缓冲区</p><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/sysfile.png" alt=""></p><h3 id="1-1-1-I-O缓冲区"><a href="#1-1-1-I-O缓冲区" class="headerlink" title="1.1.1 I/O缓冲区"></a>1.1.1 I/O缓冲区</h3><p><code>每一个FILE文件流都有一个缓冲区buffer，默认大小8KB</code>。</p><h3 id="1-1-2-区别"><a href="#1-1-2-区别" class="headerlink" title="1.1.2 区别"></a>1.1.2 区别</h3><p>然write系统调用位于C标准库I/O缓冲区的底层，但在write的底层也可以分配一个内核I/O缓冲区，所以write也不一定是直接写到文件的，也可能写到内核I/O缓冲区中，<strong>至于究竟写到了文件中还是内核缓冲区中对于进程来说是没有差别的，如果进程A和进程B打开同一文件，进程A写到内核I/O缓冲区中的数据从进程B也能读到，而C标准库的I/O缓冲区则不具有这一特性</strong></p><h2 id="1-2-PCB概念"><a href="#1-2-PCB概念" class="headerlink" title="1.2 PCB概念"></a>1.2 PCB概念</h2><p>广义上，所有的进程信息被放在一个叫做进程控制块的数据结构中，可以理解为进程属性的集合。</p><p><strong>每个进程在内核中都有一个进程控制块来维护进程的相关信息，Linux内核的进程控制块是task_struct结构体</strong>，PCB结构体所在位置如下:</p><pre><code class="c">/usr/src/linux-headers/include/linux/sched.h</code></pre><h2 id="1-3-文件描述符"><a href="#1-3-文件描述符" class="headerlink" title="1.3 文件描述符"></a>1.3 文件描述符</h2><p><strong>一个进程默认打开3个文件描述符</strong></p><pre><code class="shell">STDIN_FILENO 0  　 标准输入STDOUT_FILENO 1　　标准输出STDERR_FILENO 2　　错误输出</code></pre><p><strong>新打开文件返回文件描述符表中未使用的最小文件描述符。</strong><br>open函数可以打开或创建一个文件。</p><h2 id="1-4-open-close函数"><a href="#1-4-open-close函数" class="headerlink" title="1.4 open/close函数"></a>1.4 open/close函数</h2><h3 id="1-4-1-open函数"><a href="#1-4-1-open函数" class="headerlink" title="1.4.1 open函数"></a>1.4.1 open函数</h3><pre><code class="c">#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;fcntl.h&gt;int open(const char *pathname, int flags);int open(const char *pathname, int flags, mode_t mode);int open(const char *pathname, int flags, ...);返回值：成功返回新分配的文件描述符，出错返回-1并设置errno</code></pre><h4 id="1-4-1-1-pathname"><a href="#1-4-1-1-pathname" class="headerlink" title="1.4.1.1 pathname"></a>1.4.1.1 pathname</h4><p>pathname参数是要打开或创建的文件名，和fopen一样，pathname既可以是相对路径也可以是绝对路径。</p><h4 id="1-4-1-2-flags"><a href="#1-4-1-2-flags" class="headerlink" title="1.4.1.2 flags"></a>1.4.1.2 flags</h4><p>flags参数有一系列常数值可供选择，可以同时选择多个常数用按位或运算符连接起来，所以这些常数的宏定义都以O_开头，表示or。</p><p><strong>必选项</strong>：以下三个常数中必须指定一个，且仅允许指定一个。</p><ul><li><strong>O_RDONLY 只读打开</strong></li><li><strong>O_WRONLY 只写打开</strong></li><li><strong>O_RDWR 可读可写打开</strong></li></ul><p>以下<strong>可选项可以同时指定0个或多个</strong>，和必选项按位或起来作为flags参数。可选项有很多，<br>这里只介绍常用部分:</p><ul><li><strong>O_APPEND 表示追加</strong>。如果文件已有内容，这次打开文件所写的数据附加到文件的末尾而不覆盖原来的内容。</li><li><strong>O_CREAT 若此文件不存在则创建它</strong>。使用此选项时需要提供第三个参数mode，表示该文件的访问权限。</li><li><strong>O_EXCL</strong> 如果同时指定了O_CREAT，并且文件已存在，则出错返回</li><li><strong>O_TRUNC</strong> 如果文件已存在，并且以只写或可读可写方式打开，则将其长度截断（Truncate）为0字节。</li><li><strong>O_NONBLOCK 对于设备文件，以O_NONBLOCK方式打开可以做非阻塞I/O（Nonblock I/O）</strong></li></ul><h4 id="1-4-1-4-mask"><a href="#1-4-1-4-mask" class="headerlink" title="1.4.1.4 mask"></a>1.4.1.4 mask</h4><p>第三个参数mode指定文件权限，可以用八进制数表示，比如0644表示-rw-r-r–，也可以用S_IRUSR、S_IWUSR等宏定义按位或起来表示，详见open(2)的Man Page。要注意的是，文件权限由open的mode参数和当前进程的umask掩码共同决定。</p><pre><code class="shell">$ umask 0002 </code></pre><p>可以看到umask值为0002，其中第一个0与特殊权限有关，可以暂时不用理会，后三位002则与普通权限(rwx)有关</p><ul><li><p>其中002中第一个0与用户(user)权限有关，表示从用户权限减0，也就是权限不变，所以文件的创建者的权限是默认权限(rw)</p></li><li><p>第二个0与组权限（group）有关，表示从组的权限减0，所以群组的权限也保持默认权限（rw）</p></li><li><p>最后一位2则与系统中其他用户（others）的权限有关，由于w=2，所以需要从其他用户默认权限（rw）减去2，也就是去掉写（w）权限，则其他人的权限为rw - w = r</p></li></ul><p>则创建文件的最终默认权限为 -rw-rw-r– 。同理，目录的默认权限为 drwxrwxrwx ，则d rwx rwx rwx - 002 = (d rwx rwx rwx)</p><p>用touch命令创建一个文件时，创建权限是0666，而touch进程继承了Shell进程的umask<br>掩码，所以最终的文件权限是0666&amp;∼022=0644。</p><h4 id="1-4-1-5-open函数与fopen区别"><a href="#1-4-1-5-open函数与fopen区别" class="headerlink" title="1.4.1.5 open函数与fopen区别"></a>1.4.1.5 open函数与fopen区别</h4><p>注意<strong>open函数与C标准I/O库的fopen函数有些细微的区别</strong>：</p><ul><li>以可写的方式fopen一个文件时，如果文件不存在会自动创建，而open一个文件时必须明确指定O_CREAT才会创建文件，否则文件不存在就出错返回。</li><li>以w或w+方式fopen一个文件时，如果文件已存在就截断为0字节，而open一个文件时必须明确指定O_TRUNC才会截断文件，否则直接在原来的数据上改写。</li></ul><h3 id="1-4-2-close函数"><a href="#1-4-2-close函数" class="headerlink" title="1.4.2 close函数"></a>1.4.2 close函数</h3><p>close函数关闭一个已打开的文件：</p><pre><code class="c">#include &lt;unistd.h&gt;int close(int fd);</code></pre><p><strong>返回值：成功返回0，出错返回-1并设置errno</strong></p><h4 id="1-4-2-1-fd"><a href="#1-4-2-1-fd" class="headerlink" title="1.4.2.1 fd"></a>1.4.2.1 fd</h4><p><strong>参数fd(file descriptor)是要关闭的文件描述符。需要说明的是，当一个进程终止时，内核对该进程所有尚未关闭的文件描述符调用close关闭，所以即使用户程序不调用close，在终止时内核也会自动关闭它打开的所有文件</strong></p><p>由<strong>open返回的文件描述符一定是该进程尚未使用的最小描述符</strong>。由于程序启动时自动打开文件描述符0、1、2，因此第一次调用open打开文件通常会返回描述符3，再调用open就会返回4。可以利用这一点在标准输入、标准输出或标准错误输出上打开一个新文件，实现重定向的功能。</p><p>例如，<strong>首先调用close关闭文件描述符1，然后调用open打开一个常规文件，则一定会返回文件描述符1，这时候标准输出就不再是终端，而是一个常规文件了，再调用printf就不会打印到屏幕上，而是写到这个文件中了</strong></p><h3 id="1-4-3-最大打开文件个数"><a href="#1-4-3-最大打开文件个数" class="headerlink" title="1.4.3 最大打开文件个数"></a>1.4.3 最大打开文件个数</h3><p><strong>可以打开多少个文件 跟电脑内存有直接关系</strong></p><p>查看当前系统允许打开最大文件个数</p><pre><code class="shell">cat /proc/sys/fs/file-max</code></pre><p> 当前默认设置最大打开文件个数1024</p><pre><code class="shell">ulimit -a</code></pre><p>修改默认设置最大打开文件个数为4096</p><pre><code class="shell">ulimit -n 4096</code></pre><h2 id="1-5-read-write函数"><a href="#1-5-read-write函数" class="headerlink" title="1.5 read/write函数"></a>1.5 read/write函数</h2><h3 id="1-5-1-read"><a href="#1-5-1-read" class="headerlink" title="1.5.1 read"></a>1.5.1 read</h3><p>read函数从打开的设备或文件中读取数据。</p><pre><code class="c">#include &lt;unistd.h&gt;ssize_t read(int fd, void *buf, size_t count);</code></pre><p><strong>返回值：成功返回读取的字节数，出错返回-1并设置errno，如果在调read之前已到达文件末尾，则这次read返回0</strong></p><p><strong>参数count是请求读取的字节数，读上来的数据保存在缓冲区buf中，同时文件的当前读写位置向后移</strong></p><p>注意这个读写位置和使用C标准I/O库时的读写位置有可能不同，这个读写位置是记在内核中的，而使用C标准I/O库时的读写位置是用户空间I/O缓冲区中的位置。比如用fgetc读一个字节，fgetc有可能从内核中预读1024个字节到I/O缓冲区中，再返回第一个字节，这时该文件在内核中记录的读写位置是1024，而在FILE结构体中记录的读写位置是1。</p><p><strong>注意返回值类型是ssize_t，表示有符号的size_t，这样既可以返回正的字节数、0（表示到达文件末尾）也可以返回负值-1（表示出错）</strong>。</p><p>read函数返回时，返回值说明了buf中前多少个字节是刚读上来的。<strong>有些情况下，实际读到的字节数（返回值）会小于请求读的字节数count</strong>，例如：</p><ul><li>读常规文件时，在读到count个字节之前已到达文件末尾。例如，距文件末尾还有30个字节而请求读100个字节，则read返回30，下次read将返回0。</li><li>从终端设备读，通常以行为单位，读到换行符就返回了。</li><li>从网络读，根据不同的传输层协议和内核缓存机制，返回值可能小于请求的字节数，后面socket编程部分会详细讲解</li></ul><h3 id="1-5-2-write"><a href="#1-5-2-write" class="headerlink" title="1.5.2 write"></a>1.5.2 write</h3><pre><code class="c">#include &lt;unistd.h&gt;ssize_t write(int fd, const void *buf, size_t count);</code></pre><p><strong>返回值：成功返回写入的字节数，出错返回-1并设置errno</strong></p><p>写常规文件时，write的返回值通常等于请求写的字节数count，而向终端设备或网络写则不一定。</p><h2 id="1-6-阻塞和非阻塞"><a href="#1-6-阻塞和非阻塞" class="headerlink" title="1.6 阻塞和非阻塞"></a>1.6 阻塞和非阻塞</h2><p><strong>明确一下阻塞（Block）这个概念。当进程调用一个阻塞的系统函数时，该进程被置于睡眠（Sleep）状态，这时内核调度其它进程运行，直到该进程等待的事件发生了（比如网络上接收到数据包，或者调用sleep指定的睡眠时间到了）它才有可能继续运行。</strong></p><p><strong>读常规文件是不会阻塞的，不管读多少字节，read一定会在有限的时间内返回。</strong></p><p><strong>从终端设备或网络读则不一定，如果从终端输入的数据没有换行符，调用read读终端设备就会阻塞，如果网络上没有接收到数据包，调用read从网络读就会阻塞，至于会阻塞多长时间也是不确定的，如果一直没有数据到达就一直阻塞在那里。</strong></p><p><strong>同样，写常规文件是不会阻塞的，而向终端设备或网络写则不一定。</strong></p><p>非阻塞I/O有一个缺点，如果所有设备都一直没有数据到达，调用者需要反复查询做无用功，如果阻塞在那里，操作系统可以调度别的进程执行，就不会做无用功了。在使用非阻塞I/O时，通常不会在一个while循环中一直不停地查询（这称为Tight Loop），而是每延迟等待一会儿来查询一下，以免做太多无用功，在延迟等待的时候可以调度其它进程执行。</p><pre><code class="c">while(1) {    非阻塞read(设备1);    if(设备1有数据到达)        处理数据;    非阻塞read(设备2);    if(设备2有数据到达)        处理数据;    ...    sleep(n);}</code></pre><h3 id="1-6-1-demo"><a href="#1-6-1-demo" class="headerlink" title="1.6.1 demo"></a>1.6.1 demo</h3><pre><code class="c">#include &lt;unistd.h&gt;#include &lt;fcntl.h&gt;#include &lt;errno.h&gt;#include &lt;string.h&gt;#include &lt;stdlib.h&gt;#define MSG_TRY &quot;try again\n&quot;#define MSG_TIMEOUT &quot;timeout\n&quot;int main(void) {    char buf[10];    int fd, n, i;    fd = open(&quot;/dev/tty&quot;, O_RDONLY | O_NONBLOCK);    if (fd &lt; 0) {        perror(&quot;open /dev/tty&quot;);        exit(1);    }    for (i = 0; i &lt; 5; i++) { //保证有数据到达时处理延迟较小        n = read(fd, buf, 10);        if (n &gt;= 0)            break;        if (errno != EAGAIN) {            perror(&quot;read /dev/tty&quot;);            exit(1);        }        sleep(1);        write(STDOUT_FILENO, MSG_TRY, strlen(MSG_TRY));    }    if (i == 5)//超时退出的逻辑        write(STDOUT_FILENO, MSG_TIMEOUT, strlen(MSG_TIMEOUT));    else        write(STDOUT_FILENO, buf, n);    close(fd);    return 0;}</code></pre><h2 id="1-7-lseek"><a href="#1-7-lseek" class="headerlink" title="1.7 lseek"></a>1.7 lseek</h2><p>每个打开的文件都记录着当前读写位置，打开文件时读写位置是0，表示文件开头，通常读写多少个字节就会将读写位置往后移多少个字节。但是有一个例外，如果以O_APPEND方式打开，每次写操作都会在文件末尾追加数据，然后将读写位置移到新的文件末尾。</p><p><strong>lseek和标准I/O库的fseek函数类似，可以移动当前读写位置（或者叫偏移量）。</strong></p><pre><code class="c">#include &lt;sys/types.h&gt;#include &lt;unistd.h&gt;off_t lseek(int fd, off_t offset, int whence);</code></pre><p>参数offset和whence的含义和fseek函数完全相同。只不过第一个参数换成了文件描述符。和fseek一样，偏移量允许超过文件末尾，这种情况下对该文件的下一次写操作将延长文件，中间空洞的部分读出来都是0。</p><h2 id="1-8-fcntl"><a href="#1-8-fcntl" class="headerlink" title="1.8 fcntl"></a>1.8 fcntl</h2><p><strong>可以用fcntl函数改变一个已打开的文件的属性，可以重新设置读、写、追加、非阻塞等标志（这些标志称为File Status Flag），而不必重新open文件。</strong></p><pre><code class="c">#include &lt;unistd.h&gt;#include &lt;fcntl.h&gt;int fcntl(int fd, int cmd);int fcntl(int fd, int cmd, long arg);int fcntl(int fd, int cmd, struct flock *lock);</code></pre><h3 id="1-8-1-用fcntl改变File-Status-Flag"><a href="#1-8-1-用fcntl改变File-Status-Flag" class="headerlink" title="1.8.1 用fcntl改变File Status Flag"></a>1.8.1 用fcntl改变File Status Flag</h3><pre><code class="c">#include &lt;unistd.h&gt;#include &lt;fcntl.h&gt;#include &lt;errno.h&gt;#include &lt;string.h&gt;#include &lt;stdlib.h&gt;#define MSG_TRY &quot;try again\n&quot;int main(void) {    char buf[10];    int n;    int flags;    //获取文件属性    flags = fcntl(STDIN_FILENO, F_GETFL);    //增加非阻塞属性    flags |= O_NONBLOCK;    if (fcntl(STDIN_FILENO, F_SETFL, flags) == -1) {        perror(&quot;fcntl&quot;);        exit(1);    }    tryagain:    n = read(STDIN_FILENO, buf, 10);    if (n &lt; 0) {        if (errno == EAGAIN) {            sleep(1);            write(STDOUT_FILENO, MSG_TRY, strlen(MSG_TRY));            goto tryagain;        }        perror(&quot;read stdin&quot;);        exit(1);    }    write(STDOUT_FILENO, buf, n);    return 0;}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 基础 </category>
          
          <category> Linux系统编程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> 系统编程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HTTP2和3</title>
      <link href="/2020/04/13/HTTP2%E5%92%8C3/"/>
      <url>/2020/04/13/HTTP2%E5%92%8C3/</url>
      
        <content type="html"><![CDATA[<h2 id="1-HTTP-1-1遇到的问题"><a href="#1-HTTP-1-1遇到的问题" class="headerlink" title="1 HTTP/1.1遇到的问题"></a>1 HTTP/1.1遇到的问题</h2><ul><li><strong>高延时</strong><ul><li><strong>并发连接有限</strong></li><li><strong>同一连接同时只能在完成一个 HTTP 事务（请求/响应）才能处理下一个事务</strong></li></ul></li><li><strong>重复传输的体积巨大的 HTTP 头部</strong></li><li><strong>不支持服务器推送消息</strong></li></ul><h2 id="2-HTTP2"><a href="#2-HTTP2" class="headerlink" title="2 HTTP2"></a>2 HTTP2</h2><h3 id="2-1-HTTP2的由来"><a href="#2-1-HTTP2的由来" class="headerlink" title="2.1 HTTP2的由来"></a>2.1 HTTP2的由来</h3><p><strong>早期的SPDY演化而来</strong></p><p> <strong>HTTP 协议取消了小版本号，所以 HTTP/2 的正式名字不是 2.0而是HTTP/2；</strong></p><h3 id="2-2-特性"><a href="#2-2-特性" class="headerlink" title="2.2 特性"></a>2.2 特性</h3><ul><li><p><strong>兼容HTTP/1.x,保留了请求方法、URI 等传统概念</strong></p></li><li><p><strong>数据量大幅减少</strong></p><ul><li><strong>使用“HPACK”算法压缩头部信息，消除冗余数据节约带宽</strong></li><li><strong>消息不再是“Header+Body”的形式，而是分散为多个二进制“帧”</strong></li></ul></li><li><p><strong>使用虚拟的“流”传输消息，在应用解决了困扰多年的“队头阻塞”问题，同时实现了“多路复用”，提高连接的利用率</strong></p></li><li><p><strong>服务器消息推送</strong></p></li></ul><h3 id="2-3-核心概念"><a href="#2-3-核心概念" class="headerlink" title="2.3 核心概念"></a>2.3 核心概念</h3><ul><li><strong>连接 Connection</strong>：1个 TCP 连接，包含一个 或者多个 Stream</li><li><strong>数据流 Stream</strong>：一个双向通讯数据流，包含 1 条或者多条 Message</li><li><strong>消息 Message</strong>：对应 HTTP/1 中的请求或者响应，包含一条或者多条 Frame</li><li><strong>数据帧 Frame</strong>：最小单位，以二进制压缩格 式存放 HTTP/1 中的内容</li></ul><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/neth2core.png" alt=""></p><h3 id="2-4-h2和h2c"><a href="#2-4-h2和h2c" class="headerlink" title="2.4 h2和h2c"></a>2.4 h2和h2c</h3><p>为了区分“加密”和“明文”这两个不同的版本，HTTP/2 协议定义了两个字符串标识符：</p><ul><li>“h2”表示加密的 HTTP/2,有TLS安全套件</li><li>“h2c”表示明文的 HTTP/2，多出的那个字母“c”的意思是“clear text”。</li></ul><h2 id="3-HTTP3"><a href="#3-HTTP3" class="headerlink" title="3 HTTP3"></a>3 HTTP3</h2><h3 id="3-1-HTTP-2-的队头阻塞"><a href="#3-1-HTTP-2-的队头阻塞" class="headerlink" title="3.1 HTTP/2 的队头阻塞"></a>3.1 HTTP/2 的队头阻塞</h3><p>让我们从协议栈的角度来仔细看一下。在 HTTP/2 把多个“请求 - 响应”分解成流，交给TCP 后，TCP 会再拆成更小的包依次发送（其实在 TCP 里应该叫 segment，也就是“段”）。<br>在网络良好的情况下，包可以很快送达目的地。但如果网络质量比较差，像手机上网的时候，就有可能会丢包。而 TCP 为了保证可靠传输，有个特别的“丢包重传”机制，丢失的包必须要等待重新传输确认，其他的包即使已经收到了，也只能放在缓冲区里，上层的应用拿不出来，只能“干着急”</p><h3 id="3-2-QUIC"><a href="#3-2-QUIC" class="headerlink" title="3.2 QUIC"></a>3.2 QUIC</h3><p>Google 在推 SPDY 的时候就已经意识到了这个问题，于是就又发明了一个新的“QUIC”协议，让 HTTP 跑在 QUIC 上而不是 TCP 上。</p><p>而这个“HTTP over QUIC”就是 HTTP 协议的下一个大版本，HTTP/3。它在 HTTP/2 的基础上又实现了质的飞跃，真正“完美”地解决了“队头阻塞”问题。<br><strong>不过 HTTP/3 目前还处于草案阶段!</strong></p><h3 id="3-3-QUCI特性"><a href="#3-3-QUCI特性" class="headerlink" title="3.3 QUCI特性"></a>3.3 QUCI特性</h3><ul><li>QUIC 是一个新的传输层协议，建立在 <strong>UDP 之上，实现了可靠传输</strong></li><li>QUIC 内含了 TLS1.3，只能加密通信，支持 0-RTT 快速建连；</li><li>QUIC 的连接使用“不透明”的连接 ID，不绑定在“IP 地址 + 端口”上，支持“连接迁移”；</li><li>QUIC 的流与 HTTP/2 的流很相似，但分为双向流和单向流；</li><li>HTTP/3 没有指定默认端口号，需要用 HTTP/2 的扩展帧“Alt-Svc”来发现。</li></ul><h2 id="4-HTTP版本比较"><a href="#4-HTTP版本比较" class="headerlink" title="4 HTTP版本比较"></a>4 HTTP版本比较</h2><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/netquic.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 基础 </category>
          
          <category> 网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 网络 </tag>
            
            <tag> HTTP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HTTPS和TLS</title>
      <link href="/2020/04/13/HTTPS%E5%92%8CTLS/"/>
      <url>/2020/04/13/HTTPS%E5%92%8CTLS/</url>
      
        <content type="html"><![CDATA[<h2 id="1-为什么要有HTTPS"><a href="#1-为什么要有HTTPS" class="headerlink" title="1 为什么要有HTTPS"></a>1 为什么要有HTTPS</h2><p><strong>因为HTTP不安全！</strong></p><p>由于 HTTP 天生“明文”的特点，整个传输过程完全透明，任何人都能够在链路中截获、修改或者伪造请求 / 响应报文，数据不具有可信性。</p><h2 id="2-什么是安全的通信"><a href="#2-什么是安全的通信" class="headerlink" title="2 什么是安全的通信"></a>2 什么是安全的通信</h2><p>通常认为如果通信过程具备了四个特性，就可以认为是“安全”的，这四个特性是：</p><ul><li><strong>保密性</strong></li><li><strong>完整性</strong></li><li><strong>身份认证</strong></li></ul><p>而HTTPS则实现了这三个特性,原因在于它的”S”===&gt; SSL/TLS协议</p><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/netssl.jpg" alt=""></p><p><strong>SSL 是 “Secure Sockets Layer” 的缩写，中文意思为“安全套接层”，所以说明－－戴套更安全～</strong></p><h2 id="3-SSL-TLS协议"><a href="#3-SSL-TLS协议" class="headerlink" title="3 SSL/TLS协议"></a>3 SSL/TLS协议</h2><h3 id="3-1-设计的目的"><a href="#3-1-设计的目的" class="headerlink" title="3.1 设计的目的"></a>3.1 设计的目的</h3><ul><li><strong>保密性</strong></li><li><strong>完整性</strong></li><li><strong>身份认证</strong></li></ul><h3 id="3-2-版本"><a href="#3-2-版本" class="headerlink" title="3.2 版本"></a>3.2 版本</h3><p><strong>一开始叫SSL,后来更名为TLS,目前的版本号是TLS1.3</strong></p><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/nettls.png" alt=""></p><h3 id="3-3-对称加密"><a href="#3-3-对称加密" class="headerlink" title="3.3 对称加密"></a>3.3 对称加密</h3><p>“对称加密”很好理解，就是指加密和解密时使用的密钥都是同一个，是“对称”的。只要保证了密钥的安全，那整个通信过程就可以说具有了机密性。<br>举个例子，你想要登录某网站，只要事先和它约定好使用一个对称密码，通信过程中传输的全是用密钥加密后的密文，只有你和网站才能解密。黑客即使能够窃听，看到的也只是乱码，因为没有密钥无法解出明文，所以就实现了机密性。</p><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/netdcjm.png" alt=""></p><p><strong>常用的对称加密算法为AES算法</strong></p><p>AES 的意思是“高级加密标准”（Advanced Encryption Standard），密钥长度可以是128、192 或 256。它是 DES 算法的替代者，安全强度很高，性能也很好，而且有的硬件还会做特殊优化，所以非常流行，是应用最广泛的对称加密算法。</p><h3 id="3-4-非对称加密"><a href="#3-4-非对称加密" class="headerlink" title="3.4 非对称加密"></a>3.4 非对称加密</h3><p>对称加密看上去好像完美地实现了机密性，但其中有一个很大的问题：如何把密钥安全地传递给对方，术语叫“密钥交换”。</p><p><strong>此时就出现了非对称加密（也叫公钥加密算法）。它有两个密钥，一个叫“公钥”（public key），一个叫“私钥”（private key）。</strong></p><p>两个密钥是不同的，“不对称”，公钥可以公开给任何人使用，而私钥必须严格保密。公钥和私钥有个特别的“单向”性，虽然都可以用来加密解密，但公钥加密后只能用私钥解密，反过来，私钥加密后也只能用公钥解密。</p><p>非对称加密可以解决“密钥交换”的问题。网站秘密保管私钥，在网上任意分发公钥，你想要登录网站只要用公钥加密就行了，密文只能由私钥持有者才能解密。而黑客因为没有私钥，所以就无法破解密文。</p><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/netfdc.png" alt=""></p><p><strong>常用的非对称加密算法为RSA算法,后起之秀是基于椭圆曲线的ECDH协议</strong></p><h3 id="3-5-混合加密"><a href="#3-5-混合加密" class="headerlink" title="3.5 混合加密"></a>3.5 混合加密</h3><p><strong>现在 TLS 里使用的混合加密方式</strong>，其实说穿了也很简单：</p><ul><li>在通信刚开始的时候<strong>使用非对称算法</strong>，比如 RSA、ECDH，首先<strong>解决密钥交换</strong>的问题。</li><li>然后用随机数产生对称算法使用的“会话密钥”（session key），再用公钥加密。因为会话密钥很短，通常只有 16 字节或 32 字节，所以慢一点也无所谓。</li><li>对方拿到密文后用私钥解密，取出会话密钥。这样，双方就实现了对称密钥的安全交换，后续就不再使用非对称加密，全都使用对称加密。</li></ul><h3 id="3-6-数字签名"><a href="#3-6-数字签名" class="headerlink" title="3.6 数字签名"></a>3.6 数字签名</h3><ul><li>基于私钥加密，只能使用公钥解密：起到身份认证的使用</li><li>公钥的管理：Public Key Infrastructure（PKI）公钥基础设施<ul><li>由 Certificate Authority（CA）数字证书认证机构将用户个人身份与公开密钥关联在一起</li><li>公钥数字证书组成<ul><li>CA 信息、公钥用户信息、公钥、权威机构的签字、有效期</li></ul></li><li>PKI 用户<ul><li>向 CA 注册公钥的用户</li><li>希望使用已注册公钥的用户</li></ul></li></ul></li></ul><h3 id="3-6-1-签发证书的流程"><a href="#3-6-1-签发证书的流程" class="headerlink" title="3.6.1 签发证书的流程"></a>3.6.1 签发证书的流程</h3><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/netcert.png" alt=""></p><h4 id="3-6-2-签名和验签流程"><a href="#3-6-2-签名和验签流程" class="headerlink" title="3.6.2 签名和验签流程"></a>3.6.2 签名和验签流程</h4><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/netsign.png" alt=""></p><h4 id="3-6-3-PKI公钥基础设施"><a href="#3-6-3-PKI公钥基础设施" class="headerlink" title="3.6.3 PKI公钥基础设施"></a>3.6.3 PKI公钥基础设施</h4><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/netpki.png" alt=""></p><h2 id="3-7-TLS1-3和TLS1-2对比"><a href="#3-7-TLS1-3和TLS1-2对比" class="headerlink" title="3.7 TLS1.3和TLS1.2对比"></a>3.7 TLS1.3和TLS1.2对比</h2><ul><li>相比过去的的版本，引入了新的密钥协商机制 — PSK</li><li>支持 0-RTT 数据传输，在建立连接时节省了往返时间</li><li>废弃了 3DES、RC4、AES-CBC 等加密组件，废弃了 SHA1、MD5 等哈希算法</li><li>ServerHello 之后的所有握手消息采取了加密操作，可见明文大大减少</li><li>不再允许对加密报文进行压缩、不再允许双方发起重协商</li><li>DSA 证书不再允许在 TLS 1.3 中使用</li></ul><h4 id="3-7-1-更快的访问速度"><a href="#3-7-1-更快的访问速度" class="headerlink" title="3.7.1 更快的访问速度"></a>3.7.1 更快的访问速度</h4><p>初始建立TLS连接时TLS1.2需要两次RTT,而TLS1.3则需要一次RTT</p><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/nettlsrtt.png" alt=""></p><p>再次建立连接时,基于<strong>session ticket</strong>,<strong>TLS1.2需要一次RTT,而TLS1.3则需要0次RTT</strong></p><h4 id="3-7-2-更强安全性"><a href="#3-7-2-更强安全性" class="headerlink" title="3.7.2 更强安全性"></a>3.7.2 更强安全性</h4><p>TLS 1.3 在之前版本的基础上删除了那些不安全的加密算法，这些加密算法包括：</p><ul><li>RSA 密钥传输 —— 不支持前向安全性</li><li>CBC 模式密码 —— 易受 BEAST 和 Lucky 13 攻击</li><li>RC4 流密码 —— 在 HTTPS 中使用并不安全</li><li>SHA-1 哈希函数 —— 建议以 SHA-2 取而代之</li><li>任意 Diffie-Hellman 组—— CVE-2016-0701 漏洞</li><li>输出密码 —— 易受 FREAK 和 LogJam 攻击</li></ul>]]></content>
      
      
      <categories>
          
          <category> 基础 </category>
          
          <category> 网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 网络 </tag>
            
            <tag> HTTP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HTTP协议</title>
      <link href="/2020/04/13/HTTP%E5%8D%8F%E8%AE%AE/"/>
      <url>/2020/04/13/HTTP%E5%8D%8F%E8%AE%AE/</url>
      
        <content type="html"><![CDATA[<h2 id="1-URI统一资源标识符"><a href="#1-URI统一资源标识符" class="headerlink" title="1 URI统一资源标识符"></a>1 URI统一资源标识符</h2><h3 id="1-1-什么是URI"><a href="#1-1-什么是URI" class="headerlink" title="1.1 什么是URI"></a>1.1 什么是URI</h3><ul><li><strong>URL</strong>：Uniform Resource Locator，表示资源的位置， 期望提供查找资源的方法</li><li><strong>URN</strong>：Uniform Resource Name，期望为资源提供持久 的、位置无关的标识方式，并允许简单地将多个命名空间映射到单个URN命名 空间<ul><li>例如磁力链接 magnet:?xt=urn:sha1:YNCKHTQC5C </li></ul></li><li><strong>URI</strong>：Uniform Resource Identifier，用以区分资源，是 URL 和 URN 的超集，用以取代 URL 和 URN 概念</li></ul><p>严格地说，URI 不完全等同于网址，它包含有 URL 和 URN两个部分，在 HTTP 世界里用的网址实际上是 URL——统一资源定位符（Uniform Resource Locator）。但因为URL 实在是太普及了，所以常常把这两者简单地视为相等。</p><h3 id="1-2-URI的组成"><a href="#1-2-URI的组成" class="headerlink" title="1.2 URI的组成"></a>1.2 URI的组成</h3><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/neturi2.png" alt=""></p><ul><li>URI 通常由 scheme、host:port、path 和 query 四个部分组成，有的可以省略；</li><li>scheme 叫“方案名”或者“协议名”，表示资源应该使用哪种协议来访问；</li><li>“host:port”表示资源所在的主机名和端口号;</li><li>path 标记资源所在的位置；</li><li>query 表示对资源附加的额外要求；</li><li>在 URI 里对“<strong>@&amp;/”等特殊字符和汉字必须要做编码，否则服务器收到 HTTP 报文后会无法正确处理</strong></li></ul><h2 id="2-常见方法"><a href="#2-常见方法" class="headerlink" title="2 常见方法"></a>2 常见方法</h2><ul><li><strong>GET</strong>：主要的获取信息方法，大量的性能优化都针对该方法，<strong>幂等方法</strong></li><li><strong>HEAD</strong>：类似 GET 方法，但服务器不发送 BODY，用以获取 HEAD 元数据，<strong>幂等方法</strong></li><li><strong>POST</strong>：常用于提交 HTML FORM 表单、新增资源等</li><li><strong>PUT</strong>：更新资源，带条件时是<strong>幂等方法</strong> </li><li><strong>DELETE</strong>：删除资源，<strong>幂等方法</strong> </li><li><strong>CONNECT</strong>：建立 tunnel 隧道 </li><li><strong>OPTIONS</strong>：显示服务器对访问资源支持的方法，幂等方法 </li><li><strong>TRACE</strong>：回显服务器收到的请求，用于定位问题。有安全风险（<strong>已不使用</strong>）</li></ul><h2 id="3-HTTP-Code"><a href="#3-HTTP-Code" class="headerlink" title="3 HTTP Code"></a>3 HTTP Code</h2><h3 id="3-1-分类"><a href="#3-1-分类" class="headerlink" title="3.1 分类"></a>3.1 分类</h3><p>RFC 标准把状态码分成了五类，用数字的第一位表示分类:</p><ul><li><strong>1××</strong>：<strong>请求已接收到，需要进一步处理才能完成，HTTP1.0 不支持</strong>；</li><li><strong>2××</strong>：<strong>成功</strong>，报文已经收到并被正确处理；</li><li><strong>3××</strong>：<strong>重定向</strong>，资源位置发生变动，需要客户端重新发送请求;</li><li><strong>4××</strong>：<strong>客户端错误</strong>，请求报文有误，服务器无法处理;</li><li><strong>5××</strong>：<strong>服务器错误</strong>，服务器在处理请求时内部发生了错误</li></ul><h3 id="3-2-1xx"><a href="#3-2-1xx" class="headerlink" title="3.2 1xx"></a>3.2 1xx</h3><ul><li><strong>100 Continue</strong>：<strong>上传大文件前使用</strong></li><li><strong>101 Switch Protocols</strong>：<strong>协议升级使用</strong> ,由客户端发起请求中携带 Upgrade: 头部触发，如升级 websocket 或者 http/2.0</li></ul><h3 id="3-3-2xx"><a href="#3-3-2xx" class="headerlink" title="3.3 2xx"></a>3.3 2xx</h3><ul><li><strong>200 OK</strong>:是最常见的成功状态码，表示一切正常，服务器如客户端所期望的那样返回了处理结果，如果是非 HEAD请求，通常在响应头后都会有 body 数据</li><li><strong>204 No Content</strong>:是另一个很常见的成功状态码，它的含义<strong>与“200 OK”基本相同，但响应头后没有 body 数据</strong></li><li><strong>206 Partial Content</strong>：使用 <strong>range 协议时返回部分响应内容时的响应码</strong>，状态码 206 通常还会伴随着头字段“<strong>Content-Range</strong>”，表示响应报文里 body 数据的具体范围，供客户端确认，例如“Content-Range: bytes 0-99/2000”，意思是此次获取的是总计 2000 个字节的前 100 个字节。</li></ul><h3 id="3-4-3xx"><a href="#3-4-3xx" class="headerlink" title="3.4 3xx"></a>3.4 3xx</h3><ul><li><strong>301 Moved Permanently</strong>：资源<strong>永久性的重定</strong>向到另一个 URI 中</li><li><strong>302 Found</strong>：资源<strong>临时的重定向</strong>到另一个 URI </li><li><strong>304 Not Modified</strong>：当客户端拥有可能过期的缓存时，会携带缓存的标识 etag、时间等信息询问服务器缓存是否仍可复用，而304是告诉客户端可以<strong>复用缓存</strong></li><li><strong>307 Temporary Redirect</strong>：<strong>类似302</strong>，但明确重定向后请求方法必须<strong>与原请求方法相同</strong>，不得改变</li><li><strong>308 Permanent Redirect</strong>：<strong>类似301</strong>，但明确重定向后请求方法必须<strong>与原请求方法相同</strong>，不得改变</li></ul><h3 id="3-5-4xx"><a href="#3-5-4xx" class="headerlink" title="3.5 4xx"></a>3.5 4xx</h3><ul><li><strong>400 Bad Request</strong>：服务器认为客户端出现了错误，但<strong>不能明确判断为以下哪种错误</strong>时使用此错误码。例如HTTP请求格式错误</li><li><strong>401 Unauthorized</strong>：<strong>用户认证信息缺失或者不正确</strong>，导致服务器无法处理请求</li><li><strong>403 Forbidden</strong>：服务器理解请求的含义，但<strong>没有权限执行</strong>此请求</li><li><strong>404 Not Found</strong>：服务器没有找到对应的资源</li></ul><h3 id="3-6-5xx"><a href="#3-6-5xx" class="headerlink" title="3.6 5xx"></a>3.6 5xx</h3><ul><li><strong>500 Internal Server Error</strong>：服务器<strong>内部错误</strong>，且不属于以下错误类型</li><li><strong>501 Not Implemented</strong>：<strong>服务器不支持实现请求所需要的功能</strong> </li><li><strong>502 Bad Gateway</strong>：代理服务器<strong>无法获取到合法响应</strong></li><li><strong>503 Service Unavailable</strong>：服务器资源<strong>尚未准备好处理当前请求</strong></li><li><strong>504 Gateway Timeout</strong>：代理服务器无法及时的<strong>从上游获得响应</strong></li></ul><h2 id="4-HTTP连接流程"><a href="#4-HTTP连接流程" class="headerlink" title="4 HTTP连接流程"></a>4 HTTP连接流程</h2><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/httpduring.png" alt=""></p><h2 id="5-长连接与短连接"><a href="#5-长连接与短连接" class="headerlink" title="5 长连接与短连接"></a>5 长连接与短连接</h2><h3 id="5-1-短连接"><a href="#5-1-短连接" class="headerlink" title="5.1 短连接"></a>5.1 短连接</h3><p>HTTP 协议最初（0.9/1.0）是个非常简单的协议，通信过程也采用了简单的“请求 - 应答”方式。</p><p><strong>它底层的数据传输基于 TCP/IP，每次发送请求前需要先与服务器建立连接，收到响应报文后会立即关闭连接。</strong></p><p>因为客户端与服务器的整个连接过程很短暂，不会与服务器保持长时间的连接状态，所以就被称为“短连接”（shortlived connections）。早期的 HTTP 协议也被称为是“无连接”的协议。</p><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/nethttpshort.png" alt=""></p><h3 id="5-2-长连接"><a href="#5-2-长连接" class="headerlink" title="5.2 长连接"></a>5.2 长连接</h3><p>针对短连接暴露出的缺点，HTTP 协议就提出了“长连接”的通信方式，也叫“持久连接”（persistent connections）、“连接保活”（keep alive）、“连接复用”（connection reuse）。<br>其实解决办法也很简单，用的就是“成本均摊”的思路，<strong>既然 TCP 的连接和关闭非常耗时间，那么就把这个时间成本由原来的一个“请求 - 应答”均摊到多个“请求 - 应答”上</strong>。<br>这样虽然不能改善 TCP 的连接效率，但基于“分母效应”，每个“请求 - 应答”的无效时间就会降低不少，整体传输效率也就提高了。<br>这里我画了一个短连接与长连接的对比示意图</p><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/nethttplong.png" alt=""></p><h3 id="5-3-连接相关的头字段"><a href="#5-3-连接相关的头字段" class="headerlink" title="5.3 连接相关的头字段"></a>5.3 连接相关的头字段</h3><ul><li><strong>Keep-Alive</strong>：长连接<ul><li>客户端请求长连接 <pre><code>- Connection: Keep-Alive</code></pre></li><li>服务器表示支持长连接<ul><li>Connection: Keep-Alive</li></ul></li><li>客户端复用连接</li><li>HTTP/1.1 默认支持长连接 </li></ul></li><li><strong>Close</strong>：短连接</li><li>对代理服务器的要求<ul><li>不转发 Connection 列出头部，该头部仅与当前连接相关</li></ul></li></ul><h3 id="5-4-Connection作用范围"><a href="#5-4-Connection作用范围" class="headerlink" title="5.4 Connection作用范围"></a>5.4 Connection作用范围</h3><p><strong>Connection 仅针对当前连接有效!</strong></p><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/netkeepalive.png" alt=""></p><h3 id="5-5-桥头堵塞问题"><a href="#5-5-桥头堵塞问题" class="headerlink" title="5.5 桥头堵塞问题"></a>5.5 桥头堵塞问题</h3><p>因为 HTTP 规定报文必须是“一发一收”，这就形成了一个先进先出的“串行”队列。队列里的请求没有轻重缓急的优先级，只有入队的先后顺序，排在最前面的请求被最优先处理。<br><strong>如果队首的请求因为处理的太慢耽误了时间，那么队列里后面的所有请求也不得不跟着一起等待，结果就是其他的请求承担了不应有的时间成本</strong></p><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/httpheadblocking.png" alt=""></p><h4 id="5-5-1-性能优化"><a href="#5-5-1-性能优化" class="headerlink" title="5.5.1 性能优化"></a>5.5.1 性能优化</h4><p>因为“请求 - 应答”模型不能变，所以“队头阻塞”问题在HTTP/1.1 里无法解决，只能缓解，有什么办法呢？</p><p><strong>通过HTTP 里的“并发连接”（concurrentconnections）来缓解此问题，也就是同时对一个域名发起多个长连接，用数量来解决质量的问题。</strong></p><p>一个客户端<strong>最多对一个域名发起6~8个并发连接</strong></p><p>若果是多个域名,一共可以发起并发的数量为:<strong>域名数乘以(6~8)</strong>，通过多个域名提高并发的技术我们称为<strong>域名分片</strong></p><p><strong>总结:“队头阻塞”问题会导致性能下降，可以用“并发连接”和“域名分片”技术缓解</strong></p><h2 id="6-HTTP-Range规范"><a href="#6-HTTP-Range规范" class="headerlink" title="6 HTTP Range规范"></a>6 HTTP Range规范</h2><h3 id="6-1-Http-Range"><a href="#6-1-Http-Range" class="headerlink" title="6.1 Http Range"></a>6.1 Http Range</h3><ul><li><p>允许服务器基于客户端的请求只发送响应包体的一部分给到客户端，而客户端 自动将多个片断的包体组合成完整的体积更大的包体</p><ul><li><p>支持断点续传</p></li><li><p>支持多线程下载</p></li><li><p>支持视频播放器实时拖动</p></li></ul></li><li><p>服务器通过 Accept-Range 头部表示是否支持 Range 请求</p><ul><li>Accept-Ranges = acceptable-ranges</li><li>例如:<ul><li>Accept-Ranges: bytes：支持 </li><li>Accept-Ranges: none：不支持</li></ul></li></ul></li></ul><h3 id="6-2-Range-请求范围的单位"><a href="#6-2-Range-请求范围的单位" class="headerlink" title="6.2 Range 请求范围的单位"></a>6.2 Range 请求范围的单位</h3><p>基于字节，设包体总长度为 10000 </p><ul><li><p>第 1 个 500 字节：bytes=0-499</p></li><li><p>第 2 个 500 字节</p><ul><li>bytes=500-999 </li><li>bytes=500-600,601-999 •</li><li>bytes=500-700,601-999</li></ul></li><li><p>最后 1 个 500 字节</p><ul><li>bytes=-500 </li><li>bytes=9500</li></ul></li><li><p>仅要第 1 个和最后 1 个字节：bytes=0-0,-1 </p></li></ul><p><strong>通过Range头部传递请求范围，如：Range: bytes=0-499</strong></p><h3 id="6-3-Range-条件请求"><a href="#6-3-Range-条件请求" class="headerlink" title="6.3 Range 条件请求"></a>6.3 Range 条件请求</h3><ul><li>如果客户端已经得到了 Range 响应的一部分，并想在这部分响应未过期 的情况下，获取其他部分的响应<ul><li>常与 If-Unmodified-Since 或者 If-Match 头部共同使用</li></ul></li><li>If-Range = entity-tag / HTTP-date<ul><li>可以使用 Etag 或者 Last-Modified</li></ul></li></ul><h3 id="6-4-服务器响应"><a href="#6-4-服务器响应" class="headerlink" title="6.4 服务器响应"></a>6.4 服务器响应</h3><ul><li><strong>206 Partial Content</strong> :<strong>正常返回</strong>,Content-Range 头部：显示当前片断包体在完整包体中的位置</li><li><strong>416 Range Not Satisfiable</strong> :<strong>请求范围不满足实际资源的大小</strong>，其中 Content-Range 中的 complete- length 显示完整响应的长度，例如:Content-Range: bytes */1234</li><li><strong>200 OK</strong> :服务器<strong>不支持 Range 请求时</strong>，则以 200 返回完整的响应包体</li></ul><h3 id="6-5-多重范围与-multipart"><a href="#6-5-多重范围与-multipart" class="headerlink" title="6.5 多重范围与 multipart"></a>6.5 多重范围与 multipart</h3><ul><li>请求：<ul><li>Range: bytes=0-50, 100-150</li></ul></li><li>响应:<ul><li>Content-Type：multipart/byteranges; boundary=…</li></ul></li></ul><h2 id="7-Cookie"><a href="#7-Cookie" class="headerlink" title="7 Cookie"></a>7 Cookie</h2><h3 id="7-1-什么是Cookie"><a href="#7-1-什么是Cookie" class="headerlink" title="7.1 什么是Cookie"></a>7.1 什么是Cookie</h3><p>保存在客户端、由浏览器维护、表示应用状态的 HTTP 头部</p><ul><li>存放在内存或者磁盘中</li><li>服务器端生成 Cookie 在响应中通过 Set-Cookie 头部告知客户端（允许多 个 Set-Cookie 头部传递多个值）</li><li>客户端得到 Cookie 后，后续请求都会 自动将 Cookie 头部携带至请求中</li></ul><h3 id="7-2-Cookie属性"><a href="#7-2-Cookie属性" class="headerlink" title="7.2 Cookie属性"></a>7.2 Cookie属性</h3><ul><li><strong>expires-av = “Expires=” sane-cookie-date</strong> <ul><li>cookie 到日期 sane-cookie-date 后失效</li></ul></li><li><strong>max-age-av = “Max-Age=” x</strong><ul><li>cookie 经过x 秒后失效。max-age 优先级高于 expires</li></ul></li><li><strong>domain-av = “Domain=” domain-value</strong><ul><li>指定 cookie 可用于哪些域名，默认可以访问当前域名</li></ul></li><li><strong>path-av = “Path=” path-value</strong> <ul><li>指定 Path 路径下才能使用 cookie</li></ul></li><li><strong>secure-av = “Secure“</strong> <ul><li>只有使用 TLS/SSL 协议（https）时才能使用 cookie</li></ul></li><li><strong>httponly-av = “HttpOnly“</strong> <ul><li>不能使用 JavaScript（Document.cookie 、XMLHttpRequest 、Request APIs）访问到 cookie</li></ul></li></ul><h3 id="7-3-Cookie-在协议设计上的问题"><a href="#7-3-Cookie-在协议设计上的问题" class="headerlink" title="7.3 Cookie 在协议设计上的问题"></a>7.3 Cookie 在协议设计上的问题</h3><ul><li>Cookie 会被附加在每个 HTTP 请求中，所以<strong>无形中增加了流量</strong></li><li>由于在 HTTP 请求中的 Cookie 是明文传递的，<strong>所以安全性成问题</strong>（除非用 HTTPS）</li><li>Cookie 的大小不应超过 4KB，故对于复杂的存储需求来说是不够用的</li></ul><h3 id="7-4-Cookie的应用"><a href="#7-4-Cookie的应用" class="headerlink" title="7.4 Cookie的应用"></a>7.4 Cookie的应用</h3><ul><li><strong>身份识别</strong></li><li><strong>广告追踪</strong></li></ul><h2 id="8-同源策略"><a href="#8-同源策略" class="headerlink" title="8 同源策略"></a>8 同源策略</h2><h3 id="8-1-定义"><a href="#8-1-定义" class="headerlink" title="8.1 定义"></a>8.1 定义</h3><p><strong>所有的浏览器都遵守同源策略,服务器不管你是不是同源都返回数据！</strong>，这个策略能够保证一个源的动态脚本不能读取或操作其他源的http响应和cookie，这就使浏览器隔离了来自不同源的内容，防止它们互相操作。所谓同源是指<code>协议、域名和端口</code>都一致的情况。</p><p>简单的来说，出于安全方面的考虑，页面中的JavaScript无法访问其他服务器上的数据，即“同源策略”。而跨域就是通过某些手段来绕过同源策略限制，实现不同服务器之间通信的效果。</p><h3 id="8-2-举例"><a href="#8-2-举例" class="headerlink" title="8.2 举例"></a>8.2 举例</h3><p>举例说明：</p><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/netcrof.png" alt=""></p><h3 id="8-3-解决方案－CORS"><a href="#8-3-解决方案－CORS" class="headerlink" title="8.3 解决方案－CORS"></a>8.3 解决方案－CORS</h3><p>如果站点 A 允许站点 B 的脚本访问其资源，必须在 HTTP 响应中显式的告知浏览器：站点 B 是被允许的 :</p><ul><li><p>访问站点 A 的请求，浏览器应告知该请求来自站点 B</p></li><li><p>站点 A 的响应中，应明确哪些跨域请求是被允许的</p></li></ul><h4 id="8-3-1-简单请求"><a href="#8-3-1-简单请求" class="headerlink" title="8.3.1 简单请求"></a>8.3.1 简单请求</h4><p>何为简单请求？ </p><ul><li>GET/HEAD/POST 方法之一</li><li>仅能使用 CORS 安全的头部：Accept、Accept-Language、Content-Language、Content-Type </li><li>Content-Type 值只能是： text/plain、multipart/form-data、application/x-www-form-urlencoded 三者其中之一 </li></ul><p>处理方式:</p><ul><li>请求中携带 Origin 头部告知来自哪个域</li><li>响应中携带 Access-Control-Allow-Origin 头部表示允许哪些域</li><li>浏览器放行</li></ul><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/netsimplerequest.png" alt=""></p><h4 id="8-3-2-预检请求"><a href="#8-3-2-预检请求" class="headerlink" title="8.3.2 预检请求"></a>8.3.2 预检请求</h4><p>简单请求以外的其他请求,访问资源前需要先发起 prefilght 预检请求（方法为 OPTIONS）询问何种请求是被允许的:</p><ul><li>预检请求头部<ul><li>Access-Control-Request-Method</li><li>Access-Control-Request-Headers</li></ul></li><li>预检请求响应 <ul><li>Access-Control-Allow-Methods</li><li>Access-Control-Allow-Headers</li><li>Access-Control-Max-Age</li></ul></li></ul><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/netprerequest.png" alt=""></p><h3 id="8-4-响应头部"><a href="#8-4-响应头部" class="headerlink" title="8.4 响应头部"></a>8.4 响应头部</h3><ul><li><strong>Access-Control-Allow-Methods</strong><ul><li>在 preflight 预检请求的响应中，告知客户端后续请求允许使用的方法</li></ul></li><li><strong>Access-Control-Allow-Headers</strong><ul><li>在 preflight 预检请求的响应中，告知客户端后续请求允许携带的头部</li></ul></li><li><strong>Access-Control-Max-Age</strong><ul><li>在 preflight 预检请求的响应中，告知客户端该响应的信息可以缓存多久</li></ul></li><li><strong>Access-Control-Expose-Headers</strong><ul><li>告知浏览器哪些响应头部可以供客户端使用，默认情况下只有 Cache-Control、Content-Language、 Content-Type、Expires、Last-Modified、Pragma 可供使用 </li></ul></li><li><strong>Access-Control-Allow-Origin</strong><ul><li>告知浏览器允许哪些域访问当前资源，<code>*</code>表示允许所有域。为避免缓存错乱，响应中需要携带 Vary: Origin </li></ul></li><li><strong>Access-Control-Allow-Credentials</strong><ul><li>告知浏览器是否可以将 Credentials 暴露给客户端使用，Credentials 包含 cookie、authorization 类头部、 TLS证书等</li></ul></li></ul><h2 id="9-缓存机制"><a href="#9-缓存机制" class="headerlink" title="9 缓存机制"></a>9 缓存机制</h2><h3 id="9-1-缓存首部字段"><a href="#9-1-缓存首部字段" class="headerlink" title="9.1 缓存首部字段"></a>9.1 缓存首部字段</h3><table><thead><tr><th align="center">头字段</th><th align="left">说明</th><th align="center">备注</th></tr></thead><tbody><tr><td align="center"><strong>Pragma</strong></td><td align="left">http1.0产物,控制缓存行为和http1.1中的Cache-Control功能类似</td><td align="center">历史产物</td></tr><tr><td align="center"><strong>Expires</strong></td><td align="left">http1.0产物,Expires的值为服务端返回的到期时间，即下一次请求时，请求时间小于服务端返回的到期时间，直接使用缓存数据。</td><td align="center">历史产物</td></tr><tr><td align="center"><strong>Cache-Control</strong></td><td align="left">http1.1 时期的缓存方案</td><td align="center">主流使用</td></tr></tbody></table><ul><li>如果使用了Pragma: ‘no-cache’的话，再设置Expires或者Cache-Control，就没有用了，说明Pragma的权值比后两者高。</li><li>如果设置了Expires之后，客户端在需要请求数据的时候，首先会对比当前系统时间和这个Expires时间，如果没有超过Expires时间，则直接读取本地磁盘中的缓存数据，不发送请求。</li></ul><h3 id="9-2-Cache-Control"><a href="#9-2-Cache-Control" class="headerlink" title="9.2 Cache-Control"></a>9.2 Cache-Control</h3><h4 id="9-2-1-作为请求头字段"><a href="#9-2-1-作为请求头字段" class="headerlink" title="9.2.1 作为请求头字段"></a>9.2.1 作为请求头字段</h4><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/netcache3.png" alt=""></p><h4 id="9-2-2-作为响应字段"><a href="#9-2-2-作为响应字段" class="headerlink" title="9.2.2 作为响应字段"></a>9.2.2 作为响应字段</h4><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/netcache4.png" alt=""></p><h3 id="9-3-缓存校验字段"><a href="#9-3-缓存校验字段" class="headerlink" title="9.3 缓存校验字段"></a>9.3 缓存校验字段</h3><h4 id="9-3-1-Last-Modified"><a href="#9-3-1-Last-Modified" class="headerlink" title="9.3.1 Last-Modified"></a>9.3.1 Last-Modified</h4><p>服务器将资源传递给客户端时，会将资源最后更改的时间以“Last-Modified: GMT”的形式加在实体首部上一起返回给客户端。</p><pre><code class="http">Last-Modified: Fri, 22 Jul 2016 01:47:00 GMT</code></pre><p>客户端会为资源标记上该信息，下次再次请求时，会把该信息附带在请求报文中一并带给服务器去做检查，若传递的时间值与服务器上该资源最终修改时间是一致的，则说明该资源没有被修改过，直接返回304状态码，内容为空，这样就节省了传输数据量 。</p><p>如果两个时间不一致，则服务器会发回该资源并返回200状态码，和第一次请求时类似。这样保证不向客户端重复发出资源，也保证当服务器有变化时，客户端能够得到最新的资源。一个304响应比一个静态资源通常小得多，这样就节省了网络带宽。</p><p>至于传递标记起来的最终修改时间的请求报文为：</p><p><strong>If-Modified-Since: Last-Modified-value</strong></p><p>示例为:</p><pre><code class="http">If-Modified-Since: Thu, 31 Mar 2016 07:07:52 GMT</code></pre><p>该请求首部告诉服务器如果客户端传来的最后修改时间与服务器上的一致，则直接回送304 和响应报头即可。<br>当前各浏览器均是使用的该请求首部来向服务器传递保存的 Last-Modified 值。</p><p><strong>Last-Modified 存在一定问题，如果在服务器上，一个资源被修改了，但其实际内容根本没发生改变，会因为Last-Modified时间匹配不上而返回了整个实体给客户端（即使客户端缓存里有个一模一样的资源</strong>）。</p><h4 id="9-3-2-ETag"><a href="#9-3-2-ETag" class="headerlink" title="9.3.2 ETag"></a>9.3.2 ETag</h4><p>为了解决上述Last-Modified可能存在的不准确的问题，Http1.1还推出了 ETag 实体首部字段。 服务器会通过某种算法，给资源计算得出一个唯一标志符（比如md5标志），在把资源响应给客户端的时候，会在实体首部上“ETag: 唯一标识符”一起返回给客户端。例如：</p><pre><code class="http">Etag: &quot;5d8c72a5edda8d6a:3239&quot;</code></pre><p>客户端会保留该 ETag 字段，并在下一次请求时将其一并带过去给服务器。服务器只需要比较客户端传来的ETag跟自己服务器上该资源的ETag是否一致，就能很好地判断资源相对客户端而言是否被修改过了。<br>如果服务器发现ETag匹配不上，那么直接以常规GET 200回包形式将新的资源（当然也包括了新的ETag）发给客户端；如果ETag是一致的，则直接返回304知会客户端直接使用本地缓存即可。</p><p>那么客户端是如何把标记在资源上的 ETag 传回给服务器的呢？请求报文中有两个首部字段可以带上 ETag 值：</p><p><strong>If-None-Match: ETag-value</strong><br>示例为:</p><pre><code class="http">If-None-Match: &quot;5d8c72a5edda8d6a:3239&quot; </code></pre><p>告诉服务端如果 ETag 没匹配上需要重发资源数据，否则直接回送304 和响应报头即可。 当前各浏览器均是使用的该请求首部来向服务器传递保存的 ETag 值。</p><h3 id="9-4-缓存流程图"><a href="#9-4-缓存流程图" class="headerlink" title="9.4 缓存流程图"></a>9.4 缓存流程图</h3><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/netcachelc.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 基础 </category>
          
          <category> 网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 网络 </tag>
            
            <tag> HTTP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TCP关闭连接</title>
      <link href="/2020/04/11/TCP%E5%85%B3%E9%97%AD%E8%BF%9E%E6%8E%A5/"/>
      <url>/2020/04/11/TCP%E5%85%B3%E9%97%AD%E8%BF%9E%E6%8E%A5/</url>
      
        <content type="html"><![CDATA[<h2 id="1-两个关键的参数"><a href="#1-两个关键的参数" class="headerlink" title="1 两个关键的参数"></a>1 两个关键的参数</h2><ul><li><strong>time_wait</strong>:客户端断开连接时</li><li><strong>close_wait</strong>:服务端断开连接时</li></ul><h2 id="2-time-wait"><a href="#2-time-wait" class="headerlink" title="2 time_wait"></a>2 time_wait</h2><h3 id="2-1-为什么会有time-wait"><a href="#2-1-为什么会有time-wait" class="headerlink" title="2.1 为什么会有time_wait"></a>2.1 为什么会有time_wait</h3><ul><li><strong>可靠地实现TCP全双工连接的终止。（确保最后的ACK能让被关闭方接收）</strong></li><li><strong>允许老的重复分节在网络中消逝</strong></li></ul><h3 id="2-2-隐患"><a href="#2-2-隐患" class="headerlink" title="2.2 隐患"></a>2.2 隐患</h3><p>在socket的处于TIME_WAIT状态之后到它结束之前，<strong>该socket所占用的本地端口号将一直无法释放</strong>，因此服务在高并发高负载下运行一段时间后，就常常会出现做为客户端的程序<strong>无法向服务端建立新的sockett连接的情况</strong></p><p>这是因为<strong>服务方socket资源已经耗尽</strong>。<strong>netstat命令查看系统将会发现机器上存在大量处于TIME_WAIT状态的socket连接</strong></p><h3 id="2-3-解决方法"><a href="#2-3-解决方法" class="headerlink" title="2.3 解决方法"></a>2.3 解决方法</h3><ul><li><p><strong>net.ipv4.tcp_tw_reuse = 1</strong></p><ul><li>开启后，作为客户端时新连接<strong>可以使用仍然处于 TIME-WAIT 状态的端口</strong></li><li>需要把<strong>net.ipv4.tcp_timestamps设置为1</strong>,由于 timestamp 的存在，操作系统可以拒绝迟到的报文 </li></ul></li><li><p><strong>net.ipv4.tcp_max_tw_buckets = 262144</strong></p><ul><li><strong>time_wait 状态连接的最大数量</strong> </li><li><strong>超出后直接关闭连</strong></li></ul></li><li><p>net.ipv4.tcp_tw_recycle = 0 </p><ul><li>开启后，同时作为客户端和服务器都可以使用 TIME-WAIT 状态的端口</li><li><strong>不安全</strong>，无法避免报文延迟、重复等给新连接造成混乱</li><li><strong>不要使用</strong></li></ul></li><li><p>Windows下可以修改time_wait的等待时间,但Linux下不能修改</p></li></ul><h2 id="3-close-wait"><a href="#3-close-wait" class="headerlink" title="3 close_wait"></a>3 close_wait</h2><p><strong>一般都是代码问题～</strong></p><p><strong>没有立即发送FIN，堵塞住了</strong></p><p>检查代码,有可能的原因:</p><ul><li><strong>Mysql没有rollback或commit</strong>　自身经历．．．</li></ul><p><strong>可以使用perf或者strace工具进行分析查看</strong></p>]]></content>
      
      
      <categories>
          
          <category> 基础 </category>
          
          <category> 网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 网络 </tag>
            
            <tag> TCP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TCP协议</title>
      <link href="/2020/04/11/TCP%E5%8D%8F%E8%AE%AE/"/>
      <url>/2020/04/11/TCP%E5%8D%8F%E8%AE%AE/</url>
      
        <content type="html"><![CDATA[<h2 id="1-TCP三次握手"><a href="#1-TCP三次握手" class="headerlink" title="1 TCP三次握手"></a>1 TCP三次握手</h2><h3 id="1-1-握手过程"><a href="#1-1-握手过程" class="headerlink" title="1.1 握手过程"></a>1.1 握手过程</h3><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/tcpws.png" alt=""></p><h2 id="2-TCP四次断开"><a href="#2-TCP四次断开" class="headerlink" title="2 TCP四次断开"></a>2 TCP四次断开</h2><h3 id="2-1-断开过程"><a href="#2-1-断开过程" class="headerlink" title="2.1 断开过程"></a>2.1 断开过程</h3><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/nettcpdk.png" alt=""></p><h3 id="2-2-为何一定要等-2MSL"><a href="#2-2-为何一定要等-2MSL" class="headerlink" title="2.2 为何一定要等 2MSL"></a>2.2 为何一定要等 2MSL</h3><p>如果不等，释放的端口可能会重连刚断开的服务器端口，这样依然存活在网络里的老的 TCP 报文可能与新 TCP 连接报文冲突，造成数据冲突，为避免此种情况，<strong>需要耐心等待网络老的 TCP 连接的活跃报文全部死翘翘，2MSL 时间可以满足这个需求</strong>（尽管非常保守）！</p><h2 id="3-TCP如何保证传输可靠性"><a href="#3-TCP如何保证传输可靠性" class="headerlink" title="3 TCP如何保证传输可靠性"></a>3 TCP如何保证传输可靠性</h2><ul><li><strong>数据包校验</strong>：目的是检测数据在传输过程中的任何变化，若校验出包有错，则丢弃报文段并且不给出响应，这时 TCP 发送数据端超时后会重发数据。</li><li><strong>对失序数据包重排序</strong>：既然 TCP 报文段作为 IP 数据报来传输，而 IP 数据报的到达可能会失序，因此 TC P报文段的到达也可能会失序。TCP 将对失序数据进行重新排序，然后才交给应用层。</li><li><strong>丢弃重复数据</strong>：对于重复数据，能够丢弃重复数据。</li><li><strong>应答机制</strong>：当 TCP 收到发自 TCP 连接另一端的数据，它将发送一个确认。这个确认不是立即发送，通常将推迟几分之一秒。</li><li><strong>超时重发</strong>：当 TCP 发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段。</li><li><strong>流量控制</strong>：TCP 连接的每一方都有固定大小的缓冲空间。TCP 的接收端只允许另一端发送接收端缓冲区所能接纳的数据，这可以防止较快主机致使较慢主机的缓冲区溢出，这就是流量控制。TCP 使用的流量控制协议是可变大小的<strong>滑动窗口协议</strong>。</li></ul><h2 id="4-滑动窗口"><a href="#4-滑动窗口" class="headerlink" title="4 滑动窗口"></a>4 滑动窗口</h2><p>滑动窗口协议，是传输层进行流控的一种措施，<strong>接收方通过通告发送方自己的窗口大小</strong>，从而控制发送方的发送速度，从而达到<strong>防止发送方发送速度过快而导致自己被淹没的目的</strong>。</p><p><strong>TCP 的滑动窗口解决了端到端的流量控制问题，允许接受方对传输进行限制，直到它拥有足够的缓冲空间来容纳更多的数据</strong></p><h2 id="5-重传机制"><a href="#5-重传机制" class="headerlink" title="5 重传机制"></a>5 重传机制</h2><p>TCP 数据传输的过程，和 MQ Broker 投递消息给 Consumer 是一样的，只<strong>有在 Consumer Ack 确认消息已经消费，该消息才不会再被投递给 Consumer</strong> 。</p><ul><li><strong>重传时间RTO应略大于RTT</strong></li><li><strong>重传次数限制为3次</strong></li></ul><h2 id="6-TCP堵塞"><a href="#6-TCP堵塞" class="headerlink" title="6 TCP堵塞"></a>6 TCP堵塞</h2><p>解决方法:</p><ul><li><strong>慢开始</strong>:由小到大逐渐增加拥塞窗口的大小</li><li><strong>拥塞避免</strong>:即每经过一个往返时间 RTT 就把发送方的拥塞窗口 cwnd 加 1 ，而不是加倍，这样拥塞窗口按线性规律缓慢增长</li><li><strong>快重传</strong>:接收方在收到一个失序的报文段后就立即发出重复确认（为的是使发送方及早知道有报文段没有到达对方），而不要等到自己发送数据时捎带确认</li><li><strong>快恢复</strong>:不执行慢开始算法，而是将 cwnd 设置为原来的一半大小，然后执行拥塞避免算法。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 基础 </category>
          
          <category> 网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 网络 </tag>
            
            <tag> TCP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OSI模型</title>
      <link href="/2020/04/11/OSI%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/"/>
      <url>/2020/04/11/OSI%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<p>开放系统互连参考模型 (Open System Interconnect 简称OSI）是国际标准化组织(ISO)和国际电报电话咨询委员会(CCITT)联合制定的开放系统互连参考模型，为开放式互连信息系统提供了一种功能结构的框架。</p><p>使两个不同的系统能够通信,而不需要改变底层的硬件或软件逻辑。</p><p><code>OSI是一种理想化的架构！是一个概念模型不是协议！</code><br><img src="http://base422.oss-cn-beijing.aliyuncs.com/netosi.png" alt=""></p><h2 id="1-每层作用"><a href="#1-每层作用" class="headerlink" title="1 每层作用"></a>1 每层作用</h2><ul><li>应用层Application</li></ul><p>为应用程序提供服务并规定应用程序中通信相关的细节。包括文件传输，电子邮件，远程登陆等协议。</p><ul><li>表示层Presntation</li></ul><p>主要负责数据格式的转换。将设备固有数据格式转换成网络标准传输格式。</p><ul><li>会话层Session</li></ul><p>负责建立和断开通信连接，以及数据的分割等数据传输相关的管理。</p><ul><li>传输层Transport</li></ul><p>起可靠的传输作用。</p><ul><li>网络层Network</li></ul><p>将数据传输到目标地址，主要负责寻址和路由选择。</p><ul><li>数据链路层Datalink</li></ul><p>将0，1序列划分成具有意义的数据帧传给对端。</p><ul><li>物理层Physical</li></ul><p>负责0，1比特流与电压高低之间的转换。</p><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/netdetail.png" alt=""></p><h2 id="2-实际模型"><a href="#2-实际模型" class="headerlink" title="2 实际模型"></a>2 实际模型</h2><p>OSI只是一个理想的模型，将通信分为了七层，但在实际应用中，是将通信分成了五层（也有分成四层的，将数据链路层和物理层合为了一层）</p><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/netfun.png" alt=""></p><h2 id="3-封装与对等通信"><a href="#3-封装与对等通信" class="headerlink" title="3 封装与对等通信"></a>3 封装与对等通信</h2><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/netpack.png" alt=""></p><p>实际数据的传输是一个逐层封装的过程，到达另一端后，再逐层解封装。<br>两台主机之间的通信都是对等层之间的通信。</p><blockquote><p>封装<br>上层的数据被封装在下层中，在第N层的分组的数据部分是第N+1层的整个分组。</p></blockquote><p>除链路层在数据的头尾进行封装外，应用层，运输层和网络层都只是在数据的头部进行封装。</p>]]></content>
      
      
      <categories>
          
          <category> 基础 </category>
          
          <category> 网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 网络 </tag>
            
            <tag> TCP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux转置文件</title>
      <link href="/2020/04/09/%E8%BD%AC%E7%BD%AE%E6%96%87%E4%BB%B6/"/>
      <url>/2020/04/09/%E8%BD%AC%E7%BD%AE%E6%96%87%E4%BB%B6/</url>
      
        <content type="html"><![CDATA[<pre><code class="shell">假设 file.txt 文件内容如下：name agealice 21ryan 30应当输出：name alice ryanage 21 30#解法awk &#39;{    for (i=1;i&lt;=NF;i++){        if (NR==1){            res[i]=$i        }        else{            res[i]=res[i]&quot; &quot;$i        }    }}END{    for(str in res){        print res[str]    }}&#39; file.txtNR行号NF被分割字段的数目</code></pre>]]></content>
      
      
      <categories>
          
          <category> 基础 </category>
          
          <category> Linux命令 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux命令 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux统计词频</title>
      <link href="/2020/04/09/%E7%BB%9F%E8%AE%A1%E8%AF%8D%E9%A2%91/"/>
      <url>/2020/04/09/%E7%BB%9F%E8%AE%A1%E8%AF%8D%E9%A2%91/</url>
      
        <content type="html"><![CDATA[<pre><code class="shell">方法一:cat word.txt |xargs -n 1|sort|uniq -c|sort -k1 -nr|awk &#39;{print $2&quot; &quot;$1}&#39;方法二:cat word.txt | awk &#39;{     for(i=1;i&lt;=NF;i++){        count[$i]++    } } END {     for(k in count){        print k&quot; &quot;count[k]    } }&#39; | sort -rnk 2</code></pre>]]></content>
      
      
      <categories>
          
          <category> 基础 </category>
          
          <category> Linux命令 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux命令 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux统计访问次数最多的十个ip</title>
      <link href="/2020/04/09/%E7%BB%9F%E8%AE%A1%E8%AE%BF%E9%97%AE%E6%AC%A1%E6%95%B0%E5%89%8D%E5%8D%81%E7%9A%84IP/"/>
      <url>/2020/04/09/%E7%BB%9F%E8%AE%A1%E8%AE%BF%E9%97%AE%E6%AC%A1%E6%95%B0%E5%89%8D%E5%8D%81%E7%9A%84IP/</url>
      
        <content type="html"><![CDATA[<pre><code class="shell">[root@rp-hb2-prod-01 wwwlogs]# head -n10000 access_nginx.log|awk &#39;{print $1}&#39;|sort|uniq -c|sort -k 1 -n -r |head -10    108 100.121.197.123    107 100.121.197.64    106 100.121.197.99    106 100.121.197.81    106 100.121.197.114    105 100.121.136.218    104 100.121.136.205    101 100.121.197.121    101 100.121.197.110    101 100.121.136.220</code></pre><ul><li><p><strong>sort就是对内容进行排序，默认是自然顺序排序。</strong></p></li><li><p><strong>uniq指令用于排重，而是只适用于相邻两行相同的情况。所以一般结合sort使用。即先sort排序再排重。</strong></p></li><li><p><strong>uniq -u是只显示唯一的记录行。uniq -c是显示有重复记录的情况。</strong></p></li><li><p><strong>sort -k 1 -n -r这个指令，参看下面sort指令参数的详细说明</strong></p><pre><code class="shell">-f  ：忽略大小写的差异，例如 A 与 a 视为编码相同；-b  ：忽略最前面的空格符部分；-M  ：以月份的名字来排序，例如 JAN, DEC 等等的排序方法；-n  ：使用『纯数字』进行排序(默认是以文字型态来排序的)；-r  ：反向排序；-u  ：就是 uniq ，相同的数据中，仅出现一行代表；-t  ：分隔符，默认是用 [tab] 键来分隔；-k  ：以哪个区间 (field) 来进行排序的意思所以 sort -k 1 -n -r 指令的意思就是对第一列按照纯数字逆序排序。</code></pre></li></ul>]]></content>
      
      
      <categories>
          
          <category> 基础 </category>
          
          <category> Linux命令 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux命令 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux清除n天前的日志</title>
      <link href="/2020/04/09/%E6%B8%85%E9%99%A4n%E5%A4%A9%E5%89%8D%E7%9A%84%E6%97%A5%E5%BF%97/"/>
      <url>/2020/04/09/%E6%B8%85%E9%99%A4n%E5%A4%A9%E5%89%8D%E7%9A%84%E6%97%A5%E5%BF%97/</url>
      
        <content type="html"><![CDATA[<pre><code class="shell">find logs/ -type f -mtime +n -exec rm -f {} \;</code></pre>]]></content>
      
      
      <categories>
          
          <category> 基础 </category>
          
          <category> Linux命令 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux命令 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux代码分析命令</title>
      <link href="/2020/04/08/%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90%E5%91%BD%E4%BB%A4/"/>
      <url>/2020/04/08/%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90%E5%91%BD%E4%BB%A4/</url>
      
        <content type="html"><![CDATA[<h2 id="1-strace"><a href="#1-strace" class="headerlink" title="1 strace"></a>1 strace</h2><h3 id="1-1-常用参数"><a href="#1-1-常用参数" class="headerlink" title="1.1 常用参数"></a>1.1 常用参数</h3><pre><code class="shell">-c 统计每一系统调用的所执行的时间,次数和出错的次数等.-d 输出strace关于标准错误的调试信息.-f 跟踪由fork调用所产生的子进程.-ff 如果提供-o filename,则所有进程的跟踪结果输出到相应的filename.pid中,pid是各进程的进程号.-h 输出简要的帮助信息.-i 输出系统调用的入口指针.-q 禁止输出关于脱离的消息.-r 打印出相对时间关于每一个系统调用.-t 在输出中的每一行前加上时间信息.-tt 在输出中的每一行前加上时间信息,微秒级.-ttt 微秒级输出,以秒了表示时间.-T 显示每一调用所耗的时间.-v 输出所有的系统调用.一些调用关于环境变量,状态,输入输出等调用由于使用频繁,默认不输出.-V 输出strace的版本信息.-a column 设置返回值的输出位置.默认 为40.-e expr 指定一个表达式,用来控制如何跟踪.格式如下:-e trace=set 只跟踪指定的系统调用.例如:-e trace=open,close,rean,write表示只跟踪这四个系统调用.默认的为set=all.-e trace=file 只跟踪有关文件操作的系统调用.-e trace=process 只跟踪有关进程控制的系统调用.-e trace=network 跟踪与网络有关的所有系统调用.-e strace=signal 跟踪所有与系统信号有关的系统调用.-e trace=ipc 跟踪所有与进程通讯有关的系统调用.-e abbrev=set 设定strace输出的系统调用的结果集.-v 等与 abbrev=none.默认为abbrev=all.-e raw=set 将指定的系统调用的参数以十六进制显示.-e signal=set 指定跟踪的系统信号.默认为all.如 signal=!SIGIO(或者signal=!io),表示不跟踪SIGIO信号.-e read=set 输出从指定文件中读出的数据.例如-e read=3,5-e write=set 输出写入到指定文件中的数据.-o filename 将strace的输出写入文件filename-p pid 跟踪指定的进程pid.-s strsize 指定输出的字符串的最大长度.默认为32.文件名一直全部输出.-u username 以username 的UID和GID执行被跟踪的命令.</code></pre><h3 id="1-2-使用"><a href="#1-2-使用" class="headerlink" title="1.2 使用"></a>1.2 使用</h3><pre><code class="shell">//查看cat main.c的调用strace cat main.c//查看指定pid的调用starce -tT -p pid//查看指定pid的网络调用starce -tT -e trace=network -p pid</code></pre><h2 id="2-perf"><a href="#2-perf" class="headerlink" title="2 perf"></a>2 perf</h2><p><a href="https://www.ruanyifeng.com/blog/2017/09/flame-graph.html" target="_blank" rel="noopener">参考阮一峰的博客</a></p><h2 id="3-pstack"><a href="#3-pstack" class="headerlink" title="3 pstack"></a>3 pstack</h2><p>此命令可显示每个进程的栈跟踪。pstack 命令必须由相应进程的属主或 root 运行。可以使用 pstack 来确定进程挂起的位置。此命令允许使用的唯一选项是要检查的进程的 PID。请参见 proc(1) 手册页。</p><p>这个命令在排查进程问题时非常有用，比如我们发现一个服务一直处于work状态（如假死状态，好似死循环），使用这个命令就能轻松定位问题所在；可以在一段时间内，多执行几次pstack，若发现代码栈总是停在同一个位置，那个位置就需要重点关注，很可能就是出问题的地方；</p><p>示例：查看bash程序进程栈:</p><pre><code class="shell">/opt/app/tdev1$ps -fe| grep bashtdev1   7013  7012  0 19:42 pts/1    00:00:00 -bashtdev1  11402 11401  0 20:31 pts/2    00:00:00 -bashtdev1  11474 11402  0 20:32 pts/2    00:00:00 grep bash/opt/app/tdev1$pstack 7013#0  0x00000039958c5620 in __read_nocancel () from /lib64/libc.so.6#1  0x000000000047dafe in rl_getc ()#2  0x000000000047def6 in rl_read_key ()#3  0x000000000046d0f5 in readline_internal_char ()#4  0x000000000046d4e5 in readline ()#5  0x00000000004213cf in ?? ()#6  0x000000000041d685 in ?? ()#7  0x000000000041e89e in ?? ()#8  0x00000000004218dc in yyparse ()#9  0x000000000041b507 in parse_command ()#10 0x000000000041b5c6 in read_command ()#11 0x000000000041b74e in reader_loop ()#12 0x000000000041b2aa in main ()</code></pre><h2 id="4-PHP－xhprof"><a href="#4-PHP－xhprof" class="headerlink" title="4 PHP－xhprof"></a>4 PHP－xhprof</h2><p>对于PHP的应用我们可以使用xhprof插件+xhgui来查看PHP服务的调用情况</p><p>具体安装请<a href="https://www.jianshu.com/p/c69e368de756" target="_blank" rel="noopener">参考</a></p><h2 id="5-go-pprof"><a href="#5-go-pprof" class="headerlink" title="5 go pprof"></a>5 go pprof</h2><p>和PHP不同go自带监控的package具体使用我们可以参考此篇文档<a href="https://segmentfault.com/a/1190000016412013" target="_blank" rel="noopener">Golang 大杀器之性能剖析 PProf</a></p><h2 id="6-最佳实践"><a href="#6-最佳实践" class="headerlink" title="6 最佳实践"></a>6 最佳实践</h2><p><strong>人生苦短　最好使用第三方商用的监控软件　用过才知道真香啊</strong></p>]]></content>
      
      
      <categories>
          
          <category> 基础 </category>
          
          <category> Linux命令 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux命令 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux性能分析命令</title>
      <link href="/2020/04/08/%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%91%BD%E4%BB%A4/"/>
      <url>/2020/04/08/%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%91%BD%E4%BB%A4/</url>
      
        <content type="html"><![CDATA[<h2 id="1-top-htop"><a href="#1-top-htop" class="headerlink" title="1 top/htop"></a>1 top/htop</h2><h3 id="1-1-各项含义"><a href="#1-1-各项含义" class="headerlink" title="1.1 各项含义"></a>1.1 各项含义</h3><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/linuxtop.png" alt=""></p><h3 id="1-2-对top排序"><a href="#1-2-对top排序" class="headerlink" title="1.2 对top排序"></a>1.2 对top排序</h3><ol><li><p><strong>按<code>b</code>高亮显示当前运行进程</strong></p></li><li><p><strong>按<code>x</code>高亮显示当前按照哪一个指标进行排序</strong></p></li><li><p><strong>按<code>shift+&lt;</code>或<code>shift+&gt;</code>更改排序指标</strong></p><ol><li><strong>按<code>M</code>根据驻留内存大小进行排序</strong></li><li><strong>按<code>P</code>根据CPU使用百分比大小进行排序</strong></li><li><strong>按<code>T</code>根据时间/累计时间进行排序</strong></li></ol></li></ol><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/linuxtopsort.png" alt=""></p><h3 id="1-3-查看线程"><a href="#1-3-查看线程" class="headerlink" title="1.3 查看线程"></a>1.3 查看线程</h3><ul><li><strong>按<code>H</code>查看线程</strong></li><li><strong>输入 top -Hp ${pid} 查看指定进程的线程运行情况</strong></li></ul><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/linuxtopH.png" alt=""></p><h3 id="1-4-查看每个CPU的运行情况"><a href="#1-4-查看每个CPU的运行情况" class="headerlink" title="1.4 查看每个CPU的运行情况"></a>1.4 查看每个CPU的运行情况</h3><ul><li><strong>按1查看每个CPU的运行情况</strong></li></ul><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/linuxtopC.png" alt=""></p><h3 id="1-5-htop"><a href="#1-5-htop" class="headerlink" title="1.5 htop"></a>1.5 htop</h3><p><strong>交互式的top命令,还可以用鼠标点,贼好使</strong></p><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/linuxhtop.png" alt=""></p><h2 id="2-ps-pstree"><a href="#2-ps-pstree" class="headerlink" title="2 ps/pstree"></a>2 ps/pstree</h2><h3 id="2-1-ps-aux"><a href="#2-1-ps-aux" class="headerlink" title="2.1 ps -aux"></a>2.1 ps -aux</h3><p><strong>ps -aux   列出目前所有的正在内存当中的程序</strong></p><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/linuxps.png" alt=""></p><h3 id="2-2-ps-ajx"><a href="#2-2-ps-ajx" class="headerlink" title="2.2 ps -ajx"></a>2.2 ps -ajx</h3><p><strong>ps -ajx 以完整的格式显示所有的进程</strong></p><h3 id="2-3-ps-H-p-pid"><a href="#2-3-ps-H-p-pid" class="headerlink" title="2.3 ps -H -p ${pid}"></a>2.3 ps -H -p ${pid}</h3><p> <strong>ps -H -p ${pid} 查看指定pid的所有线程</strong></p><h3 id="2-4-stat字段含义"><a href="#2-4-stat字段含义" class="headerlink" title="2.4 stat字段含义"></a>2.4 stat字段含义</h3><pre><code class="shell">D  不能中断的进程（通常为IO）R  正在运行中的进程S  已经中断的进程，通常情况下，系统中大部分进程都是这个状态T  已经停止或者暂停的进程，如果我们正在运行一个命令，比如说sleep 10，如果我们按一下ctrl -z 让他暂停，那么我们用ps查看就会显示T这个状态W 这个好像是说，从内核2.6xx 以后，表示为没有足够的内存页分配X  已经死掉的进程（这个好像从来不会出现）Z  僵尸进程，杀不掉，打不死的垃圾进程，占系统一小点资源，不过没有关系。如果太多，就有问题了。一般不会出现。I 　idle空闲状态&lt;  高优先级进程N  低优先级进程L   在内存中被锁了内存分页s   主进程l   多线程进程+  代表在前台运行的进程</code></pre><h3 id="2-5-pstree"><a href="#2-5-pstree" class="headerlink" title="2.5 pstree"></a>2.5 pstree</h3><p>树形输出进程之间的关系</p><p><strong>pstree -p　显示当前所有进程的进程号和进程id</strong>　</p><p><strong>pstree -p ${pid}　显示指定进程的进程号和进程id</strong>　</p><pre><code class="shell">ken@Ken:~/Desktop$ pstree -p 782chrome(782)─┬─{Chrome_ChildIOT}(786)            ├─{CompositorTileW}(790)            ├─{CompositorTileW}(791)            ├─{CompositorTileW}(792)            ├─{Compositor}(789)            ├─{Font_Proxy_Thre}(788)            ├─{GpuMemoryThread}(787)            ├─{MemoryInfra}(878)            ├─{TaskSchedulerFo}(785)            ├─{TaskSchedulerFo}(58151)            └─{TaskSchedulerSe}(783)</code></pre><h2 id="3-mpstat"><a href="#3-mpstat" class="headerlink" title="3 mpstat"></a>3 mpstat</h2><p>mpstat是MultiProcessor Statistics的缩写，是实时系统监控工具。报告CPU的一些统计信息，这些信息存放在/proc/stat文件中。在多CPUs系统里，其不但能查看所有CPU的平均状况信息，而且能够查看特定CPU的信息。</p><h3 id="3-1-语法"><a href="#3-1-语法" class="headerlink" title="3.1 语法"></a>3.1 语法</h3><pre><code class="shell">mpstat [-P {|ALL}] [internal [count]]参数：    （1）-P {|ALL}：表示监控哪个CPU，在[0,cpu个数-1]中取值；      （2）internal：相邻的两次采样的间隔时间；    （3）count：采样的次数，count只能和delay一起使用；    备注：当没有参数时，mpstat则显示系统启动以后所有信息的平均值。有interval时，第一行的信息自系统启动以来的平均信息。从第二行开始，输出为前一个interval时间段的平均信息。</code></pre><h3 id="3-2-demo"><a href="#3-2-demo" class="headerlink" title="3.2 demo"></a>3.2 demo</h3><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/linuxmpstat.png" alt=""></p><h2 id="4-iostat"><a href="#4-iostat" class="headerlink" title="4 iostat"></a>4 iostat</h2><h3 id="4-1-语法"><a href="#4-1-语法" class="headerlink" title="4.1 语法"></a>4.1 语法</h3><pre><code class="shell">用法: iostat [ 选项 ] [ &lt;时间间隔&gt; [ &lt;次数&gt; ] ]-c 显示CPU使用情况-d 显示磁盘使用情况-k 以 KB 为单位显示-m 以 M 为单位显示-N 显示磁盘阵列(LVM) 信息-n 显示NFS 使用情况-p[磁盘] 显示磁盘和分区的情况-t 显示终端和CPU的信息-x 显示详细信息-V 显示版本信息</code></pre><h3 id="4-2-查看磁盘io"><a href="#4-2-查看磁盘io" class="headerlink" title="4.2 查看磁盘io"></a>4.2 查看磁盘io</h3><p><code>iostat  -d -x -k  2 3</code></p><p>数据显示每隔2秒刷新一次，共显示3次。</p><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/linuxiostatd.png" alt=""></p><pre><code class="shell">rrqm/s: 每秒进行 merge 的读操作数目。即 rmerge/swrqm/s: 每秒进行 merge 的写操作数目。即 wmerge/sr/s: 每秒完成的读 I/O 设备次数。即 rio/sw/s: 每秒完成的写 I/O 设备次数。即 wio/srsec/s: 每秒读扇区数。即 rsect/swsec/s: 每秒写扇区数。即 wsect/srkB/s: 每秒读K字节数。是 rsect/s 的一半，因为每扇区大小为512字节。wkB/s: 每秒写K字节数。是 wsect/s 的一半。avgrq-sz: 平均每次设备I/O操作的数据大小 (扇区)。avgqu-sz: 平均I/O队列长度。await: 平均每次设备I/O操作的等待时间 (毫秒)。svctm: 平均每次设备I/O操作的服务时间 (毫秒)。%util: 一秒中有百分之多少的时间用于 I/O 操作，即被io消耗的cpu百分比</code></pre><ul><li><strong>如果 %util 接近 100%，说明产生的I/O请求太多，I/O系统已经满负荷，该磁盘可能存在瓶颈。</strong></li><li><strong>如果 svctm 比较接近 await，说明 I/O 几乎没有等待时间；</strong></li><li><strong>如果 await 远大于 svctm，说明I/O 队列太长，io响应太慢，则需要进行必要优化。</strong></li><li><strong>如果avgqu-sz比较大，也表示有大量io在等待。</strong></li></ul><h3 id="4-3-查看CPU"><a href="#4-3-查看CPU" class="headerlink" title="4.3 查看CPU"></a>4.3 查看CPU</h3><p><code>iostat -c 2 3</code></p><p>数据显示每隔2秒刷新一次，共显示3次。</p><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/linuxiostatc.png" alt=""></p><pre><code class="shell">%user：CPU处在用户模式下的时间百分比。%nice：CPU处在带NICE值的用户模式下的时间百分比。%system：CPU处在系统模式下的时间百分比。%iowait：CPU等待输入输出完成时间的百分比。%steal：管理程序维护另一个虚拟处理器时，虚拟CPU的无意识等待时间百分比。%idle：CPU空闲时间百分比。</code></pre><ul><li><strong>如果%iowait的值过高，表示硬盘存在I/O瓶颈</strong></li><li><strong>%idle值高，表示CPU较空闲，如果%idle值高但系统响应慢时，有可能是CPU等待分配内存，此时应加大内存容量</strong></li><li><strong>%idle值如果持续低于10，那么系统的CPU处理能力相对较低，表明系统中最需要解决的资源是CPU</strong></li></ul><h2 id="5-vmstat"><a href="#5-vmstat" class="headerlink" title="5 vmstat"></a>5 vmstat</h2><h3 id="5-1-语法"><a href="#5-1-语法" class="headerlink" title="5.1 语法"></a>5.1 语法</h3><pre><code class="shell">vmstat [-V] [-n] [delay [count]]</code></pre><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/linuxvmstat.png" alt=""></p><h3 id="5-2-字段说明"><a href="#5-2-字段说明" class="headerlink" title="5.2 字段说明"></a>5.2 字段说明</h3><pre><code class="shell">该命令默认显示监控5部分：procs、memory、swap、io、system、cpu信息。具体列信息说明如下：Procs（进程）r: 等待运行的进程数b: 处在非中断睡眠状态的进程数Memory（内存） 单位：KBswpd: 虚拟内存使用大小free: 空闲的内存buff: 用作缓冲的内存大小cache: 用作缓存的内存大小Swap （单位：KB）si: 从交换区写到内存的大小so: 每秒写入交换区的内存大小IO （单位：块/秒）bi: 每秒读取的块数bo: 每秒写入的块数System （系统）in: 每秒中断数，包括时钟中断。cs: 每秒上下文切换数。CPU（以百分比表示）：us: 用户进程执行时间(user time)sy: 系统进程执行时间(system time)id: 空闲时间(包括IO等待时间),中央处理器的空闲时间 。以百分比表示。wa: 等待IO时间</code></pre><h2 id="6-sar"><a href="#6-sar" class="headerlink" title="6 sar"></a>6 sar</h2><p>sar是目前Linux上最为全面的系统性能分析工具之一，可以从14个大方面对系统的活动进行报告，包括文件的读写情况、系统调用的使用情况、串口、CPU效率、内存使用状况、进程活动及IPC有关的活动等，使用也是较为复杂。</p><h3 id="6-1-语法"><a href="#6-1-语法" class="headerlink" title="6.1 语法"></a>6.1 语法</h3><pre><code class="shell">sar  [ 选项 ] [ &lt;时间间隔&gt; [ &lt;次数&gt; ] ]-A 汇总所有的报告-a 报告文件读写使用情况-B 报告附加的缓存的使用情况-b 报告缓存的使用情况-c 报告系统调用的使用情况-d 报告磁盘的使用情况-g 报告串口的使用情况-h 报告关于buffer使用的统计数据-m 报告IPC消息队列和信号量的使用情况-n 报告命名cache的使用情况-p 报告调页活动的使用情况-q 报告运行队列和交换队列的平均长度-R 报告进程的活动情况-r 报告没有使用的内存页面和硬盘块-u 报告CPU的利用率-v 报告进程、i节点、文件和锁表状态-w 报告系统交换活动状况-y 报告TTY设备活动状况</code></pre><h3 id="6-2-查看内存使用"><a href="#6-2-查看内存使用" class="headerlink" title="6.2 查看内存使用"></a>6.2 查看内存使用</h3><pre><code class="shell">sar -r 1 3</code></pre><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/linuxsarr.png" alt=""></p><pre><code class="shell">kbmemfree：这个值和free命令中的free值基本一致,所以它不包括buffer和cache的空间.kbmemused：这个值和free命令中的used值基本一致,所以它包括buffer和cache的空间.%memused：物理内存使用率，这个值是kbmemused和内存总量(不包括swap)的一个百分比.kbbuffers和kbcached：这两个值就是free命令中的buffer和cache.kbcommit：保证当前系统所需要的内存,即为了确保不溢出而需要的内存(RAM+swap).%commit：这个值是kbcommit与内存总量(包括swap)的一个百分比.</code></pre><h3 id="6-3-查看CPU使用情况"><a href="#6-3-查看CPU使用情况" class="headerlink" title="6.3 查看CPU使用情况"></a>6.3 查看CPU使用情况</h3><pre><code class="shell">sar -u 1 3sar 1 3  默认就是查看CPU使用情况</code></pre><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/linuxsaru.png" alt=""></p><h3 id="6-4-查看负载"><a href="#6-4-查看负载" class="headerlink" title="6.4 查看负载"></a>6.4 查看负载</h3><pre><code class="shell">sar -q 1 3</code></pre><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/linuxsarq.png" alt=""></p><pre><code class="shell">runq-sz：运行队列的长度（等待运行的进程数）plist-sz：进程列表中进程（processes）和线程（threads）的数量ldavg-1：最后1分钟的系统平均负载 ldavg-5：过去5分钟的系统平均负载ldavg-15：过去15分钟的系统平均负载</code></pre><h3 id="6-5-查看文件IO"><a href="#6-5-查看文件IO" class="headerlink" title="6.5 查看文件IO"></a>6.5 查看文件IO</h3><pre><code class="shell">sar -d 1 3</code></pre><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/linuxsard.png" alt=""></p><h3 id="6-6-通过文件分析"><a href="#6-6-通过文件分析" class="headerlink" title="6.6 通过文件分析"></a>6.6 通过文件分析</h3><p>需要安装sysstat</p><pre><code>1. 有的linux系统下，默认可能没有安装这个包，使用apt-get install sysstat 来安装；2. 安装完毕，将性能收集工具的开关打开： vi /etc/default/sysstat 设置 ENABLED=”true”3. 启动这个工具来收集系统性能数据： /etc/init.d/sysstat start</code></pre><p>使用</p><pre><code class="shell">sar -f -[需要分析的选项]　/var/log/sysstat/[具体的文件id]</code></pre><h2 id="7-df-du"><a href="#7-df-du" class="headerlink" title="7 df/du"></a>7 df/du</h2><h3 id="7-1-查看磁盘剩余"><a href="#7-1-查看磁盘剩余" class="headerlink" title="7.1 查看磁盘剩余"></a>7.1 查看磁盘剩余</h3><pre><code class="shell">ken@Ken:~/Soft/clion/bin$ df -h文件系统        容量  已用  可用 已用% 挂载点udev            5.9G     0  5.9G    0% /devtmpfs           1.2G  1.9M  1.2G    1% /run/dev/sda1        40G   16G   22G   42% /tmpfs           6.0G  175M  5.8G    3% /dev/shmtmpfs           5.0M  4.0K  5.0M    1% /run/locktmpfs           6.0G     0  6.0G    0% /sys/fs/cgrouptmpfs           1.2G   44K  1.2G    1% /run/user/1000</code></pre><h3 id="7-2-查看文件夹大小"><a href="#7-2-查看文件夹大小" class="headerlink" title="7.2 查看文件夹大小"></a>7.2 查看文件夹大小</h3><pre><code class="shell">ken@Ken:~/Soft$ du -sh clion/1.2G    clion///-s 表示递归的获取</code></pre><h3 id="7-3-查看当前目录下文件夹的大小"><a href="#7-3-查看当前目录下文件夹的大小" class="headerlink" title="7.3 查看当前目录下文件夹的大小"></a>7.3 查看当前目录下文件夹的大小</h3><pre><code class="shell">ken@Ken:~/Soft$ du -h --max-depth=1 clion/182M    clion/jbr362M    clion/lib164K    clion/help281M    clion/bin350M    clion/plugins444K    clion/license1.2G    clion/</code></pre><h3 id="7-4-查看当前目录文件和文件夹大小"><a href="#7-4-查看当前目录文件和文件夹大小" class="headerlink" title="7.4 查看当前目录文件和文件夹大小"></a>7.4 查看当前目录文件和文件夹大小</h3><pre><code class="shell">ken@Ken:~/Soft/clion$ du -h --max-depth=0 *4.0K    build.txt4.0K    Install-Linux-tar.txt4.0K    product-info.json164K    help182M    jbr281M    bin350M    plugins362M    lib444K    license</code></pre>]]></content>
      
      
      <categories>
          
          <category> 基础 </category>
          
          <category> Linux命令 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux命令 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux查找命令</title>
      <link href="/2020/04/08/%E6%9F%A5%E6%89%BE%E5%91%BD%E4%BB%A4/"/>
      <url>/2020/04/08/%E6%9F%A5%E6%89%BE%E5%91%BD%E4%BB%A4/</url>
      
        <content type="html"><![CDATA[<h2 id="1-find"><a href="#1-find" class="headerlink" title="1 find"></a>1 find</h2><h3 id="1-1-常用参数"><a href="#1-1-常用参数" class="headerlink" title="1.1 常用参数"></a>1.1 常用参数</h3><pre><code>-name             按照文件名查找文件-perm             按照文件权限查找文件-prune          不在当前指定的目录中查找-mtime -n +n     按照文件的更改时间来查找文件                    -n表示文件更改时间距现在n天以内                    +n表示文件更改时间距现在n天以前-type             查找某一类型的文件，诸如：                    b - 块设备文件。                    d - 目录。                    c - 字符设备文件。                    p - 管道文件。                    l - 符号链接文件。                    f - 普通文件。-depth n        在查找文件时，最大深度为n-size 文件大小      根据文件大小查找文件         </code></pre><h3 id="1-2-根据文件名查找文件"><a href="#1-2-根据文件名查找文件" class="headerlink" title="1.2 根据文件名查找文件"></a>1.2 根据文件名查找文件</h3><pre><code class="shell">查找文件名为code的文件ken@Ken:~$ find -name &quot;code&quot;查找文件名以cod开头的文件ken@Ken:~$ find -name &quot;cod*&quot;查找以.pdf结尾的文件ken@Ken:~$ find -name &quot;*.pdf&quot;</code></pre><h3 id="1-3-在指定目录中查找"><a href="#1-3-在指定目录中查找" class="headerlink" title="1.3 在指定目录中查找"></a>1.3 在指定目录中查找</h3><p><strong>注意文件夹放置的顺序以及后面需要跟-o</strong></p><pre><code class="shell">在目录/home/ken下查找 pdf文件ken@Ken:~$ find  -path /home/ken -o  -name &quot;*.pdf&quot;在目录/home/ken下但不包括.cache文件夹下查找 pdf文件ken@Ken:~$ find /home/ken/ -path &quot;/home/ken/.cache&quot; -prune -o -name &quot;*.pdf&quot;</code></pre><h3 id="1-4-按照文件的更改时间查找"><a href="#1-4-按照文件的更改时间查找" class="headerlink" title="1.4 按照文件的更改时间查找"></a>1.4 按照文件的更改时间查找</h3><pre><code class="shell">查找５天前修改的日志ken@Ken:~$ find . -mtime +5 -name &quot;*.log&quot;查找５天内的日志ken@Ken:~$ find . -mtime -5 -name &quot;*.log&quot;</code></pre><h3 id="1-5-指定深度查找"><a href="#1-5-指定深度查找" class="headerlink" title="1.5 指定深度查找"></a>1.5 指定深度查找</h3><pre><code class="shell">向下最大深度限制为4ken@Ken:~$ find . -maxdepth 4 -mtime +5 -name &quot;*.log&quot;搜索出深度距离当前目录至少4个子目录的所有文件ken@Ken:~$ find . -mindepth 4 -mtime +5 -name &quot;*.log&quot;</code></pre><h3 id="1-6-指定大小查找"><a href="#1-6-指定大小查找" class="headerlink" title="1.6 指定大小查找"></a>1.6 指定大小查找</h3><ul><li><strong>+代表大于</strong></li><li><strong>-代表小于</strong></li></ul><pre><code class="shell">find -size +20M -name &quot;*pdf&quot;find -size -20M -name &quot;*pdf&quot;find -size +20k -name &quot;*pdf&quot;find -size +20G -name &quot;*pdf&quot;</code></pre><h3 id="1-7-指定类型"><a href="#1-7-指定类型" class="headerlink" title="1.7 指定类型"></a>1.7 指定类型</h3><pre><code class="shell">指定文件夹类型ken@Ken:~$ find -type d -name &quot;*doc*&quot;指定文件类型ken@Ken:~$ find -type f -name &quot;*doc*&quot;</code></pre><h2 id="2-grep"><a href="#2-grep" class="headerlink" title="2 grep"></a>2 grep</h2><pre><code class="shell">当前目录以及子目录下查找包含main关键字的文件grep -r -n &quot;main&quot; .反向查找不包含grep关键字的信息ps aux|grep &quot;chrome&quot;|grep -v &quot;grep&quot;正则表达式查找grep -e &quot;正则&quot; 文件名从根目录开始查找所有扩展名为 .log 的文本文件，并找出包含 &quot;ERROR&quot; 的行find / -type f -name &quot;*.log&quot; | xargs grep &quot;ERROR&quot;</code></pre><h2 id="3-sed"><a href="#3-sed" class="headerlink" title="3 sed"></a>3 sed</h2><h3 id="3-1-替换字符串"><a href="#3-1-替换字符串" class="headerlink" title="3.1 替换字符串"></a>3.1 替换字符串</h3><p>此命令的基本格式为：<br><strong>[address]s/pattern/replacement/flags</strong></p><table><thead><tr><th align="center">flags 标记</th><th align="left">功能</th></tr></thead><tbody><tr><td align="center">n</td><td align="left">1~512 之间的数字，表示指定要替换的字符串出现第几次时才进行替换，例如，<strong>一行中</strong>有 3 个 A，但用户只想替换<strong>第二个 A</strong>，这是就用到这个标记；</td></tr><tr><td align="center">g</td><td align="left">对数据中所有匹配到的内容进行替换，如果没有 g，则只会在第一次匹配成功时做替换操作。例如，一行数据中有 3 个 A，则只会替换第一个 A；</td></tr><tr><td align="center">w file</td><td align="left">将缓冲区中的内容写到指定的 file 文件中；</td></tr></tbody></table><pre><code class="shell">ken@Ken:~/Documents/code/sed$ cat a.txt This is line number 1.This is line number 2.This is line number 3.This is line number 4.ken@Ken:~/Documents/code/sed$ sed &#39;1,3s/line/lines/g&#39; demo.txtThis is lines number 1.This is lines number 2.This is lines number 3.This is line number 4.</code></pre><h3 id="3-2-删除指定行"><a href="#3-2-删除指定行" class="headerlink" title="3.2 删除指定行"></a>3.2 删除指定行</h3><h4 id="3-2-1-删除空白行"><a href="#3-2-1-删除空白行" class="headerlink" title="3.2.1 删除空白行"></a>3.2.1 删除空白行</h4><pre><code class="shell">ken@Ken:~/Documents/code/sed$ cat demo.txt This is line number 1.This is line number 2.This is line number 3.This is line number 4.#删除空白行ken@Ken:~/Documents/code/sed$ sed &#39;/^$/d&#39; demo.txt This is line number 1.This is line number 2.This is line number 3.This is line number 4.</code></pre><h4 id="3-2-2-删除指定行"><a href="#3-2-2-删除指定行" class="headerlink" title="3.2.2 删除指定行"></a>3.2.2 删除指定行</h4><pre><code class="shell">ken@Ken:~/Documents/code/sed$ cat -n demo.txt      1    This is line number 1.     2         3    This is line number 2.     4         5    This is line number 3.     6    This is line number 4.#删除1-3行ken@Ken:~/Documents/code/sed$ sed &#39;1,3d&#39; demo.txt This is line number 3.This is line number 4.＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＃删除2-末尾行ken@Ken:~/Documents/code/sed$ sed &#39;2,$d&#39; demo.txt This is line number 1.</code></pre><h4 id="3-2-3-正则删除行数"><a href="#3-2-3-正则删除行数" class="headerlink" title="3.2.3 正则删除行数"></a>3.2.3 正则删除行数</h4><pre><code class="shell">ken@Ken:~/Documents/code/sed$ cat demo.txt This is line number 1.This is line number 2.This is line number 3.This is line number 4.#删除以1.结尾的行ken@Ken:~/Documents/code/sed$ sed &#39;/1.$/d&#39; demo.txt This is line number 2.This is line number 3.This is line number 4.</code></pre><h3 id="3-3-插入替换行"><a href="#3-3-插入替换行" class="headerlink" title="3.3 插入替换行"></a>3.3 插入替换行</h3><p><strong>a 命令表示在指定行的后面附加一行，i 命令表示在指定行的前面插入一行</strong></p><p><strong>c命令表示替换指定行</strong></p><pre><code class="shell">ken@Ken:~/Documents/code/sed$ cat demo.txt This is line number 1.This is line number 2.This is line number 3.This is line number 4.ken@Ken:~/Documents/code/sed$ sed &#39;1i new line&#39; demo.txt new lineThis is line number 1.This is line number 2.This is line number 3.This is line number 4.ken@Ken:~/Documents/code/sed$ sed &#39;1a new line&#39; demo.txt This is line number 1.new lineThis is line number 2.This is line number 3.This is line number 4.ken@Ken:~/Documents/code/sed$ sed &#39;1,3a new line&#39; demo.txt This is line number 1.new lineThis is line number 2.new lineThis is line number 3.new lineThis is line number 4.ken@Ken:~/Documents/code/sed$ sed &#39;1c new line&#39; demo.txt new lineThis is line number 2.This is line number 3.This is line number 4.</code></pre><h3 id="3-4-打印指定行"><a href="#3-4-打印指定行" class="headerlink" title="3.4 打印指定行"></a>3.4 打印指定行</h3><p>使用参数p和n</p><p>语法为: <strong>sed -n [address]p</strong></p><pre><code class="shell">ken@Ken:~/Documents/code/sed$ cat demo.txt This is line number 1.This is line number 2.This is line number 3.This is line number 4.#打印1-3行ken@Ken:~/Documents/code/sed$ sed -n &#39;1,3p&#39; demo.txt This is line number 1.This is line number 2.#打印含有number的行ken@Ken:~/Documents/code/sed$ sed -n &#39;/number/p&#39; demo.txt This is line number 1.This is line number 2.This is line number 3.This is line number 4.</code></pre><h2 id="4-awk"><a href="#4-awk" class="headerlink" title="4 awk"></a>4 awk</h2><p>基本格式为:</p><p><strong>awk [选项] ‘脚本命令’ 文件名</strong></p><table><thead><tr><th align="center">选项</th><th align="center">含义</th></tr></thead><tbody><tr><td align="center">-F fs</td><td align="center">指定以 fs 作为输入行的分隔符，awk 命令默认分隔符为空格或制表符。</td></tr><tr><td align="center">-f file</td><td align="center">从脚本文件中读取 awk 脚本指令，以取代直接在命令行中输入指令。</td></tr><tr><td align="center">-v var=val</td><td align="center">在执行处理过程之前，设置一个变量 var，并给其设备初始值为 val。</td></tr></tbody></table><pre><code class="shell">默认情况下，awk 会将如下变量分配给它在文本行中发现的数据字段：$0 代表整个文本行；$1 代表文本行中的第 1 个数据字段；$2 代表文本行中的第 2 个数据字段；$n 代表文本行中的第 n 个数据字段。</code></pre><h3 id="4-1-基本使用"><a href="#4-1-基本使用" class="headerlink" title="4.1 基本使用"></a>4.1 基本使用</h3><pre><code class="shell">ken@Ken:~/Documents/code/sed$ cat net.txt tcp      769      0 127.0.0.1:49030         127.0.1.1:139           CLOSE_WAIT tcp        0      0 192.168.31.82:40334     13.250.177.223:443      ESTABLISHEDtcp        0      0 192.168.31.82:40336     13.250.177.223:443      ESTABLISHEDtcp        0      0 192.168.31.82:33270     185.199.108.154:443     ESTABLISHEDtcp6       0      0 :::139                  :::*                    LISTEN     tcp6       0      0 ::1:631                 :::*                    LISTEN     tcp6       0      0 :::445                  :::*                    LISTEN     ken@Ken:~/Documents/code/sed$ awk &#39;{print $1,$2}&#39; net.txt tcp 769tcp 0tcp 0tcp 0tcp6 0tcp6 0tcp6 0</code></pre>]]></content>
      
      
      <categories>
          
          <category> 基础 </category>
          
          <category> Linux命令 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux命令 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux网络命令</title>
      <link href="/2020/04/08/%E7%BD%91%E7%BB%9C%E5%91%BD%E4%BB%A4/"/>
      <url>/2020/04/08/%E7%BD%91%E7%BB%9C%E5%91%BD%E4%BB%A4/</url>
      
        <content type="html"><![CDATA[<h2 id="1-netstat"><a href="#1-netstat" class="headerlink" title="1 netstat"></a>1 netstat</h2><p>Netstat 命令用于显示各种网络相关信息，如网络连接，路由表，接口状态 (Interface Statistics)，masquerade连接，多播成员 (Multicast Memberships) 等等。</p><h3 id="1-1-常见参数"><a href="#1-1-常见参数" class="headerlink" title="1.1 常见参数"></a>1.1 常见参数</h3><pre><code class="shell">常见参数-a (all)显示所有选项，默认不显示LISTEN相关-t (tcp)仅显示tcp相关选项-u (udp)仅显示udp相关选项-n 拒绝显示别名，能显示数字的全部转化成数字。-l 仅列出有在 Listen (监听) 的服務状态-p 显示建立相关链接的程序名-r 显示路由信息，路由表-e 显示扩展信息，例如uid等-s 按各个协议进行统计-c 每隔一个固定时间，执行该netstat命令。提示：LISTEN和LISTENING的状态只有用-a或者-l才能看到</code></pre><h3 id="1-2-列出所有tcp端口"><a href="#1-2-列出所有tcp端口" class="headerlink" title="1.2 列出所有tcp端口"></a>1.2 列出所有tcp端口</h3><pre><code class="shell">ken@Ken:~$ netstat -antActive Internet connections (servers and established)Proto Recv-Q Send-Q Local Address           Foreign Address         State      tcp        0      0 0.0.0.0:139             0.0.0.0:*               LISTEN     tcp        0      0 127.0.0.1:63342         0.0.0.0:*               LISTEN     tcp        0      0 127.0.0.1:39345         0.0.0.0:*               LISTEN     tcp        0      0 127.0.0.1:631           0.0.0.0:*               LISTEN     tcp        0      0 0.0.0.0:445             0.0.0.0:*               LISTEN     tcp        0      0 127.0.0.1:6942          0.0.0.0:*               LISTEN     tcp        0      1 192.168.31.82:38316     172.217.160.110:443     SYN_SENT   tcp      769      0 127.0.0.1:49030         127.0.1.1:139           CLOSE_WAIT tcp        1      0 192.168.31.82:57578     59.110.185.117:80       CLOSE_WAIT tcp        0      1 192.168.31.82:38312     172.217.160.110:443     SYN_SENT   tcp        0      1 192.168.31.82:38306     172.217.160.110:443     SYN_SENT   tcp        1      0 192.168.31.82:57580     59.110.185.117:80       CLOSE_WAIT tcp        0      1 192.168.31.82:38314     172.217.160.110:443     SYN_SENT   tcp        0      1 192.168.31.82:38308     172.217.160.110:443     SYN_SENT   tcp        0      1 192.168.31.82:38310     172.217.160.110:443     SYN_SENT   tcp6       0      0 :::139                  :::*                    LISTEN     tcp6       0      0 ::1:631                 :::*                    LISTEN     tcp6       0      0 :::445                  :::*                    LISTEN  </code></pre><h3 id="1-3-列出所有udp端口"><a href="#1-3-列出所有udp端口" class="headerlink" title="1.3 列出所有udp端口"></a>1.3 列出所有udp端口</h3><pre><code class="shell">ken@Ken:~$ netstat -anuActive Internet connections (servers and established)Proto Recv-Q Send-Q Local Address           Foreign Address         State      udp        0      0 0.0.0.0:4500            0.0.0.0:*                          udp   183296      0 224.0.0.251:5353        0.0.0.0:*                          udp   184064      0 224.0.0.251:5353        0.0.0.0:*                          udp     4352      0 0.0.0.0:68              0.0.0.0:*                          udp   251136      0 192.168.31.255:137      0.0.0.0:*                          udp    66816      0 192.168.31.82:137       0.0.0.0:*                          udp   281856      0 0.0.0.0:137             0.0.0.0:*                          udp   311296      0 192.168.31.255:138      0.0.0.0:*                          udp      704      0 192.168.31.82:138       0.0.0.0:*                          udp   311296      0 0.0.0.0:138             0.0.0.0:*                          udp        0      0 0.0.0.0:500             0.0.0.0:*                          udp6       0      0 :::4500                 :::*                               udp6       0      0 :::500                  :::*                               </code></pre><h3 id="1-4-列出监听状态的tcp请求"><a href="#1-4-列出监听状态的tcp请求" class="headerlink" title="1.4 列出监听状态的tcp请求"></a>1.4 列出监听状态的tcp请求</h3><pre><code class="shell">ken@Ken:~$ netstat -ltActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address           Foreign Address         State      tcp        0      0 0.0.0.0:netbios-ssn     0.0.0.0:*               LISTEN     tcp        0      0 localhost:63342         0.0.0.0:*               LISTEN     tcp        0      0 localhost:39345         0.0.0.0:*               LISTEN     tcp        0      0 localhost:ipp           0.0.0.0:*               LISTEN     tcp        0      0 0.0.0.0:microsoft-ds    0.0.0.0:*               LISTEN     tcp        0      0 localhost:6942          0.0.0.0:*               LISTEN     tcp6       0      0 [::]:netbios-ssn        [::]:*                  LISTEN     tcp6       0      0 ip6-localhost:ipp       [::]:*                  LISTEN     tcp6       0      0 [::]:microsoft-ds       [::]:*                  LISTEN </code></pre><h3 id="1-5-显示进程pid和名称"><a href="#1-5-显示进程pid和名称" class="headerlink" title="1.5 显示进程pid和名称"></a>1.5 显示进程pid和名称</h3><pre><code class="shell">ken@Ken:~$ netstat -np|more(Not all processes could be identified, non-owned process info will not be shown, you would have to be root to see it all.)Active Internet connections (w/o servers)Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    tcp      769      0 127.0.0.1:49030         127.0.1.1:139           CLOSE_WAIT  7870/gvfsd-smb-brow tcp        0      0 192.168.31.82:52796     54.187.241.135:443      ESTABLISHED 68041/java          tcp        0      1 192.168.31.82:38342     172.217.160.110:443     SYN_SENT    106287/chrome --typ tcp        0      1 192.168.31.82:34610     18.200.1.33:7           SYN_SENT    68041/java          tcp        0      1 192.168.31.82:38338     172.217.160.110:443     SYN_SENT    106287/chrome --typ tcp        0      1 192.168.31.82:38336     172.217.160.110:443     SYN_SENT    106287/chrome --typ tcp        0      1 192.168.31.82:38344     172.217.160.110:443     SYN_SENT    106287/chrome --typ tcp        0      1 192.168.31.82:38334     172.217.160.110:443     SYN_SENT    106287/chrome --typ tcp        0      1 192.168.31.82:38340     172.217.160.110:443     SYN_SENT    106287/chrome --typ </code></pre><h2 id="2-tcpdump"><a href="#2-tcpdump" class="headerlink" title="2 tcpdump"></a>2 tcpdump</h2><p>tcpdump命令是一款sniffer工具，它可以打印所有经过网络接口的数据包的头信息，也可以使用-w选项将数据包保存到文件中，方便以后分析。</p><p><strong>tcpdump的过滤语法部分是和wireshark的过滤语法相同的</strong></p><h3 id="2-1-监视指定网卡"><a href="#2-1-监视指定网卡" class="headerlink" title="2.1 监视指定网卡"></a>2.1 监视指定网卡</h3><pre><code class="shell"> ##tcp -i 指定的网卡root@Ken:/home/ken# tcpdump -i lo   tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on lo, link-type EN10MB (Ethernet), capture size 262144 bytes21:22:38.442247 IP localhost &gt; localhost: ICMP echo request, id 29491, seq 1, length 6421:22:39.470290 IP localhost &gt; localhost: ICMP echo request, id 29491, seq 2, length 6421:22:40.493653 IP localhost &gt; localhost: ICMP echo request, id 29491, seq 3, length 6421:22:41.518022 IP localhost &gt; localhost: ICMP echo request, id 29491, seq 4, length 64</code></pre><h3 id="2-2-监视指定的端口和ip"><a href="#2-2-监视指定的端口和ip" class="headerlink" title="2.2 监视指定的端口和ip"></a>2.2 监视指定的端口和ip</h3><pre><code class="shell">root@Ken:/home/ken# tcpdump port 443  and host 61.135.169.121tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on ens33, link-type EN10MB (Ethernet), capture size 262144 bytes21:24:30.413289 IP 192.168.31.82.40326 &gt; 61.135.169.121.https: Flags [P.], seq 2141238907:2141239819, ack 1167133579, win 352, length 91221:24:30.421605 IP 61.135.169.121.https &gt; 192.168.31.82.40326: Flags [.], ack 912, win 1080, length 021:24:30.451834 IP 192.168.31.82.40330 &gt; 61.135.169.121.https: Flags [P.], seq 1382286639:1382287704, ack 3572438141, win 352, length 1065</code></pre><h3 id="2-3-限制抓包数量"><a href="#2-3-限制抓包数量" class="headerlink" title="2.3 限制抓包数量"></a>2.3 限制抓包数量</h3><pre><code class="shell">root@Ken:/home/ken# tcpdump -c 1000tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on ens33, link-type EN10MB (Ethernet), capture size 262144 bytes21:27:08.153206 IP6 fe80::c913:dd27:f92a:68ef &gt; ip6-allrouters: ICMP6, router solicitation, length 1621:27:08.153705 IP 192.168.31.82.33193 &gt; XiaoQiang.domain: 56002+ PTR? f.e.8.6.a.2.9.f.7.2.d.d.3.1.9.c.0.0.0.0.0.0.0.0.0.0.0.0.0.8.e.f.ip6.arpa. (90)21:27:08.266506 IP XiaoQiang.domain &gt; 192.168.31.82.33193: 56002 NXDomain* 0/0/0 (90)21:27:08.266783 IP 192.168.31.82.49318 &gt; XiaoQiang.domain: 12403+ PTR? 1.31.168.192.in-addr.arpa. (43)21:27:08.270827 IP XiaoQiang.domain &gt; 192.168.31.82.49318: 12403* 1/0/0 PTR XiaoQiang. (66)21:27:08.270966 IP 192.168.31.82.56582 &gt; XiaoQiang.domain: 47210+ PTR? 82.31.168.192.in-addr.arpa. (44)</code></pre><h3 id="2-4-输出信息到磁盘"><a href="#2-4-输出信息到磁盘" class="headerlink" title="2.4 输出信息到磁盘"></a>2.4 输出信息到磁盘</h3><pre><code class="shell">root@Ken:/home/ken# tcpdump -n -vvv -c 1000 -w /tmp/tcpdump_save.captcpdump: listening on ens33, link-type EN10MB (Ethernet), capture size 262144 bytesGot 19</code></pre><p><strong>一般保存成cap文件后,用wireshark进行分析</strong></p><h2 id="3-lsof"><a href="#3-lsof" class="headerlink" title="3 lsof"></a>3 lsof</h2><p>lsof（list open files）是一个查看当前系统文件的工具。<strong>在linux环境下，任何事物都以文件的形式存在，通过文件不仅仅可以访问常规数据，还可以访问网络连接和硬件</strong>。如传输控制协议 (TCP) 和用户数据报协议 (UDP) 套接字等，系统在后台都为该应用程序分配了一个文件描述符，该文件描述符提供了大量关于这个应用程序本身的信息。</p><pre><code class="shell">lsof打开的文件可以是：- 普通文件- 目录- 网络文件系统的文件- 字符或设备文件- (函数)共享库- 管道，命名管道- 符号链接- 网络文件（例如：NFS file、网络socket，unix域名socket）- 还有其它类型的文件，等等</code></pre><h3 id="3-1-命令参数"><a href="#3-1-命令参数" class="headerlink" title="3.1 命令参数"></a>3.1 命令参数</h3><pre><code class="shell">-c&lt;进程名&gt; 列出指定进程所打开的文件-g 列出GID号进程详情-d&lt;文件号&gt; 列出占用该文件号的进程+d&lt;目录&gt; 列出目录下被打开的文件+D&lt;目录&gt; 递归列出目录下被打开的文件-n&lt;目录&gt; 列出使用NFS的文件-i&lt;条件&gt; 列出符合条件的进程。（4、6、协议、:端口、 @ip ）-p&lt;进程号&gt; 列出指定进程号所打开的文件-u 列出UID号进程详情</code></pre><h3 id="3-2-各列含义"><a href="#3-2-各列含义" class="headerlink" title="3.2 各列含义"></a>3.2 各列含义</h3><pre><code class="shell">COMMAND：进程的名称 PID：进程标识符USER：进程所有者FD：文件描述符，应用程序通过文件描述符识别该文件。如cwd、txt等 TYPE：文件类型，如DIR、REG等DEVICE：指定磁盘的名称SIZE：文件的大小NODE：索引节点（文件在磁盘上的标识）NAME：打开文件的确切名称</code></pre><h3 id="3-3-查看指定目录下被打开的文件"><a href="#3-3-查看指定目录下被打开的文件" class="headerlink" title="3.3 查看指定目录下被打开的文件"></a>3.3 查看指定目录下被打开的文件</h3><p>命令：lsof +D /home/ 或lsof +d /home/</p><p><strong>参数+D为递归列出/home/下被打开的文件，参数+d为列出/home/下被打开的文件。</strong></p><pre><code class="shell">ken@Ken:~$ lsof +d /homeCOMMAND      PID USER   FD   TYPE DEVICE SIZE/OFF    NODE NAMEstartdde    2859  ken  cwd    DIR    8,1     4096 2097181 /home/kenkwin_no_s   2986  ken  cwd    DIR    8,1     4096 2097181 /home/kenkwin_x11    2992  ken  cwd    DIR    8,1     4096 2097181 /home/kendde-sessi   3037  ken  cwd    DIR    8,1     4096 2097181 /home/kendde-deskt   3105  ken  cwd    DIR    8,1     4096 2097181 /home/kendeepin-cl   3278  ken  cwd    DIR    8,1     4096 2097181 /home/kenvmtoolsd    3300  ken  cwd    DIR    8,1     4096 2097181 /home/kendde-polki   3494  ken  cwd    DIR    8,1     4096 2097181 /home/kenapplet.py   3503  ken  cwd    DIR    8,1     4096 2097181 /home/kenTypora     47596  ken  cwd    DIR    8,1     4096 2097181 /home/kenTypora     47608  ken  cwd    DIR    8,1     4096 2097181 /home/kenTypora     47646  ken  cwd    DIR    8,1     4096 2097181 /home/kenTypora     47649  ken  cwd    DIR    8,1     4096 2097181 /home/kencode       67663  ken  cwd    DIR    8,1     4096 2097181 /home/kencode       67680  ken  cwd    DIR    8,1     4096 2097181 /home/kencode       67717  ken  cwd    DIR    8,1     4096 2097181 /home/kencode       67731  ken  cwd    DIR    8,1     4096 2097181 /home/kencode       67774  ken  cwd    DIR    8,1     4096 2097181 /home/ken</code></pre><h3 id="3-4-指定进程号查看打开哪些文件"><a href="#3-4-指定进程号查看打开哪些文件" class="headerlink" title="3.4 指定进程号查看打开哪些文件"></a>3.4 指定进程号查看打开哪些文件</h3><p><img src="http://base422.oss-cn-beijing.aliyuncs.com/linuxlsof.png" alt=""></p><h3 id="3-5-查看指定网络连接"><a href="#3-5-查看指定网络连接" class="headerlink" title="3.5 查看指定网络连接"></a>3.5 查看指定网络连接</h3><pre><code class="shell">lsof -i 4　　　　　　　#查看ipv4连接lsof -i:80　         #查看端口为80的连接lsof -i@127.0.0.1　  #查看ip为127.0.0.1的连接lsof -i tcp          #查看tcp连接</code></pre>]]></content>
      
      
      <categories>
          
          <category> 基础 </category>
          
          <category> Linux命令 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux命令 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>雪花算法</title>
      <link href="/2020/04/07/%E9%9B%AA%E8%8A%B1%E7%AE%97%E6%B3%95/"/>
      <url>/2020/04/07/%E9%9B%AA%E8%8A%B1%E7%AE%97%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h2 id="1-snowflake-介绍"><a href="#1-snowflake-介绍" class="headerlink" title="1 snowflake 介绍"></a>1 snowflake 介绍</h2><p>Twitter Snowflake算法介绍：<br><a href="https://segmentfault.com/a/1190000011282426" target="_blank" rel="noopener">https://segmentfault.com/a/1190000011282426</a></p><p>对于分布式的ID生成，以Twitter Snowflake为代表的， Flake 系列算法，属于划分命名空间并行生成的一种算法，生成的数据为64bit的long型数据，在数据库中应该用大于等于64bit的数字类型的字段来保存该值，比如在MySQL中应该使用BIGINT。</p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/snowflake.jpg" alt=""></p><ul><li>1位，不用。二进制中最高位为1的都是负数，但是我们生成的id一般都使用整数，所以这个最高位固定是0</li><li>41位，用来记录时间戳（毫秒）。<ul><li>41位可以表示$2^{41}-1$个数字，</li><li>如果只用来表示正整数（计算机中正数包含0），可以表示的数值范围是：0 至 $2^{41}-1$，减1是因为可表示的数值范围是从0开始算的，而不是1。</li><li>也就是说41位可以表示$2^{41}-1$个毫秒的值，转化成单位年则是$(2^{41}-1) / (1000 * 60 * 60 * 24 * 365) = 69$年</li></ul></li><li>10位，用来记录工作机器id。<ul><li>可以部署在$2^{10} = 1024$个节点，包括5位datacenterId和5位workerId</li><li>5位（bit）可以表示的最大正整数是$2^{5}-1 = 31$，即可以用0、1、2、3、….31这32个数字，来表示不同的datecenterId或workerId</li></ul></li><li>12位，序列号，用来记录同毫秒内产生的不同id。<ul><li>12位（bit）可以表示的最大正整数是$2^{12}-1 = 4095$，即可以用0、1、2、3、….4094这4095个数字，来表示同一机器同一时间截（毫秒)内产生的4095个ID序号</li></ul></li></ul><h2 id="2-snowflake缺点"><a href="#2-snowflake缺点" class="headerlink" title="2 snowflake缺点"></a>2 snowflake缺点</h2><p>雪花算法存在的缺点是：</p><ul><li>依赖机器时钟，如果机器时钟回拨，会导致重复ID生成</li><li>在单机上是递增的，但是由于设计到分布式环境，每台机器上的时钟不可能完全同步，有时候会出现不是全局递增的情况（此缺点可以认为无所谓，一般分布式ID只要求趋势递增，并不会严格要求递增～90%的需求都只要求趋势递增）</li></ul><h2 id="3-snowflake-算法异常情况分析"><a href="#3-snowflake-算法异常情况分析" class="headerlink" title="3 snowflake 算法异常情况分析"></a>3 snowflake 算法异常情况分析</h2><p>整个ID生成过程中，启动的时候会对外部有依赖，因为需要知道当前的机器ID，之后就独立工作。</p><p>几种常见的异常情况分析：</p><p>问：如果某个时间戳的所有ID都被用完了，那怎么办？<br>答：就继续等待下一毫秒然后在生成ID</p><p>问：获取当前时间戳时，如果获取到的时间戳比之前一个1已生成的ID的时间戳还要小，怎么办？<br>答：snowflake的做法是继续获取当前机器的时间戳，直到获取更大的时间戳才继续生成ID（在这个过程中是不分配新的ID）<br>如果snowfalke运行的服务器上时钟有大量的偏差时，整个snowflake系统就不能正常工作（偏差越多，分配新ID等待的时间越久）</p><p>snowflake的官方文档中明确要求必须配置NTP,并且NTP配置成不可向后调整的模式。</p><h2 id="4-Go语言第三方库"><a href="#4-Go语言第三方库" class="headerlink" title="4 Go语言第三方库"></a>4 Go语言第三方库</h2><p><a href="https://github.com/sony/sonyflake" target="_blank" rel="noopener">sonyflake</a></p>]]></content>
      
      
      <categories>
          
          <category> 分布式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Zookeeper简介</title>
      <link href="/2020/04/07/Zookeeper%E7%AE%80%E4%BB%8B/"/>
      <url>/2020/04/07/Zookeeper%E7%AE%80%E4%BB%8B/</url>
      
        <content type="html"><![CDATA[<h2 id="1-1-概述"><a href="#1-1-概述" class="headerlink" title="1.1 概述"></a>1.1 概述</h2><p>Zookeeper从设计模式角度来理解：是一个基于观察者模式设计的分布式服务管理框架，它<strong>负</strong><br><strong>责存储和管理大家都关心的数据</strong>，然后<strong>接受观察者的注册</strong>，一旦这些数据的状态发生变化 ，<br>ookeeper就将<strong>负责通知已经在Zookeeper上注册的那些观察者</strong>做出相应的反应。</p><h2 id="1-2-特点"><a href="#1-2-特点" class="headerlink" title="1.2 特点"></a>1.2 特点</h2><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/zookeeper.png" alt=""></p><ol><li>Zookeeper：一个领导者（Leader），多个跟随者（Follower）组成的集群。</li><li>集群中只要有半数以上节点存活，Zookeeper集群就能正常服务。</li><li>全局数据一致：每个Server保存一份相同的数据副本，Client无论连接到哪个Server，数据都是一致的。</li><li>更新请求顺序进行，来自同一个Client的更新请求按其发送顺序依次执行。</li><li>数据更新原子性，一次数据更新要么成功，要么失败。</li><li>实时性，在一定时间范围内，Client能读到最新数据。</li></ol><h2 id="1-3-数据结构"><a href="#1-3-数据结构" class="headerlink" title="1.3 数据结构"></a>1.3 数据结构</h2><p>ZooKeeper数据模型的结构与<strong>Unix文件系统很类似</strong>，整体上可以看作是一棵树，每个节点称做一<br>个ZNode。每一个ZNode默认能够存储<strong>1MB</strong>的数据，每个ZNode都可以<strong>通过其路径唯一标识</strong>。</p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/zkstruct.png" alt=""></p><h2 id="1-4-应用场景"><a href="#1-4-应用场景" class="headerlink" title="1.4 应用场景"></a>1.4 应用场景</h2><ul><li>分布式协调</li><li>分布式锁</li><li>元数据/配置信息管理</li><li>HA高可用性</li></ul><h3 id="1-4-1-分布式协调"><a href="#1-4-1-分布式协调" class="headerlink" title="1.4.1 分布式协调"></a>1.4.1 分布式协调</h3><p>这个其实是 zookeeper 很经典的一个用法，简单来说，就好比，你 A 系统发送个请求到 mq，然后 B 系统消息消费之后处理了。那 A 系统如何知道 B 系统的处理结果？用 zookeeper 就可以实现分布式系统之间的协调工作。A 系统发送请求之后可以在 zookeeper 上对某个节点的值<strong>注册个监听器</strong>，一旦 B 系统处理完了就修改 zookeeper 那个节点的值，A 系统立马就可以收到通知，完美解决。</p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/zookeeper-distributed-coordination.png" alt=""></p><h3 id="1-4-2-分布式锁"><a href="#1-4-2-分布式锁" class="headerlink" title="1.4.2 分布式锁"></a>1.4.2 分布式锁</h3><p>举个栗子。对某一个数据连续发出两个修改操作，两台机器同时收到了请求，但是只能一台机器先执行完另外一个机器再执行。那么此时就可以使用 zookeeper 分布式锁，一个机器接收到了请求之后先获取 zookeeper 上的一把分布式锁，就是可以去<strong>创建一个 znode</strong>，接着执行操作；然后另外一个机器也<strong>尝试去创建那个 znode</strong>，结果发现自己创建不了，因为被别人创建了，那只能等着，等第一个机器执行完了自己再执行。</p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/zookeeper-distributed-lock-demo.png" alt=""></p><h3 id="1-4-3-元数据-配置信息管理"><a href="#1-4-3-元数据-配置信息管理" class="headerlink" title="1.4.3 元数据/配置信息管理"></a>1.4.3 元数据/配置信息管理</h3><p>zookeeper 可以用作很多系统的配置信息的管理，比如 kafka、storm 等等很多分布式系统都会选用 zookeeper 来做一些元数据、配置信息的管理，包括 dubbo 注册中心也支持 zookeeper </p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/zookeeper-meta-data-manage.png" alt=""></p><h3 id="1-4-4-HA高可用性"><a href="#1-4-4-HA高可用性" class="headerlink" title="1.4.4 HA高可用性"></a>1.4.4 HA高可用性</h3><p>这个应该是很常见的，比如 hadoop、hdfs、yarn 等很多大数据系统，都选择基于 zookeeper 来开发 HA 高可用机制，就是一个<strong>重要进程一般会做主备两个</strong>，主进程挂了立马通过 zookeeper 感知到切换到备用进程。</p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/zookeeper-active-standby.png" alt=""></p><h2 id="1-5-节点类型"><a href="#1-5-节点类型" class="headerlink" title="1.5 节点类型"></a>1.5 节点类型</h2><p>分为四类:</p><ul><li><strong>持久化目录节点</strong>:客户端与Zookeeper断开连接后，该节点依旧存在</li><li><strong>持久化顺序编号目录节点</strong>:客户端与Zookeeper断开连接后，该节点依旧存在，只是Zookeeper给该节点名称进行顺序编号</li><li><strong>临时目录节点</strong>:客户端与Zookeeper断开连接后，该节点被删除</li><li><strong>临时顺序编号目录节点</strong>:客户端 与 Zookeeper 断开连接后 ， 该 节 点 被 删 除 ， 只 是<br>Zookeeper给该节点名称进行顺序编号</li></ul><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/nodeclass.png" alt=""></p><h2 id="1-6-监听器原理"><a href="#1-6-监听器原理" class="headerlink" title="1.6 监听器原理"></a>1.6 监听器原理</h2><h3 id="1-6-1-监听过程详解"><a href="#1-6-1-监听过程详解" class="headerlink" title="1.6.1 监听过程详解"></a>1.6.1 监听过程详解</h3><ol><li>首先要有一个main()线程</li><li>在main线程中创建Zookeeper客户端，这时就会创建两个线程，一个负责网络连接通信（connet），一个负责监听（listener）</li><li>通过connect线程将注册的监听事件发送给Zookeeper。</li><li>在Zookeeper的注册监听器列表中将注册的监听事件添加到列表中。</li><li>Zookeeper监听到有数据或路径变化，就会将这个消息发送给listener线程。 </li><li>listener线程内部调用了process()方法。</li></ol><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/zkwatch.png" alt=""></p><h3 id="1-6-2-常见的监听"><a href="#1-6-2-常见的监听" class="headerlink" title="1.6.2 常见的监听"></a>1.6.2 常见的监听</h3><ul><li><strong>监听节点数据的变化</strong>: get path [watch] </li><li><strong>监听子节点增减的变化</strong>: ls path [watch]</li></ul><h2 id="1-7-选举机制"><a href="#1-7-选举机制" class="headerlink" title="1.7 选举机制"></a>1.7 选举机制</h2><h3 id="1-7-1-核心机制"><a href="#1-7-1-核心机制" class="headerlink" title="1.7.1 核心机制"></a>1.7.1 核心机制</h3><ul><li><p><strong>半数机制：集群中半数以上(不包括半数)机器存活，集群可用</strong>。所以 Zookeeper 适合安装奇数台服务器。</p></li><li><p>Zookeeper 虽然在配置文件中并没有指定 Master 和 Slave。但是，Zookeeper 工作时，是有<strong>一个节点为 Leader，其他则为 Follower</strong>，Leader 是通过<strong>内部的选举机制临时产生的</strong>。</p></li></ul><h3 id="1-7-2-选举过程demo"><a href="#1-7-2-选举过程demo" class="headerlink" title="1.7.2 选举过程demo"></a>1.7.2 选举过程demo</h3><p>假设有五台服务器组成的 Zookeeper 集群，它们的 id 从 1-5，同时它们都是最新启动的，<br>也就是没有历史数据，在存放数据量这一点上，都是一样的。假设这些服务器依序启动，来<br>看看会发生什么，如下图所示:</p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/zkvote.png" alt=""></p><ol><li>服务器 1 启动，发起一次选举。服务器 1 投自己一票。此时服务器 1 票数一票，不够半数以上（3 票），选举无法完成，服务器 1 状态保持为 LOOKING；</li><li>服务器 2 启动，再发起一次选举。服务器 1 和 2 分别投自己一票并交换选票信息：此时服务器 1 发现服务器 2 的 ID 比自己目前投票推举的（服务器 1）大，更改选票为推举服务器 2。此时服务器 1 票数 0 票，服务器 2 票数 2 票，没有半数以上结果，选举无法完成，服务器 1，2 状态保持 LOOKING</li><li>服务器 3 启动，发起一次选举。此时服务器 1 和 2 都会更改选票为服务器 3。此次投票结果：服务器 1 为 0 票，服务器 2 为 0 票，服务器 3 为 3 票。此时服务器 3 的票数已经超过半数，服务器 3 当选 Leader。服务器 1，2 更改状态为 FOLLOWING，服务器 3 更改状态为 LEADING；</li><li>服务器 4 启动，发起一次选举。此时服务器 1，2，3 已经不是 LOOKING 状态，不会更改选票信息。交换选票信息结果：服务器 3 为 3 票，服务器 4 为 1 票。此时服务器 4服从多数，更改选票信息为服务器 3，并更改状态为 FOLLOWING；</li><li>服务器 5 启动，同 4 一样当小弟。</li></ol><h2 id="1-8-写数据流程"><a href="#1-8-写数据流程" class="headerlink" title="1.8 写数据流程"></a>1.8 写数据流程</h2><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/zkwrite.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 分布式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式 </tag>
            
            <tag> zookeeper </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分布式选举</title>
      <link href="/2020/04/06/%E5%88%86%E5%B8%83%E5%BC%8F%E9%80%89%E4%B8%BE/"/>
      <url>/2020/04/06/%E5%88%86%E5%B8%83%E5%BC%8F%E9%80%89%E4%B8%BE/</url>
      
        <content type="html"><![CDATA[<h2 id="1-为什么要有分布式选举"><a href="#1-为什么要有分布式选举" class="headerlink" title="1 为什么要有分布式选举"></a>1 为什么要有分布式选举</h2><p><strong>主节点，在一个分布式集群中负责对其他节点的协调和管理，也就是说，其他节点都必须听</strong><br><strong>从主节点的安排。</strong><br>主节点的存在，就可以保证其他节点的有序运行，以及数据库集群中的写入数据在每个节点<br>上的一致性。这里的一致性是指，数据在每个集群节点中都是一样的，不存在不同的情况。<br>当然，如果主故障了，集群就会天下大乱，就好比一个国家的皇帝驾崩了，国家大乱一样。<br>比如，数据库集群中主节点故障后，可能导致每个节点上的数据会不一致。<br><strong>这，就应了那句话“国不可一日无君”，对应到分布式系统中就是“集群不可一刻无主”。</strong></p><p><strong>总结来说，选举的作用就是选出一个主节点，由它来协调和管理其他节点，以保证集群有序</strong><br><strong>运行和节点间数据的一致性。</strong></p><h2 id="2-分布式选举常见算法"><a href="#2-分布式选举常见算法" class="headerlink" title="2 分布式选举常见算法"></a>2 分布式选举常见算法</h2><ul><li><strong>Bully算法</strong></li><li><strong>Raft算法</strong></li><li><strong>ZAB算法</strong></li><li><strong>Base Paxos</strong></li><li><strong>Multi Paxos</strong></li></ul><h2 id="3-长者为大：Bully-算法"><a href="#3-长者为大：Bully-算法" class="headerlink" title="3 长者为大：Bully 算法"></a>3 长者为大：Bully 算法</h2><p>Bully 算法是一种霸道的集群选主算法，为什么说是霸道呢？</p><p><strong>因为它的选举原则是“长者”为大，即在所有活着的节点中，选取 ID 最大的节点作为主节点。</strong></p><p>在 Bully 算法中，节点的角色有两种：</p><ul><li>普通节点</li><li>主节点</li></ul><p>初始化时，所有节点都是平等的，都是普通节点，并且都有成为主的权利。但是，当选主成功后，有且仅有一个节点成为主节点，其他所有节点都是普通节点。<br><strong>当且仅当主节点故障或与其他节点失去联系后，才会重新选主。</strong></p><p>Bully 算法在选举过程中，需要用到以下 3 种消息：</p><ul><li><strong>Election 消息，用于发起选举；</strong></li><li><strong>Alive 消息，对 Election 消息的应答；</strong></li><li><strong>Victory 消息，竞选成功的主节点向其他节点发送的宣誓主权的消息。</strong></li></ul><p>Bully 算法选举的原则是“长者为大”，意味着它的假设条件是，集群中每个节点均知道其他节点的 ID。在此前提下，其具体的选举过程是:</p><ol><li>集群中每个节点判断自己的 ID 是否为当前活着的节点中 ID 最大的，如果是，则直接向其他节点发送 Victory 消息，宣誓自己的主权；</li><li>如果自己不是当前活着的节点中 ID 最大的，则向比自己 ID 大的所有节点发送Election 消息，并等待其他节点的回复；</li><li>若在给定的时间范围内，本节点没有收到其他节点回复的 Alive 消息，则认为自己成为主节点，并向其他节点发送 Victory 消息，宣誓自己成为主节点；若接收到来自比自己ID 大的节点的 Alive 消息，则等待其他节点发送 Victory 消息；</li><li>若本节点收到比自己 ID 小的节点发送的 Election 消息，则回复一个 Alive 消息，告知其他节点，我比你大，重新选举。</li></ol><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/disbully.png" alt=""></p><p>目前已经有很多开源软件采用了 Bully 算法进行选主，比如 MongoDB 的副本集故障转移功能。MongoDB 的分布式选举中，采用节点的最后操作时间戳来表示 ID，时间戳最新的节点其 ID 最大，也就是说时间戳最新的、活着的节点是主节点。</p><p>小结一下。<strong>Bully 算法的选择特别霸道和简单，谁活着且谁的 ID 最大谁就是主节点，其他节点必须无条件服从。这种算法的优点是，选举速度快、算法复杂度低、简单易实现。</strong><br><strong>但这种算法的缺点在于，需要每个节点有全局的节点信息，因此额外信息存储较多；其次，任意一个比当前主节点 ID 大的新节点或节点故障后恢复加入集群的时候，都可能会触发重新选举，成为新的主节点，如果该节点频繁退出、加入集群，就会导致频繁切主。</strong></p><h2 id="4-民主投票：Raft-算法"><a href="#4-民主投票：Raft-算法" class="headerlink" title="4 民主投票：Raft 算法"></a>4 民主投票：Raft 算法</h2><p>Raft 算法是典型的多数派投票选举算法，其选举机制与我们日常生活中的民主投票机制类似，核心思想是“少数服从多数”。也就是说，Raft 算法中，获得投票最多的节点成为主。</p><p>采用 Raft 算法选举，集群节点的角色有 3 种：</p><ul><li><strong>Leader</strong>，即主节点，同一时刻只有一个 Leader，负责协调和管理其他节点；</li><li><strong>Candidate</strong>，即候选者，每一个节点都可以成为 Candidate，节点在该角色下才可以被选为新的 Leader；</li><li><strong>Follower</strong>，Leader 的跟随者，不可以发起选举。</li></ul><p>Raft 选举的流程，可以分为以下几步：</p><ol><li>初始化时，<strong>所有节点均为 Follower 状态</strong>。</li><li>开始选主时，所有节点的状态由 <strong>Follower 转化为 Candidate</strong>，并向其他节点发送选举请求。</li><li>其他节点根据接收到的选举请求的先后顺序，回复是否同意成为主。<strong>这里需要注意的是，在每一轮选举中，一个节点只能投出一张票。</strong></li><li>若发起选举请求的节点<strong>获得超过一半的投票，则成为主节点</strong>，其状态转化为 Leader，其他节点的状态则由Candidate 降为 Follower。Leader 节点与 Follower 节点之间会定期发送心跳包，以检测主节点是否活着。</li><li><strong>当 Leader 节点的任期到了</strong>，即发现其他服务器开始下一轮选主周期时，Leader 节点的状态由 Leader 降级为 Follower，进入新一轮选主。</li></ol><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/disraft.png" alt=""></p><p><strong>请注意，每一轮选举，每个节点只能投一次票</strong>。这种选举就类似人大代表选举，正常情况下每个人大代表都有一定的任期，任期到后会触发重新选举，且投票者只能将自己手里唯一的票投给其中一个候选者。对应到 Raft 算法中，选主是周期进行的，包括选主和任值两个时间段，选主阶段对应投票阶段，任值阶段对应节点成为主之后的任期。<strong>但也有例外的时候，如果主节点故障，会立马发起选举，重新选出一个主节点。</strong></p><p>Google 开源的 Kubernetes，擅长容器管理与调度，为了保证可靠性，通常会部署 3 个节点用于数据备份。这 3 个节点中，有一个会被选为主，其他节点作为备。Kubernetes 的选主采用的是开源的 etcd 组件。而，etcd 的集群管理器 etcds，是一个高可用、强一致性的服务发现存储仓库，就是采用了 Raft 算法来实现选主和一致性的。</p><p>小结一下。</p><p><strong>Raft 算法具有选举速度快、算法复杂度低、易于实现的优点；</strong></p><p><strong>缺点是，它要求系统内每个节点都可以相互通信，且需要获得过半的投票数才能选主成功，因此通信量大。该算法选举稳定性比 Bully 算法好，这是因为当有新节点加入或节点故障恢复后，会触发选主，但不一定会真正切主，除非新节点或故障后恢复的节点获得投票数过半，才会导致切主。</strong></p><h2 id="5-具有优先级的民主投票：ZAB-算法"><a href="#5-具有优先级的民主投票：ZAB-算法" class="headerlink" title="5 具有优先级的民主投票：ZAB 算法"></a>5 具有优先级的民主投票：ZAB 算法</h2><p>ZAB（ZooKeeper Atomic Broadcast）选举算法是为 ZooKeeper 实现分布式协调功能而设计的。相较于 Raft 算法的投票机制，<strong>ZAB 算法增加了通过节点 ID 和数据 ID 作为参考进行选主</strong>，<strong>节点 ID 和数据 ID 越大，表示数据越新，优先成为主</strong>。<strong>相比较于 Raft 算法，ZAB 算法尽可能保证数据的最新性。所以，ZAB 算法可以说是对 Raft 算法的改进</strong></p><p>使用 ZAB 算法选举时，集群中每个节点拥有 3 种角色：</p><ul><li><strong>Leader</strong>，主节点；</li><li><strong>Follower</strong>，跟随者节点；</li><li><strong>Observer</strong>，观察者，无投票权。</li></ul><p>选举过程中，集群中的节点拥有 4 个状态：</p><ul><li><strong>Looking 状态</strong>，即选举状态。当节点处于该状态时，它会认为当前集群中没有 Leader，因此自己进入选举状态。</li><li><strong>Leading 状态</strong>，即领导者状态，表示已经选出主，且当前节点为 Leader。</li><li><strong>Following 状态</strong>，即跟随者状态，集群中已经选出主后，其他非主节点状态更新为Following，表示对 Leader 的追随。</li><li><strong>Observing 状态</strong>，即观察者状态，表示当前节点为 Observer，持观望态度，没有投票权和选举权。</li></ul><p>投票过程中，每个节点都有一个唯一的三元组 (server_id, server_zxID, epoch)，其中：</p><ul><li><strong>server_id 表示本节点的唯一 ID；</strong></li><li><strong>server_zxID 表示本节点存放的数据 ID，数据 ID 越大表示数据越新，选举权重越大；</strong></li><li><strong>epoch 表示当前选取轮数，一般用逻辑时钟表示。</strong></li></ul><p>ZAB 选举算法的核心是“<strong>少数服从多数，ID 大的节点优先成为主</strong>”，因此选举过程中通过(vote_id, vote_zxID) 来表明投票给哪个节点，其中 vote_id 表示被投票节点的 ID，vote_zxID 表示被投票节点的服务器 zxID。ZAB 算法选主的原则是：<strong>server_zxID 最大者成为 Leader；若 server_zxID 相同，则 server_id 最大者成为 Leader</strong>。</p><p>接下来，我以 3 个 Server 的集群为例，此处每个 Server 代表一个节点，与你介绍 ZAB 选主的过程。</p><p>第一步：当系统刚启动时，3 个服务器当前投票均为第一轮投票，即 epoch=1，且 zxID均为 0。此时每个服务器都推选自己，并将选票信息 &lt;epoch, vote_id, vote_zxID&gt; 广播出去</p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/diszab1.png" alt=""></p><p>第二步：根据判断规则，由于 3 个 Server 的 epoch、zxID 都相同，因此比较 server_id，较大者即为推选对象，因此 Server 1 和 Server 2 将 vote_id 改为 3，更新自己的投票箱并重新广播自己的投票。</p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/diszab2.png" alt=""></p><p>第三步：此时系统内所有服务器都推选了 Server 3，因此 Server 3 当选 Leader，处于Leading 状态，向其他服务器发送心跳包并维护连接；Server1 和 Server2 处于Following 状态</p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/diszab3.png" alt=""></p><p>小结一下。</p><p>ZAB 算法性能高，对系统无特殊要求，采用广播方式发送信息，若节点中有 n个节点，每个节点同时广播，则集群中信息量为 n<em>(n-1) 个消息，容易出现广播风暴；且除了投票，还增加了对比节点 ID 和数据 ID，这就意味着还需要知道所有节点的 ID 和数据ID，所以*</em>选举时间相对较长。但该算法选举稳定性比较好<strong>，当有新节点加入或节点故障恢复后，会触发选主，但不一定会真正切主，除非新节点或故障后恢复的</strong>节点数据 ID 和节点ID 最大，且获得投票数过半，才会导致切主**</p><h2 id="6-三种选举算法的对比分析"><a href="#6-三种选举算法的对比分析" class="headerlink" title="6 三种选举算法的对比分析"></a>6 三种选举算法的对比分析</h2><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/disbj.png" alt=""></p><h2 id="7-多数派选主奇数节点原因"><a href="#7-多数派选主奇数节点原因" class="headerlink" title="7 多数派选主奇数节点原因"></a>7 多数派选主奇数节点原因</h2><p>多数派选主算法的核心是少数服从多数，获得投票多的节点胜出。想象一下，如果现在采用偶数节点集群，当两个节点均获得一半投票时，到底应该选谁为主呢？<br>答案是，<strong>在这种情况下，无法选出主，必须重新投票选举。但即使重新投票选举，两个节点拥有相同投票数的概率也会很大。因此，多数派选主算法通常采用奇数节点。</strong><br>这，也是大家通常看到 ZooKeeper、 etcd、Kubernetes 等开源软件选主均采用奇数节点的一个关键原因。</p><h2 id="8-总结"><a href="#8-总结" class="headerlink" title="8 总结"></a>8 总结</h2><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/diszongjie.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 分布式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>乐观锁与悲观锁</title>
      <link href="/2020/04/06/%E4%B9%90%E8%A7%82%E9%94%81%E4%B8%8E%E6%82%B2%E8%A7%82%E9%94%81/"/>
      <url>/2020/04/06/%E4%B9%90%E8%A7%82%E9%94%81%E4%B8%8E%E6%82%B2%E8%A7%82%E9%94%81/</url>
      
        <content type="html"><![CDATA[<h2 id="1-悲观锁定义"><a href="#1-悲观锁定义" class="headerlink" title="1 悲观锁定义"></a>1 悲观锁定义</h2><p><strong>Pessimistic Lock</strong>：</p><p>每次获取数据的时候，都会担心数据被修改，所以<strong>每次获取数据的时候都会进行加锁</strong>，确保在自己使用的过程中数据不会被别人修改，使用完成后进行数据解锁。由于数据进行加锁，<strong>期间对该数据进行读写的其他线程都会进行等待</strong>。</p><h2 id="2-乐观锁定义"><a href="#2-乐观锁定义" class="headerlink" title="2 乐观锁定义"></a>2 乐观锁定义</h2><p>每次获取数据的时候，都不会担心数据被修改，<strong>所以每次获取数据的时候都不会进行加锁</strong>，但是在更新数据的时候需要判断该数据是否被别人修改过。如果数据被其他线程修改，则不进行数据更新，如果数据没有被其他线程修改，则进行数据更新。<strong>由于数据没有进行加锁，期间该数据可以被其他线程进行读写操作</strong>。</p><h2 id="3-适用场景"><a href="#3-适用场景" class="headerlink" title="3 适用场景"></a>3 适用场景</h2><ul><li><strong>悲观锁</strong>：比较适合<strong>写入操作比较频繁</strong>的场景，如果出现大量的读取操作，每次读取的时候都会进行加锁，这样会增加大量的锁的开销，降低了系统的吞吐量。</li><li><strong>乐观锁</strong>：比较适合<strong>读取操作比较频繁</strong>的场景，如果出现大量的写入操作，数据发生冲突的可能性就会增大，为了保证数据的一致性，应用层需要不断的重新获取数据，这样会增加大量的查询操作，降低了系统的吞吐量。</li></ul><h2 id="4-悲观锁的实现"><a href="#4-悲观锁的实现" class="headerlink" title="4 悲观锁的实现"></a>4 悲观锁的实现</h2><p><strong>使用应用自带的锁机制,一般都是悲观锁机制</strong></p><p>如:Java中<strong>synchronized和ReentrantLock</strong>等独占锁就是悲观锁思想的实现</p><h2 id="5-乐观锁的实现"><a href="#5-乐观锁的实现" class="headerlink" title="5 乐观锁的实现"></a>5 乐观锁的实现</h2><p>使用CAS机制实现</p><h2 id="6-总结"><a href="#6-总结" class="headerlink" title="6 总结"></a>6 总结</h2><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/dislock.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 分布式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CAS原理</title>
      <link href="/2020/04/06/CAS%E7%9A%84%E5%8E%9F%E7%90%86/"/>
      <url>/2020/04/06/CAS%E7%9A%84%E5%8E%9F%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h2 id="1-什么是CAS"><a href="#1-什么是CAS" class="headerlink" title="1 什么是CAS"></a>1 什么是CAS</h2><p><strong>CAS，是Compare and Swap(比较换算)的简称</strong>，<strong>是乐观锁的典型实现</strong>,在这个机制中有三个核心的参数：</p><ul><li><strong>V表示变量当前的值</strong></li><li><strong>E表示预期的值</strong></li><li><strong>N表示新值</strong></li></ul><h2 id="2-CAS核心思想"><a href="#2-CAS核心思想" class="headerlink" title="2 CAS核心思想"></a>2 CAS核心思想</h2><p><strong>一个期望值和一个变量的当前值进行比较，如果当前变量的值与我们期望的值相等，就使用一个新值替换当前变量的值</strong>,<strong>如果失败了,什么都不做或者重试</strong></p><h3 id="2-1-流程图"><a href="#2-1-流程图" class="headerlink" title="2.1 流程图"></a>2.1 流程图</h3><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/cas.png" alt=""></p><h3 id="2-2-CAS解决的问题"><a href="#2-2-CAS解决的问题" class="headerlink" title="2.2 CAS解决的问题"></a>2.2 CAS解决的问题</h3><p>值得注意的是CAS机制中的这步步骤是原子性的（<strong>从指令层面提供的原子操作</strong>），<strong>所以CAS机制可以解决多线程并发编程对共享变量读写的原子性问题</strong>。</p><h2 id="3-CAS的优点"><a href="#3-CAS的优点" class="headerlink" title="3 CAS的优点"></a>3 CAS的优点</h2><ul><li><p>可以保证变量操作的原子性；</p></li><li><p>并发量不是很高的情况下，使用CAS机制比使用锁机制效率更高；</p></li><li><p>在线程对共享资源占用时间较短的情况下，使用CAS机制效率也会较高。</p></li></ul><h2 id="4-CAS的缺点"><a href="#4-CAS的缺点" class="headerlink" title="4 CAS的缺点"></a>4 CAS的缺点</h2><ul><li><strong>ABA问题</strong></li><li><strong>自旋导致的消耗较高的CPU</strong></li><li><strong>只能保证一个共享变量的原子操作,不能保证代码块的原子性</strong></li></ul><h3 id="4-1-ABA问题"><a href="#4-1-ABA问题" class="headerlink" title="4.1 ABA问题"></a>4.1 ABA问题</h3><h4 id="4-1-1-描述"><a href="#4-1-1-描述" class="headerlink" title="4.1.1 描述"></a>4.1.1 描述</h4><p>ABA问题：CAS在操作的时候会检查变量的值是否被更改过，如果没有则更新值，但是带来一个问题，最开始的值是A，接着变成B，最后又变成了A。经过检查这个值确实没有修改过，因为最后的值还是A，但是实际上这个值确实已经被修改过了。</p><h4 id="4-1-2-解决方法"><a href="#4-1-2-解决方法" class="headerlink" title="4.1.2 解决方法"></a>4.1.2 解决方法</h4><p>为了解决这个问题，在<strong>每次进行操作的时候加上一个版本号，每次操作的就是两个值</strong>，一个版本号和某个值，对当前引用进行检查，再对版本号标志进行检查，只有全部相等才更新值。</p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/casaba.png" alt=""></p><h3 id="4-2-自旋导致大量消耗CPU"><a href="#4-2-自旋导致大量消耗CPU" class="headerlink" title="4.2 自旋导致大量消耗CPU"></a>4.2 自旋导致大量消耗CPU</h3><h4 id="4-2-1-描述"><a href="#4-2-1-描述" class="headerlink" title="4.2.1 描述"></a>4.2.1 描述</h4><p>看起来CAS比锁的效率高，从阻塞机制变成了非阻塞机制，减少了线程之间等待的时间。每个方法不能绝对的比另一个好，在线程之间竞争程度大的时候，如果使用CAS，每次都有很多的线程在竞争，也就是说CAS机制不能更新成功。<strong>这种情况下CAS机制会一直重试，这样就会比较耗费CPU。</strong></p><h4 id="4-2-2-解决方法"><a href="#4-2-2-解决方法" class="headerlink" title="4.2.2 解决方法"></a>4.2.2 解决方法</h4><ul><li><strong>限制重试次数</strong></li><li><strong>如果可以使用CPU的延时流水线指令(de-pipeline)</strong></li></ul><h3 id="4-3-不能保证代码块的原子性"><a href="#4-3-不能保证代码块的原子性" class="headerlink" title="4.3 不能保证代码块的原子性"></a>4.3 不能保证代码块的原子性</h3><h4 id="4-3-1-描述"><a href="#4-3-1-描述" class="headerlink" title="4.3.1 描述"></a>4.3.1 描述</h4><p><strong>CAS 只对单个共享变量有效，当操作涉及跨多个共享变量时 CAS 无效</strong>。</p><h4 id="4-3-2-解决方法"><a href="#4-3-2-解决方法" class="headerlink" title="4.3.2 解决方法"></a>4.3.2 解决方法</h4><ul><li>但是从 JDK 1.5开始，提供了<code>AtomicReference</code>类来保证引用对象之间的原子性，你可以把多个变量放在一个对象里来进行 CAS 操作.所以我们可以使用锁或者利用<code>AtomicReference</code>类把多个共享变量合并成一个共享变量来操作。</li><li>golang提供了<code>sync/atomic</code>包来解决此问题</li></ul>]]></content>
      
      
      <categories>
          
          <category> 分布式 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>20.ES分片及生命周期</title>
      <link href="/2020/04/05/20-ES%E5%88%86%E7%89%87%E5%8F%8A%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/"/>
      <url>/2020/04/05/20-ES%E5%88%86%E7%89%87%E5%8F%8A%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/</url>
      
        <content type="html"><![CDATA[<h2 id="20-1-倒排索引不可变性"><a href="#20-1-倒排索引不可变性" class="headerlink" title="20.1 倒排索引不可变性"></a>20.1 倒排索引不可变性</h2><p><strong>倒排索引采⽤ Immutable Design，⼀旦⽣成，不可更改</strong></p><h3 id="20-1-1-好处"><a href="#20-1-1-好处" class="headerlink" title="20.1.1 好处"></a>20.1.1 好处</h3><ul><li>⽆需考虑并发写⽂件的问题，避免了锁机制带来的性能问题</li><li>⼀旦读⼊内核的⽂件系统缓存，便留在哪⾥。只要⽂件系统存有⾜够的空间，⼤部分请求就会直接请求内存，不会命中磁盘，提升了很⼤的性能</li><li>缓存容易⽣成和维护 / 数据可以被压缩</li></ul><h3 id="20-1-2-挑战"><a href="#20-1-2-挑战" class="headerlink" title="20.1.2 挑战"></a>20.1.2 挑战</h3><p>如果需要让⼀个新的⽂档可以被搜索，<strong>需要重建整个索引</strong>。</p><h2 id="20-2-写数据底层原理"><a href="#20-2-写数据底层原理" class="headerlink" title="20.2 写数据底层原理"></a>20.2 写数据底层原理</h2><h3 id="20-2-1-写入过程"><a href="#20-2-1-写入过程" class="headerlink" title="20.2.1 写入过程"></a>20.2.1 写入过程</h3><ul><li>数据先写入内存 buffer</li><li><strong>Reflush</strong>:然后每隔 1s，将数据 refresh 到 os cache，到了 os cache 数据就能被搜索到（所以我们才说 es 从写入到能被搜索到，中间有 1s 的延迟）</li><li><strong>每隔 5s，将数据写入 translog 文件</strong>（这样如果机器宕机，内存数据全没，最多会有 5s 的数据丢失）</li><li><strong>Flush:</strong>translog 大到一定程度(512MB)，或者默认每隔 30mins，会触发 commit 操作，将缓冲区的数据都 flush 到 segment file 磁盘文件中。</li></ul><blockquote><p>为什么叫 es 是准实时的？ NRT，全称 near real-time。默认是每隔 1 秒 refresh 一次的，所以 es 是准实时的，因为写入的数据 1 秒之后才能被看</p></blockquote><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/es-write-detail.png" alt=""></p><h3 id="20-2-2-删除过程"><a href="#20-2-2-删除过程" class="headerlink" title="20.2.2 删除过程"></a>20.2.2 删除过程</h3><p>如果是删除操作，<strong>commit 的时候会生成一个 .del 文件</strong>，里面将某个 doc 标识为 deleted 状态，那么搜索的时候根据 .del 文件就知道这个 doc 是否被删除了。</p><h3 id="20-2-3-更新过程"><a href="#20-2-3-更新过程" class="headerlink" title="20.2.3 更新过程"></a>20.2.3 更新过程</h3><p>如果是更新操作，就是将原来的 doc 标识为 deleted 状态，然后新写入一条数据。</p><h3 id="20-2-4-segment-merge"><a href="#20-2-4-segment-merge" class="headerlink" title="20.2.4 segment merge"></a>20.2.4 segment merge</h3><ul><li><strong>buffer 每 refresh 一次，就会产生一个 segment file</strong>，所以默认情况下是 1 秒钟一个 segment file，这样下来 segment file 会越来越多，此时会定期执行 merge。</li><li>每次 merge 的时候，<strong>会将多个 segment file 合并成一个</strong>，<strong>同时这里会将标识为 deleted 的 doc 给物理删除掉</strong>，然后将新的 segment file 写入磁盘，这里会写一个 <strong>commit point</strong>，标识所有新的 segment file，然后打开 segment file 供搜索使用，同时删除旧的 segment file。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Elaticsearch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elaticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>19.ESReindex</title>
      <link href="/2020/04/05/19-ES-Reindex/"/>
      <url>/2020/04/05/19-ES-Reindex/</url>
      
        <content type="html"><![CDATA[<h2 id="19-1-为什么要reindex"><a href="#19-1-为什么要reindex" class="headerlink" title="19.1 为什么要reindex"></a>19.1 为什么要reindex</h2><p>⼀般在以下⼏种情况时，我们需要重建索引:</p><ul><li>索引的 Mappings 发⽣变更：字段类型更改，分词器及字典更新</li><li>索引的 Settings 发⽣变更：索引的主分⽚数发⽣改变</li><li>集群内，集群间需要做数据迁移</li></ul><h2 id="19-2-Reindex-API"><a href="#19-2-Reindex-API" class="headerlink" title="19.2 Reindex API"></a>19.2 Reindex API</h2><ul><li><strong>Reindex API ⽀持把⽂档从⼀个索引拷⻉到另外⼀个索引</strong></li><li><strong>使用是要注意原索引库要有_source字段</strong></li><li><strong>新的索引库要自行将Mapping建好</strong></li></ul><pre><code class="json">POST _reindex{    &quot;source&quot;:{        &quot;index&quot;:&quot;blogs&quot;    },    &quot;dest&quot;:{        &quot;index&quot;:&quot;blogs_fix&quot;    }}</code></pre><h2 id="19-3-Index-alias"><a href="#19-3-Index-alias" class="headerlink" title="19.3 Index alias"></a>19.3 Index alias</h2><p>在前面提到的，<strong>重建索引的问题是必须更新应用中的索引名称</strong>。 </p><p>索引别名就是用来解决这个问题的！</p><p><strong>索引别名</strong> 就像一个快捷方式或软连接，可以指向一个或多个索引，也可以给任何一个需要索引名的API来使用。别名 带给我们极大的灵活性</p><h3 id="19-3-1-创建别名"><a href="#19-3-1-创建别名" class="headerlink" title="19.3.1 创建别名"></a>19.3.1 创建别名</h3><pre><code class="json">POST /_aliases{  &quot;actions&quot;: [    {      &quot;add&quot;: {        &quot;index&quot;: &quot;l1&quot;,        &quot;alias&quot;: &quot;a1&quot;      }    }  ]}</code></pre><h3 id="19-3-2-删除别名"><a href="#19-3-2-删除别名" class="headerlink" title="19.3.2 删除别名"></a>19.3.2 删除别名</h3><pre><code class="json">POST /_aliases{  &quot;actions&quot;: [    {      &quot;remove&quot;: {        &quot;index&quot;: &quot;l1&quot;,        &quot;alias&quot;: &quot;a1&quot;      }    }  ]}</code></pre><h3 id="19-3-3-重命名别名"><a href="#19-3-3-重命名别名" class="headerlink" title="19.3.3 重命名别名"></a>19.3.3 重命名别名</h3><p><strong>reindex时使用！</strong></p><pre><code class="json">POST /_aliases{  &quot;actions&quot;: [    {&quot;remove&quot;: {&quot;index&quot;: &quot;l1&quot;, &quot;alias&quot;: &quot;a1&quot;}},    {&quot;add&quot;: {&quot;index&quot;: &quot;l2&quot;, &quot;alias&quot;: &quot;a1&quot;}}  ]}</code></pre><h3 id="19-3-4-多个索引指向同一别名"><a href="#19-3-4-多个索引指向同一别名" class="headerlink" title="19.3.4 多个索引指向同一别名"></a>19.3.4 多个索引指向同一别名</h3><pre><code class="json">POST /_aliases{  &quot;actions&quot;: [    {&quot;add&quot;: {&quot;index&quot;: &quot;l1&quot;, &quot;alias&quot;: &quot;a1&quot;}},    {&quot;add&quot;: {&quot;index&quot;: &quot;l2&quot;, &quot;alias&quot;: &quot;a1&quot;}},    {&quot;add&quot;: {&quot;index&quot;: &quot;l3&quot;, &quot;alias&quot;: &quot;a1&quot;}}  ]}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Elaticsearch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elaticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>18.ES搜索提示</title>
      <link href="/2020/04/05/18-ES%E6%90%9C%E7%B4%A2%E6%8F%90%E7%A4%BA/"/>
      <url>/2020/04/05/18-ES%E6%90%9C%E7%B4%A2%E6%8F%90%E7%A4%BA/</url>
      
        <content type="html"><![CDATA[<h2 id="18-1-自动补全"><a href="#18-1-自动补全" class="headerlink" title="18.1 自动补全"></a>18.1 自动补全</h2><ul><li><strong>Completion Suggester</strong> 提供了“⾃动完成” (Auto Complete) 的功能。⽤户每输⼊⼀个字符，就需要即时发送⼀个查询请求到后段查找匹配项</li><li>对性能要求⽐较苛刻。Elasticsearch 采⽤了不同的数据结构，并⾮通过倒排索引来完成。⽽是将 Analyze 的数据编码成 FST 和索引⼀起存放。FST 会被 ES 整个加载进内存，速度很快</li><li>FST 只能⽤于前缀查找</li></ul><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/escompletionsugger.png" alt=""></p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/essguuest.png" alt=""></p><h2 id="18-2-基于上下文提示"><a href="#18-2-基于上下文提示" class="headerlink" title="18.2 基于上下文提示"></a>18.2 基于上下文提示</h2><p><strong>使用Context Suggester</strong></p><h2 id="18-3-错误提示"><a href="#18-3-错误提示" class="headerlink" title="18.3 错误提示"></a>18.3 错误提示</h2><p><strong>使用Term &amp; Phrase Suggester</strong></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Elaticsearch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elaticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>17.ES运维</title>
      <link href="/2020/04/05/17-ES%E8%BF%90%E7%BB%B4/"/>
      <url>/2020/04/05/17-ES%E8%BF%90%E7%BB%B4/</url>
      
        <content type="html"><![CDATA[<p>我使用的是阿里云的ES服务,提供智能运维诊断,可以自动进行诊断且给出诊断建议</p><p>如果是自建的ES服务,需要关注以下指标:</p><ul><li><p><strong>慢日志</strong></p></li><li><p><strong>进群状态:red,yellow,green</strong></p></li><li><p><strong>查询的QPS</strong></p></li><li><p><strong>写QPS</strong></p></li><li><p><strong>节点CPU使用率,CPU异常可能的原因:</strong></p><ul><li><strong>监控期间查询QPS或写入QPS流量存在突增或波动比较大的情况</strong></li><li><strong>监控期间存在个别慢查询或慢写入请求</strong></li><li><strong>监控期间该ES集群中存在大量索引或总分片数量非常多</strong></li><li><strong>监控期间在该集群上执行过Merge操作。</strong></li><li><strong>监控期间执行过GC操作</strong></li><li><strong>监控期间执行过定时任务</strong></li></ul></li><li><p><strong>磁盘使用率,建议在75%以下</strong></p></li><li><p><strong>节点HeapMemory使用率</strong></p></li><li><p><strong>节点1分钟内的负载情况</strong></p></li></ul><p><strong>注意:一定要对数据进行备份!</strong></p><p>附可以做的运维监控:</p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/esop.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Elaticsearch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elaticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>16.ES读性能优化</title>
      <link href="/2020/03/05/16-ES%E8%AF%BB%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"/>
      <url>/2020/03/05/16-ES%E8%AF%BB%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/</url>
      
        <content type="html"><![CDATA[<ul><li><strong>加大filesystem cache，写入 es 的数据最好小于等于，或者是略微大于 es 的 filesystem cache 的内存容量。</strong>然后你从 es 检索可能就花费 20ms，然后再根据 es 返回的 id 去 hbase 里查询，查 20 条数据，可能也就耗费个 30ms</li><li><strong>数据预热</strong></li><li><strong>冷热分离</strong>,最好是将冷数据写入一个索引中，然后热数据写入另外一个索引中，这样可以确保热数据在被预热之后，尽量都让他们留在 filesystem os cache 里，别让冷数据给冲刷掉。</li><li><strong>不允许深度分页</strong></li><li><strong>尽量使用 Filter Context，利用缓存机制，减少不必要的算分</strong></li><li><strong>反范式化数据,尽量不要父子文档和nested类型数据</strong></li><li><strong>严禁使用 * 开头通配符 Terms 查询与正则查询</strong></li><li><strong>避免查询是使用脚本,可以在 Index 文档时，使用 Ingest Pipeline，计算并写 入某个字段</strong></li><li><strong>聚合查询会消耗内存，特别是针对很大的数据集进行聚合运算</strong></li><li><strong>避免过度分片,控制单分片尺寸:</strong><ul><li><strong>search类20GB</strong></li><li><strong>Logging类40GB</strong></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Elaticsearch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elaticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>15.ES写性能优化</title>
      <link href="/2020/03/05/15-ES%E5%86%99%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"/>
      <url>/2020/03/05/15-ES%E5%86%99%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/</url>
      
        <content type="html"><![CDATA[<ul><li><strong>增大写吞吐量（Events Per Second），越高越好</strong></li><li><strong>客户端:多线程,批量写</strong></li><li><strong>建立高质量的数据建模,反范式化</strong></li><li><strong>关闭无关的功能:</strong><ul><li><strong>只需要聚合不需要搜索，Index 设置成 false</strong> </li><li><strong>不需要算分，Norms 设置成 false</strong> </li><li><strong>不要对字符串使用默认的 dynamic mapping。字段 数量过多，会对性能产生比较大的影响</strong> </li><li><strong>Index_options 控制在创建倒排索引时，哪些内容 会被添加到倒排索引中。优化这些设置，一定程度 可以节约 CPU</strong> </li><li><strong>指标型数据关闭 _source，减少 IO 操作</strong></li></ul></li><li><strong>降低refresh频率</strong></li><li><strong>降低translog频率</strong></li><li><strong>副本数可以在写入时设置为0,完成后再增加</strong></li></ul>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Elaticsearch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elaticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>14.ES的并发控制</title>
      <link href="/2020/03/04/14-ES%E7%9A%84%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6/"/>
      <url>/2020/03/04/14-ES%E7%9A%84%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<p>两个 Web 程序同时更新某个⽂档，如果缺乏有效的并发，会导致更改的数据丢失</p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/eslock.png" alt=""></p><h2 id="14-1-锁的选择"><a href="#14-1-锁的选择" class="headerlink" title="14.1 锁的选择"></a>14.1 锁的选择</h2><p>ES采用乐观锁实现并发控制</p><h2 id="14-2-具体实现"><a href="#14-2-具体实现" class="headerlink" title="14.2 具体实现"></a>14.2 具体实现</h2><p>ES 中的⽂档是不可变更的。如果你更新⼀个⽂档，会将就⽂档标记为删除，同时增加⼀个全新的⽂档。同时⽂档的 version 字段加 1</p><p>ES实现用两种方式实现乐观锁的CAS机制:</p><ul><li><strong>内部版本控制</strong>:version</li><li><strong>使⽤外部版本(使⽤其他数据库作为主要数据存储)</strong> :version + version_type=external</li></ul><h3 id="14-2-1-内部版本控制"><a href="#14-2-1-内部版本控制" class="headerlink" title="14.2.1 内部版本控制"></a>14.2.1 内部版本控制</h3><pre><code class="json">GET staffs/base/1#获取结果{  &quot;_index&quot;: &quot;staffs&quot;,  &quot;_type&quot;: &quot;base&quot;,  &quot;_id&quot;: &quot;1&quot;,  &quot;_version&quot;: 7,  &quot;found&quot;: true,  &quot;_source&quot;: {    &quot;firstName&quot;: &quot;Song&quot;,    &quot;lastName&quot;: &quot;Gao&quot;,    &quot;age&quot;: 11,    &quot;mobile&quot;: &quot;13888888888&quot;,    &quot;birthday&quot;: &quot;1999-01-01&quot;,    &quot;died&quot;: false,    &quot;province&quot;: &quot;tj&quot;,    &quot;address&quot;: &quot;tj tanggu daliangzi&quot;,    &quot;tags&quot;: [      &quot;yellow&quot;,      &quot;blue&quot;    ],    &quot;tagsCount&quot;: 2  }}# 根据version值进行更新PUT staffs/base/1?version=7{  &quot;firstName&quot;: &quot;Song&quot;,  &quot;lastName&quot;: &quot;Gao&quot;,  &quot;age&quot;: 11,  &quot;mobile&quot;: &quot;13888888888&quot;,  &quot;birthday&quot;: &quot;1999-01-01&quot;,  &quot;died&quot;: false,  &quot;province&quot;: &quot;tj&quot;,  &quot;address&quot;: &quot;tj tanggu daliangzi&quot;,  &quot;tags&quot;: [    &quot;yellow&quot;,    &quot;blue&quot;  ],  &quot;tagsCount&quot;: 2}#获得结果{  &quot;_index&quot;: &quot;staffs&quot;,  &quot;_type&quot;: &quot;base&quot;,  &quot;_id&quot;: &quot;1&quot;,  &quot;_version&quot;: 8,  &quot;result&quot;: &quot;updated&quot;,  &quot;_shards&quot;: {    &quot;total&quot;: 2,    &quot;successful&quot;: 2,    &quot;failed&quot;: 0  },  &quot;_seq_no&quot;: 10,  &quot;_primary_term&quot;: 1}#同版本再次更新PUT staffs/base/1?version=7{  &quot;firstName&quot;: &quot;Song&quot;,  &quot;lastName&quot;: &quot;Gao&quot;,  &quot;age&quot;: 11,  &quot;mobile&quot;: &quot;13888888888&quot;,  &quot;birthday&quot;: &quot;1999-01-01&quot;,  &quot;died&quot;: false,  &quot;province&quot;: &quot;tj&quot;,  &quot;address&quot;: &quot;tj tanggu daliangzi&quot;,  &quot;tags&quot;: [    &quot;yellow&quot;,    &quot;blue&quot;  ],  &quot;tagsCount&quot;: 2}#获得结果{  &quot;error&quot;: {    &quot;root_cause&quot;: [      {        &quot;type&quot;: &quot;version_conflict_engine_exception&quot;,        &quot;reason&quot;: &quot;[base][1]: version conflict, current version [8] is different than the one provided [7]&quot;,        &quot;index_uuid&quot;: &quot;R3L64DNzQjWcdoUo8mLJNw&quot;,        &quot;shard&quot;: &quot;3&quot;,        &quot;index&quot;: &quot;staffs&quot;      }    ],    &quot;type&quot;: &quot;version_conflict_engine_exception&quot;,    &quot;reason&quot;: &quot;[base][1]: version conflict, current version [8] is different than the one provided [7]&quot;,    &quot;index_uuid&quot;: &quot;R3L64DNzQjWcdoUo8mLJNw&quot;,    &quot;shard&quot;: &quot;3&quot;,    &quot;index&quot;: &quot;staffs&quot;  },  &quot;status&quot;: 409}</code></pre><h3 id="14-2-2-外部版本控制"><a href="#14-2-2-外部版本控制" class="headerlink" title="14.2.2 外部版本控制"></a>14.2.2 外部版本控制</h3><ul><li><strong>GET传参多加入version_type=external参数</strong></li><li><strong>此时的version等于外部的版本号</strong></li></ul><pre><code class="json">PUT staffs/base/1?version=3000&amp;version_type=external{  &quot;firstName&quot;: &quot;Song&quot;,  &quot;lastName&quot;: &quot;Gao&quot;,  &quot;age&quot;: 11,  &quot;mobile&quot;: &quot;13888888888&quot;,  &quot;birthday&quot;: &quot;1999-01-01&quot;,  &quot;died&quot;: false,  &quot;province&quot;: &quot;tj&quot;,  &quot;address&quot;: &quot;tj tanggu daliangzi&quot;,  &quot;tags&quot;: [    &quot;yellow&quot;,    &quot;blue&quot;  ],  &quot;tagsCount&quot;: 2}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Elaticsearch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elaticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>13.ES分布式查询及相关性算分</title>
      <link href="/2020/03/04/13-ES%E5%88%86%E5%B8%83%E5%BC%8F%E6%9F%A5%E8%AF%A2%E5%8F%8A%E7%9B%B8%E5%85%B3%E6%80%A7%E7%AE%97%E5%88%86/"/>
      <url>/2020/03/04/13-ES%E5%88%86%E5%B8%83%E5%BC%8F%E6%9F%A5%E8%AF%A2%E5%8F%8A%E7%9B%B8%E5%85%B3%E6%80%A7%E7%AE%97%E5%88%86/</url>
      
        <content type="html"><![CDATA[<h2 id="13-1-分布式搜索的运行机制"><a href="#13-1-分布式搜索的运行机制" class="headerlink" title="13.1 分布式搜索的运行机制"></a>13.1 分布式搜索的运行机制</h2><p>ES的搜索会分两个阶段进行:</p><ul><li>第一阶段－－Query</li><li>第二阶段－－Fetch</li></ul><p>因此我们称ES的搜索运行机制为 <strong>Query-Then-Fetch</strong></p><h2 id="13-2-Query阶段"><a href="#13-2-Query阶段" class="headerlink" title="13.2 Query阶段"></a>13.2 Query阶段</h2><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/esquery.png" alt=""></p><h2 id="13-3-Fetch阶段"><a href="#13-3-Fetch阶段" class="headerlink" title="13.3  Fetch阶段"></a>13.3  Fetch阶段</h2><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/esfetch.png" alt=""></p><h2 id="13-4-Query-Then-Fetch-潜在的问题"><a href="#13-4-Query-Then-Fetch-潜在的问题" class="headerlink" title="13.4 Query Then Fetch 潜在的问题"></a>13.4 Query Then Fetch 潜在的问题</h2><h3 id="13-4-1-深度分页"><a href="#13-4-1-深度分页" class="headerlink" title="13.4.1 深度分页"></a>13.4.1 深度分页</h3><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/esfromsize.png" alt=""></p><ul><li><strong>每个分片上需要查的文档个数=from + size</strong></li><li><strong>最终协调节点需要处理：number_of_shard * ( from+size )</strong></li><li><strong>导致深度分页</strong></li></ul><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/esdeep.png" alt=""></p><h3 id="13-4-2-相关性算分"><a href="#13-4-2-相关性算分" class="headerlink" title="13.4.2 相关性算分"></a>13.4.2 相关性算分</h3><p><strong>每个分片都基于自己的分片上的数据进行相关度计算</strong>。</p><p>这会导致打分偏离的情况，特别是数据量很少时。相关性算分在分片之间是相互独立。当文档总数很少的情况下，如果主分片大于1,主分片数越多，相关性算分会越不准</p><h2 id="13-5-解决问题"><a href="#13-5-解决问题" class="headerlink" title="13.5 解决问题"></a>13.5 解决问题</h2><h3 id="13-4-1-深度分页-1"><a href="#13-4-1-深度分页-1" class="headerlink" title="13.4.1 深度分页"></a>13.4.1 深度分页</h3><p>使用search_after或scroll api来避免深度分页问题</p><p>思想都是:</p><ul><li><strong>可以实时获取下⼀⻚⽂档信息</strong></li><li><strong>不⽀持指定⻚数（From）</strong></li><li><strong>只能往下翻</strong></li></ul><h4 id="13-4-1-1-search-after"><a href="#13-4-1-1-search-after" class="headerlink" title="13.4.1.1 search after"></a>13.4.1.1 search after</h4><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/essearchafter.png" alt=""></p><pre><code class="json">#第一次取GET staffs/base/_search{  &quot;query&quot;: {      &quot;match_all&quot;: {}  },  &quot;size&quot;: 1,  &quot;sort&quot;: [    {      &quot;age&quot;: {        &quot;order&quot;: &quot;desc&quot;      },      &quot;_id&quot;:{        &quot;order&quot;: &quot;desc&quot;      }    }  ]}## 获取到sort数组{  &quot;took&quot;: 3,  &quot;timed_out&quot;: false,  &quot;_shards&quot;: {    &quot;total&quot;: 5,    &quot;successful&quot;: 5,    &quot;skipped&quot;: 0,    &quot;failed&quot;: 0  },  &quot;hits&quot;: {    &quot;total&quot;: 8,    &quot;max_score&quot;: null,    &quot;hits&quot;: [      {        &quot;_index&quot;: &quot;staffs&quot;,        &quot;_type&quot;: &quot;base&quot;,        &quot;_id&quot;: &quot;6&quot;,        &quot;_score&quot;: null,        &quot;_source&quot;: {          &quot;firstName&quot;: &quot;MML&quot;,          &quot;lastName&quot;: &quot;ZLA&quot;,          &quot;age&quot;: 88,          &quot;mobile&quot;: &quot;23688885589&quot;,          &quot;birthday&quot;: &quot;1944-01-02&quot;,          &quot;died&quot;: false,          &quot;province&quot;: &quot;sh&quot;,          &quot;address&quot;: &quot;zn minghanglu  aaa  daliangzi&quot;        },        &quot;sort&quot;: [          88,          &quot;6&quot;        ]      }    ]  }}## 根据sort数组里面的值　使用search after查询GET staffs/base/_search{  &quot;query&quot;: {      &quot;match_all&quot;: {}  },  &quot;size&quot;: 1,  &quot;search_after&quot;:[88,&quot;6&quot;],  &quot;sort&quot;: [    {      &quot;age&quot;: {        &quot;order&quot;: &quot;desc&quot;      },      &quot;_id&quot;:{        &quot;order&quot;: &quot;desc&quot;      }    }  ]}</code></pre><h4 id="13-4-1-2-scroll-API"><a href="#13-4-1-2-scroll-API" class="headerlink" title="13.4.1.2 scroll API"></a>13.4.1.2 scroll API</h4><ul><li><strong>创建一个快照，有新的数据写入以后，无法被查到</strong></li><li>每次查询后，输入上一次的Scroll Id</li></ul><pre><code class="json">#先获取到scroll_id#scroll=5m含义:将快照保留5minGET staffs/base/_search?scroll=5m{  &quot;size&quot;: 2,  &quot;query&quot;: {    &quot;match_all&quot;: {}  }}#根据scroll_id获取信息#注意每次返回的size等于第一次查询的时候指定的size#scroll:1m 表明快照再延续保留1minGET _search/scroll{  &quot;scroll&quot;:&quot;1m&quot;,  &quot;scroll_id&quot;: &quot;DnF1ZXJ5VGhlbkZldGNoBQAAAAAAAKo3Fk1mWktWa0ViVHh1OEcyZTE1eVF2MUEAAAAAAACqNhZNZlpLVmtFYlR4dThHMmUxNXlRdjFBAAAAAAAAqjkWTWZaS1ZrRWJUeHU4RzJlMTV5UXYxQQAAAAAAAKo4Fk1mWktWa0ViVHh1OEcyZTE1eVF2MUEAAAAAAACqOhZNZlpLVmtFYlR4dThHMmUxNXlRdjFB&quot;}</code></pre><h4 id="13-4-1-3-scroll-api和search-after的区别"><a href="#13-4-1-3-scroll-api和search-after的区别" class="headerlink" title="13.4.1.3 scroll api和search after的区别"></a>13.4.1.3 scroll api和search after的区别</h4><ul><li><strong>search after可以实时获取下一页文档信息</strong></li><li><strong>scroll 是从快照信息中获取数据</strong></li></ul><h3 id="13-4-2-相关性算分-1"><a href="#13-4-2-相关性算分-1" class="headerlink" title="13.4.2 相关性算分"></a>13.4.2 相关性算分</h3><ul><li>数据量不⼤的时候，可以将<strong>主分⽚数设置为 1</strong> </li><li>当数据量⾜够⼤时候，<strong>只要保证⽂档均匀分散在各个分⽚上</strong>，结果⼀般就不会出现偏差</li></ul>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Elaticsearch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elaticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>12.ES查询</title>
      <link href="/2020/03/04/12-ES%E5%9F%BA%E6%9C%AC%E6%A3%80%E7%B4%A2%E7%B1%BB%E5%9E%8B/"/>
      <url>/2020/03/04/12-ES%E5%9F%BA%E6%9C%AC%E6%A3%80%E7%B4%A2%E7%B1%BB%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<h2 id="12-1-检索和过滤"><a href="#12-1-检索和过滤" class="headerlink" title="12.1 检索和过滤"></a>12.1 检索和过滤</h2><h3 id="12-1-1-检索和过滤的区别"><a href="#12-1-1-检索和过滤的区别" class="headerlink" title="12.1.1 检索和过滤的区别"></a>12.1.1 检索和过滤的区别</h3><ul><li><strong>query</strong>：查询操作不仅仅会进行查询，还会计算分值，用于确定相关度；</li><li><strong>filter</strong>：查询操作仅判断是否满足查询条件，不会计算得分，查询的结果可以被缓存。</li></ul><h3 id="12-1-2-检索和过滤的适用场景"><a href="#12-1-2-检索和过滤的适用场景" class="headerlink" title="12.1.2 检索和过滤的适用场景"></a>12.1.2 检索和过滤的适用场景</h3><ul><li>全文检索以及任何使用相关性评分的场景使用query检索。</li><li>除此之外的其他使用filter过滤器过滤。</li></ul><h2 id="12-2-结构化检索"><a href="#12-2-结构化检索" class="headerlink" title="12.2 结构化检索"></a>12.2 结构化检索</h2><h3 id="12-2-1-精确匹配检索"><a href="#12-2-1-精确匹配检索" class="headerlink" title="12.2.1 精确匹配检索"></a>12.2.1 精确匹配检索</h3><ul><li><strong>term 单值精确匹配</strong></li><li><strong>terms多值精确匹配</strong></li></ul><p>Term 查询，对输⼊不做分词。会将输⼊作为⼀个整体，在倒排索引中查找准确的词项，并且使⽤相关度算分公式为<strong>每个包含该词项的⽂档</strong>进⾏相关度算分</p><pre><code class="json">#search address contains &quot;zn&quot;GET staffs/base/_search{  &quot;query&quot;: {    &quot;term&quot;: {      &quot;address&quot;: {        &quot;value&quot;: &quot;zn&quot;      }    }  }}#search tags contains &quot;yellow&quot; or &quot;red&quot;GET staffs/base/_search{  &quot;query&quot;: {    &quot;constant_score&quot;: {      &quot;filter&quot;: {        &quot;terms&quot;: {          &quot;tags&quot;: [            &quot;yellow&quot;,            &quot;red&quot;          ]        }      }    }  }}</code></pre><h3 id="12-2-2-范围检索"><a href="#12-2-2-范围检索" class="headerlink" title="12.2.2 范围检索"></a>12.2.2 范围检索</h3><ul><li><strong>关键字 range</strong></li><li>gt大于,lt小于,gte大于等于,Ite小于等于</li></ul><pre><code class="json">GET  staffs/base/_search{  &quot;query&quot;: {    &quot;constant_score&quot;: {      &quot;filter&quot;: {        &quot;range&quot;: {          &quot;age&quot;: {            &quot;gte&quot;: 10,            &quot;lte&quot;: 20          }        }      }    }  }}</code></pre><h3 id="12-2-3-存在与否检索"><a href="#12-2-3-存在与否检索" class="headerlink" title="12.2.3 存在与否检索"></a>12.2.3 存在与否检索</h3><ul><li><strong>关键字 exist</strong></li></ul><pre><code class="json"># existGET staffs/base/_search{  &quot;query&quot;: {    &quot;constant_score&quot;: {      &quot;filter&quot;: {        &quot;exists&quot;: {          &quot;field&quot;: &quot;mobile&quot;        }      }    }  }}# not exist#注意是返回mobile字段不存在的doc#不包含doc中mobile为空的GET staffs/base/_search{  &quot;query&quot;: {    &quot;constant_score&quot;: {      &quot;filter&quot;: {        &quot;bool&quot;: {          &quot;must_not&quot;:{            &quot;exists&quot;:{              &quot;field&quot;:&quot;mobile&quot;            }          }        }      }    }  }}</code></pre><h3 id="12-2-4-前缀检索"><a href="#12-2-4-前缀检索" class="headerlink" title="12.2.4 前缀检索"></a>12.2.4 前缀检索</h3><ul><li><strong>关键字prefix</strong></li></ul><pre><code class="json">#查询address以zn开头的数据GET staffs/base/_search{  &quot;query&quot;: {    &quot;prefix&quot;: {      &quot;address&quot;: {        &quot;value&quot;: &quot;zn&quot;      }    }  }}</code></pre><h3 id="12-2-5-通配符模糊检索"><a href="#12-2-5-通配符模糊检索" class="headerlink" title="12.2.5 通配符模糊检索"></a>12.2.5 通配符模糊检索</h3><ul><li><strong>关键字wildcard</strong></li><li>通配符*匹配任意字符（包含空字符）,通配符？匹配任何单个字符。</li><li><strong>注意这个査询可能会比较缓慢，需要在许多索引词上面重复执行。为了避免极端缓慢的通配符査询，通配符索引词不应该以一个通配符开头</strong></li></ul><pre><code class="json">GET staffs/base/_search{  &quot;query&quot;: {    &quot;wildcard&quot;: {      &quot;mobile&quot;: {        &quot;value&quot;: &quot;138*8&quot;      }    }  }}</code></pre><h3 id="12-2-6-正则检索"><a href="#12-2-6-正则检索" class="headerlink" title="12.2.6 正则检索"></a>12.2.6 正则检索</h3><ul><li><strong>关键字regexp</strong></li></ul><pre><code class="json">GET staffs/base/_search{  &quot;query&quot;: {    &quot;regexp&quot;:{      &quot;mobile&quot;:&quot;13[0-9]{9}&quot;    }  }}</code></pre><h3 id="12-2-7-模糊检索"><a href="#12-2-7-模糊检索" class="headerlink" title="12.2.7 模糊检索"></a>12.2.7 模糊检索</h3><ul><li><strong>关键字fuzzy</strong></li></ul><pre><code class="jso">GET staffs/base/_search{  &quot;query&quot;: {    &quot;fuzzy&quot;: {      &quot;address&quot;: {        &quot;value&quot;: &quot;aaa&quot;,        &quot;fuzziness&quot;: 0.5,        &quot;prefix_length&quot;: 0,        &quot;max_expansions&quot;:10      }    }  }}</code></pre><h3 id="12-2-8-主键检索"><a href="#12-2-8-主键检索" class="headerlink" title="12.2.8 主键检索"></a>12.2.8 主键检索</h3><ul><li><strong>关键字ids</strong></li></ul><pre><code class="json">GET staffs/base/_search{  &quot;query&quot;: {    &quot;ids&quot;:{      &quot;values&quot;:[&quot;1&quot;,&quot;2&quot;]    }  }}</code></pre><h2 id="12-3-全文检索"><a href="#12-3-全文检索" class="headerlink" title="12.3 全文检索"></a>12.3 全文检索</h2><h3 id="12-3-1-分词全文检索"><a href="#12-3-1-分词全文检索" class="headerlink" title="12.3.1 分词全文检索"></a>12.3.1 分词全文检索</h3><ul><li><strong>关键字match</strong></li><li>会将query里面的单词进行分词,然后默认or操作搜索</li></ul><pre><code class="json">GET staffs/base/_search{  &quot;query&quot;: {    &quot;match&quot;: {      &quot;address&quot;: {        &quot;query&quot;: &quot;zn daliangzi aaa&quot;      }    }  }}#address中最少应该包含&quot;zn&quot;,&quot;daliangzi&quot;,&quot;aaa&quot;中的两个GET staffs/base/_search{  &quot;query&quot;: {    &quot;match&quot;: {      &quot;address&quot;: {        &quot;query&quot;: &quot;zn daliangzi aaa&quot;,        &quot;minimum_should_match&quot;:2      }    }  }}#change match query operator to andGET staffs/base/_search{  &quot;query&quot;: {    &quot;match&quot;: {      &quot;address&quot;:{         &quot;query&quot;: &quot;zn daliangzi&quot;,        &quot;operator&quot;: &quot;AND&quot;      }    }  }}</code></pre><h3 id="12-3-2-短语检索"><a href="#12-3-2-短语检索" class="headerlink" title="12.3.2 短语检索"></a>12.3.2 短语检索</h3><ul><li><strong>关键字match_phrase</strong></li><li>不将query中的单词进行分词,按照一个整体进行搜索</li><li><strong>slop</strong> 搜索的单词之间最多可以隔几个单词</li></ul><pre><code class="json">GET staffs/base/_search{  &quot;query&quot;: {    &quot;match_phrase&quot;: {      &quot;address&quot;:{        &quot;query&quot;: &quot;zn aaa&quot;      }    }  }}GET staffs/base/_search{  &quot;query&quot;: {    &quot;match_phrase&quot;: {      &quot;address&quot;:{        &quot;query&quot;: &quot;zn aaa&quot;,        &quot;slop&quot;:1      }    }  }}</code></pre><h3 id="12-3-3-短语前缀检索"><a href="#12-3-3-短语前缀检索" class="headerlink" title="12.3.3 短语前缀检索"></a>12.3.3 短语前缀检索</h3><ul><li><strong>关键字match_phrase_prefix</strong></li></ul><pre><code class="json"># 可以匹配:# zn minaaa# zn minbbb# zn mincccGET staffs/base/_search{  &quot;query&quot;: {    &quot;match_phrase_prefix&quot;: {      &quot;address&quot;: &quot;zn min&quot;    }  }}</code></pre><h3 id="12-3-4-多字段匹配检索"><a href="#12-3-4-多字段匹配检索" class="headerlink" title="12.3.4 多字段匹配检索"></a>12.3.4 多字段匹配检索</h3><ul><li><strong>关键字multi_match</strong></li></ul><h4 id="12-3-4-1-三种场景"><a href="#12-3-4-1-三种场景" class="headerlink" title="12.3.4.1 三种场景"></a>12.3.4.1 三种场景</h4><ol><li><strong>最佳字段(Best Fields)</strong>:当字段之间相互竞争，又相互关联。例如title和body这样的字段。评分来自最匹配字段</li><li><strong>多数字段(Most Fields)</strong>:处理英文内容时：一种常见的手段是，在主字English Analyzer),抽取词干，加入同义词，以匹配更多的文档。相同的文本，加入子字段(Standard Analyzer),以提供更加精确的匹配。其他字段作为匹配文档提高相关度的信号。匹配字段越多则越好</li><li><strong>混合字段(Cross Field)</strong>:对于某些实体，例如人名，地址，图书信息。需要在多个字段中确定信息，单个字段只能作为整体的一部分。希望在任何这些列出的字段中找到尽可能多的词</li></ol><h4 id="12-3-4-2-demo"><a href="#12-3-4-2-demo" class="headerlink" title="12.3.4.2 demo"></a>12.3.4.2 demo</h4><pre><code class="json">//adress或者province里包含zn 按照这两个字段中分数高的一个字段排序GET staffs/base/_search{  &quot;query&quot;: {    &quot;multi_match&quot;: {      &quot;query&quot;: &quot;zn&quot;,      &quot;fields&quot;: [&quot;address&quot;,&quot;province&quot;],      &quot;type&quot;:&quot;best_fields&quot;    }  }}//adress或者province里包含zn或sh 按照这两个字段的分数和排序GET staffs/base/_search{  &quot;query&quot;: {    &quot;multi_match&quot;: {      &quot;query&quot;: &quot;zn sh&quot;,      &quot;fields&quot;: [&quot;address&quot;,&quot;province&quot;],      &quot;type&quot;:&quot;most_fields&quot;    }  }}//adress和province里　总共包含zn和sh//按照这两个字段的分数和排序GET staffs/base/_search{  &quot;query&quot;: {    &quot;multi_match&quot;: {      &quot;query&quot;: &quot;zn sh&quot;,      &quot;fields&quot;: [&quot;address&quot;,&quot;province&quot;],      &quot;type&quot;:&quot;cross_fields&quot;,      &quot;operator&quot;:&quot;AND&quot;    }  }}</code></pre><h3 id="12-3-5-支持与或非字符串检索"><a href="#12-3-5-支持与或非字符串检索" class="headerlink" title="12.3.5 支持与或非字符串检索"></a>12.3.5 支持与或非字符串检索</h3><ul><li><strong>关键字query string</strong></li><li>可以添加 AND/OR查询条件</li><li>支持多字段查询</li></ul><pre><code class="json">GET staffs/base/_search{  &quot;query&quot;: {    &quot;query_string&quot;: {      &quot;query&quot;: &quot;MML OR Song&quot;,      &quot;fields&quot;: [&quot;firstName&quot;,&quot;lastName&quot;]    }  }}</code></pre><h3 id="12-3-6-简化的字符串检索"><a href="#12-3-6-简化的字符串检索" class="headerlink" title="12.3.6 简化的字符串检索"></a>12.3.6 简化的字符串检索</h3><ul><li><strong>关键字simple_query_string</strong></li><li>类似 Query String , 但是会忽略错误的语法同时只支持部分查询语句</li><li>不支持 AND OR NOT , 但会当作字符串处理</li><li>Term 之间默认的关系是 OR, 可以指定 default_operator</li></ul><pre><code class="json">GET staffs/base/_search{  &quot;query&quot;: {    &quot;simple_query_string&quot;: {      &quot;query&quot;: &quot;MML Song&quot;,      &quot;default_operator&quot;: &quot;AND&quot;,       &quot;fields&quot;: [&quot;firstName&quot;,&quot;lastName&quot;]    }  }}</code></pre><h2 id="12-4-复合检索"><a href="#12-4-复合检索" class="headerlink" title="12.4 复合检索"></a>12.4 复合检索</h2><h3 id="12-4-1-固定得分检索"><a href="#12-4-1-固定得分检索" class="headerlink" title="12.4.1 固定得分检索"></a>12.4.1 固定得分检索</h3><ul><li><strong>关键字constant_score</strong> </li><li>Wraps a filter query and returns every matching document with a relevance score equal to the boost parameter value.</li></ul><pre><code class="json">GET /_search{    &quot;query&quot;: {        &quot;constant_score&quot; : {            &quot;filter&quot; : {                &quot;term&quot; : { &quot;user&quot; : &quot;kimchy&quot;}            },            &quot;boost&quot; : 1.2        }    }}</code></pre><h3 id="12-4-2-bool组合检索"><a href="#12-4-2-bool组合检索" class="headerlink" title="12.4.2 bool组合检索"></a>12.4.2 bool组合检索</h3><p>一个bool查询，是一个或者多个查询子句的组合,总共包括4种子句</p><ul><li><strong>must</strong>:必须匹配。贡献算</li><li><strong>should</strong>:选择性匹配。贡献算分</li><li><strong>must_not</strong>:Filter Context 查询字句，必须不能匹配</li><li><strong>filter</strong>:Filter Context 必须匹配，但是不贡献算分</li></ul><pre><code class="json">GET staffs/base/_search{  &quot;query&quot;: {    &quot;bool&quot;: {      &quot;should&quot;: [        {&quot;term&quot;:{&quot;age&quot;: {&quot;value&quot;: &quot;18&quot;}}},        {&quot;term&quot;: {&quot;age&quot;: {&quot;value&quot;: &quot;88&quot;}}}      ],      &quot;must&quot;: [        {&quot;term&quot;: {&quot;tags&quot;: &quot;yellow&quot;}},        {&quot;term&quot;: {&quot;tagsCount&quot;:1}}      ]    }  }}GET staffs/base/_search{    &quot;query&quot;: {    &quot;bool&quot;: {      &quot;should&quot;: [        {&quot;term&quot;:{&quot;age&quot;: {&quot;value&quot;: &quot;18&quot;}}},        {&quot;term&quot;: {&quot;age&quot;: {&quot;value&quot;: &quot;88&quot;}}}      ],      &quot;must_not&quot;: [        {&quot;term&quot;: {&quot;tags&quot;: &quot;yellow&quot;}},        {&quot;term&quot;: {&quot;tagsCount&quot;:2}}      ],      &quot;filter&quot;: {        &quot;term&quot;: {          &quot;province&quot;: &quot;sh&quot;        }      }    }  }}GET staffs/base/_search{  &quot;query&quot;: {    &quot;bool&quot;: {      &quot;should&quot;: [        {&quot;term&quot;: {          &quot;province&quot;: {            &quot;value&quot;: &quot;zn&quot;          }        }},        {          &quot;term&quot;: {            &quot;address&quot;: {              &quot;value&quot;: &quot;zn&quot;            }          }        }      ]    }  }}#将评分最⾼的字段评分作为结果返回，满⾜两个字段是竞争关系的场景GET staffs/base/_search{  &quot;query&quot;: {    &quot;dis_max&quot;: {      &quot;queries&quot;: [        {&quot;match&quot;: {&quot;province&quot;: &quot;zn&quot;}},        {&quot;match&quot;: {&quot;address&quot;: &quot;zn&quot;}}      ],      &quot;tie_breaker&quot;: 0.2    }  }}</code></pre><h3 id="12-4-3-改变评分检索"><a href="#12-4-3-改变评分检索" class="headerlink" title="12.4.3 改变评分检索"></a>12.4.3 改变评分检索</h3><h4 id="12-4-3-1-boosting-query"><a href="#12-4-3-1-boosting-query" class="headerlink" title="12.4.3.1 boosting query"></a>12.4.3.1 boosting query</h4><ul><li><p><strong>关键字boosting</strong></p></li><li><p><strong>positive</strong>:(Required, query object) Query you wish to run. Any returned documents must match this query.</p></li><li><p><strong>negative</strong>:(Required, query object) Query used to decrease the relevance score of matching documents.If a returned document matches the positive query and this query, the boosting query calculates the final relevance score for the document as follows:</p><ul><li><p>Take the original relevance score from the positive query.</p></li><li><p>Multiply the score by the negative_boost value.</p></li></ul></li><li><p><strong>negative_boost</strong>:(Required, float) Floating point number between 0 and 1.0 used to decrease the relevance scores of documents matching the negative query.</p></li></ul><pre><code class="demo">GET /_search{    &quot;query&quot;: {        &quot;boosting&quot; : {            &quot;positive&quot; : {                &quot;term&quot; : {                    &quot;text&quot; : &quot;apple&quot;                }            },            &quot;negative&quot; : {                 &quot;term&quot; : {                     &quot;text&quot; : &quot;pie tart fruit crumble tree&quot;                }            },            &quot;negative_boost&quot; : 0.5        }    }}</code></pre><h4 id="12-4-3-2-dis-max-query"><a href="#12-4-3-2-dis-max-query" class="headerlink" title="12.4.3.2 dis max query"></a>12.4.3.2 dis max query</h4><ul><li><strong>关键字dis_max</strong></li><li>获得<strong>最佳匹配语句的评分</strong></li><li>将<strong>其他匹配语句的评分与tie_breaker相乘</strong></li><li>对以上评分<strong>求和</strong></li></ul><pre><code class="json">GET staffs/base/_search{  &quot;query&quot;: {    &quot;dis_max&quot;: {      &quot;tie_breaker&quot;: 0.7,      &quot;boost&quot;: 1.2,      &quot;queries&quot;: [        {&quot;match&quot;: {&quot;address&quot;: &quot;zn&quot;}},        {&quot;match&quot;: {&quot;province&quot;: &quot;zn&quot;}}      ]    }  }}</code></pre><h4 id="12-4-3-3-function-scoring-query"><a href="#12-4-3-3-function-scoring-query" class="headerlink" title="12.4.3.3 function scoring query"></a>12.4.3.3 function scoring query</h4><ul><li><strong>Function Score Query</strong>:可以在查询结束后，对每⼀个匹配的⽂档进⾏⼀系列的重新算分，根据新⽣成的分数进⾏排序。</li><li>提供了⼏种默认的计算分值的函<ul><li>Weight ：为每⼀个⽂档设置⼀个简单⽽不被规范化的权重</li><li>Field Value Factor：使⽤该数值来修改 _score，例如将 “热度”和“点赞数”作为算分的参考因素</li><li>Random Score：为每⼀个⽤户使⽤⼀个不同的，随机算分结果</li><li>衰减函数： 以某个字段的值为标准，距离某个值越近，得分越⾼</li><li>Script Score：⾃定义脚本完全控制所需逻辑</li></ul></li></ul><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/essearch1.png" alt=""><br><img src="http://dist415.oss-cn-beijing.aliyuncs.com/essearch2.png" alt=""><br><img src="http://dist415.oss-cn-beijing.aliyuncs.com/essearch3.png" alt=""><br><img src="http://dist415.oss-cn-beijing.aliyuncs.com/essearch4.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Elaticsearch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elaticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>11.ES集群规划</title>
      <link href="/2020/03/04/11-ES%E9%9B%86%E7%BE%A4%E8%A7%84%E5%88%92/"/>
      <url>/2020/03/04/11-ES%E9%9B%86%E7%BE%A4%E8%A7%84%E5%88%92/</url>
      
        <content type="html"><![CDATA[<h2 id="11-1-分片"><a href="#11-1-分片" class="headerlink" title="11.1 分片"></a>11.1 分片</h2><h3 id="11-1-1-如何确定主分片数"><a href="#11-1-1-如何确定主分片数" class="headerlink" title="11.1.1 如何确定主分片数"></a>11.1.1 如何确定主分片数</h3><ul><li><p>从存储的物理角度看</p><ul><li><p>日志类应用，单个分片不要大于50 GB</p></li><li><p>搜索类应用，单个分片不要超过20 GB</p></li></ul></li><li><p>为什么要控制分片存储大小</p><ul><li>提高Update的性能</li><li>Merge时，减少所需的资源</li><li>丢失节点后，具备更快的恢复速度/便于分片在集群内Rebalancing</li></ul></li></ul><h3 id="11-1-2-如何确定副本分片数"><a href="#11-1-2-如何确定副本分片数" class="headerlink" title="11.1.2 如何确定副本分片数"></a>11.1.2 如何确定副本分片数</h3><ul><li><p>副本是主分片的拷贝</p><ul><li><p>提高系统可用性：相应査询请求，防止数据丢失</p></li><li><p>需要占用和主分片一样的资源</p></li></ul></li><li><p>对性能的影响</p><ul><li>副本会降低数据的索引速度：有几份副本就会有几倍的CPU资源消耗在索引上</li><li>会减缓对主分片的査询压力，但是会消耗同样的内存资源<ul><li>如果机器资源充分，提高副本数，可以提高整体的査询QPS</li></ul></li></ul></li></ul><h2 id="11-2-硬件配置"><a href="#11-2-硬件配置" class="headerlink" title="11.2 硬件配置"></a>11.2 硬件配置</h2><ul><li><p>选择合理的硬件，数据节点尽可能使用SSD</p></li><li><p>搜索等性能要求高的场景，建议SSD</p><ul><li><strong>按照1 ： 10的比例配置内存和硬盘</strong></li></ul></li><li><p>日志类和查询并发低的场景，可以考虑使用机械硬盘存储</p><ul><li><strong>按照1： 50的比例配置内存和硬盘</strong></li></ul></li><li><p>单节点数据建议控制在2TB以内，最大不建议超过5TB</p></li><li><p>JVM配置机器内存的一半，JVM内存配置不建议超过32G</p></li></ul><h2 id="11-3-部署方式"><a href="#11-3-部署方式" class="headerlink" title="11.3 部署方式"></a>11.3 部署方式</h2><ul><li>按需选择合理的部署方式，线上定要选择集群模式</li><li>如果需要考虑可靠性高可用，建议<strong>部署3台以上的dedicated的Master节点</strong></li><li>如果有复杂的查询和聚合，建议设置Coordinating节点</li></ul><h2 id="11-4-JVM设定"><a href="#11-4-JVM设定" class="headerlink" title="11.4 JVM设定"></a>11.4 JVM设定</h2><ul><li><p>从ES 6开始，只支持64位的JVM</p><ul><li>配置 config / jvm. options</li></ul></li><li><p>避免修改默认配置</p><ul><li>将内存Xms和Xmx设置成一样，避免heap resize时引发停顿</li><li>Xmx设置不要超过物理内存的50%；单个节点上，最大内存建议不要超过32 G内存</li><li>生产环境，JVM必须使用Server模式</li><li>关闭 JVM Swapping</li></ul></li></ul><h2 id="11-5-内存设定计算实例"><a href="#11-5-内存设定计算实例" class="headerlink" title="11.5 内存设定计算实例"></a>11.5 内存设定计算实例</h2><ul><li><p>内存大小要根据 Node 需要存储的数据来进行估算  </p><ul><li><p>搜索类的比例建议：1:16 </p></li><li><p>日志类： 1:48 - 1:96 之间 </p></li></ul></li><li><p>总数据量 1T， 设置一个副本 = 2T 总数据量 </p><ul><li>一台机器假设总内存为32G,可用内存为31G</li><li>如果搜索类的项目，每个节点 <code>31 *16 = 496G</code>，加上预留空间。所以每个节点最多 400 G 数据，至少需 要 5 个数据节点 </li><li>如果是日志类项目，每个节点 <code>31*50 = 1550GB</code>，2 个数据节点 即可</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Elaticsearch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elaticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>10.ES集群再进阶</title>
      <link href="/2020/03/04/10-ES%E9%9B%86%E7%BE%A4%E5%86%8D%E8%BF%9B%E9%98%B6/"/>
      <url>/2020/03/04/10-ES%E9%9B%86%E7%BE%A4%E5%86%8D%E8%BF%9B%E9%98%B6/</url>
      
        <content type="html"><![CDATA[<h2 id="10-1-Hot-amp-Warm-Architecture"><a href="#10-1-Hot-amp-Warm-Architecture" class="headerlink" title="10.1 Hot &amp; Warm Architecture"></a>10.1 Hot &amp; Warm Architecture</h2><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/eshotwarm.png" alt=""></p><h3 id="10-1-1-什么是-Hot-amp-Warm-Architecture"><a href="#10-1-1-什么是-Hot-amp-Warm-Architecture" class="headerlink" title="10.1.1 什么是 Hot &amp; Warm Architecture"></a>10.1.1 什么是 Hot &amp; Warm Architecture</h3><p>传统的Elasticsearch集群中所有节点均采用相同的配置，然而Elasticsearch并没有对节点的规格一致性做要求，换而言之就是每个节点可以是任意规格，当然这样做会导致集群各节点性能不一致，影响集群稳定性。但是如果有规则的将集群的节点分成不同类型，部分是高性能的节点用于存储热点数据，部分是性能相对差些的大容量节点用于存储冷数据，却可以一方面保证热数据的性能，另一方面保证冷数据的存储，降低存储成本，这也是Elasticsearch冷热分离架构的基本思想</p><h2 id="10-1-2-Node分类"><a href="#10-1-2-Node分类" class="headerlink" title="10.1.2 Node分类"></a>10.1.2 Node分类</h2><ul><li><strong>Hot节点</strong>（通常使用SSD）:索引有不断有新文档写入。通常使用SSD</li><li><strong>Wann节点</strong>（通常使用HDD）:索引不存在新数据的写入；同时也不存在大量的数据査询</li></ul><h3 id="10-1-3-配置"><a href="#10-1-3-配置" class="headerlink" title="10.1.3 配置"></a>10.1.3 配置</h3><p><strong>使用Shard Filtering</strong>,步骤分为以下几步</p><ol><li>标记节点（Tagging）</li><li>配置索引到Hot Node</li><li>配置索引到Warm节点</li></ol><h4 id="10-1-3-1-标记节点"><a href="#10-1-3-1-标记节点" class="headerlink" title="10.1.3.1 标记节点"></a>10.1.3.1 标记节点</h4><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/essign.png" alt=""></p><h4 id="10-1-3-2-配置索引到Hot-Node"><a href="#10-1-3-2-配置索引到Hot-Node" class="headerlink" title="10.1.3.2 配置索引到Hot Node"></a>10.1.3.2 配置索引到Hot Node</h4><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/essignhot.png" alt=""></p><h4 id="10-1-3-3-配置索引到Warm节点"><a href="#10-1-3-3-配置索引到Warm节点" class="headerlink" title="10.1.3.3 配置索引到Warm节点"></a>10.1.3.3 配置索引到Warm节点</h4><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/essignwarm.png" alt=""></p><h2 id="10-2-Rack-Awareness"><a href="#10-2-Rack-Awareness" class="headerlink" title="10.2 Rack Awareness"></a>10.2 Rack Awareness</h2><ul><li>ES的节点可能分布在不同的机架</li><li>当一个机架断电，可能会同时丢失几个节点</li><li>如果一个索引相同的主分片和副本分片，同时在这个机架上，就有可能导致数据的丢失</li><li>通过Rack Awareness的机制，就可以尽可能避免将同一个索引的主副分片同时分配在一个机架的节点上</li></ul><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/esrock.png" alt=""></p><h3 id="10-2-1标记-Rack-节点-配置集群"><a href="#10-2-1标记-Rack-节点-配置集群" class="headerlink" title="10.2.1标记 Rack 节点 + 配置集群"></a>10.2.1标记 Rack 节点 + 配置集群</h3><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/esrocksign.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Elaticsearch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elaticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>9.ES集群进阶</title>
      <link href="/2020/03/04/9-ES%E9%9B%86%E7%BE%A4%E8%BF%9B%E9%98%B6/"/>
      <url>/2020/03/04/9-ES%E9%9B%86%E7%BE%A4%E8%BF%9B%E9%98%B6/</url>
      
        <content type="html"><![CDATA[<h2 id="9-1-设置单一职责节点"><a href="#9-1-设置单一职责节点" class="headerlink" title="9.1 设置单一职责节点"></a>9.1 设置单一职责节点</h2><p>一个节点只承担一个角色</p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/esclusterdy.png" alt=""></p><p>好处可以使用不同的配置:</p><ul><li>Dedicated master eligible nodes：负责集群状态(cluster state)的管理<ul><li>使用低配置的CPU, RAM和磁盘</li></ul></li><li>Dedicated data nodes：负责数据存储及处理客户端请求<ul><li>使用高配置的CPU, RAM和磁盘</li></ul></li><li>Dedicated ingest nodes：负责数据处理<ul><li>使用高配置CPU；中等配置的RAM；低配置的磁盘</li></ul></li><li>Dedicate Coordinating Only Node (Client Node)<ul><li>配置：将 Master, Data, Ingest 都配置成 False</li><li>Medium/High CUP； Medium/High RAM； Low Disk</li></ul></li></ul><h2 id="9-2-Coordinating-Only-Nodes"><a href="#9-2-Coordinating-Only-Nodes" class="headerlink" title="9.2 Coordinating Only Nodes"></a>9.2 Coordinating Only Nodes</h2><ul><li>扮演 Load Balancers。降低 Master 和 Data Nodes 的负载</li><li>负责搜索结果的 Gather/Reduce </li><li>有时候无法预知客户端会发送怎么样的请求 <ul><li>大量占用内存的结合操作，一个深度聚合可能会引发 OOM</li></ul></li></ul><h2 id="9-3-Dedicate-Master-Node"><a href="#9-3-Dedicate-Master-Node" class="headerlink" title="9.3 Dedicate Master Node"></a>9.3 Dedicate Master Node</h2><ul><li>从高可用&amp;避免脑裂的角度出发</li><li>一般在生产环境中配置3台</li><li>一个集群只有1台活跃的主节点<ul><li>负责分片管理，索引创建，集群管理等操作</li></ul></li><li>如果和数据节点或者Coordinate节点混合部署<ul><li>数据节点相对有比较大的内存占用</li><li>Coordinate节点有时候可能会有开销很高的査询，导致OOM</li><li>这些都有可能影响Master节点，导致集群的不稳定</li></ul></li></ul><h2 id="9-4-基本部署"><a href="#9-4-基本部署" class="headerlink" title="9.4 基本部署"></a>9.4 基本部署</h2><p>当磁盘容量无法满足需求时，可以增加数据节点；</p><p>磁盘读写压力大时，增加数据节点</p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/esclusterbase.png" alt=""></p><h2 id="9-5-水平扩展"><a href="#9-5-水平扩展" class="headerlink" title="9.5 水平扩展"></a>9.5 水平扩展</h2><p>当系统中有大量的复杂查询及聚合时候，增加 Coordinating 节点，增加查询的性能</p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/esclustersp.png" alt=""></p><h2 id="9-6-读写分离"><a href="#9-6-读写分离" class="headerlink" title="9.6 读写分离"></a>9.6 读写分离</h2><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/esclusterrw.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Elaticsearch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elaticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>8.ES集群分片与文档存储</title>
      <link href="/2020/03/03/8-ES%E9%9B%86%E7%BE%A4%E5%88%86%E7%89%87%E4%B8%8E%E6%96%87%E6%A1%A3%E5%AD%98%E5%82%A8/"/>
      <url>/2020/03/03/8-ES%E9%9B%86%E7%BE%A4%E5%88%86%E7%89%87%E4%B8%8E%E6%96%87%E6%A1%A3%E5%AD%98%E5%82%A8/</url>
      
        <content type="html"><![CDATA[<h2 id="8-1-分片类型"><a href="#8-1-分片类型" class="headerlink" title="8.1 分片类型"></a>8.1 分片类型</h2><ul><li>主分片</li><li>副本分片</li></ul><h3 id="8-1-1-Primary-Shard"><a href="#8-1-1-Primary-Shard" class="headerlink" title="8.1.1 Primary Shard"></a>8.1.1 Primary Shard</h3><ul><li>通过主分⽚，将数据分布在所有节点上,<strong>用来提升系统存储容量</strong></li><li>可以将⼀份索引的数据，分散在多个 Data Node 上，<strong>实现存储的⽔平扩展</strong></li><li>主分⽚(Primary Shard)数在索引<strong>创建时候指定，后续默认不能修改，如要修改，需重建索引</strong></li></ul><h3 id="8-1-2-Replica-Shard"><a href="#8-1-2-Replica-Shard" class="headerlink" title="8.1.2 Replica Shard"></a>8.1.2 Replica Shard</h3><ul><li>通过引⼊副本分⽚ (Replica Shard) <strong>提⾼数据的可⽤性</strong>。⼀旦主分⽚丢失，副本分⽚可以 Promote 成主分⽚。副本分⽚数可以动态调整。每个节点上都有完备的数据。如果不设置副本分⽚，⼀旦出现节点硬件故障，就有可能造成数据丢失提升系统的读取性能</li><li>副本分⽚由主分⽚(Primary Shard)同步。通过⽀持增加 Replica 个数，⼀定程度可以<strong>提⾼读取的吞吐量</strong></li></ul><h2 id="8-2-分片数设定"><a href="#8-2-分片数设定" class="headerlink" title="8.2 分片数设定"></a>8.2 分片数设定</h2><ul><li>主分⽚数过⼩：例如创建了 1 个 Primary Shard 的 Index</li><li>如果该索引增⻓很快，集群⽆法通过增加节点实现对这个索引的数据扩展</li><li>主分⽚数设置过⼤：导致单个 Shard 容量很⼩，引发⼀个节点上有过多分⽚，影响性能</li><li>副本分⽚数设置过多，会降低集群整体的写⼊性能</li></ul><p><strong>总结</strong>: 实在有太多相关的因素了：你使用的硬件、文档的大小和复杂度、文档的索引分析方式、运行的查询类型、执行的聚合以及你的数据模型等等。<br><strong>建议设置Primary Shard数量为master node的数量的倍数,Primary Shard数量不能为0</strong></p><h2 id="8-3-新增节点分片转移过程"><a href="#8-3-新增节点分片转移过程" class="headerlink" title="8.3 新增节点分片转移过程"></a>8.3 新增节点分片转移过程</h2><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/esshardzy.png" alt=""></p><h2 id="8-5-故障转移"><a href="#8-5-故障转移" class="headerlink" title="8.5 故障转移"></a>8.5 故障转移</h2><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/esfailover.png" alt=""></p><h2 id="8-6-文档分布式储存"><a href="#8-6-文档分布式储存" class="headerlink" title="8.6 文档分布式储存"></a>8.6 文档分布式储存</h2><p><strong>⽂档会存储在具体的某个主分⽚和副本分⽚上：例如 ⽂档 1， 会存储在 P0 和 R0 分⽚上</strong></p><p>每个shard都是一个最小工作单元，承载部分数据，lucene实例，完整的建立索引和处理请求的能力</p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/esfenpian.png" alt=""></p><h2 id="8-7-⽂档到分⽚的路由算法"><a href="#8-7-⽂档到分⽚的路由算法" class="headerlink" title="8.7 ⽂档到分⽚的路由算法"></a>8.7 ⽂档到分⽚的路由算法</h2><blockquote><p>shard = hash(_routing) % number_of_primary_shards</p></blockquote><ul><li>Hash 算法确保⽂档均匀分散到分⽚中</li><li>默认的 _routing 值是⽂档 id</li><li>可以⾃⾏制定 routing数值，例如⽤相同国家的商品，都分配到指定的shard</li></ul><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/eshashrouting.png" alt=""></p><ul><li>设置 Index Settings 后， <strong>Primary 数不能随意修改的根本原因</strong></li></ul><h2 id="8-8-更新一个文档"><a href="#8-8-更新一个文档" class="headerlink" title="8.8 更新一个文档"></a>8.8 更新一个文档</h2><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/esdocupdate.png" alt=""></p><ol><li>打到一台Coordinating node节点</li><li>根据路由算法找到存储文档的Primary shard</li><li>路由到指定shard</li><li>删除文档</li><li>新建文档</li><li>同步到replica shard成功</li><li>返回</li></ol><h2 id="8-9-删除一个文档"><a href="#8-9-删除一个文档" class="headerlink" title="8.9 删除一个文档"></a>8.9 删除一个文档</h2><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/esdocdel.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Elaticsearch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elaticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>7.ES分布式集群</title>
      <link href="/2020/03/03/7-ES%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4/"/>
      <url>/2020/03/03/7-ES%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4/</url>
      
        <content type="html"><![CDATA[<h2 id="7-1-分布式特性"><a href="#7-1-分布式特性" class="headerlink" title="7.1 分布式特性"></a>7.1 分布式特性</h2><p>Elasticsearch 的分布式架构带来的好处:</p><ul><li>存储的⽔平扩容，⽀持 PB 级数据</li><li>提⾼系统的可⽤性，部分节点停⽌服务，整个集群的服务不受影响</li></ul><h2 id="7-2-集群节点类型"><a href="#7-2-集群节点类型" class="headerlink" title="7.2 集群节点类型"></a>7.2 集群节点类型</h2><ul><li><p><strong>Master Eligible Node</strong>:可以被选为主节点的节点</p></li><li><p><strong>Voting-only master-eligible node</strong>:只能投票选择主节点的节点</p></li><li><p><strong>Data nodes:</strong>数据节点</p></li><li><p><strong>Coordinating node</strong>:协调调度节点</p></li><li><p><strong>Ingest nodes</strong>: 流水线节点</p></li><li><p><strong>Machine learning node</strong>:机器学习节点</p></li></ul><h3 id="7-2-1-Master-Node"><a href="#7-2-1-Master-Node" class="headerlink" title="7.2.1 Master Node"></a>7.2.1 Master Node</h3><ul><li>Master Node 的职责:<ul><li><strong>处理创建，删除索引等请求 /决定分⽚被分配到哪个节点 / 负责索引的创建与删除</strong></li><li><strong>维护并且更新 Cluster State</strong></li></ul></li></ul><ul><li>Master Node 的最佳实践:<ul><li>Master 节点⾮常重要，在部署上需要考虑解决单点的问题</li><li>为⼀个集群设置多个 Master 节点 / 每个节点只承担 Master 的单⼀⻆⾊</li></ul></li></ul><h3 id="7-2-2-Master-Eligible-Nodes"><a href="#7-2-2-Master-Eligible-Nodes" class="headerlink" title="7.2.2 Master Eligible Nodes"></a>7.2.2 Master Eligible Nodes</h3><ul><li>⼀个集群，⽀持配置多个 Master Eligible 节点。这些节点可以在必要时(如 Master 节点出</li></ul><p>现故障，⽹络故障时)参与选主流程，成为 Master 节点</p><ul><li>每个节点启动后，默认就是⼀个 Master eligible 节点<ul><li>可以设置 node.master: false 禁⽌</li></ul></li><li>当集群内第⼀个 Master eligible 节点启动时候，它会将⾃⼰选举成 Master 节点</li></ul><h3 id="7-2-3-Data-Node"><a href="#7-2-3-Data-Node" class="headerlink" title="7.2.3 Data Node"></a>7.2.3 Data Node</h3><ul><li>可以保存数据的节点，叫做 Data Node,节点启动后，默认就是数据节点。可以设置 node.data: false 禁⽌</li><li>Data Node的职责:保存分⽚数据。在数据扩展上起到了⾄关重要的作⽤（由 Master Node 决定如何把分⽚分发到数据节点上）</li><li>通过增加数据节点可以解决数据⽔平扩展和解决数据单点问题</li></ul><h2 id="7-3-集群架构图"><a href="#7-3-集群架构图" class="headerlink" title="7.3 集群架构图"></a>7.3 集群架构图</h2><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/escluster.png" alt=""></p><h2 id="7-4-集群健康状态"><a href="#7-4-集群健康状态" class="headerlink" title="7.4 集群健康状态"></a>7.4 集群健康状态</h2><p>健康状态针对一个索引，Elasticsearch 中其实有专门的衡量索引健康状况的标志，分为三个等级：</p><ul><li><strong>green，绿色</strong>。<strong>这代表所有的主分片和副本分片都已分配。你的集群是 100% 可用的</strong></li><li><strong>yellow，黄色</strong>。<strong>所有的主分片已经分片了，但至少还有一个副本是缺失的</strong>。不会有数据丢失，所以搜索结果依然是完整的。不过，你的高可用性在某种程度上被弱化。如果更多的分片消失，你就会丢数据了。所以可把 yellow 想象成一个需要及时调查的警告。</li><li><strong>red，红色</strong>。<strong>至少一个主分片以及它的全部副本都在缺失中</strong>。这意味着你在缺少数据：搜索只能返回部分数据，而分配到这个分片上的写入请求会返回一个异常。</li></ul><h2 id="7-5-集群选主过程"><a href="#7-5-集群选主过程" class="headerlink" title="7.5 集群选主过程"></a>7.5 集群选主过程</h2><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/esmaster.png" alt=""></p><h2 id="7-6-如何避免脑裂问题"><a href="#7-6-如何避免脑裂问题" class="headerlink" title="7.6 如何避免脑裂问题"></a>7.6 如何避免脑裂问题</h2><ul><li><p>限定⼀个选举条件，设置 quorum(仲裁)，只有在 Master eligible 节点数⼤于 quorum 时，才能进⾏选举</p><ul><li>Quorum = （master 节点总数 /2）+ 1 </li><li>当 3 个 master eligible 时，设置 discovery.zen.minimum_master_nodes 为 2，即可避免脑裂</li></ul></li><li><p>从 7.0 开始，⽆需这个配置</p><ul><li>移除 minimum_master_nodes 参数，让Elasticsearch⾃⼰选择可以形成仲裁的节点。</li><li>典型的主节点选举现在只需要很短的时间就可以完成。集群的伸缩变得更安全、更容易，并且可能造成丢失数据的系统配置选项更少了。</li><li>节点更清楚地记录它们的状态，有助于诊断为什么它们不能加⼊集群或为什么⽆法选举出主节点</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Elaticsearch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elaticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>6.ES算法</title>
      <link href="/2020/03/03/6-ES%E7%AE%97%E6%B3%95/"/>
      <url>/2020/03/03/6-ES%E7%AE%97%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h2 id="6-1-相关性"><a href="#6-1-相关性" class="headerlink" title="6.1 相关性"></a>6.1 相关性</h2><p>搜索的相关性算分，描述了一个<strong>文档和査询语句匹配的程度</strong>。ES会对每个匹配查询条件的结果进行算分_score</p><p><strong>打分的本质是排序，需要把最符合用户需求的文档排在前面。</strong></p><p><strong>ES5之前，默认的相关性算分采用TF-IDF,现在采用BM 25</strong></p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/esrele.png" alt=""></p><h2 id="6-2-词频-TF"><a href="#6-2-词频-TF" class="headerlink" title="6.2 词频 TF"></a>6.2 词频 TF</h2><ul><li><strong>Term Frequency：检索词在一篇文档中出现的频率</strong><ul><li><strong>检索词出现的次数除以文档的总字数</strong></li></ul></li><li>度量一条查询和结果文档相关性的简单方法：简单将搜索中<strong>每一个词的TF进行相加</strong><ul><li>TF（区块链）+ TF（的）+ TF（应用）</li></ul></li><li>Stop Word<ul><li>“的”在文档中出现了很多次，但是对贡献相关度几乎没有用处，不应该考虑他们的TF</li></ul></li></ul><h2 id="6-3-逆⽂档频率-IDF"><a href="#6-3-逆⽂档频率-IDF" class="headerlink" title="6.3     逆⽂档频率 IDF"></a>6.3     逆⽂档频率 IDF</h2><ul><li>DF：检索词索词在所有文档中出现的频率<ul><li>“区块链”在相对比较少的文档中出现</li><li>“应用”在相对比较多的文档中出现</li><li>“Stop Word”在大量的文档中出现</li></ul></li><li>Inverse Document Frequency :<strong>简单说=log（全部文档数/検索词出现过的文档总数）</strong></li><li>TF-IDF本质上就是将TF求和变成了加权求和<ul><li><code>TF（区块链）*IDF（区块链）+ TF（的）*IDF（的）+ TF（应用）*IDF（应用）</code></li></ul></li></ul><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/esidf.png" alt=""></p><h2 id="6-4-TF-IDF-评分公式"><a href="#6-4-TF-IDF-评分公式" class="headerlink" title="6.4 TF-IDF 评分公式"></a>6.4 TF-IDF 评分公式</h2><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/estf-idf.png" alt=""></p><h2 id="6-5-BM25"><a href="#6-5-BM25" class="headerlink" title="6.5 BM25"></a>6.5 BM25</h2><ul><li>从ES5开始，默认算法改为BM 25</li><li>和经典的TF-IDF相比，当TF无限增加时,BM 25算分会趋于一个数值</li></ul><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/esbm25.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Elaticsearch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elaticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>5.ESMapping介绍</title>
      <link href="/2020/03/03/5-ESMaping%E4%BB%8B%E7%BB%8D/"/>
      <url>/2020/03/03/5-ESMaping%E4%BB%8B%E7%BB%8D/</url>
      
        <content type="html"><![CDATA[<h2 id="5-1-什么是Mapping"><a href="#5-1-什么是Mapping" class="headerlink" title="5.1 什么是Mapping"></a>5.1 什么是Mapping</h2><ul><li>Mapping类似数据库中的schema的定义，作用如下<ul><li>定义索引中的字段的名称</li><li>定义字段的数据类型，例如字符串，数字，布尔……<ul><li>字段，倒排索引的相关配置，(Analyzed r Nt Analyzed,Analyzer)</li></ul></li></ul></li><li>Mapping会把JSN文档映射成Lucene所需要的扁平格式</li><li>—个Mapping属于一个索引的Type<ul><li>每个文档都属于一个Type</li><li>—个Type有一个Mapping定义</li><li>7.0开始，不需要在Mapping定义中指定type信息</li></ul></li></ul><h2 id="5-2-字段的数据类型"><a href="#5-2-字段的数据类型" class="headerlink" title="5.2 字段的数据类型"></a>5.2 字段的数据类型</h2><ul><li><p>简单类型</p><ul><li><p>Text / Keyword</p></li><li><p>Date</p></li><li><p>Integer / Floating</p></li><li><p>Boolean</p></li><li><p>IPv4 &amp; IPv6</p></li></ul></li><li><p>复杂类型-对象和嵌套对象</p><ul><li>对象类型/嵌套类型</li></ul></li><li><p>特殊类型</p><ul><li>geo_point &amp; geo_shape / percolator</li></ul></li></ul><h2 id="5-3-什么是Dynamic-Mapping"><a href="#5-3-什么是Dynamic-Mapping" class="headerlink" title="5.3 什么是Dynamic Mapping"></a>5.3 什么是Dynamic Mapping</h2><ul><li>在写入文档时候，如果索引不存在,会自动创建索引</li><li>Dynamic Mapping的机制，使得我们无需手动定义Mappings</li><li>Elasticsearch会自动根据文档信息，推算出字段的类型</li><li>但是有时候会推算的不对，例如地理位置信息</li><li>当类型如果设置不对时，会导致一些功能无法正常运行，例如Range查询</li></ul><h2 id="5-4-类型的自动识别"><a href="#5-4-类型的自动识别" class="headerlink" title="5.4 类型的自动识别"></a>5.4 类型的自动识别</h2><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/esmapping.png" alt=""></p><h2 id="5-5-能否更改Mapping的字段类型"><a href="#5-5-能否更改Mapping的字段类型" class="headerlink" title="5.5 能否更改Mapping的字段类型"></a>5.5 能否更改Mapping的字段类型</h2><h3 id="5-5-1-新增加字段"><a href="#5-5-1-新增加字段" class="headerlink" title="5.5.1 新增加字段"></a>5.5.1 新增加字段</h3><ul><li>Dynamic设为true时，一旦有新增字段的文档写入，Mapping也同时被</li><li>Dynamic设为false, Mapping不会被更新，新增字段的数据无法被索引,但是信息会出现在_source中</li><li>Dynamic设置成Strict,文档写入失败</li></ul><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/esdynamic.png" alt=""></p><h3 id="5-5-2-对已有字段"><a href="#5-5-2-对已有字段" class="headerlink" title="5.5.2 对已有字段"></a>5.5.2 对已有字段</h3><p><strong>一旦已经有数据写入，就不再支持修改字段定义</strong><br><strong>Lucene实现的倒排索引，一旦生成后，就不允许修改!如果希望改变字段类型，必须Reindex API,重建索引</strong></p><p>原因</p><ul><li>如果修改了字段的数据类型，会导致已被索引的属于无法被搜索</li><li>但是如果是增加新的字段，就不会有这样的影响</li></ul>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Elaticsearch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elaticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>4.ES分词器</title>
      <link href="/2020/03/02/4-ES%E5%88%86%E8%AF%8D%E5%99%A8/"/>
      <url>/2020/03/02/4-ES%E5%88%86%E8%AF%8D%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<h2 id="4-1-Analysis"><a href="#4-1-Analysis" class="headerlink" title="4.1 Analysis"></a>4.1 Analysis</h2><p><strong>文本分析,把全文本转换一系列单词(term/token)的过程,也叫作分词</strong></p><h2 id="4-2-Analyzer"><a href="#4-2-Analyzer" class="headerlink" title="4.2 Analyzer"></a>4.2 Analyzer</h2><p><strong>分词通过分词器来实现,可以使用ES内置的分词器,也可以按需定制化分词器</strong></p><h3 id="4-2-1-Analyzer组成"><a href="#4-2-1-Analyzer组成" class="headerlink" title="4.2.1 Analyzer组成"></a>4.2.1 Analyzer组成</h3><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/esalsis.png" alt=""></p><ul><li>Character Filters （针对原始文本处理，例如去除html）</li><li>Tokenizer （按照规则切分为单词）</li><li>Token Filter（将切分的的单词进行加工，小写，删除stopwords,增加同义词）</li></ul><h3 id="4-2-2-Character-Filters"><a href="#4-2-2-Character-Filters" class="headerlink" title="4.2.2 Character Filters"></a>4.2.2 Character Filters</h3><ul><li>在Tokenizer之前对文本进行处理，例如增加删除及替换字符。可以配置多个 Character Filters。会影响 Tokenizer的 position 和 offset 信息</li><li>—些自带的 Character Filters<ul><li>HTML strip —出除 html 标签</li><li>Mapping 一字符串替换</li><li>Pattern replace —正则匹配替换</li></ul></li></ul><h3 id="4-2-3-Tokenizer"><a href="#4-2-3-Tokenizer" class="headerlink" title="4.2.3 Tokenizer"></a>4.2.3 Tokenizer</h3><ul><li><p>将原始的文本按照一定的规则，切分为词(term or token)</p></li><li><p>Elasticsearch 内置的 Tokenizers</p><ul><li>whitespace / standard / uax_url_email / pattern / keyword / path hierarchy</li></ul></li><li><p>可以用Java开发插件，实现自己的Tokenizer</p></li></ul><h3 id="4-2-4-Token-Filters"><a href="#4-2-4-Token-Filters" class="headerlink" title="4.2.4 Token Filters"></a>4.2.4 Token Filters</h3><ul><li>将Tokenizer输出的单词（term ）,进行增加，修改，删除</li><li>自带的 Token Filters<ul><li>Lowercase / stop / synonym （添加近义词）</li></ul></li></ul><h3 id="4-2-2-ES内置分词器"><a href="#4-2-2-ES内置分词器" class="headerlink" title="4.2.2 ES内置分词器"></a>4.2.2 ES内置分词器</h3><ul><li><strong>Standard Analyzer</strong> 一默认分词器，按词切分，小写处理</li><li><strong>Simple Analyzer</strong> 一按照非字母切分（符号被过滤），小写处理</li><li><strong>Stop Analyzer</strong> —小写处理，停用词过滤（the, a, is）</li><li><strong>Whitespace Analyzer</strong> —按照空格切分，不转小写</li><li><strong>Keyword Analyzer</strong> 一不分词，直接将输入当作输出</li><li><strong>Patter Analyzer</strong> -正则表达式，默认\W+ （非字符分隔）</li><li><strong>Language</strong> 一提供了30多种常见语言的分词器</li><li><strong>Customer Analyzer</strong>自定义分词器</li></ul><h2 id="4-3-中文分词"><a href="#4-3-中文分词" class="headerlink" title="4.3 中文分词"></a>4.3 中文分词</h2><p>常用的中文分词器如下:</p><ul><li><strong><a href="https://github.com/medcl/elasticsearch-analysis-ik" target="_blank" rel="noopener">IK</a></strong>:支持自定义词库，支持热更新分词字典</li><li><strong><a href="https://github.com/microbun/elasticsearch-thulac-plugin" target="_blank" rel="noopener">THULAC</a></strong>:清华大学自然语言处理和社会人文计算实验室的一套中文分词器 </li></ul>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Elaticsearch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elaticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>3.Lucene倒排索引</title>
      <link href="/2020/03/02/3-Lucene%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95/"/>
      <url>/2020/03/02/3-Lucene%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95/</url>
      
        <content type="html"><![CDATA[<h2 id="3-1-介绍"><a href="#3-1-介绍" class="headerlink" title="3.1 介绍"></a>3.1 介绍</h2><p><strong>Lucene是Apache软件基金会中一个开放源代码的全文搜索引擎工具包，是一个全文搜索引擎的架构，提供了完整的查询引擎和索引引擎，部分文本分析引擎</strong>。Lucene的目的是为软件开发人员提供一个简单易用的工具包，以方便在目标系统中实现全文检索的功能，或者是以此为基础建立起完整的全文搜索引擎。</p><h2 id="3-2-倒排索引"><a href="#3-2-倒排索引" class="headerlink" title="3.2 倒排索引"></a>3.2 倒排索引</h2><p>倒排索引源于实际应用中需要根据属性的值来查找记录。这种索引表中的每一项都包括一个属性值和具有该属性值的各记录的地址。<strong>由于不是由记录来确定属性值，而是由属性值来确定记录的位置，因而称为倒排索引(inverted index)</strong>。带有倒排索引的文件我们称为倒排索引文件，简称倒排文件(inverted file)</p><p><strong>倒排索引中的索引对象是文档或者文档集合中的单词等</strong>，用来存储这些单词在一个文档或者一组文档中的存储位置，是对文档或者文档集合的一种最常用的索引机制.</p><p><strong>搜索引擎的关键步骤就是建立倒排索引，倒排索引一般表示为一个关键词，然后是它的频度(出现的次数)、位置</strong>(出现在哪一篇文章或网页中，及有关的日期，作者等信息)，好比一本书的目录、标签一般，读者想看哪一个主题相关的章节，直接根据目录即可找到相关的页面.不必再从书的第一页到最后一页，一页一页地查找.</p><p>下面用例子介绍该结构及相应的生成算法° 假设有两篇文章1和文章2.</p><p>文章 1 的内容为：Tom lives in Guangzhou,! live in Guangzhou too.</p><p>文章 2 的内容为：He once lived in Shanghai.</p><h2 id="3-3-取得关键字"><a href="#3-3-取得关键字" class="headerlink" title="3.3 取得关键字"></a>3.3 取得关键字</h2><p>首先会进行一遍过滤,一般过滤的方式如下:</p><ul><li><strong>时态的转换</strong></li><li><strong>单复数的转换</strong></li><li><strong>同义词的转换</strong></li><li><strong>大小写的转换</strong></li><li><strong>删除没有实际意义的词</strong></li></ul><p>最后得到的处理结果如下:</p><pre><code>文章1的所有关键词为：[tom] [live] [guangzhou] [i] [live] [guangzhou]文章2的所有关键词为：[he] [live] [shanghai]</code></pre><h2 id="3-4-建立倒排索引"><a href="#3-4-建立倒排索引" class="headerlink" title="3.4 建立倒排索引"></a>3.4 建立倒排索引</h2><p><strong>我们注意到关键字是按字符顺序排列的（Lucene没有使用B树结构），因此Lucene可以用二元搜索算法快速定位关键词。</strong></p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/essort.png" alt=""></p><h2 id="3-5-实现"><a href="#3-5-实现" class="headerlink" title="3.5 实现"></a>3.5 实现</h2><p>实现时,Lucene将上面三列分别作为<strong>词典文件(TermDictionary),频率文件(frequencies)、位置文件(positions)</strong>保存。其中词典文件不仅保存了每个关键词，还保留了指向频率文件和位置文件的指针，通过指针可以找到该关键字的频率信息和位置信息。</p><h2 id="3-6-压缩算法"><a href="#3-6-压缩算法" class="headerlink" title="3.6 压缩算法"></a>3.6 压缩算法</h2><p>为了减小索引文件的大小，Lucene对索引还使用了压缩技术</p><p>首先，<strong>对词典文件中的关键词进行了压缩</strong>，关键词压缩为＜前缀长度.后缀＞，例如:当前词为“阿拉伯语”，上一个词为“阿拉伯”，那么“阿拉伯语”压缩为＜3,语＞<br>其次大量用到的是对数字的压缩，数字只保存与上一个值的差值（这样可以减少数字的长度，进而减少保存该数字需要的字节数）。例如当前文章号是16389 （不压缩要用3个字节保存）.上一文章号是16382,压缩后保存7（只用一个字节）</p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Elaticsearch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elaticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2.ES核心概念及基本操作</title>
      <link href="/2020/03/02/2-ES%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/"/>
      <url>/2020/03/02/2-ES%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/</url>
      
        <content type="html"><![CDATA[<h2 id="2-1-核心概念"><a href="#2-1-核心概念" class="headerlink" title="2.1 核心概念"></a>2.1 核心概念</h2><ul><li><strong>Near Realtime（NRT）</strong>：近实时，两个意思，从写入数据到数据可以被搜索到有一个小延迟（大概1秒）；基于es执行搜索和分析可以达到秒级</li><li><strong>Cluster</strong>：集群，包含多个节点，每个节点属于哪个集群是通过一个配置（集群名称，默认是elasticsearch）来决定的，对于中小型应用来说，刚开始一个集群就一个节点很正常</li><li><strong>Node</strong>：节点，集群中的一个节点，节点也有一个名称（默认是随机分配的），节点名称很重要（在执行运维管理操作的时候），默认节点会去加入一个名称为“elasticsearch”的集群，如果直接启动一堆节点，那么它们会自动组成一个elasticsearch集群，当然一个节点也可以组成一个elasticsearch集群</li><li><strong>Document&amp;field</strong>：文档，<strong>es中的最小数据单元</strong>，一个document可以是一条客户数据，一条商品分类数据，一条订单数据，通常用JSON数据结构表示，每个index下的type中，都可以去存储多个document。一个document里面有多个field，每个field就是一个数据字段。</li><li><strong>Index</strong>：索引，包含一堆有相似结构的文档数据，比如可以有一个客户索引，商品分类索引，订单索引，索引有一个名称。一个index包含很多document，一个index就代表了一类类似的或者相同的document。比如说建立一个product index，商品索引，里面可能就存放了所有的商品数据，所有的商品document。</li><li><strong>Type</strong>：类型，每个索引里都可以有一个或多个type，type是index中的一个逻辑数据分类，一个type下的document，都有相同的field，比如博客系统，有一个索引，可以定义用户数据type，博客数据type，评论数据type。</li></ul><pre><code>举例商品index，里面存放了所有的商品数据，商品document但是商品分很多种类，每个种类的document的field可能不太一样，比如说电器商品，可能还包含一些诸如售后时间范围这样的特殊field；生鲜商品，还包含一些诸如生鲜保质期之类的特殊fieldtype，日化商品type，电器商品type，生鲜商品type日化商品type：product_id，product_name，product_desc，category_id，category_name电器商品type：product_id，product_name，product_desc，category_id，category_name，service_period生鲜商品type：product_id，product_name，product_desc，category_id，category_name，eat_period每一个type里面，都会包含一堆document</code></pre><ul><li><strong>shard</strong>：单台机器无法存储大量数据，es可以将一个索引中的数据切分为多个shard，分布在多台服务器上存储。<strong>有了shard就可以横向扩展</strong>，存储更多数据，<strong>让搜索和分析等操作分布到多台服务器上去执行，提升吞吐量和性能</strong>。每个shard都是一个lucene index。</li><li><strong>replica</strong>：任何一个服务器随时可能故障或宕机，此时shard可能就会丢失，因此可以为每个shard创建多个replica副本。replica可以在shard故障时提供备用服务，保证数据不丢失，多个replica还可以提升搜索操作的吞吐量和性能。primary shard（建立索引时一次设置，不能修改，默认5个），replica shard（随时修改数量，默认1个），<strong>默认每个索引10个shard，5个primary shard，5个replica shard，最小的高可用配置，是2台服务器</strong>。</li></ul><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/Es-cluster.png" alt=""></p><h2 id="2-2-elasticsearch-vs-数据库核心概念"><a href="#2-2-elasticsearch-vs-数据库核心概念" class="headerlink" title="2.2 elasticsearch vs. 数据库核心概念"></a>2.2 elasticsearch vs. 数据库核心概念</h2><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/esandrdbms.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Elaticsearch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elaticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>1.ES简介</title>
      <link href="/2020/03/02/1-ES%E7%AE%80%E4%BB%8B/"/>
      <url>/2020/03/02/1-ES%E7%AE%80%E4%BB%8B/</url>
      
        <content type="html"><![CDATA[<h2 id="1-1-介绍"><a href="#1-1-介绍" class="headerlink" title="1.1 介绍"></a>1.1 介绍</h2><p>Elaticsearch，简称为es， es是一个开源的<strong>高扩展的分布式全文检索引擎</strong>，它可以近<strong>乎实时的存储、检索数据</strong>；本身扩展性很好，可以扩展到上百台服务器，处理PB级别（大数据时代）的数据。es也使用Java开发并使用Lucene作为其核心来实现所有索引和搜索的功能，但是它的目的是通过简单<strong>RESTful API</strong>来隐藏Lucene的复杂性，从而让全文搜索变得简单。<br>据国际权威的数据库产品评测机构DB Engines的统计，在2016年1月，ElasticSearch已超过Solr等，<strong>成为排名第一的搜索引擎类应用</strong></p><h2 id="1-2-功能"><a href="#1-2-功能" class="headerlink" title="1.2 功能"></a>1.2 功能</h2><h3 id="1-2-1-分布式的搜索引擎和数据分析引擎"><a href="#1-2-1-分布式的搜索引擎和数据分析引擎" class="headerlink" title="1.2.1 分布式的搜索引擎和数据分析引擎"></a>1.2.1 分布式的搜索引擎和数据分析引擎</h3><p>搜索：百度，网站的站内搜索，IT系统的检索<br>数据分析：电商网站，最近7天牙膏这种商品销量排名前10的商家有哪些；新闻网站，最近1个月访问量排名前3的新闻版块是哪些<br>分布式，搜索，数据分析</p><h3 id="1-2-2-全文检索，结构化检索，数据分析"><a href="#1-2-2-全文检索，结构化检索，数据分析" class="headerlink" title="1.2.2 全文检索，结构化检索，数据分析"></a>1.2.2 全文检索，结构化检索，数据分析</h3><p><strong>全文检索</strong>：我想搜索商品名称包含牙膏的商品，select * from products where product_name like “%牙膏%”<br><strong>结构化检索</strong>：我想搜索商品分类为日化用品的商品都有哪些，<code>select * from products where category_id=&#39;日化用品&#39;</code></p><p>部分匹配、自动完成、搜索纠错、搜索推荐</p><p><strong>数据分析</strong>：我们分析每一个商品分类下有多少个商品，select category_id,count(*) from products group by category_id</p><h3 id="1-2-3-对海量数据进行近实时的处理"><a href="#1-2-3-对海量数据进行近实时的处理" class="headerlink" title="1.2.3 对海量数据进行近实时的处理"></a>1.2.3 对海量数据进行近实时的处理</h3><p><strong>分布式</strong>：ES自动可以将海量数据分散到多台服务器上去存储和检索<br>海联数据的处理：分布式以后，就可以采用大量的服务器去存储和检索数据，自然而然就可以实现海量数据的处理了<br><strong>近实时</strong>：检索个数据要花费1小时（这就不要近实时，离线批处理，batch-processing）；在秒级别对数据进行搜索和分析</p><p>跟分布式/海量数据相反的：lucene，单机应用，只能在单台服务器上使用，最多只能处理单台服务器可以处理的数据量</p><h2 id="1-3-主要概念"><a href="#1-3-主要概念" class="headerlink" title="1.3 主要概念"></a>1.3 主要概念</h2><p>Elasticsearch的主要概念如下:</p><ul><li><strong>节点</strong> - 它指的是Elasticsearch的单个正在运行的实例。单个物理和虚拟服务器容纳多个节点，这取决于其物理资源的能力，如RAM，存储和处理能力。</li><li><strong>集群</strong> - 它是一个或多个节点的集合。 集群为整个数据提供跨所有节点的集合索引和搜索功能。</li><li><strong>索引</strong> - 它是不同类型的文档和文档属性的集合。索引还使用分片的概念来提高性能。 例如，一组文档包含社交网络应用的数据。</li><li><strong>类型/映射</strong> - 它是共享同一索引中存在的一组公共字段的文档的集合。 例如，索引包含社交网络应用的数据，然后它可以存在用于用户简档数据的特定类型，另一类型可用于消息的数据，以及另一类型可用于评论的数据。</li><li><strong>文档</strong> - 它是以JSON格式定义的特定方式的字段集合。每个文档都属于一个类型并驻留在索引中。每个文档都与唯一标识符(称为UID)相关联。</li><li><strong>碎片</strong> - 索引被水平细分为碎片。这意味着每个碎片包含文档的所有属性，但包含的数量比索引少。水平分隔使碎片成为一个独立的节点，可以存储在任何节点中。主碎片是索引的原始水平部分，然后这些主碎片被复制到副本碎片中。</li><li><strong>副本</strong> - Elasticsearch允许用户创建其索引和分片的副本。 复制不仅有助于在故障情况下增加数据的可用性，而且还通过在这些副本中执行并行搜索操作来提高搜索的性能。</li></ul><h2 id="1-4-优点"><a href="#1-4-优点" class="headerlink" title="1.4 优点"></a>1.4 优点</h2><p>Elasticsearch的优点:</p><ul><li>Elasticsearch是基于Java开发的，这使得它在几乎每个平台上都兼容。</li><li>Elasticsearch是实时的，换句话说，一秒钟后，添加的文档可以在这个引擎中搜索得到</li><li>Elasticsearch是分布式的，这使得它易于在任何大型组织中扩展和集成。</li><li>通过使用Elasticsearch中的网关概念，创建完整备份很容易。</li><li>与Apache Solr相比，在Elasticsearch中处理多租户非常容易。</li><li>Elasticsearch使用JSON对象作为响应，这使得可以使用不同的编程语言调用Elasticsearch服务器</li><li>Elasticsearch支持几乎大部分文档类型，但不支持文本呈现的文档类型。</li></ul><h2 id="1-5-缺点"><a href="#1-5-缺点" class="headerlink" title="1.5 缺点"></a>1.5 缺点</h2><p>Elasticsearch的缺点:</p><ul><li>Elasticsearch在处理请求和响应数据方面没有多语言和数据格式支持(仅在JSON中可用)，与Apache Solr不同，Elasticsearch不可以使用CSV，XML等格式</li></ul><h2 id="1-6-特点"><a href="#1-6-特点" class="headerlink" title="1.6 特点"></a>1.6 特点</h2><ul><li>可以作为一个大型分布式集群（数百台服务器）技术，处理PB级数据，服务大公司；也可以运行在单机上，服务小公司</li><li>Elasticsearch不是什么新技术，主要是将全文检索、数据分析以及分布式技术，合并在了一起，才形成了独一无二的ES；lucene（全文检索），商用的数据分析软件（也是有的），分布式数据库（mycat）</li><li>对用户而言，是开箱即用的，非常简单，作为中小型的应用，直接3分钟部署一下ES，就可以作为生产环境的系统来使用了，数据量不大，操作不是太复杂</li><li>数据库的功能面对很多领域是不够用的（事务，还有各种联机事务型的操作）；特殊的功能，比如全文检索，同义词处理，相关度排名，复杂数据分析，海量数据的近实时处理；Elasticsearch作为传统数据库的一个补充，提供了数据库所不不能提供的很多功能</li></ul>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Elaticsearch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Elaticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>消息顺序性的保证</title>
      <link href="/2020/03/01/%E6%B6%88%E6%81%AF%E9%A1%BA%E5%BA%8F%E6%80%A7%E7%9A%84%E4%BF%9D%E8%AF%81/"/>
      <url>/2020/03/01/%E6%B6%88%E6%81%AF%E9%A1%BA%E5%BA%8F%E6%80%A7%E7%9A%84%E4%BF%9D%E8%AF%81/</url>
      
        <content type="html"><![CDATA[<h2 id="1-什么是顺序性"><a href="#1-什么是顺序性" class="headerlink" title="1 什么是顺序性"></a>1 什么是顺序性</h2><p>顾名思义，消息顺序性是指保证消息有序。这个功能有个很常见的应用场景就是CDC（Change Data Chapture），以MySQL为例，如果其传输的binlog的顺序出错，比如原本是先对一条数据加1，然后再乘以2，发送错序之后就变成了先乘以2后加1了，造成了数据不一致。</p><h2 id="2-会出现顺序错乱的场景"><a href="#2-会出现顺序错乱的场景" class="headerlink" title="2 会出现顺序错乱的场景"></a>2 会出现顺序错乱的场景</h2><h3 id="2-1-RabbitMQ"><a href="#2-1-RabbitMQ" class="headerlink" title="2.1 RabbitMQ"></a>2.1 RabbitMQ</h3><p><strong>一个 queue，多个 consumer</strong>。比如，生产者向 RabbitMQ 里发送了三条数据，顺序依次是 data1/data2/data3，压入的是 RabbitMQ 的一个内存队列。有三个消费者分别从 MQ 中消费这三条数据中的一条，结果消费者2先执行完操作，把 data2 存入数据库，然后是 data1/data3。这不明显乱了。</p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/rabbitmq-order-01.png" alt=""></p><h3 id="2-2-Kafka"><a href="#2-2-Kafka" class="headerlink" title="2.2 Kafka"></a>2.2 Kafka</h3><p><strong>一个topic，一个partition，一个consumer，内部多线程</strong></p><p>比如说我们建了一个 topic，有三个 partition。生产者在写的时候，其实可以指定一个 key，比如说我们指定了某个订单 id 作为 key，那么这个订单相关的数据，一定会被分发到同一个 partition 中去，而且这个 partition 中的数据一定是有顺序的。<br>消费者从 partition 中取出来数据的时候，也一定是有顺序的。到这里，顺序还是 ok 的，没有错乱。接着，我们在消费者里可能会搞多个线程来并发处理消息。因为如果消费者是单线程消费处理，而处理比较耗时的话，比如处理一条消息耗时几十 ms，那么 1 秒钟只能处理几十条消息，这吞吐量太低了。而<strong>多个线程并发跑的话，顺序可能就乱掉了</strong>。</p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/kafka-order-01.png" alt=""></p><h2 id="3-解决方式"><a href="#3-解决方式" class="headerlink" title="3 解决方式"></a>3 解决方式</h2><h3 id="3-1-RabbitMQ"><a href="#3-1-RabbitMQ" class="headerlink" title="3.1 RabbitMQ"></a>3.1 RabbitMQ</h3><p>在 MQ 里面<strong>创建多个 queue，同一规则的数据（对唯一标识进行 hash），有顺序的放入 MQ 的 queue 里面</strong>，消费者只取一个 queue 里面获取数据消费，这样执行的顺序是有序的。</p><p>或者还是只有一个 queue 但是对应一个消费者，然后这个消费者<strong>内部用内存队列做排队</strong>，然后分发给底层不同的 worker 来处理。</p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/rabbitmq-order-02.png" alt=""></p><h3 id="3-2-Kafka"><a href="#3-2-Kafka" class="headerlink" title="3.2 Kafka"></a>3.2 Kafka</h3><p>由于kafka没有多个队列概念可以用不同的partition来做,原理和多个队列相同，同一规则的数据（对唯一标识进行 hash)放到不同的partition中,但这种不常用,常用的是所有的都放到一个partition中<strong>,一个消费者,然后根据同一规则的数据（对唯一标识进行 hash），有顺序的放入消费者的不同内存队列中</strong>,保证有序性</p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/kafka-order-02.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> 消息队列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 消息队列 </tag>
            
            <tag> RabbitMQ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>消息幂等性保证</title>
      <link href="/2020/03/01/%E6%B6%88%E6%81%AF%E5%B9%82%E7%AD%89%E6%80%A7%E4%BF%9D%E8%AF%81/"/>
      <url>/2020/03/01/%E6%B6%88%E6%81%AF%E5%B9%82%E7%AD%89%E6%80%A7%E4%BF%9D%E8%AF%81/</url>
      
        <content type="html"><![CDATA[<h2 id="1-传输保证机制"><a href="#1-传输保证机制" class="headerlink" title="1 传输保证机制"></a>1 传输保证机制</h2><p>对于确保消息在生产者和消费者之间进行传输而言一般有三种传输保障（delivery guarantee）：</p><ul><li><strong>At least once</strong>:至少一次，消息绝不会丢，但是可能会重复；</li><li><strong>Exactly once</strong>:精确一次，每条消息肯定会被传输一次且仅一次。</li></ul><p>对于大多数消息中间件而言，<strong>一般只提供At most once和At least once两种传输保障</strong>，对于第三种一般很难做到，由此消息幂等性也很难保证。</p><p><strong>Kafka自0.11版本开始引入了幂等性和事务，Kafka的幂等性是指单个生产者对于单分区单会话的幂等，而事务可以保证原子性地写入到多个分区，即写入到多个分区的消息要么全部成功，要么全部回滚，这两个功能加起来可以让Kafka具备EOS（Exactly Once Semantic）的能力。</strong></p><p>我们实现消息的幂等性一般都是通过下游消费的代码来实现其幂等性:</p><h2 id="2-出现非幂等的情况"><a href="#2-出现非幂等的情况" class="headerlink" title="2 出现非幂等的情况"></a>2 出现非幂等的情况</h2><ol><li><strong>生产者已把消息发送到mq</strong>，在mq给生产者返回ack的时候网络中断，故生产者未收到确定信息，生产者认为消息未发送成功，但实际情况是，mq已成功接收到了消息，在网络重连后，生产者会重新发送刚才的消息，造成mq接收了重复的消息</li><li><strong>消费者在消费mq中的消息时，mq已把消息发送给消费者</strong>，消费者在给mq返回ack时网络中断，故mq未收到确认信息，该条消息会重新发给其他的消费者，或者在网络重连后再次发送给该消费者，但实际上该消费者已成功消费了该条消息，造成消费者消费了重复的消息；</li></ol><h2 id="3-实现幂等必备条件"><a href="#3-实现幂等必备条件" class="headerlink" title="3 实现幂等必备条件"></a>3 实现幂等必备条件</h2><ul><li>全局唯一的id</li><li>根据全局唯一id滤重</li></ul><h2 id="4-具体实现方式"><a href="#4-具体实现方式" class="headerlink" title="4 具体实现方式"></a>4 具体实现方式</h2><h3 id="4-1-全局唯一id"><a href="#4-1-全局唯一id" class="headerlink" title="4.1 全局唯一id"></a>4.1 全局唯一id</h3><p>生成全局以为id的方式有很多:</p><ul><li>可以生成一个与业务无关的全局id,比如使用twitter的雪花算法</li><li>也可以根据业务来指定全局唯一id,比如使用订单号,用户唯一id等</li></ul><h3 id="4-2-根据全局唯一id滤重"><a href="#4-2-根据全局唯一id滤重" class="headerlink" title="4.2 根据全局唯一id滤重"></a>4.2 根据全局唯一id滤重</h3><p>可以使用的方式:</p><ol><li><strong>如果使用的是业务id来做全局唯一</strong>，那么可以在业务表字段加上唯一约束条件，<strong>每次操作时有就更新,没有就插入</strong></li><li><strong>添加消息表</strong>:再数据库里面，添加一张消息消费记录表，表字段加上唯一约束条件,消费完之后就往表里插入一条数据。因为加了唯一约束条件，第二次保存的时候，MySQL 就会报错，就插入不进去；通过数据库可以限制重复消费。</li><li><strong>使用Redis的Set类型保存消费过的id</strong>,每次操作前先查一下是否在set中,如果在,则过滤</li></ol><h3 id="4-3-高并发下需要考虑的问题"><a href="#4-3-高并发下需要考虑的问题" class="headerlink" title="4.3 高并发下需要考虑的问题"></a>4.3 高并发下需要考虑的问题</h3><p>在高并发下,消费端消费id=2的数据过程中,<strong>还没有使用上面的方式将全局唯一id加入滤重复表</strong>,也有可能造成重复消费的情况,此时我们需要考虑在消费消息前加入<strong>分布式锁(Redis/Zookeeper实现)</strong>,先判断是否有锁,如果有锁则等待</p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> 消息队列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 消息队列 </tag>
            
            <tag> RabbitMQ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>消息积压处理</title>
      <link href="/2020/03/01/%E6%B6%88%E6%81%AF%E7%A7%AF%E5%8E%8B%E5%A4%84%E7%90%86/"/>
      <url>/2020/03/01/%E6%B6%88%E6%81%AF%E7%A7%AF%E5%8E%8B%E5%A4%84%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h2 id="1-核心思路"><a href="#1-核心思路" class="headerlink" title="1 核心思路"></a>1 核心思路</h2><p><strong>快速增加消费者</strong></p><h2 id="2-RabbitMQ处理消息堆积"><a href="#2-RabbitMQ处理消息堆积" class="headerlink" title="2 RabbitMQ处理消息堆积"></a>2 RabbitMQ处理消息堆积</h2><p><strong>RabbitMQ可以直接增加消费者进行消费</strong></p><h2 id="3-Kafka处理消息堆积"><a href="#3-Kafka处理消息堆积" class="headerlink" title="3 Kafka处理消息堆积"></a>3 Kafka处理消息堆积</h2><p>Kafka由于partition的扩容需要分区重新分配，在生产的同时进行数据迁移会出现重复数据。所以迁移的时候避免重复生产数据，<strong>应该停止迁移主题的生产</strong>。所以一般都不会进行原有topic的partition的扩容,一般kafka增加消费者的方式如下:</p><ol><li><p><strong>新建一个topic，partition是原来的10倍</strong>，临时建立好原先10倍或者20倍的queue数量</p></li><li><p>然后写一个临时的分发数据的consumer程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，<strong>直接均匀轮询写入临时建立好的10倍数量的queue</strong></p></li><li><p>这是增加<strong>十倍的consumer数量,订阅新的topic,</strong>来处理堆积</p></li><li><p>消费完成后需要<strong>切换回旧的topic和consumer</strong></p></li></ol><p><strong>这里要注意一点是consumer的数量要根据下游Mysql的最大并发来调整,不要把Mysql写挂了！</strong></p><h2 id="4-RabbitMQ消息队列过期了怎么办"><a href="#4-RabbitMQ消息队列过期了怎么办" class="headerlink" title="4 RabbitMQ消息队列过期了怎么办"></a>4 RabbitMQ消息队列过期了怎么办</h2><p>这种情况是对RabbitMQ设置了TTL,我们需要记住的原则是:</p><p><strong>线上不要对MQ设置TTL！即使设置了也要设置死信队列来接收!</strong></p><p>假如没有设置死信,消息也过期了,没有别的办法,只有<strong>通宵熬夜补数据+写事故报告了</strong></p><h2 id="5-消息队列快写满了怎么办"><a href="#5-消息队列快写满了怎么办" class="headerlink" title="5 消息队列快写满了怎么办"></a>5 消息队列快写满了怎么办</h2><p>这种要分情况来看:</p><ul><li>一般来说看了快写满了都是某个下游消费者出了问题造成的<strong>,这种情况下</strong>第一要保证的是MQ不挂<strong>,MQ挂了导致的一系列连锁反应可以把初级程序员吓尿,</strong>解决方式一般就是暴力的快速对消息进行消费,不做任何逻辑处理<strong>,保证MQ不倒,然后同上一条:</strong>通宵熬夜补数据+写事故报告了**</li><li>如果是因为业务量自然增长造成的快写满了,那<strong>就需要提前进行扩容,运维做预警</strong>,一般来说这种原因满了的话,运维也可以收拾东西领单子走人了= =||</li></ul>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> 消息队列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 消息队列 </tag>
            
            <tag> RabbitMQ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>消息队列的作用</title>
      <link href="/2020/02/27/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%9A%84%E4%BD%9C%E7%94%A8/"/>
      <url>/2020/02/27/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%9A%84%E4%BD%9C%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<h2 id="1-作用"><a href="#1-作用" class="headerlink" title="1 作用"></a>1 作用</h2><ul><li>解耦</li><li>异步</li><li>削峰</li><li>数据同步</li></ul><h3 id="1-1-解耦"><a href="#1-1-解耦" class="headerlink" title="1.1 解耦"></a>1.1 解耦</h3><p>比如，用户成功支付完成订单后，需要通知生产配货系统、发票系统、库存系统、推荐系统、搜索系统等进行业务处理，而未来需要支持哪些业务是不知道的，并且这些业务不需要实时处理、不需要强一致，只需要保证最終一致性即可，因此，可以通过消息队列/任务队列进行系统解耦。</p><p>看这么个场景。A 系统发送数据到 BCD 三个系统，通过接口调用发送。如果 E 系统也要这个数据呢？那如果 C 系统现在不需要了呢？A 系统负责人几乎崩溃……</p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/mq-1.png" alt=""></p><p>在这个场景中，A 系统跟其它各种乱七八糟的系统严重耦合，A 系统产生一条比较关键的数据，很多系统都需要 A 系统将这个数据发送过来。A 系统要时时刻刻考虑 BCDE 四个系统如果挂了该咋办？要不要重发，要不要把消息存起来？头发都白了啊！</p><p>如果使用 MQ，Pub/Sub 发布订阅消息这么一个模型，A 系统就跟其它系统彻底解耦了</p><p>A 系统产生一条数据，发送到 MQ 里面去，哪个系统需要数据自己去 MQ 里面消费。如果新系统需要数据，直接从 MQ 里消费即可；如果某个系统不需要这条数据了，就取消对 MQ 消息的消费即可。这样下来，A 系统压根儿不需要去考虑要给谁发送数据，不需要维护这个代码，也不需要考虑人家是否调用成功、失败超时等情况。</p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/mq-2.png" alt=""></p><h3 id="1-2-异步"><a href="#1-2-异步" class="headerlink" title="1.2 异步"></a>1.2 异步</h3><p>使用队列的一个主要原因是进行异步处理，比如，用户注册成功后，需要发送注册成功邮件/新用户积分/优患券等；缓存过期时，先返回过期数据，然后异步更新缓存、异步写日志等。通过异步处理，可以提升主流程响应速度，而非主流程/非重要处理可以集中处理，这样还可以将任务聚合批量处理。因此，可以使用消息队列/任务队列来进行异步处理。</p><p>再来看一个场景，A 系统接收一个请求，需要在自己本地写库，还需要在 BCD 三个系统写库，自己本地写库要 3ms，BCD 三个系统分别写库要 300ms、450ms、200ms。最终请求总延时是 3 + 300 + 450 + 200 = 953ms，接近 1s，用户感觉搞个什么东西，慢死了慢死了。用户通过浏览器发起请求，等待个 1s，这几乎是不可接受的。</p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/mq-3.png" alt=""></p><p>一般互联网类的企业，对于用户直接的操作，一般要求是每个请求都<strong>必须在 200 ms 以内</strong>完成，对用户几乎是无感知的。</p><p>如果使用 MQ，那么 A 系统连续发送 3 条消息到 MQ 队列中，假如耗时 5ms，A 系统从接受一个请求到返回响应给用户，总时长是 3 + 5 = 8ms，对于用户而言，其实感觉上就是点个按钮，8ms 以后就直接返回了，爽！网站做得真好，真快！</p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/mq-4.png" alt=""></p><h3 id="1-3-削峰"><a href="#1-3-削峰" class="headerlink" title="1.3 削峰"></a>1.3 削峰</h3><p>流量削峰：系统瓶颈一般在数据库上，比如扣减库存、下单等。此时可以考虑使用队列将变更请求暂时放入队列，通过缓存+队列暫存的方式将数据库流量削峰。同样，对于秒杀系统，下单服务会是该系统的瓶颈，此时，可以使用队列进行排队和限流，从而保护下单服务，通过队列暂存或者队列限流进行流量削峰。</p><p>场景:每天 0:00 到 12:00，A 系统风平浪静，每秒并发请求数量就 50 个。结果每次一到 12:00 ~ 13:00 ，每秒并发请求数量突然会暴增到 5k+ 条。但是系统是直接基于 MySQL 的，大量的请求涌入 MySQL，每秒钟对 MySQL 执行约 5k 条 SQL。</p><p>一般的 MySQL，扛到每秒 2k 个请求就差不多了，如果每秒请求到 5k 的话，可能就直接把 MySQL 给打死了，导致系统崩溃，用户也就没法再使用系统了。</p><p>但是高峰期一过，到了下午的时候，就成了低峰期，可能也就 1w 的用户同时在网站上操作，每秒中的请求数量可能也就 50 个请求，对整个系统几乎没有任何的压力。</p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/mq-5.png" alt=""></p><p>如果使用 MQ，每秒 5k 个请求写入 MQ，A 系统每秒钟最多处理 2k 个请求，因为 MySQL 每秒钟最多处理 2k 个。A 系统从 MQ 中慢慢拉取请求，每秒钟就拉取 2k 个请求，不要超过自己每秒能处理的最大请求数量就 ok，这样下来，哪怕是高峰期的时候，A 系统也绝对不会挂掉。而 MQ 每秒钟 5k 个请求进来，就 2k 个请求出去，结果就导致在中午高峰期（1 个小时），可能有几十万甚至几百万的请求积压在 MQ 中。</p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/mq-6.png" alt=""></p><p>这个短暂的高峰期积压是 ok 的，因为高峰期过了之后，每秒钟就 50 个请求进 MQ，但是 A 系统依然会按照每秒 2k 个请求的速度在处理。所以说，只要高峰期一过，A 系统就会快速将积压的消息给解决掉</p><h3 id="1-4-数据同步"><a href="#1-4-数据同步" class="headerlink" title="1.4 数据同步"></a>1.4 数据同步</h3><p>比如，想把MySQL变更的数据同步到Redis,或者将MySQL的数据同步到Mongodb,或者让机房之间的数据同步，或者主从数据同步等，此时可以考虑使用databus、canal、otter等。使用数据总线队列进行数据同步的好处是可以保证数据修改的有序性。</p><h2 id="2-缺点"><a href="#2-缺点" class="headerlink" title="2 缺点"></a>2 缺点</h2><ul><li>系统可用性降低</li><li>系统复杂度提高</li><li>一致性问题</li></ul><h3 id="2-1-系统可用性降低"><a href="#2-1-系统可用性降低" class="headerlink" title="2.1 系统可用性降低"></a>2.1 系统可用性降低</h3><p>系统引入的外部依赖越多，越容易挂掉。本来你就是 A 系统调用 BCD 三个系统的接口就好了，ABCD 四个系统还好好的，没啥问题，你偏加个 MQ 进来，万一 MQ 挂了咋整？MQ 一挂，整套系统崩溃，你不就完了？如何保证消息队列的高可用，可以点击这里查看。</p><h3 id="2-2-系统复杂度提高"><a href="#2-2-系统复杂度提高" class="headerlink" title="2.2 系统复杂度提高"></a>2.2 系统复杂度提高</h3><p>硬生生加个 MQ 进来，你怎么保证消息没有重复消费？怎么处理消息丢失的情况？怎么保证消息传递的顺序性？头大头大，问题一大堆，痛苦不已。</p><h3 id="2-3-一致性问题"><a href="#2-3-一致性问题" class="headerlink" title="2.3 一致性问题"></a>2.3 一致性问题</h3><p>A 系统处理完了直接返回成功了，人都以为你这个请求就成功了；但是问题是，要是 BCD 三个系统那里，BD 两个系统写库成功了，结果 C 系统写库失败了，咋整？你这数据就不一致了。</p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> 消息队列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 消息队列 </tag>
            
            <tag> RabbitMQ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>消息队列可靠性保证</title>
      <link href="/2020/02/27/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E5%8F%AF%E9%9D%A0%E6%80%A7%E4%BF%9D%E8%AF%81/"/>
      <url>/2020/02/27/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E5%8F%AF%E9%9D%A0%E6%80%A7%E4%BF%9D%E8%AF%81/</url>
      
        <content type="html"><![CDATA[<p>消息丢失是使用消息中间件时所不得不面对的一个痛点，其背后消息可靠性也是衡量消息中间件好坏的一个关键因素。尤其是在金融支付领域，消息可靠性尤为重要。</p><p>我们要保证数据不丢失，下面我们看下RabbitMQ和Kafka怎样实现的消息可靠性</p><h2 id="RabbitMQ"><a href="#RabbitMQ" class="headerlink" title="RabbitMQ"></a>RabbitMQ</h2><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/rmqsis.png" alt=""></p><h2 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h2><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/kafkasis.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> 消息队列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 消息队列 </tag>
            
            <tag> RabbitMQ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kafka和RabbitMQ的比较</title>
      <link href="/2020/02/27/Kafka%E5%92%8CRabbitmq%E7%9A%84%E6%AF%94%E8%BE%83/"/>
      <url>/2020/02/27/Kafka%E5%92%8CRabbitmq%E7%9A%84%E6%AF%94%E8%BE%83/</url>
      
        <content type="html"><![CDATA[<table><thead><tr><th align="center">功能项</th><th align="center">Kafka（1.1.0版本）</th><th align="center">RabbitMQ（3.6.10版本）</th></tr></thead><tbody><tr><td align="center">优先级队列</td><td align="center">不支持</td><td align="center">支持。建议优先级大小设置在0-10之间</td></tr><tr><td align="center">延迟队列</td><td align="center">不支持</td><td align="center">支持</td></tr><tr><td align="center">死信队列</td><td align="center">不支持</td><td align="center">支持</td></tr><tr><td align="center">重试队列</td><td align="center">不支持</td><td align="center">不支持</td></tr><tr><td align="center">消费模式</td><td align="center">pull</td><td align="center">pull+push</td></tr><tr><td align="center">广播消费</td><td align="center">支持</td><td align="center">支持</td></tr><tr><td align="center">消息回溯</td><td align="center">Kafka支持按照offset和timestamp两种维度进行消息回溯</td><td align="center">不支持。RabbitMQ中消息一旦被确认消费就会被标记删除</td></tr><tr><td align="center">消息堆积</td><td align="center">支持</td><td align="center">支持</td></tr><tr><td align="center">持久化</td><td align="center">支持</td><td align="center">支持</td></tr><tr><td align="center">消息过滤</td><td align="center">通过客户端interceptor拦截器实现</td><td align="center">不支持</td></tr><tr><td align="center">消息追踪</td><td align="center">不支持。消息追踪可以通过外部系统来支持，但是支持粒度没有内置的细腻。</td><td align="center">支持。RabbitMQ中可以采用Firehose或者rabbitmq_tracing插件实现。不过开启rabbitmq_tracing插件件会大幅影响性能，不建议生产环境开启，反倒是可以使用Firehose与外部链路系统结合提供高细腻度的消息追踪支持。</td></tr><tr><td align="center">多租户(vhost)支持</td><td align="center">不支持</td><td align="center">支持</td></tr><tr><td align="center">多协议支持</td><td align="center">只支持定义协议</td><td align="center">RabbitMQ本身就是AMQP协议的实现，同时支持MQTT、STOMP等协议</td></tr><tr><td align="center">跨语言支持</td><td align="center">采用Scala和Java编写，支持多种语言的客户端</td><td align="center">采用Erlang编写，支持多种语言的客户端</td></tr><tr><td align="center">幂等性</td><td align="center">支持单个生产者单分区单会话的幂等性</td><td align="center">不支持</td></tr><tr><td align="center">事务性消息</td><td align="center">支持</td><td align="center">支持</td></tr><tr><td align="center">消息顺序性</td><td align="center">支持单分区（partition）级别的顺序性</td><td align="center">顺序性的条件比较苛刻，需要单线程发送、单线程消费并且不采用延迟队列、优先级队列等一些高级功能，从某种意义上来说不算支持顺序性</td></tr><tr><td align="center">安全机制</td><td align="center">（TLS/SSL、SASL）身份认证和（读写）权限控制</td><td align="center">与Kafka相似</td></tr><tr><td align="center">控制中心</td><td align="center">外部依赖zookeeper</td><td align="center">自己实现的NameSrv</td></tr><tr><td align="center">单机吞吐量</td><td align="center">十万级</td><td align="center">万级</td></tr><tr><td align="center">topic对吞吐量影响</td><td align="center">topic 从几十到几百个时候，吞吐量会大幅度下降，在同等机器下，Kafka 尽量保证 topic 数量不要过多，如果要支撑大规模的 topic，需要增加更多的机器资源</td><td align="center">－</td></tr><tr><td align="center">时效性</td><td align="center">微妙级</td><td align="center">ms级</td></tr><tr><td align="center">可靠性</td><td align="center">基本不丢</td><td align="center">经过参数优化配置，可以做到 0 丢失</td></tr></tbody></table><p>​        </p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> 消息队列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 消息队列 </tag>
            
            <tag> RabbitMQ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kafka幂等性保证</title>
      <link href="/2020/02/26/Kafka%E5%B9%82%E7%AD%89%E6%80%A7%E4%BF%9D%E8%AF%81/"/>
      <url>/2020/02/26/Kafka%E5%B9%82%E7%AD%89%E6%80%A7%E4%BF%9D%E8%AF%81/</url>
      
        <content type="html"><![CDATA[<h2 id="1-Kafka生产端自带幂等性"><a href="#1-Kafka生产端自带幂等性" class="headerlink" title="1 Kafka生产端自带幂等性"></a>1 Kafka生产端自带幂等性</h2><p>为了实现Producer的幂等性，Kafka引入了Producer ID（即PID）和Sequence Number。</p><ul><li>PID。每个新的Producer在初始化的时候会被分配一个唯一的PID，这个PID对用户是不可见的。</li><li>Sequence Numbler。（对于每个PID，该Producer发送数据的每个&lt;Topic, Partition&gt;都对应一个从0开始单调递增的Sequence Number</li></ul><p>Kafka可能存在多个生产者，会同时产生消息，但对Kafka来说，<strong>只需要保证每个生产者内部的消息幂等就可以了</strong>，所有引入了PID来标识不同的生产者。</p><p>对于Kafka来说，要解决的是生产者发送消息的幂等问题。也即需要区分每条消息是否重复。<br>Kafka通过为每条消息增加一个Sequence Numbler，通过Sequence Numbler来区分每条消息。每条消息对应一个分区，不同的分区产生的消息不可能重复。所有Sequence Numbler对应每个分区</p><p>Broker端在缓存中保存了这seq number，对于接收的每条消息，如果其序号比Broker缓存中序号大于1则接受它，否则将其丢弃。这样就可以实现了消息重复提交了。</p><p><strong>但是，只能保证单个Producer对于同一个&lt;Topic, Partition&gt;的Exactly Once语义。不能保证同一个Producer一个topic不同的partion幂等。</strong></p><h2 id="2-消费端幂等性"><a href="#2-消费端幂等性" class="headerlink" title="2 消费端幂等性"></a>2 消费端幂等性</h2><p>将在消息队列幂等性文章中统一说明</p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> 消息队列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kafka </tag>
            
            <tag> 消息队列 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kafka可靠性保证</title>
      <link href="/2020/02/26/Kafka%E5%8F%AF%E9%9D%A0%E6%80%A7%E4%BF%9D%E8%AF%81/"/>
      <url>/2020/02/26/Kafka%E5%8F%AF%E9%9D%A0%E6%80%A7%E4%BF%9D%E8%AF%81/</url>
      
        <content type="html"><![CDATA[<h2 id="1-生产者可靠性保证"><a href="#1-生产者可靠性保证" class="headerlink" title="1. 生产者可靠性保证"></a>1. 生产者可靠性保证</h2><p>设置<strong>acks=-1(all)&amp;&amp;retries=MAX</strong>，一定不会丢，要求是，你的 leader 接收到消息，所有的 follower 都同步到了消息之后，才认为本次写成功了。如果没满足这个条件，生产者会自动不断的重试，重试无限次。</p><h2 id="2-消费者可靠性保证"><a href="#2-消费者可靠性保证" class="headerlink" title="2. 消费者可靠性保证"></a>2. 消费者可靠性保证</h2><h3 id="2-1-消费者提交方式"><a href="#2-1-消费者提交方式" class="headerlink" title="2.1 消费者提交方式"></a>2.1 消费者提交方式</h3><ul><li>自动提交</li><li>手动提交<ul><li>同步提交(阻塞线程)</li><li>异步提交(非阻塞)</li></ul></li></ul><p><strong>无论是同步提交还是异步提交 offset，都有可能会造成数据的漏消费或者重复消费。</strong></p><p><strong>先提交 offset 后消费，有可能造成数据的漏消费；</strong></p><p><strong>而先消费后提交 offset，有可能会造成数据的重复消费</strong></p><h3 id="2-2-消费者可靠性选择"><a href="#2-2-消费者可靠性选择" class="headerlink" title="2.2 消费者可靠性选择"></a>2.2 消费者可靠性选择</h3><p><strong>我们采取异步先消费后提交的方式来保证消费者端的可靠性,造成的重复消费我们使用幂等性来规避</strong></p><h2 id="3-Broker可靠性保证"><a href="#3-Broker可靠性保证" class="headerlink" title="3 Broker可靠性保证"></a>3 Broker可靠性保证</h2><p><strong>这块比较常见的一个场景，就是 Kafka 某个 broker 宕机，然后重新选举 partition 的 leader。要是此时其他的 follower 刚好还有些数据没有同步，结果此时 leader 挂了，然后选举某个 follower 成 leader 之后，就会丢一些数据</strong></p><p>所以此时一般是要求起码设置如下 2 个参数：</p><ul><li><strong>给 topic 设置 replication.factor 参数：这个值必须大于 1，要求每个 partition 必须有至少 2 个副本。</strong></li><li>在 Kafka 服务端设置 <strong>min.insync.replicas</strong> 参数：<strong>这个值必须大于 1，这个是要求一个 leader 至少感知到有至少一个 follower 还跟自己保持联系，没掉队，这样才能确保 leader 挂了还有一个 follower 吧。</strong></li></ul><p>我们生产环境就是按照上述要求配置的，这样配置之后，至少在 Kafka broker 端就可以保证在 leader 所在 broker 发生故障，进行 leader 切换时，数据不会丢失。</p><h2 id="4-总结"><a href="#4-总结" class="headerlink" title="4 总结"></a>4 总结</h2><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/kafkasis.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> 消息队列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kafka </tag>
            
            <tag> 消息队列 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kafka介绍</title>
      <link href="/2020/02/26/Kafka%E4%BB%8B%E7%BB%8D/"/>
      <url>/2020/02/26/Kafka%E4%BB%8B%E7%BB%8D/</url>
      
        <content type="html"><![CDATA[<h2 id="1-基础架构"><a href="#1-基础架构" class="headerlink" title="1 基础架构"></a>1 基础架构</h2><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/kafkaarc.png" alt=""></p><ul><li><strong>Producer</strong> ：消息生产者，就是向kafka broker发消息的客户端；</li><li><strong>Consumer</strong> ：消息消费者，向kafka broker取消息的客户端；</li><li><strong>ConsumerGroup （CG）</strong>：消费者组，由多个consumer组成。<strong>消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费；消费者组之间互不影响</strong>。所有的消费者都属于某个消费者组，即消费者组是<strong>逻辑上的一个订阅者</strong>。</li><li><strong>Broker</strong> ：一台kafka服务器就是一个broker。一个集群由多个broker组成。一个broker 可以容纳多个topic。</li><li><strong>Topic</strong> ：可以理解为一个队列，<strong>生产者和消费者面向的都是一个topic</strong>；</li><li><strong>Partition</strong>：为了实现扩展性，一个非常大的topic可以分布到多个broker（即服务器）上，<strong>一个topic可以分为多个partition，每个partition是一个有序的队列</strong>；</li><li><strong>Replica</strong>：副本，为保证集群中的某个节点发生故障时，<strong>该节点上的partition数据不丢失，且kafka仍然能够继续工作</strong>，kafka提供了副本机制，一个topic的每个分区都有若干个副本，一个leader和若干个follower。</li><li><strong>leader</strong>：每个分区多个副本的“主”，生产者发送数据的对象，以及消费者消费数据的对象都是leader。</li><li><strong>follower</strong>：每个分区多个副本中的“从”，实时从leader中同步数据，保持和leader数据的同步。leader发生故障时，某个follower会成为新的follower。</li></ul><h2 id="2-Kafka工作流程"><a href="#2-Kafka工作流程" class="headerlink" title="2 Kafka工作流程"></a>2 Kafka工作流程</h2><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/kafkaworkflow.png" alt=""></p><p>Kafka中消息是以<strong>topic</strong>进行分类的，生产者生产消息，消费者消费消息，都是面向topic的</p><p>topic是逻辑上的概念，而partition是物理上的概念，每个partition对应于一个log文件，该log文件中存储的就是producer生产的数据。Producer生产的数据会被不断追加到该log文件末端，且每条数据都有自己的offset。<strong>消费者组中的每个消费者，都会实时记录自己消费到了哪个offset</strong>，以便出错恢复时，从上次的位置继续消费。</p><h2 id="3-Kafka文件储存机制"><a href="#3-Kafka文件储存机制" class="headerlink" title="3 Kafka文件储存机制"></a>3 Kafka文件储存机制</h2><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/kafkafilearc.png" alt=""></p><p>由于生产者生产的消息会不断追加到 log 文件末尾，为防止 log 文件过大导致数据定位<br>效率低下，Kafka 采取了<strong>分片和索引</strong>机制，将每个 partition 分为多个 segment。每个 segment<br>对应两个文件——“.index”文件和“.log”文件。这些文件位于一个文件夹下，该文件夹的命名<br>规则为：<strong>topic 名称+分区序号</strong>。例如，first 这个 topic 有三个分区，则其对应的文件夹为 first-<br>0,first-1,first-2。</p><pre><code class="ini">00000000000000000000.index00000000000000000000.log00000000000000170410.index00000000000000170410.log00000000000000239430.index00000000000000239430.log</code></pre><p>index 和 log 文件以当前 segment 的<strong>第一条消息的 offset</strong> 命名。下图为 index 文件和 log<br>文件的结构示意图</p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/kafkafileindex.png" alt=""></p><p><strong>“.index”文件存储大量的索引信息，“.log”文件存储大量的数据，索引文件中的元数据指向对应数据文件中message的物理偏移地址。</strong></p><h2 id="4-Kafka生产者"><a href="#4-Kafka生产者" class="headerlink" title="4 Kafka生产者"></a>4 Kafka生产者</h2><h3 id="4-1-分区策略"><a href="#4-1-分区策略" class="headerlink" title="4.1 分区策略"></a>4.1 分区策略</h3><h4 id="4-1-1-分区原因"><a href="#4-1-1-分区原因" class="headerlink" title="4.1.1 分区原因"></a>4.1.1 分区原因</h4><ul><li><strong>方便在集群中扩展</strong>，每个Partition可以通过调整以适应它所在的机器，而一个topic 又可以有多个Partition组成，因此整个集群就可以适应任意大小的数据了；</li><li><strong>可以提高并发</strong>，因为可以以Partition为单位读写了</li></ul><h4 id="4-1-2-分区原则"><a href="#4-1-2-分区原则" class="headerlink" title="4.1.2 分区原则"></a>4.1.2 分区原则</h4><p>在生产端发送数据的时候,发送到的分区根据以下顺序选择:</p><ol><li>指明partition 的情况下，直接将指明的值直接作为partiton 值；</li><li>没有指明partition 值但有key 的情况下，将key 的hash 值与topic 的partition 数进行取余得到partition 值；</li><li>既没有partition 值又没有key 值的情况下，第一次调用时随机生成一个整数（后面每次调用在这个整数上自增），将这个值与topic 可用的partition 总数取余得到partition 值，也就是常说的round-robin 算法。</li></ol><h3 id="4-2-数据可靠性"><a href="#4-2-数据可靠性" class="headerlink" title="4.2 数据可靠性"></a>4.2 数据可靠性</h3><p><strong>为保证producer发送的数据，能可靠的发送到指定的topic，topic的每个partition收到producer发送的数据后，都需要向producer发送ack（acknowledgement确认收到），如果producer收到ack，就会进行下一轮的发送，否则重新发送数据。</strong></p><h4 id="4-2-1-发送方案"><a href="#4-2-1-发送方案" class="headerlink" title="4.2.1 发送方案"></a>4.2.1 发送方案</h4><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/kafkaack.png" alt=""></p><p>Kafka 选择了<strong>第二种</strong>方案，原因如下：</p><ul><li><p>同样为了容忍 n 台节点的故障，第一种方案需要 2n+1 个副本，而第二种方案只需要 n+1个副本，而 Kafka 的每个分区都有大量的数据，<strong>第一种方案会造成大量数据的冗余</strong>。</p></li><li><p>虽然第二种方案的网络延迟会比较高，但网络延迟对 Kafka 的影响较小。</p></li></ul><h4 id="4-2-2-ISR"><a href="#4-2-2-ISR" class="headerlink" title="4.2.2 ISR"></a>4.2.2 ISR</h4><p>采用第二种方案之后，设想以下情景：leader 收到数据，所有 follower 都开始同步数据，<br>但有一个 follower，因为某种故障，迟迟不能与 leader 进行同步，那 leader 就要一直等下去，<br>直到它完成同步，才能发送 ack。这个问题怎么解决呢？</p><p><strong>Leader维护了一个动态的in-syncreplicaset(ISR)，意为和leader保持同步的follower集合。当ISR中的follower完成数据的同步之后，leader就会给follower发送ack。如果follower长时间未向leader同步数据，则该follower将被踢出ISR，该时间阈值由replica.lag.time.max.ms参数设定。Leader发生故障之后，就会从ISR中选举新的leader。</strong></p><h4 id="4-2-3-ACK应答机制"><a href="#4-2-3-ACK应答机制" class="headerlink" title="4.2.3 ACK应答机制"></a>4.2.3 ACK应答机制</h4><p>对于某些不太重要的数据，对数据的可靠性要求不是很高，能够容忍数据的少量丢失，所以没必要等ISR中的follower全部接收成功。所以<strong>Kafka为用户提供了三种可靠性级别</strong>，用户根据对可靠性和延迟的要求进行权衡，选择以下的配置。</p><ul><li><strong>0</strong>：<strong>producer不等待broker的ack</strong>，这一操作提供了一个最低的延迟，broker一接收到还没有写入磁盘就已经返回，当broker故障时有可能丢失数据；</li><li><strong>1</strong>：<strong>producer等待broker的ack，partition的leader落盘成功后返回ack</strong>，如果在follower同步成功之前leader故障，那么将会丢失数据；</li><li><strong>-1</strong>（all）：<strong>producer等待broker的ack，partition的leader和follower全部落盘成功后才返回ack</strong>。但是如果在follower同步完成后，broker发送ack之前，leader发生故障，那么会造成<strong>数据重复</strong></li></ul><h4 id="4-2-4-HW和LEO"><a href="#4-2-4-HW和LEO" class="headerlink" title="4.2.4 HW和LEO"></a>4.2.4 HW和LEO</h4><p><strong>LEO：指的是每个副本最大的 offset；</strong><br><strong>HW：指的是消费者能见到的最大的 offset，ISR 队列中最小的 LEO。</strong></p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/kafkahw.png" alt=""></p><ul><li><p><strong>follower故障</strong>：follower发生故障后会被临时踢出ISR，待该follower恢复后，follower会读取本地磁盘记录的上次的HW，并将log文件高于HW的部分截取掉，从HW开始向leader进行同步。等该<strong>follower的LEO大于等于该Partition的HW</strong>，即follower追上leader之后，就可以重新加入ISR了。</p></li><li><p><strong>leader故障</strong>:leader发生故障之后，会从ISR中选出一个新的leader，之后，为保证多个副本之间的数据一致性，其余的follower会先将各自的log文件高于<strong>HW的部分截掉</strong>，然后从新的leader 同步数据。</p></li></ul><p><strong>注意：这只能保证副本之间的数据一致性，并不能保证数据不丢失或者不重复。</strong></p><h3 id="4-3-ExactlyOnce语义"><a href="#4-3-ExactlyOnce语义" class="headerlink" title="4.3 ExactlyOnce语义"></a>4.3 ExactlyOnce语义</h3><p>将服务器的ACK级别设置为-1,可以保证Producer到Server之间不会丢失数据，即<strong>At Least Once语义</strong>。相对的，将服务器ACK级别设置为0,可以保证生产者每条消息只会被发送一次，即<strong>AtMostOnce语义</strong>。</p><p><strong>AtLeastOnce可以保证数据不丢失，但是不能保证数据不重复</strong></p><p><strong>AtLeastOnce 可以保证数据不重复，但是不能保证数据不丢失</strong></p><p>但是，对于一些非常重要的信息，比如说交易数据，下游数据消费者要求数据既不重复也不丢失，即ExactlyOnce语义。在0.11版本以前的Kafka，对此是无能为力的，只<strong>能保证数据不丢失，再在下游消费者对数据做全局去重</strong>。对于多个下游应用的情况，每个都需要单独做全局去重，这就对性能造成了很大影响。</p><p>0.11版本的Kafka，引入了一项重大特性：<strong>幂等性</strong>。<strong>所谓的幂等性就是指Producer不论向Server发送多少次重复数据，Server端都只会持久化一条</strong>。幂等性结合AtLeastOnce语义，就构成了Kafka的ExactlyOnce语义。即：</p><pre><code>AtLeastOnce+幂等性=ExactlyOnce</code></pre><p>要启用幂等性，只需要将<strong>Producer的参数中enable.idompotence设置为true即可</strong>。</p><p><strong>Kafka 的幂等性实现其实就是将原来下游需要做的去重放在了数据上游</strong>。开启幂等性的Producer在初始化的时候会被分配一个PID，发往同一Partition的消息会附带SequenceNumber。<strong>而Broker端会对&lt;PID,Partition,SeqNumber&gt;做缓存，当具有相同主键的消息提交时，Broker只会持久化一条</strong>。</p><p><strong>但是PID重启就会变化，同时不同的Partition也具有不同主键，所以幂等性无法保证跨分区跨会话的ExactlyOnce。</strong></p><h2 id="5-Kafka消费者"><a href="#5-Kafka消费者" class="headerlink" title="5 Kafka消费者"></a>5 Kafka消费者</h2><h3 id="5-1-消费方式"><a href="#5-1-消费方式" class="headerlink" title="5.1 消费方式"></a>5.1 消费方式</h3><p><strong>consumer采用pull（拉）模式从broker中读取数据</strong>。</p><p>push（推）模式很难适应消费速率不同的消费者，因为消息发送速率是由broker决定的。它的目标是尽可能以最快速度传递消息，但是这样很容易造成consumer来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。而pull模式则可以根据consumer的消费能力以适当的速率消费消息。</p><p><strong>pull模式不足之处是，如果kafka没有数据，消费者可能会陷入循环中，一直返回空数据</strong>。针对这一点，Kafka的消费者在消费数据时会传入一个时长参数<strong>timeout</strong>，如果当前没有数据可供消费，consumer会等待一段时间之后再返回，这段时长即为timeout。</p><h3 id="5-2-offset维护"><a href="#5-2-offset维护" class="headerlink" title="5.2 offset维护"></a>5.2 offset维护</h3><p>由于consumer在消费过程中可能会出现断电宕机等故障，consumer恢复后，需要从故障前的位置的继续消费，所以<strong>consumer需要实时记录自己消费到了哪个offset，以便故障恢复后继续消费</strong>。</p><p><strong>Kafka0.9版本之前，consumer默认将offset保存在Zookeeper中，从0.9版本开始，consumer默认将offset保存在Kafka一个内置的topic中，该topic为__consumer_offsets</strong></p><h2 id="6-Kafka高效读写数据原因"><a href="#6-Kafka高效读写数据原因" class="headerlink" title="6 Kafka高效读写数据原因"></a>6 Kafka高效读写数据原因</h2><ul><li>顺序写磁盘</li><li>零拷贝技术</li></ul><h3 id="6-1-顺序读写磁盘"><a href="#6-1-顺序读写磁盘" class="headerlink" title="6.1 顺序读写磁盘"></a>6.1 顺序读写磁盘</h3><p>Kafka的producer生产数据，要写入到log文件中，写的过程是一直追加到文件末端,为顺序写。官网有数据表明，同样的磁盘，顺序写能到600M/s，而随机写只有100K/s。这与磁盘的机械机构有关，顺序写之所以快，是因为其省去了大量磁头寻址的时间。</p><h3 id="6-2-零拷贝技术"><a href="#6-2-零拷贝技术" class="headerlink" title="6.2 零拷贝技术"></a>6.2 零拷贝技术</h3><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/kafkazero.png" alt=""></p><h2 id="7-Zookeeper在Kafka中的作用"><a href="#7-Zookeeper在Kafka中的作用" class="headerlink" title="7 Zookeeper在Kafka中的作用"></a>7 Zookeeper在Kafka中的作用</h2><p><strong>Kafka 集群中有一个 broker 会被选举为 Controller，负责管理集群 broker 的上下线，所有 topic 的分区副本分配和 leader 选举等工作。</strong><br><strong>Controller 的管理工作都是依赖于 Zookeeper 的。</strong></p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/kafkazk.png" alt=""></p><h2 id="8-Kafka事务"><a href="#8-Kafka事务" class="headerlink" title="8 Kafka事务"></a>8 Kafka事务</h2><p>Kafka 从 0.11 版本开始引入了事务支持。事务可以保证 Kafka 在 Exactly Once 语义的基<br>础上，<strong>生产和消费可以跨分区和会话，要么全部成功，要么全部失败</strong></p><h3 id="8-1-Producer事务"><a href="#8-1-Producer事务" class="headerlink" title="8.1 Producer事务"></a>8.1 Producer事务</h3><p>为了实现跨分区跨会话的事务，需要引入一个全局唯一的 Transaction ID，并将 Producer<br>获得的PID 和Transaction ID 绑定。这样当Producer 重启后就可以通过正在进行的 Transaction<br>ID 获得原来的 PID。<br>为了管理 Transaction，Kafka 引入了一个新的组件 <strong>Transaction Coordinator</strong>。Producer 就<br>是通过和 Transaction Coordinator 交互获得 Transaction ID 对应的任务状态。Transaction<br>Coordinator 还负责将事务所有写入 Kafka 的一个内部 Topic，这样即使整个服务重启，由于<br>事务状态得到保存，进行中的事务状态可以得到恢复，从而继续进行。</p><h3 id="8-2-Consumer事务"><a href="#8-2-Consumer事务" class="headerlink" title="8.2 Consumer事务"></a>8.2 Consumer事务</h3><p>上述事务机制主要是从 Producer 方面考虑，对于 Consumer 而言，事务的保证就会相对<br>较弱，尤其时无法保证 Commit 的信息被精确消费。<strong>这是由于 Consumer 可以通过 offset 访</strong><br><strong>问任意信息，而且不同的 Segment File 生命周期不同，同一事务的消息可能会出现重启后被</strong><br><strong>删除的情况</strong></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> 消息队列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kafka </tag>
            
            <tag> 消息队列 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RabbitMQ集群模式</title>
      <link href="/2020/02/25/RabbitMQ%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F/"/>
      <url>/2020/02/25/RabbitMQ%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<ul><li>主备模式(了解)</li><li>远程模式(了解)</li><li>镜像模式(推荐使用)</li><li>多活模式(推荐使用)</li></ul><h2 id="1-主备模式"><a href="#1-主备模式" class="headerlink" title="1 主备模式"></a>1 主备模式</h2><p>使用Haproxy做的主备模式</p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/rmqwarren.png" alt=""></p><h2 id="2-远程模式"><a href="#2-远程模式" class="headerlink" title="2 远程模式"></a>2 远程模式</h2><p>远距离通信和复制，所谓Shovel就是我们可以把消息进行不同数据中心的复制工作，我们可以跨地域的让两个mq集群互联。</p><p>在使用了shovel插件后，<strong>模型变成了近端同步确认，远端异步确认方式</strong>，大大提高了订单确认速度，并且还能保证可靠性。</p><p>我们下面看一下Shovel架构模型：</p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/rmqshovel.png" alt=""></p><h2 id="3-镜像模式"><a href="#3-镜像模式" class="headerlink" title="3 镜像模式"></a>3 镜像模式</h2><ul><li><p>镜像模式：集群模式非常经典的就是Mirror镜像模式，保证100%数据不丢失，在实际工作中用的最多的。并且实现集群非常的简单，<strong>一般互联网大厂都会构建这种镜像集群模式</strong>。</p></li><li><p>Mirror镜像队列，目的是为了保证rabbitmq数据的高可靠性解决方案，主要就是实现数据的同步，一般来讲是3-5个实现数据同步（对于100%数据可靠性解决方案一般是3个节点）集群架构如下：</p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/rmqmirror.png" alt=""></p></li></ul><h2 id="4-多活模式"><a href="#4-多活模式" class="headerlink" title="4 多活模式"></a>4 多活模式</h2><ul><li><p>多活模式：这种模式也是实现异地数据复制的主流模式，因为Shovel模式配置比较复杂，所以一般来说实现异地集群都是使用双活或者多活模式来实现的。这种模式需要依赖rabbitmq的<strong>federation</strong>插件，可以实现继续的可靠AMQP数据通信，多活模式在实际配置与应用非常的简单。</p></li><li><p>RabbitMQ部署架构采用双中心模式（多中心），那么在两套（或多套）数据中心中各部署一套RabbitMQ集群，各中心之间还需要实现部分队列消息共享。多活集群架构如下：</p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/rmqfeder.png" alt=""></p></li><li><p><strong>Federation</strong>插件是一个不需要构建Cluster，而在Brokers之间传输消息的高性能插件，Federation插件可以在Brokers或者Cluster之间传输消息，连接双方可以使用<strong>不同的users和vistual hosts</strong>，双方也可以使用版本不同的RabbitMQ和Erlang。Federation插件使用AMQP协议通信，可以接收不连续的传输。</p></li><li><p>Federation Exchanges,可以看成<strong>Downstream从Upstream主动拉取消息</strong>，但并不是拉取所有消息，必须是在Downstream上已经明确定义Bindings关系的Exchange，也就是有实际的物理Queue来接收消息，才会从Upstream拉取消息到Downstream。使用AMQP协议实施代理间通信，Downstream会将绑定关系组合在一起，绑定/解绑命令将会发送到Upstream交换机。因此，FederationExchange只接收具有订阅的消息。</p></li></ul><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/rmqfederation.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> 消息队列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 消息队列 </tag>
            
            <tag> RabbitMQ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RabbitMQ数据可靠性保证</title>
      <link href="/2020/02/25/RabbitMQ%E5%8F%AF%E9%9D%A0%E6%80%A7%E4%BF%9D%E8%AF%81/"/>
      <url>/2020/02/25/RabbitMQ%E5%8F%AF%E9%9D%A0%E6%80%A7%E4%BF%9D%E8%AF%81/</url>
      
        <content type="html"><![CDATA[<h2 id="1-生产者可靠性保证"><a href="#1-生产者可靠性保证" class="headerlink" title="1 生产者可靠性保证"></a>1 生产者可靠性保证</h2><p>在使用RabbitMQ的时候，我们可以通过消息持久化操作来解决因为服务器的异常奔溃导致的消息丢失，除此之外我们还会遇到一个问题，当消息的发布者在将消息发送出去之后，消息到底有没有正确到达broker代理服务器</p><p>如果不进行特殊配置的话，默认情况下发布操作<strong>是不会返回任何信息给生产者的</strong>，也就是默认情况下我们的生产者是不知道消息有没有正确到达broker的，如果在消息到达broker之前已经丢失的话，持久化操作也解决不了这个问题，因为消息根本就没到达代理服务器，你怎么进行持久化，那么这个问题该怎么解决呢？</p><p>RabbitMQ为我们提供了两种方式：</p><ul><li>通过AMQP<strong>事务机制</strong>实现，这也是AMQP协议层面提供的解决方案；</li><li>通过将channel设置成<strong>confirm模式</strong>来实现；</li></ul><h3 id="1-1-事务机制"><a href="#1-1-事务机制" class="headerlink" title="1.1 事务机制"></a>1.1 事务机制</h3><p>选择用 RabbitMQ 提供的事务功能，就是生产者发送数据之前开启 RabbitMQ 事务channel.txSelect，然后发送消息，如果消息没有成功被 RabbitMQ 接收到，那么生产者会收到异常报错，此时就可以回滚事务channel.txRollback，然后重试发送消息；如果收到了消息，那么可以提交事务channel.txCommit。</p><pre><code class="java">// 开启事务channel.txSelecttry {    // 这里发送消息} catch (Exception e) {    channel.txRollback    // 这里再次重发这条消息}// 提交事务channel.txCommit</code></pre><p>但是问题是，RabbitMQ 事务机制（同步）一搞，基本上<strong>吞吐量会下来，因为太耗性能</strong>。</p><h3 id="1-2-Comfirm机制"><a href="#1-2-Comfirm机制" class="headerlink" title="1.2 Comfirm机制"></a>1.2 Comfirm机制</h3><p>生产者将信道设置成confirm模式，一旦信道进入confirm模式，所有在该信道上面发布的消息都会被指派一个唯一的ID(从1开始)，一旦消息被投递到所有匹配的队列之后，broker就会发送一个确认给生产者（包含消息的唯一ID）,这就使得生产者知道消息已经正确到达目的队列了，如果消息和队列是可持久化的，那么确认消息会将消息写入磁盘之后发出，broker回传给生产者的确认消息中deliver-tag域包含了确认消息的序列号，此外broker也可以设置basic.ack的multiple域，表示到这个序列号之前的所有消息都已经得到了处理。</p><p>confirm模式最大的好处在于他是<strong>异步的</strong>，一旦发布一条消息，生产者应用程序就可以在等信道返回确认的同时继续发送下一条消息，当消息最终得到确认之后，生产者应用便可以通过回调方法来处理该确认消息，如果RabbitMQ因为自身内部错误导致消息丢失，就会发送一条nack消息，生产者应用程序同样可以在回调方法中处理该nack消息。</p><p>在channel 被设置成 confirm 模式之后，所有被 publish 的后续消息都将被 confirm（即 ack） 或者被nack一次。但是没有对消息被 confirm 的快慢做任何保证，并且同一条消息不会既被 confirm又被nack 。</p><h4 id="1-2-1-编程模式"><a href="#1-2-1-编程模式" class="headerlink" title="1.2.1 编程模式"></a>1.2.1 编程模式</h4><p>confirm有三种编程方式：</p><ul><li><strong>批量confirm模式</strong>：每发送一批消息后，调用waitForConfirms()方法，等待服务器端confirm。</li><li><strong>异步confirm模式</strong>：提供一个回调方法，服务端confirm了一条或者多条消息后Client端会回调这个方法(推荐使用的)</li></ul><h2 id="2-消费者可靠性保证"><a href="#2-消费者可靠性保证" class="headerlink" title="2 消费者可靠性保证"></a>2 消费者可靠性保证</h2><p>在Consumer中Confirm模式中分为</p><ul><li>手动确认</li><li>自动确认</li></ul><h3 id="2-1-自动确认"><a href="#2-1-自动确认" class="headerlink" title="2.1 自动确认"></a>2.1 自动确认</h3><p>默认模式是自动确认模式:消息在发送后立即被认为是发送成功。 这种模式可以提高吞吐量（只要消费者能够跟上），不过会降低投递和消费者处理的安全性。 这种模式通常被称为“发后即忘”。 与手动确认模式不同，如果消费者的TCP连接或信道在成功投递之前关闭，该消息则会丢失。</p><h3 id="2-２-手动确认"><a href="#2-２-手动确认" class="headerlink" title="2.２ 手动确认"></a>2.２ 手动确认</h3><p>为了保证消息从队列可靠地到达消费者，RabbitMQ提供消息确认机制(message acknowledgment)。消费者在声明队列时，可以指定noAck参数，当<strong>noAck=false时，RabbitMQ会等待消费者显式发回ack信号后才从内存(和磁盘，如果是持久化消息的话)中移去消息</strong>。否则，RabbitMQ会在队列中消息被消费后<strong>立即删除</strong>它。</p><p>采用消息确认机制后，只要令noAck=false，消费者就有足够的时间处理消息(任务)，不用担心处理消息过程中消费者进程挂掉后消息丢失的问题，因为RabbitMQ会一直持有消息直到消费者显式调用basicAck为止。</p><p>当noAck=false时，对于RabbitMQ服务器端而言，队列中的消息分成了两部分：</p><ul><li><p>一部分是等待投递给消费者的消息；</p></li><li><p>一部分是已经投递给消费者，但是还没有收到消费者ack信号的消息。</p></li></ul><p>RabbitMQ<strong>不会为没有ack确认的消息设置超时时间</strong>，它判断此消息是否需要重新投递给消费者的唯一依据是消费该消息的消费者连接是否已经断开。这么设计的原因是RabbitMQ允许消费者消费一条消息的时间可以很久很久。</p><p><strong>建议使用手动模式</strong></p><ul><li>如果服务器端<strong>一直没有收到消费者的ack信号，并且消费此消息的消费者已经断开连接</strong>，则服务器端会<strong>安排该消息重新进入队列，靠近队列头位置</strong>，等待投递给下一个消费者（也可能还是原来的那个消费者）。</li><li>如果收到了<strong>nack/reject信号且requeue为true</strong>,服务器端也会<strong>安排该消息重新进入队列，靠近队列头位置</strong>，等待投递给下一个消费者（也可能还是原来的那个消费者）。</li><li>如果收到了<strong>nack/reject信号且requeue为false</strong>,则<strong>进入死信队列</strong></li></ul><h2 id="3-broke可靠性保证"><a href="#3-broke可靠性保证" class="headerlink" title="3 broke可靠性保证"></a>3 broke可靠性保证</h2><p>broke可靠性需要两方面保证:</p><ul><li>持久化保证</li><li>集群高可用保证</li></ul><h3 id="3-1-持久化保证"><a href="#3-1-持久化保证" class="headerlink" title="3.1 持久化保证"></a>3.1 持久化保证</h3><p>就是 RabbitMQ 自己弄丢了数据，这个你必须<strong>开启 RabbitMQ 的持久化</strong>，就是消息写入之后会持久化到磁盘，哪怕是 RabbitMQ 自己挂了，恢复之后会自动读取之前存储的数据，一般数据不会丢。除非极其罕见的是，RabbitMQ 还没持久化，自己就挂了，可能导致少量数据丢失，但是这个概率较小。</p><p>设置持久化有两个步骤：</p><ul><li><strong>创建 queue 的时候将其设置为持久化</strong>,这样就可以保证 RabbitMQ 持久化 queue 的元数据，但是它是不会持久化 queue 里的数据的</li><li>发送消息的时候将消息的 <strong>deliveryMode 设置为 2</strong>就是将消息设置为持久化的，此时 RabbitMQ 就会将消息持久化到磁盘上去。</li></ul><p><strong>必须要同时设置这两个持久化才行</strong>，RabbitMQ 哪怕是挂了，再次重启，也会从磁盘上重启恢复 queue，恢复这个 queue 里的数据。</p><p>注意，哪怕是你给 RabbitMQ 开启了持久化机制，也有一种可能，就是这个消息写到了 RabbitMQ 中，但是还没来得及持久化到磁盘上，结果不巧，此时 RabbitMQ 挂了，就会导致内存里的一点点数据丢失。</p><p>所以，持久化可以跟生产者那边的 confirm 机制配合起来，只有消息被持久化到磁盘之后，才会通知生产者 ack 了，所以哪怕是在持久化到磁盘之前，RabbitMQ 挂了，数据丢了，生产者收不到 ack，你也是可以自己重发的。</p><h3 id="3-2-集群高可用"><a href="#3-2-集群高可用" class="headerlink" title="3.2 集群高可用"></a>3.2 集群高可用</h3><p><strong>开启镜像高可用模式</strong>。跟普通集群模式不一样的是，在镜像集群模式下，你创建的 queue，无论元数据还是 queue 里的消息都会存在于多个实例上，就是说，<strong>每个 RabbitMQ 节点都有这个 queue 的一个完整镜像</strong>，包含 queue 的全部数据的意思。然后每次你写消息到 queue 的时候，都会自动把消息同步到多个实例的 queue 上。</p><h2 id="4-总结"><a href="#4-总结" class="headerlink" title="4 总结"></a>4 总结</h2><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/rmqsis.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> 消息队列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 消息队列 </tag>
            
            <tag> RabbitMQ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RabbitMQ特殊队列</title>
      <link href="/2020/02/25/RabbitMQ%E7%89%B9%E6%AE%8A%E9%98%9F%E5%88%97/"/>
      <url>/2020/02/25/RabbitMQ%E7%89%B9%E6%AE%8A%E9%98%9F%E5%88%97/</url>
      
        <content type="html"><![CDATA[<ul><li>死信队列</li><li>延时队列</li><li>优先级队列</li></ul><h2 id="1-死信队列"><a href="#1-死信队列" class="headerlink" title="1 死信队列"></a>1 死信队列</h2><p>DLX, Dead-Letter-Exchange</p><p>利用DLX, 当消息在一个队列中变成死信（dead message）之后，它能被重新publish到<strong>另一个Exchange</strong>，这个Exchange就是DLX。</p><h3 id="1-1-产生情况"><a href="#1-1-产生情况" class="headerlink" title="1.1 产生情况"></a>1.1 产生情况</h3><p>消息变成死信一向有一下几种情况:</p><ul><li><strong>消息被拒绝（basic.reject/ basic.nack）并且requeue=false</strong></li><li><strong>消息TTL过期</strong></li><li><strong>队列达到最大长度</strong></li></ul><h3 id="1-2-特性"><a href="#1-2-特性" class="headerlink" title="1.2 特性"></a>1.2 特性</h3><ul><li>DLX也是一个<strong>正常的Exchange</strong>,和一般的Exchange没有区别，它能在任何的队列上被指定，实际上就是设置某个队列的属性。</li><li>当这个队列中有死信时，RabbitMQ就会<strong>自动的将这个消息重新发布</strong>到设置的Exchange上去，进而被路由到另一个队列。</li><li><strong>可以监听这个队列中消息</strong>做相应的处理，这个特性可以弥补RabbitMQ3.0以前支持的immediate参数的功能。</li></ul><h3 id="1-3-设置"><a href="#1-3-设置" class="headerlink" title="1.3 设置"></a>1.3 设置</h3><ul><li>首先需要设置死信队列的exchange和queue,然后进行绑定:<ul><li>Exchange: dlx.exchange</li><li>Queue: dlx.queue</li><li>Routing Key: #</li></ul></li><li>然后我们进行正常声明交换机、队列、绑定，只不过我们需要在队列加上一个参数即可：arguments.put(nx-dead-letter-exchange”,”dlx.exchange”)；</li><li>这样消息在过期、requeue、队列在达到最大长度时，消息就可以直接路由到死信队列</li></ul><h2 id="2-延时队列"><a href="#2-延时队列" class="headerlink" title="2 延时队列"></a>2 延时队列</h2><p><strong>延时队列</strong>，首先，它是一种队列，队列意味着内部的元素是<strong>有序</strong>的，元素出队和入队是有方向性的，元素从一端进入，从另一端取出。</p><p>其次，<strong>延时队列</strong>，最重要的特性就体现在它的<strong>延时</strong>属性上，跟普通的队列不一样的是，<strong>普通队列中的元素总是等着希望被早点取出处理，而延时队列中的元素则是希望被在指定时间得到取出和处理</strong>，所以延时队列中的元素是都是带时间属性的，通常来说是需要被处理的消息或者任务。</p><p>简单来说，延时队列就是用来存放需要在指定时间被处理的元素的队列。</p><h3 id="2-1-使用场景"><a href="#2-1-使用场景" class="headerlink" title="2.1 使用场景"></a>2.1 使用场景</h3><p>那么什么时候需要用延时队列呢？考虑一下以下场景：</p><ul><li>订单在十分钟之内未支付则自动取消。</li><li>新创建的店铺，如果在十天内都没有上传过商品，则自动发送消息提醒。</li><li>账单在一周内未支付，则自动结算。</li><li>用户注册成功后，如果三天内没有登陆则进行短信提醒。</li><li>用户发起退款，如果三天内没有得到处理则通知相关运营人员。</li><li>预定会议后，需要在预定的时间点前十分钟通知各个与会人员参加会议。</li></ul><p>这些场景都有一个特点，需要在某个事件发生之后或者之前的指定时间点完成某一项任务，如：发生订单生成事件，在十分钟之后检查该订单支付状态，然后将未支付的订单进行关闭；发生店铺创建事件，十天后检查该店铺上新商品数，然后通知上新数为0的商户；发生账单生成事件，检查账单支付状态，然后自动结算未支付的账单；发生新用户注册事件，三天后检查新注册用户的活动数据，然后通知没有任何活动记录的用户；发生退款事件，在三天之后检查该订单是否已被处理，如仍未被处理，则发送消息给相关运营人员；发生预定会议事件，判断离会议开始是否只有十分钟了，如果是，则通知各个与会人员。</p><p>看起来<strong>似乎使用定时任务</strong>，一直轮询数据，每秒查一次，取出需要被处理的数据，然后处理不就完事了吗？如果数据量比较少，确实可以这样做，比如：对于“如果账单一周内未支付则进行自动结算”这样的需求，如果对于时间不是严格限制，而是宽松意义上的一周，那么每天晚上跑个定时任务检查一下所有未支付的账单，确实也是一个可行的方案。但对于数据量比较大，并且时效性较强的场景，如：“订单十分钟内未支付则关闭“，短期内未支付的订单数据可能会有很多，活动期间甚至会达到百万甚至千万级别，对这么庞大的数据量仍旧使用轮询的方式显然是不可取的，很可能在一秒内无法完成所有订单的检查，同时会给数据库带来很大压力，无法满足业务要求而且性能低下。</p><p>这时候，延时队列就可以闪亮登场了，<strong>以上场景，正是延时队列的用武之地</strong>。</p><p>既然延时队列可以解决很多特定场景下，带时间属性的任务需求，那么如何构造一个延时队列呢？接下来，本文将介绍如何用RabbitMQ来实现延时队列。</p><h3 id="2-2-RabbitMQ中的TTL"><a href="#2-2-RabbitMQ中的TTL" class="headerlink" title="2.2 RabbitMQ中的TTL"></a>2.2 RabbitMQ中的TTL</h3><p>在介绍延时队列之前，还需要先介绍一下RabbitMQ中的一个高级特性——<strong>TTL（Time To Live）</strong>。</p><p>TTL是什么呢？TTL是RabbitMQ中一个消息或者队列的属性，表明一条消息或者该队列中的所有消息的最大存活时间，单位是毫秒。换句话说，如果一条消息设置了TTL属性或者进入了设置TTL属性的队列，那么这条消息如果在TTL设置的时间内没有被消费，则会成为“死信”（至于什么是死信，请翻看上一篇）。如果同时配置了队列的TTL和消息的TTL，那么较小的那个值将会被使用。</p><p>那么，如何设置这个TTL值呢？有两种方式，第一种是在创建队列的时候设置队列的“<strong>x-message-ttl</strong>”属性，如下：</p><pre><code class="java">Map&lt;String, Object&gt; args = new HashMap&lt;String, Object&gt;();args.put(&quot;x-message-ttl&quot;, 6000);channel.queueDeclare(queueName, durable, exclusive, autoDelete, args);</code></pre><p>这样所有被投递到该队列的消息都最多不会存活超过6s。</p><p>另一种方式便是针对每条消息设置TTL，代码如下：</p><pre><code class="java">AMQP.BasicProperties.Builder builder = new AMQP.BasicProperties.Builder();builder.expiration(&quot;6000&quot;);AMQP.BasicProperties properties = builder.build();channel.basicPublish(exchangeName, routingKey, mandatory, properties, &quot;msg body&quot;.getBytes());</code></pre><p>这样这条消息的过期时间也被设置成了6s。</p><p>但这两种方式是有区别的，<strong>如果设置了队列的TTL属性，那么一旦消息过期，就会被队列丢弃，而第二种方式，消息即使过期，也不一定会被马上丢弃，因为消息是否过期是在即将投递到消费者之前判定的，如果当前队列有严重的消息积压情况，则已过期的消息也许还能存活较长时间</strong>。</p><p>另外，还需要注意的一点是，如果不设置TTL，表示消息永远不会过期，如果将TTL设置为0，则表示除非此时可以直接投递该消息到消费者，否则该消息将会被丢弃。</p><h3 id="2-3-实现延时队列"><a href="#2-3-实现延时队列" class="headerlink" title="2.3 实现延时队列"></a>2.3 实现延时队列</h3><h4 id="2-3-1-通过死信队列实现"><a href="#2-3-1-通过死信队列实现" class="headerlink" title="2.3.1 通过死信队列实现"></a>2.3.1 通过死信队列实现</h4><p>延时队列，不就是想要消息延迟多久被处理吗，TTL则刚好能让消息在延迟多久之后成为死信，另一方面，成为死信的消息都会被投递到死信队列里，这样只需要消费者一直消费死信队列里的消息就万事大吉了，因为里面的消息都是希望被立即处理的消息。</p><p>但如果使用在消息属性上设置TTL的方式，消息可能并不会按时“死亡“，因为RabbitMQ只会检查第一个消息是否过期，如果过期则丢到死信队列，索引如果第一个消息的延时时长很长，而第二个消息的延时时长很短，则第二个消息并不会优先得到执行</p><p><strong>所以不推荐使用此种方式!</strong></p><h4 id="2-3-2-通过插件实现"><a href="#2-3-2-通过插件实现" class="headerlink" title="2.3.2 通过插件实现"></a>2.3.2 通过插件实现</h4><p>安装一个插件即可：<a href="https://www.rabbitmq.com/community-plugins.html" target="_blank" rel="noopener">https://www.rabbitmq.com/community-plugins.html</a> ，下载rabbitmq_delayed_message_exchange插件，然后解压放置到RabbitMQ的插件目录。</p><p>接下来，进入RabbitMQ的安装目录下的sbin目录，执行下面命令让该插件生效，然后重启RabbitMQ。</p><h2 id="3-优先级队列"><a href="#3-优先级队列" class="headerlink" title="3 优先级队列"></a>3 优先级队列</h2><p>优先级队列，顾名思义，具有更高优先级的队列具有较高的优先权，优先级高的消息具备优先被消费的特权。</p><h3 id="3-1-实现方式"><a href="#3-1-实现方式" class="headerlink" title="3.1 实现方式"></a>3.1 实现方式</h3><p>可以通过设置<strong>x-max-priority</strong>属性来实现优先级队列</p><p>当然，在消费端速度大于生产端速度，且broker中没有消息堆积的话，对发送的消息设置优先级也没什么实际意义，因为发送端刚发送完一条消息就被消费端消费了，那么就相当于broker至多只有一条消息，那么对于单条消息来说优先级是没有什么意义的。</p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> 消息队列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 消息队列 </tag>
            
            <tag> RabbitMQ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RabbitMQ介绍</title>
      <link href="/2020/02/25/RabbitMQ%E4%BB%8B%E7%BB%8D/"/>
      <url>/2020/02/25/RabbitMQ%E4%BB%8B%E7%BB%8D/</url>
      
        <content type="html"><![CDATA[<h2 id="1-RabbitMQ是什么"><a href="#1-RabbitMQ是什么" class="headerlink" title="1 RabbitMQ是什么"></a>1 RabbitMQ是什么</h2><p>RabbitMQ 是一个由 Erlang 语言开发的 AMQP 的开源实现。</p><blockquote><p>AMQP ：Advanced Message Queue，高级消息队列协议。它是应用层协议的一个开放标准，为面向消息的中间件设计，基于此协议的客户端与消息中间件可传递消息，并不受产品、开发语言等条件的限制。</p></blockquote><h2 id="2-RabbitMQ特点"><a href="#2-RabbitMQ特点" class="headerlink" title="2 RabbitMQ特点"></a>2 RabbitMQ特点</h2><ul><li>可靠性</li><li>灵活路由机制</li><li>消息集群</li><li>高可用</li></ul><h3 id="2-1-可靠性"><a href="#2-1-可靠性" class="headerlink" title="2.1 可靠性"></a>2.1 可靠性</h3><p>RabbitMQ 使用一些机制来保证可靠性，如持久化、传输确认、发布确认。</p><h3 id="2-2-灵活路由机制"><a href="#2-2-灵活路由机制" class="headerlink" title="2.2 灵活路由机制"></a>2.2 灵活路由机制</h3><p>在消息进入队列之前，通过 Exchange 来路由消息的。对于典型的路由功能，RabbitMQ 已经提供了一些内置的 Exchange 来实现。针对更复杂的路由功能，可以将多个 Exchange 绑定在一起，也通过插件机制实现自己的 Exchange 。</p><h3 id="2-3-消息集群"><a href="#2-3-消息集群" class="headerlink" title="2.3 消息集群"></a>2.3 消息集群</h3><p>多个 RabbitMQ 服务器可以组成一个集群，形成一个逻辑 Broker 。</p><h3 id="2-4-高可用"><a href="#2-4-高可用" class="headerlink" title="2.4 高可用"></a>2.4 高可用</h3><p>队列可以在集群中的机器上进行镜像，使得在部分节点出问题的情况下队列仍然可用。</p><h2 id="3-AMQP协议"><a href="#3-AMQP协议" class="headerlink" title="3 AMQP协议"></a>3 AMQP协议</h2><h3 id="3-1-什么是AMQP协议"><a href="#3-1-什么是AMQP协议" class="headerlink" title="3.1 什么是AMQP协议"></a>3.1 什么是AMQP协议</h3><p>是具有现代特征的二进制协议。是一个提供统一消息服务的应用层标准高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计。</p><h3 id="3-2-协议模型"><a href="#3-2-协议模型" class="headerlink" title="3.2 协议模型"></a>3.2 协议模型</h3><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/amqpprot.png" alt=""></p><h3 id="3-3-核心概念"><a href="#3-3-核心概念" class="headerlink" title="3.3 核心概念"></a>3.3 核心概念</h3><ul><li><strong>Server</strong>:又称<strong>Broker</strong>,接受客户端的连接，实现AMQP实体服务</li><li><strong>Connection</strong>:连接，应用程序与Broker的网络连接</li><li><strong>Channel</strong>:网络信道，几乎所有的操作都在Channel中进行，Channel是进行消息读写的通道。客户端可建立多个Channel,每个Channel代表一个会话任务</li><li><strong>Message</strong>:消息，服务器和应用程序之间传送的数据，由Properties和Body组成。Properties可以对消息进行修饰，比如消息的优先级、延迟等高级特性；Body则就是消息体内容</li><li><strong>Virtual host</strong>:虚拟地址，用于进行逻辑隔离，最上层的消息路由。—个Virtual Host里面可以有若干个Exchange和Queue,<strong>同一个 VHost里面不能有相同名称的Exchange或Queue</strong></li><li><strong>Exchange</strong>:交换机，接收消息，根据路由键转发消息到绑定的队列</li><li><strong>Binding</strong>: Exchange和Queue之间的虚拟连接，binding中可以包含routing key</li><li><strong>Routing key</strong>: 一个路由规则,虚拟机可用它来确定如何路由一个特定消息</li><li><strong>Queue</strong>:也称为Message Queue,消息队列，保存消息并将它们转发给消费者</li></ul><h4 id="3-3-1-channel"><a href="#3-3-1-channel" class="headerlink" title="3.3.1 channel"></a>3.3.1 channel</h4><p>信道是生产消费者与rabbit通信的渠道，生产者publish或是消费者subscribe一个队列都是通过信道来通信的。信道是建立在TCP连接上的虚拟连接，rabbitmq在一条TCP上建立成百上千个信道来达到多个线程处理，这个TCP被多个线程共享，每个线程对应一个信道，信道在rabbit都有唯一的ID ,保证了信道私有性，对应上唯一的线程使用。</p><blockquote><p>疑问：为什么不建立多个TCP连接呢？原因是rabbit保证性能，系统为每个线程开辟一个TCP是非常消耗性能，每秒成百上千的建立销毁TCP会严重消耗系统。所以rabbitmq选择建立多个信道（建立在tcp的虚拟连接）连接到rabbit上。</p></blockquote><h4 id="3-3-2-queue"><a href="#3-3-2-queue" class="headerlink" title="3.3.2 queue"></a>3.3.2 queue</h4><ol><li>推模式：通过AMQP的basic.consume命令订阅，有消息会自动接收，吞吐量高</li><li>拉模式：通过AMQP的bsaic.get命令</li></ol><p>注：当队列拥有多个消费者时，队列收到的消息将以循环的方式发送给消费者。每条消息只会发送给一个订阅的消费者</p><h2 id="4-RabbitMQ整体结构"><a href="#4-RabbitMQ整体结构" class="headerlink" title="4 RabbitMQ整体结构"></a>4 RabbitMQ整体结构</h2><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/rabbitserver.png" alt=""></p><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/rabbitmqtxt.png" alt=""></p><h2 id="5-工作模式"><a href="#5-工作模式" class="headerlink" title="5 工作模式"></a>5 工作模式</h2><h3 id="5-1-simple-queue"><a href="#5-1-simple-queue" class="headerlink" title="5.1 simple queue"></a>5.1 simple queue</h3><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/rmqsimple.png" alt=""></p><ol><li>消息产生消息，将消息放入队列</li><li>消息的消费者(consumer) 监听 消息队列,如果队列中有消息,就消费掉,消息被拿走后,自动从队列中删除</li></ol><h3 id="5-2-work-queue"><a href="#5-2-work-queue" class="headerlink" title="5.2 work queue"></a>5.2 work queue</h3><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/rmqwork.png" alt=""></p><ol><li>消息产生者将消息放入队列消费者可以有多个,消费者1,消费者2同时监听同一个队列,消息被消费。C1 C2共同争抢当前的消息队列内容,谁先拿到谁负责消费消息(隐患：高并发情况下,默认会产生某一个消息被多个消费者共同使用,可以设置一个开关(syncronize) 保证一条消息只能被一个消费者使用)。</li></ol><h3 id="5-3-publish-subscribe"><a href="#5-3-publish-subscribe" class="headerlink" title="5.3 publish/subscribe"></a>5.3 publish/subscribe</h3><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/rmqsub.png" alt=""></p><ol><li>每个消费者监听自己的队列；</li><li>生产者将消息发给broker，由交换机将消息转发到绑定此交换机的每个队列，每个绑定交换机的队列都将接收到消息。</li></ol><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/rmqfanout.png" alt=""></p><h3 id="5-4-routing"><a href="#5-4-routing" class="headerlink" title="5.4 routing"></a>5.4 routing</h3><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/rmqroute.png" alt=""></p><ol><li>消息生产者将消息发送给交换机按照路由判断,路由是字符串(info) 当前产生的消息携带路由字符(对象的方法),交换机根据路由的key,只能匹配上路由key对应的消息队列,对应的消费者才能消费消息;</li><li>根据业务功能定义路由字符串</li><li>从系统的代码逻辑中获取对应的功能字符串,将消息任务扔到对应的队列中。</li><li>业务场景:error 通知;EXCEPTION;错误通知的功能;传统意义的错误通知;客户通知;利用key路由,可以将程序中的错误封装成消息传入到消息队列中,开发者可以自定义消费者,实时接收错误;</li></ol><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/rmqdirect.png" alt=""></p><h3 id="5-5-topic"><a href="#5-5-topic" class="headerlink" title="5.5 topic"></a>5.5 topic</h3><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/rmqtopic.png" alt=""></p><ol><li>星号井号代表通配符</li><li>星号代表多个单词,井号代表一个单词</li><li>路由功能添加模糊匹配</li><li>消息产生者产生消息,把消息交给交换机</li><li>交换机根据key的规则模糊匹配到对应的队列,由队列的监听消费者接收消息消费</li></ol><p><img src="http://dist415.oss-cn-beijing.aliyuncs.com/rmqtopicex.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> 消息队列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 消息队列 </tag>
            
            <tag> RabbitMQ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>19.Redis雪崩击穿穿透</title>
      <link href="/2020/02/23/19-Redis%E9%9B%AA%E5%B4%A9%E5%87%BB%E7%A9%BF%E7%A9%BF%E9%80%8F/"/>
      <url>/2020/02/23/19-Redis%E9%9B%AA%E5%B4%A9%E5%87%BB%E7%A9%BF%E7%A9%BF%E9%80%8F/</url>
      
        <content type="html"><![CDATA[<h2 id="19-1-雪崩"><a href="#19-1-雪崩" class="headerlink" title="19.1 雪崩"></a>19.1 雪崩</h2><h3 id="19-1-1-定义"><a href="#19-1-1-定义" class="headerlink" title="19.1.1 定义"></a>19.1.1 定义</h3><p>缓存同一时间大面积的失效，后面的请求都会落到数据库上，造成数据库短时间内承受大量请求而崩掉。</p><h3 id="19-1-2-解决方式"><a href="#19-1-2-解决方式" class="headerlink" title="19.1.2 解决方式"></a>19.1.2 解决方式</h3><ul><li><p>事前:尽量保证整个 redis 集群的高可用性，发现机器宕机尽快补上。选择合适的内存淘汰策略</p><ul><li><strong>缓存预热</strong>:数据加热的含义就是在正式部署之前，把可能的数据先预先访问一遍，这样部分可能大量访问的数据就会加载到缓存中。可以使用阿里开源的<strong>canal</strong></li><li><strong>设置热点数据永远不过期</strong>，有更新操作就更新缓存就好了</li><li>往Redis存数据的时候，把每个Key的<strong>失效时间都加个随机值</strong>就好了，这样可以保证数据不会在同一时间大面积失效</li></ul><pre><code class="java">setRedis（Key，value，time + Math.random() * 10000）；</code></pre></li><li><p>事中：本地ehcache缓存 + hystrix限流&amp;降级，避免MySQL崩掉</p></li><li><p>事后：利用 redis 持久化机制保存的数据尽快恢复缓存</p></li></ul><h2 id="19-2-击穿"><a href="#19-2-击穿" class="headerlink" title="19.2 击穿"></a>19.2 击穿</h2><h3 id="19-2-1-定义"><a href="#19-2-1-定义" class="headerlink" title="19.2.1 定义"></a>19.2.1 定义</h3><p>缓存击穿，就是说某个 key 非常热点，访问非常频繁，处于集中式高并发访问的情况，当这个 key 在失效的瞬间，大量的请求就击穿了缓存，直接请求数据库，就像是在一道屏障上凿开了一个洞。</p><h3 id="19-2-2-解决方式"><a href="#19-2-2-解决方式" class="headerlink" title="19.2.2 解决方式"></a>19.2.2 解决方式</h3><p>不同场景下的解决方式可如下：</p><ul><li>若缓存的数据是基本不会发生更新的，则可尝试将该热点数据设置为永不过期。</li><li>若缓存的数据更新不频繁，且缓存刷新的整个流程耗时较少的情况下，则可以采用基于 redis、zookeeper 等分布式中间件的分布式互斥锁，或者本地互斥锁以保证仅少量的请求能请求数据库并重新构建缓存，其余线程则在锁释放后能访问到新缓存。</li><li>若缓存的数据更新频繁或者缓存刷新的流程耗时较长的情况下，可以利用定时线程在缓存过期前主动的重新构建缓存或者延后缓存的过期时间，以保证所有的请求能一直访问到对应的缓存。</li></ul><h2 id="19-3-穿透"><a href="#19-3-穿透" class="headerlink" title="19.3 穿透"></a>19.3 穿透</h2><h3 id="19-3-1-定义"><a href="#19-3-1-定义" class="headerlink" title="19.3.1 定义"></a>19.3.1 定义</h3><p>对于系统A，假设一秒 5000 个请求，结果其中 4000 个请求是黑客发出的恶意攻击。</p><p>黑客发出的那 4000 个攻击，缓存中查不到，每次你去数据库里查，也查不到。</p><p>举个栗子。数据库 id 是从 1 开始的，结果黑客发过来的请求 id 全部都是负数。这样的话，缓存中不会有，请求每次都“视缓存于无物”，直接查询数据库。这种恶意攻击场景的缓存穿透就会直接把数据库给打死。</p><h3 id="19-3-2-解决方式"><a href="#19-3-2-解决方式" class="headerlink" title="19.3.2 解决方式"></a>19.3.2 解决方式</h3><ul><li><strong>初级</strong>:每次系统 A 从数据库中只要没查到，就<strong>写一个空值到缓存</strong>里去，比如 <code>set -999 UNKNOWN</code>。然后设置一个过期时间，这样的话，下次有相同的 key 来访问的时候，在缓存失效之前，都可以直接从缓存中取数据。</li><li><strong>进阶</strong>: <strong>在接口层增加校验</strong>，比如用户鉴权校验，参数做校验，不合法的参数直接代码Return，比如：id 做基础校验，id &lt;=0的直接拦截等。</li><li><strong>高级</strong>: 使用<strong>布隆过滤器（Bloom Filter）</strong>这个也能很好的防止缓存穿透的发生，他的原理也很简单就是利用高效的数据结构和算法快速<strong>判断出你这个Key是否在数据库中存在，不存在你return就好了，存在你就去查了DB刷新KV再return</strong>。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>20.Redis缓存数据库读写一致性</title>
      <link href="/2020/02/23/20-Redis%E7%BC%93%E5%AD%98%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AF%BB%E5%86%99%E4%B8%80%E8%87%B4%E6%80%A7/"/>
      <url>/2020/02/23/20-Redis%E7%BC%93%E5%AD%98%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AF%BB%E5%86%99%E4%B8%80%E8%87%B4%E6%80%A7/</url>
      
        <content type="html"><![CDATA[<h2 id="20-1-Cache-Aside-Pattern"><a href="#20-1-Cache-Aside-Pattern" class="headerlink" title="20.1 Cache Aside Pattern"></a>20.1 Cache Aside Pattern</h2><p>最经典的缓存+数据库读写的模式:Cache Aside Pattern 　旁路缓存</p><p>有几个原则:</p><ul><li>读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。</li><li>更新的时候，先<strong>删除缓存</strong>，然后再更新数据库。</li></ul><h3 id="20-1-1-删除缓存"><a href="#20-1-1-删除缓存" class="headerlink" title="20.1.1 删除缓存"></a>20.1.1 删除缓存</h3><p>更新时是删除缓存，而不是更新缓存</p><ul><li><p>缓存有的时候不但是从数据库里取出的一个简单值,可能会经过复杂计算</p></li><li><p>更新的数据不一定会被频繁访问到,如果去更新缓存可能会<strong>造成大量的冷数据</strong></p></li><li><p>懒加载思想:<strong>用到缓存才去算缓存</strong></p></li></ul><h2 id="20-2-双写不一致问题"><a href="#20-2-双写不一致问题" class="headerlink" title="20.2 双写不一致问题"></a>20.2 双写不一致问题</h2><h3 id="20-2-1-更新顺序颠倒情形"><a href="#20-2-1-更新顺序颠倒情形" class="headerlink" title="20.2.1 更新顺序颠倒情形"></a>20.2.1 更新顺序颠倒情形</h3><p>问题描述: <strong>先修改数据库,再删除缓存</strong>,当删除缓存失败了,会导致数据库中是新数据,缓存中是旧数据</p><p>解决思路: <strong>先删除缓存,再更新数据库</strong>,如果删除缓存成功了,修改数据库失败了,那么数据库中是旧数据,缓存中是空的,那么数据不会不一致,因为读的时候缓存没有,则读数据库中的旧数据,然后更新到缓存中</p><h3 id="20-2-2-更新数据库并发读情形"><a href="#20-2-2-更新数据库并发读情形" class="headerlink" title="20.2.2 更新数据库并发读情形"></a>20.2.2 更新数据库并发读情形</h3><p>问题描述:数据发生了变更,先删除了缓存,然后要去修改数据库,<strong>此时还没有修改数据库</strong>,一个请求过来去读缓存,没有读到,去查数据库,<strong>查到了修改前的旧数据,放到缓存中</strong>,数据变更的程序完成了数据库的修改,此时数据库和缓存的数据不一致了</p><p>解决思路:　更新数据的时候，根据数据的唯一标识，hash之后，<strong>发送到一个队列中,队列可是redis的队列,Java的内存队列</strong>等,读取数据的时候，如果发现数据不在缓存中，那么将重新执行“读取数据+更新缓存”的操作，根据唯一标识路由之后，也发送到同一个队列中。</p><p>一个队列对应一个工作线程，每个工作线程串行拿到对应的操作，然后一条一条的执行。这样的话，一个数据变更的操作，先删除缓存，然后再去更新数据库，但是还没完成更新。此时如果一个读请求过来，没有读到缓存，那么可以先将缓存更新的请求发送到队列中，此时会在队列中积压，然后同步等待缓存更新完成。</p><p>这里有一个<strong>优化点</strong>，一个队列中，<strong>其实多个更新缓存请求串在一起是没意义的</strong>，因此可以做过滤，如果发现队列中已经有一个更新缓存的请求了，那么就不用再放个更新请求操作进去了，直接等待前面的更新操作请求完成即可。</p><p>待那个队列对应的工作线程完成了上一个操作的数据库的修改之后，才会去执行下一个操作，也就是缓存更新的操作，此时会从数据库中读取最新的值，然后写入缓存中。</p><p>如果请求还在等待时间范围内，不断轮询发现可以取到值了，那么就直接返回；如果请求等待的时间超过一定时长，那么这一次直接从数据库中读取当前的旧值</p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>18.Redis高可用模式总结</title>
      <link href="/2020/02/23/18-Redis%E9%AB%98%E5%8F%AF%E7%94%A8%E6%A8%A1%E5%BC%8F%E6%80%BB%E7%BB%93/"/>
      <url>/2020/02/23/18-Redis%E9%AB%98%E5%8F%AF%E7%94%A8%E6%A8%A1%E5%BC%8F%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<h2 id="18-1-Redis的三种高可用模式"><a href="#18-1-Redis的三种高可用模式" class="headerlink" title="18.1 Redis的三种高可用模式"></a>18.1 Redis的三种高可用模式</h2><ul><li>Redis主从模式</li><li>Redis哨兵模式</li><li>Redis cluster模式</li></ul><h2 id="18-2-使用场景"><a href="#18-2-使用场景" class="headerlink" title="18.2 使用场景"></a>18.2 使用场景</h2><h3 id="18-2-1-Redis主从"><a href="#18-2-1-Redis主从" class="headerlink" title="18.2.1 Redis主从"></a>18.2.1 Redis主从</h3><p>单机Redis无法支撑较大的QPS，如果业务类型是读多写少类型，需要采用多个只读节点的部署方式来突破Redis单线程的性能瓶颈。</p><h3 id="18-2-2-Redis哨兵"><a href="#18-2-2-Redis哨兵" class="headerlink" title="18.2.2 Redis哨兵"></a>18.2.2 Redis哨兵</h3><p>通常搭建了主从之后建议再配合哨兵模式使用,去保证redis主从架构的高可用性</p><h3 id="18-2-3-Redis-cluster"><a href="#18-2-3-Redis-cluster" class="headerlink" title="18.2.3 Redis cluster"></a>18.2.3 Redis cluster</h3><p>redis cluster 主要是针对海量数据+高并发+高可用的场景，如果是海量数据，如果你的数据量很大，那么建议就用redis cluster</p><h2 id="18-3-应用连接方式"><a href="#18-3-应用连接方式" class="headerlink" title="18.3 应用连接方式"></a>18.3 应用连接方式</h2><p>不同的高可用模式,应用的连接方式会发生改变,下面以python代码示例:</p><h3 id="18-3-1-连接-sentinel"><a href="#18-3-1-连接-sentinel" class="headerlink" title="18.3.1 连接 sentinel"></a>18.3.1 连接 sentinel</h3><pre><code class="python">&gt;&gt;&gt; from redis.sentinel import Sentinel&gt;&gt;&gt; sentinel = Sentinel([(&#39;localhost&#39;, 26379)], socket_timeout=0.1)&gt;&gt;&gt; master = sentinel.master_for(&#39;mymaster&#39;, socket_timeout=0.1)&gt;&gt;&gt; master.set(&#39;foo&#39;, &#39;bar&#39;)&gt;&gt;&gt; slave = sentinel.slave_for(&#39;mymaster&#39;, socket_timeout=0.1)&gt;&gt;&gt; slave.get(&#39;foo&#39;)&#39;bar&#39;</code></pre><h3 id="18-3-2-连接cluster"><a href="#18-3-2-连接cluster" class="headerlink" title="18.3.2 连接cluster"></a>18.3.2 连接cluster</h3><pre><code class="python">&gt;&gt;&gt; from rediscluster import RedisCluster&gt;&gt;&gt; # Requires at least one node for cluster discovery. Multiple nodes is recommended.&gt;&gt;&gt; startup_nodes = [{&quot;host&quot;: &quot;127.0.0.1&quot;, &quot;port&quot;: &quot;7000&quot;}]&gt;&gt;&gt; rc = RedisCluster(startup_nodes=startup_nodes, decode_responses=True)&gt;&gt;&gt; rc.set(&quot;foo&quot;, &quot;bar&quot;)True&gt;&gt;&gt; print(rc.get(&quot;foo&quot;))&#39;bar&#39;</code></pre><h2 id="18-4-Redis云产品"><a href="#18-4-Redis云产品" class="headerlink" title="18.4 Redis云产品"></a>18.4 Redis云产品</h2><p>阿里云的云产品Redis提供三类产品:</p><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/alredis.png" alt=""></p><p>我之前用过读写分离版本很稳定,<strong>实践证明了花钱真香～</strong>,推荐开发进度紧张,没时间运维的公司可以尝试使用下</p><h3 id="18-4-1-优势"><a href="#18-4-1-优势" class="headerlink" title="18.4.1 优势"></a>18.4.1 优势</h3><p>相比自己搭建Redis数据库，云数据库Redis版在数据安全、运维投入、内核优化等方面都有一定的优势。</p><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/alredisdiff.png" alt=""></p><h3 id="18-4-2-劣势"><a href="#18-4-2-劣势" class="headerlink" title="18.4.2 劣势"></a>18.4.2 劣势</h3><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/money.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>17.RedisCluster</title>
      <link href="/2020/02/22/17-RedisCluster/"/>
      <url>/2020/02/22/17-RedisCluster/</url>
      
        <content type="html"><![CDATA[<h2 id="17-1-redis-cluster介绍"><a href="#17-1-redis-cluster介绍" class="headerlink" title="17.1 redis cluster介绍"></a>17.1 redis cluster介绍</h2><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/rediscluster.png" alt=""></p><ul><li>自动将数据进行分片,每个master上放一部分数据</li><li>提供内置的高可用支持,部分master不可用时,还是可以继续工作的，因为每个master都有salve节点，那么如果mater挂掉，redis cluster这套机制，就会自动将某个slave切换成master；</li><li>支持读写分离：对于每个master来说，都负责写请求，写就写到master，然后读就从mater对应的slave去读；</li></ul><p>redisCluster是Redis的官方分布式解决方案,解决了上一章提到的Redis主从模式的1,2,3缺陷</p><p>redisCluster = 多master+读写分离+sentinal</p><h2 id="17-2-分区规则"><a href="#17-2-分区规则" class="headerlink" title="17.2 分区规则"></a>17.2 分区规则</h2><h3 id="17-2-1-常见分区规则"><a href="#17-2-1-常见分区规则" class="headerlink" title="17.2.1 常见分区规则"></a>17.2.1 常见分区规则</h3><p>分布式数据库首要解决把整个数据集按照分区规则映射到多个节点的问题，即把数据集划分到多个节点上，每个节点负责整个数据的一个子集。</p><p>常见的分区规则有<code>哈希分区和顺序分区</code>。Redis Cluster采用哈希分区规则，因此接下来会讨论哈希分区规则。常见的哈希分区有以下几种：</p><ul><li>节点取余分区</li><li>一致性哈希分区</li><li>虚拟槽分区</li></ul><p>Redis Cluster采用虚拟槽分区</p><h3 id="17-2-2-hash算法"><a href="#17-2-2-hash算法" class="headerlink" title="17.2.2 hash算法"></a>17.2.2 hash算法</h3><p>来了一个 key，首先计算 hash 值，然后对节点数取模。然后打在不同的 master 节点上。一旦某一个 master 节点宕机，所有请求过来，都会基于最新的剩余 master 节点数去取模，尝试去取数据。这会<strong>导致大部分的请求过来，全部无法拿到有效的缓存，导致大量的流量涌入数据库</strong></p><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/hash-1.png" alt=""></p><h3 id="17-2-3-一致性-hash-算法"><a href="#17-2-3-一致性-hash-算法" class="headerlink" title="17.2.3 一致性 hash 算法"></a>17.2.3 一致性 hash 算法</h3><p>一致性 hash 算法将整个 hash 值空间组织成一个虚拟的圆环，整个空间按顺时针方向组织，下一步将各个 master 节点（使用服务器的 ip 或主机名）进行 hash。这样就能确定每个节点在其哈希环上的位置。</p><p>来了一个 key，首先计算 hash 值，并确定此数据在环上的位置，从此位置沿环<strong>顺时针“行走”</strong>，遇到的第一个 master 节点就是 key 所在位置。</p><p>在一致性哈希算法中，如果<strong>一个节点挂了，受影响的数据仅仅是此节点到环空间前一个节点（沿着逆时针方向行走遇到的第一个节点）之间的数据，其它不受影响</strong>。增加一个节点也同理。</p><p>燃鹅，一致性哈希算法在节点太少时，容易因为节点分布不均匀而造成<strong>缓存热点</strong>的问题。为了解决这种热点问题，<strong>一致性 hash 算法引入了虚拟节点机制，即对每一个节点计算多个 hash，每个计算结果位置都放置一个虚拟节点</strong>。这样就实现了数据的均匀分布，负载均衡。</p><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/consistent-hashing-algorithm.png" alt=""></p><h3 id="17-2-2-redis使用的hash-slot"><a href="#17-2-2-redis使用的hash-slot" class="headerlink" title="17.2.2 redis使用的hash slot"></a>17.2.2 redis使用的hash slot</h3><p>虚拟槽分区巧妙地使用了哈希空间，使用分散度良好的哈希函数把所有的数据映射到一个固定范围内的整数集合，整数定义为槽（slot）。</p><p>redis cluster有固定的16384个hash slot，对每个key计算CRC16值，然后对16384取模，可以获取key对应的hash slot<br>redis cluster中每个master都会持有部分slot，比如有3个master，那么可能每个master持有5000多个hash slot<br>hash slot让node的增加和移除很简单，增加一个master，就将其他master的hash slot移动部分过去，减少一个master，就将它的hash slot移动到其他master上去<br>移动hash slot的成本是非常低的<br>客户端的api，可以对指定的数据，让他们走同一个hash slot，通过hash tag来实现出处。</p><h2 id="17-3-节点间的通信协议"><a href="#17-3-节点间的通信协议" class="headerlink" title="17.3 节点间的通信协议"></a>17.3 节点间的通信协议</h2><h3 id="17-3-1-基本通信原理"><a href="#17-3-1-基本通信原理" class="headerlink" title="17.3.1 基本通信原理"></a>17.3.1 基本通信原理</h3><p>集群元数据的维护有两种方式：</p><ul><li>集中式协议</li><li>Gossip 协议</li></ul><p>redis cluster 节点间采用 gossip 协议进行通信。</p><h3 id="17-3-2-集中式协议"><a href="#17-3-2-集中式协议" class="headerlink" title="17.3.2 集中式协议"></a>17.3.2 集中式协议</h3><p>集中式是将集群元数据（节点信息、故障等等）几种存储在某个节点上。集中式元数据集中存储的一个典型代表，就是大数据领域的 storm。它是分布式的大数据实时计算引擎，是集中式的元数据存储的结构，底层基于 zookeeper（分布式协调的中间件）对所有元数据进行存储维护。</p><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/zookeeper-centralized-storage.png" alt=""></p><ul><li>集中式的好处: 元数据的读取和更新，时效性非常好，一旦元数据出现了变更，就立即更新到集中式的存储中，其它节点读取的时候就可以感知到</li><li>不好在于，所有的元数据的更新压力全部集中在一个地方，可能会导致元数据的存储有压力。</li></ul><h3 id="17-3-3-gossip-协议"><a href="#17-3-3-gossip-协议" class="headerlink" title="17.3.3 gossip 协议"></a>17.3.3 gossip 协议</h3><p>gossip 协议包含多种消息，包含 ping,pong,meet,fail 等等。</p><ul><li><p>meet：某个节点发送 meet 给新加入的节点，让新节点加入集群中，然后新节点就会开始与其它节点进行通信。</p><pre><code>aredis-trib.rb add-node其实内部就是发送了一个 gossip meet 消息给新加入的节点，通知那个节点去加入我们的集群</code></pre></li><li><p>ping：每个节点都会频繁给其它节点发送 ping，其中包含自己的状态还有自己维护的集群元数据，互相通过 ping 交换元数据。</p></li><li><p>pong：返回 ping 和 meeet，包含自己的状态和其它信息，也用于信息广播和更新。</p></li><li><p>fail：某个节点判断另一个节点 fail 之后，就发送 fail 给其它节点，通知其它节点说，某个节点宕机啦。</p></li></ul><p>gossip协议优缺点:</p><ul><li>gossip 好处在于，元数据的更新比较分散，不是集中在一个地方，更新请求会陆陆续续打到所有节点上去更新，降低了压力</li><li>不好在于，元数据的更新有延时，可能导致集群中的一些操作会有一些滞后。</li></ul><h3 id="17-3-4-Redis中的gossip协议"><a href="#17-3-4-Redis中的gossip协议" class="headerlink" title="17.3.4 Redis中的gossip协议"></a>17.3.4 Redis中的gossip协议</h3><p>redis 维护集群元数据采用另一个方式， gossip 协议，所有节点都持有一份元数据，不同的节点如果出现了元数据的变更，就不断将元数据发送给其它的节点，让其它节点也进行元数据的变更。</p><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/redis-gossip.png" alt=""></p><ul><li>10000 端口：每个节点都有一个专门用于节点间通信的端口，就是自己提供服务的端口号+10000，比如 7001，那么用于节点间通信的就是 17001 端口。每个节点每隔一段时间都会往另外几个节点发送 ping 消息，同时其它几个节点接收到 ping 之后返回 pong。</li><li>交换的信息：信息包括故障信息，节点的增加和删除，hash slot 信息等等。</li></ul><h2 id="17-4Redis-cluster功能限制"><a href="#17-4Redis-cluster功能限制" class="headerlink" title="17.4Redis cluster功能限制"></a>17.4Redis cluster功能限制</h2><p>Redis集群相对单机在功能上有一定限制:</p><ul><li>key批量操作支持有限。如：MSET,MGET，目前只支持具有相同slot值的key执行批量操作。</li><li>key事务操作支持有限。支持多key在同一节点上的事务操作，不支持分布在多个节点的事务功能。</li><li>key作为数据分区的最小粒度，因此不能将一个大的键值对象映射到不同的节点。如：hash、list。</li><li>不支持多数据库空间。单机下Redis支持16个数据库，集群模式下只能使用一个数据库空间，即db0。</li><li>复制结构只支持一层，不支持嵌套树状复制结构。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>16.Redis哨兵模式</title>
      <link href="/2020/02/22/16-Redis%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F/"/>
      <url>/2020/02/22/16-Redis%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<p>类似与Mysql的主备切换，Sentinel是Redis的高可用性解决方案之一</p><h2 id="16-1-主从复制的问题"><a href="#16-1-主从复制的问题" class="headerlink" title="16.1 主从复制的问题"></a>16.1 主从复制的问题</h2><ul><li>一旦 主节点宕机，从节点 晋升成 主节点，同时需要修改 应用方 的 主节点地址，还需要命令所有 从节点去复制 新的主节点，整个过程需要人工干预。</li><li>主节点的写能力受到 单机的限制。</li><li>主节点的存储能力受到单机的限制。</li></ul><h2 id="16-2-哨兵模式作用"><a href="#16-2-哨兵模式作用" class="headerlink" title="16.2 哨兵模式作用"></a>16.2 哨兵模式作用</h2><p>哨兵模式可以解决主从的第一个问题</p><ul><li>集群监控：负责监控 redis master 和 slave 进程是否正常工作</li><li>消息通知：如果某个 redis 实例有故障，那么哨兵负责发送消息作为报警通知给管理员</li><li>故障转移：如果 master node 挂掉了，会自动转移到 slave node 上</li><li>配置中心：如果故障转移发生了，通知 client 客户端新的 master 地址</li><li>应用透明 : 应用不需要重启改配置文件</li></ul><h2 id="16-3-哨兵模式架构"><a href="#16-3-哨兵模式架构" class="headerlink" title="16.3 哨兵模式架构"></a>16.3 哨兵模式架构</h2><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/sentinel.png" alt=""></p><ul><li><p>哨兵至少需要 3 个实例，来保证自己的健壮性。(分布式quorum选举)</p></li><li><p>哨兵 + redis 主从的部署架构，是<strong>不保证数据零丢失的，只能保证 redis 集群的高可用性</strong>。</p></li></ul><h2 id="16-4-工作原理"><a href="#16-4-工作原理" class="headerlink" title="16.4 工作原理"></a>16.4 工作原理</h2><p>每个 Sentinel 节点都需要 定期执行 以下任务：</p><ul><li>每个 Sentinel 以 每秒钟 一次的频率，向它所知的 主服务器、从服务器 以及其他 Sentinel 实例 发送一个 PING 命令。</li><li>如果一个 实例（instance）距离 最后一次 有效回复 PING 命令的时间超过 down-after-milliseconds 所指定的值，那么这个实例会被 Sentinel 标记为 主观下线。</li><li>如果一个 主服务器 被标记为 主观下线，那么正在 监视 这个 主服务器 的所有 Sentinel 节点，要以 每秒一次 的频率确认 主服务器 的确进入了 主观下线 状态。</li><li>如果一个 主服务器 被标记为 主观下线，并且有 足够数量 的 Sentinel（至少要达到 配置文件 指定的数量）在指定的 时间范围 内同意这一判断，那么这个 主服务器 被标记为 客观下线。</li><li>在一般情况下， 每个 Sentinel 会以每 10 秒一次的频率，向它已知的所有 主服务器 和 从服务器 发送 INFO 命令。当一个 主服务器 被 Sentinel 标记为 客观下线 时，Sentinel 向 下线主服务器 的所有 从服务器 发送 INFO 命令的频率，会从 10 秒一次改为 每秒一次</li><li>Sentinel 和其他 Sentinel 协商 主节点 的状态，如果 主节点 处于 SDOWN 状态，则投票自动选出新的 主节点。将剩余的 从节点 指向 新的主节点 进行 数据复制。</li><li>当没有足够数量的 Sentinel 同意 主服务器 下线时， 主服务器 的 客观下线状态 就会被移除。当 主服务器 重新向 Sentinel 的 PING 命令返回 有效回复 时，主服务器 的 主观下线状态 就会被移除。</li></ul><h3 id="16-4-1-sdown-和-odown-转换机制"><a href="#16-4-1-sdown-和-odown-转换机制" class="headerlink" title="16.4.1 sdown 和 odown 转换机制"></a>16.4.1 sdown 和 odown 转换机制</h3><ul><li>sdown 是主观宕机，就一个哨兵如果自己觉得一个 master 宕机了，那么就是主观宕机</li><li>odown 是客观宕机，如果 quorum 数量的哨兵都觉得一个 master 宕机了，那么就是客观宕机</li></ul><p>sdown 达成的条件很简单，如果一个哨兵 ping 一个 master，超过了 is-master-down-after-milliseconds 指定的毫秒数之后，就主观认为 master 宕机了；如果一个哨兵在指定时间内，收到了 quorum 数量的其它哨兵也认为那个 master 是 sdown 的，那么就认为是 odown 了。</p><h3 id="16-4-2-哨兵集群的自动发现机制"><a href="#16-4-2-哨兵集群的自动发现机制" class="headerlink" title="16.4.2 哨兵集群的自动发现机制"></a>16.4.2 哨兵集群的自动发现机制</h3><p>哨兵互相之间的发现，是通过 redis 的 pub/sub 系统实现的，每个哨兵都会往 <strong>sentinel</strong>:hello 这个 channel 里发送一个消息，这时候所有其他哨兵都可以消费到这个消息，并感知到其他的哨兵的存在。</p><p>每隔两秒钟，每个哨兵都会往自己监控的某个 master+slaves 对应的 <strong>sentinel</strong>:hello channel 里发送一个消息，内容是自己的 host、ip 和 runid 还有对这个 master 的监控配置。</p><p>每个哨兵也会去监听自己监控的每个 master+slaves 对应的 <strong>sentinel</strong>:hello channel，然后去感知到同样在监听这个 master+slaves 的其他哨兵的存在。</p><p>每个哨兵还会跟其他哨兵交换对 master 的监控配置，互相进行监控配置的同步。</p><h3 id="16-4-3-选举算法"><a href="#16-4-3-选举算法" class="headerlink" title="16.4.3 选举算法"></a>16.4.3 选举算法</h3><p>如果一个 master 被认为 odown 了，而且 majority 数量的哨兵都允许主备切换，那么某个哨兵就会执行主备切换操作，此时首先要选举一个 slave 来，会考虑 slave 的一些信息：</p><ul><li>跟 master 断开连接的时长</li><li>slave 优先级</li><li>复制 offset</li><li>run id</li></ul><p>如果一个 slave 跟 master 断开连接的时间已经超过了 down-after-milliseconds 的 10 倍，外加 master 宕机的时长，那么 slave 就被认为不适合选举为 master。</p><p>接下来会对 slave 进行排序：</p><ul><li>按照 slave 优先级进行排序，slave priority 越低，优先级就越高。</li><li>如果 slave priority 相同，那么看 replica offset，哪个 slave 复制了越多的数据，offset 越靠后，优先级就越高。</li><li>如果上面两个条件都相同，那么选择一个 run id 比较小的那个 slave。</li></ul><h3 id="16-4-4-configuration传播"><a href="#16-4-4-configuration传播" class="headerlink" title="16.4.4 configuration传播"></a>16.4.4 configuration传播</h3><p>执行切换的那个哨兵，会从要切换到的新 master（salve-&gt;master）那里得到一个 configuration epoch，这就是一个 version 号，每次切换的 <code>version</code>号都必须是唯一的。</p><p>如果第一个选举出的哨兵切换失败了，那么其他哨兵，会等待 failover-timeout 时间，然后接替继续执行切换，此时会重新获取一个新的 configuration epoch，作为新的 <code>version</code> 号。</p><p>哨兵完成切换之后，会在自己本地更新生成最新的 master 配置，然后同步给其他的哨兵，就是通过之前说的 pub/sub 消息机制。</p><p>这里之前的 version 号就很重要了，因为各种消息都是通过一个 channel 去发布和监听的，所以一个哨兵完成一次新的切换之后，新的 master 配置是跟着新的<code>version</code> 号的。其他的哨兵都是根据版本号的大小来更新自己的 master 配置的。</p><h2 id="16-5-主备切换数据丢失问题"><a href="#16-5-主备切换数据丢失问题" class="headerlink" title="16.5 主备切换数据丢失问题"></a>16.5 主备切换数据丢失问题</h2><p>主备切换的过程，可能会导致数据丢失：</p><ul><li>异步复制导致的数据丢失</li><li>脑裂导致的数据丢失</li></ul><h3 id="16-5-1-异步复制导致的数据丢失"><a href="#16-5-1-异步复制导致的数据丢失" class="headerlink" title="16.5.1 异步复制导致的数据丢失"></a>16.5.1 异步复制导致的数据丢失</h3><p>因为 master-&gt;slave 的复制是异步的，所以可能有部分数据还没复制到 slave，master 就宕机了，此时这部分数据就丢失了</p><h3 id="16-5-2-脑裂导致的数据丢失"><a href="#16-5-2-脑裂导致的数据丢失" class="headerlink" title="16.5.2 脑裂导致的数据丢失"></a>16.5.2 脑裂导致的数据丢失</h3><p>脑裂，也就是说，某个 master 所在机器突然脱离了正常的网络，跟其他 slave 机器不能连接，但是实际上 master 还运行着。此时哨兵可能就会认为 master 宕机了，然后开启选举，将其他 slave 切换成了 master。这个时候，集群里就会有两个 master ，也就是所谓的<strong>脑裂</strong>。</p><p>此时虽然某个 slave 被切换成了 master，但是可能 client 还没来得及切换到新的 master，还继续向旧 master 写数据。因此旧 master 再次恢复的时候，会被作为一个 slave 挂到新的 master 上去，自己的数据会清空，重新从新的 master 复制数据。而新的 master 并没有后来 client 写入的数据，因此，这部分数据也就丢失了。</p><h3 id="16-5-3-数据丢失问题的解决方案"><a href="#16-5-3-数据丢失问题的解决方案" class="headerlink" title="16.5.3 数据丢失问题的解决方案"></a>16.5.3 数据丢失问题的解决方案</h3><p><strong>注意：数据丢失只能说减少丢失不能完全规避丢失</strong></p><p>进行如下配置：</p><pre><code class="ini">min-slaves-to-write 1min-slaves-max-lag 10</code></pre><p>表示，要求至少有 1 个 slave，数据复制和同步的延迟不能超过 10 秒。</p><p>如果说一旦所有的 slave，数据复制和同步的延迟都超过了 10 秒钟，那么这个时候，master 就不会再接收任何请求了。</p><ul><li>减少异步复制数据的丢失</li></ul><p>有了 min-slaves-max-lag 这个配置，就可以确保说，一旦 slave 复制数据和 ack 延时太长，就认为可能 master 宕机后损失的数据太多了，那么就拒绝写请求，这样可以把 master 宕机时由于部分数据未同步到 slave 导致的数据丢失降低的可控范围内。</p><ul><li>减少脑裂的数据丢失</li></ul><p>如果一个 master 出现了脑裂，跟其他 slave 丢了连接，那么上面两个配置可以确保说，如果不能继续给指定数量的 slave 发送数据，而且 slave 超过 10 秒没有给自己 ack 消息，那么就直接拒绝客户端的写请求。因此在脑裂场景下，最多就丢失 10 秒的数据</p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>15.Redis主从架构</title>
      <link href="/2020/02/22/15-Redis%E4%B8%BB%E4%BB%8E%E6%9E%B6%E6%9E%84/"/>
      <url>/2020/02/22/15-Redis%E4%B8%BB%E4%BB%8E%E6%9E%B6%E6%9E%84/</url>
      
        <content type="html"><![CDATA[<p>在Redis中,用户可以使用<code>SLAVE OF</code>命令或者设置<code>slave of</code>选项,让一个Redis服务去复制另一个Redis服务,从而来实现类似于Mysql的读写分离</p><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/slave.png" alt=""></p><p>同样的Redis也可以和Mysql一样,做级联模式</p><h2 id="15-1-旧版复制功能实现"><a href="#15-1-旧版复制功能实现" class="headerlink" title="15.1 旧版复制功能实现"></a>15.1 旧版复制功能实现</h2><p>Redis2.8之前Redis的复制分为两个阶段 ： </p><ul><li>同步</li><li>命令传播</li></ul><h3 id="15-1-1-同步"><a href="#15-1-1-同步" class="headerlink" title="15.1.1 同步"></a>15.1.1 同步</h3><ul><li>从服务器向主服务器发送SYNC命令</li><li>收到SYNC命令后，主服务器开始执行BGSAVE操作生成RDB文件，并使用一个缓冲区记录现在开始执行的所有写命令（用于命令传播阶段保持数据库一致性）</li><li>当主服务器的BGSAVE操作执行完时，主服务器会将BGSAVE命令生成的RDB文件发送给从服务器，从服务器接收并载入这个RDB文件，将自己的数据库状态更新至主服务器执行BGSAVE命令时的数据库状态</li><li>主服务器将记录在缓冲区里面的所有写命令发送给从服务器，从服务器执行这些写命令。将自己数据库状态更新至主服务器数据库当前状态</li></ul><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/sync.jpg" alt=""></p><h3 id="15-1-2-命令传播"><a href="#15-1-2-命令传播" class="headerlink" title="15.1.2 命令传播"></a>15.1.2 命令传播</h3><p>主服务器将执行的写命令，发送给从服务器执行，当从服务器执行了相同写命令后，主从服务器将再次回到一致性状态</p><h3 id="15-1-3-旧版复制功能的缺陷"><a href="#15-1-3-旧版复制功能的缺陷" class="headerlink" title="15.1.3 旧版复制功能的缺陷"></a>15.1.3 旧版复制功能的缺陷</h3><p><strong>为了让从服务器补足一小部分缺失的数据，而让主服务器重新执行一次BGSAVE操作，造成断线重连后的效率会很低</strong></p><h2 id="15-2-新版复制功能的实现"><a href="#15-2-新版复制功能的实现" class="headerlink" title="15.2 新版复制功能的实现"></a>15.2 新版复制功能的实现</h2><h3 id="15-2-1-SYNC命令换成PSYNC"><a href="#15-2-1-SYNC命令换成PSYNC" class="headerlink" title="15.2.1 SYNC命令换成PSYNC"></a>15.2.1 SYNC命令换成PSYNC</h3><p>PSYNC命令具有完整重同步和部分重同步两种模式：</p><ul><li>完整重同步用于处理初次复制的情况：与SYNC命令的执行步骤基本一致 ， 都是通过让主服务器创建并发送RDB文件，以及向从服务器发送保存在缓冲区里面的写命令来进行同步。</li><li>部分重同步用于处理断线后重复制的情况：当从服务器在断线后重新连接主服务器时，如果条件允许，主服务器可以将主从服务器连接断开期间执行的写命令发送给从服务器，从服务器只要接收并执行这些写命令，就可以将数据库更新至主服务器当前所在状态了。</li></ul><h3 id="15-2-2-部分重同步的实现"><a href="#15-2-2-部分重同步的实现" class="headerlink" title="15.2.2 部分重同步的实现"></a>15.2.2 部分重同步的实现</h3><ul><li><p>主从服务器的复制偏移量</p></li><li><p>主服务器的复制积压缓冲区,默认大小为1MB，为安全期间建议按照如下公式设置</p><pre><code>复制积压缓冲区大小 :    2 * second * writer_size_per_secondsecond: 从服务断线重连需要的秒数writer_size_per_second: 主服务器每秒写书的数据量</code></pre></li></ul><ul><li>从服务器记录主服务器运行ID</li></ul><h3 id="15-2-3-主从复制核心原理"><a href="#15-2-3-主从复制核心原理" class="headerlink" title="15.2.3 主从复制核心原理"></a>15.2.3 主从复制核心原理</h3><p>当启动一个 slave node 的时候，它会发送一个 PSYNC 命令给 master node。</p><p>如果这是 slave node 初次连接到 master node，那么会触发一次<code>full resynchronization</code> 全量复制。此时 master 会启动一个后台线程，开始生成一份 RDB 快照文件，同时还会将从客户端 client 新收到的所有写命令缓存在内存中。RDB 文件生成完毕后， master 会将这个 RDB 发送给 slave，slave 会先<strong>写入本地磁盘，然后再从本地磁盘加载到内存中</strong>，接着 master 会将内存中缓存的写命令发送到 slave，slave 也会同步这些数据。slave node 如果跟 master node 有网络故障，断开了连接，会自动重连，连接之后 master node 仅会复制给 slave 部分缺少的数据。</p><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/redis-master-slave-replication.png" alt=""></p><h3 id="15-2-4-复制完整流程"><a href="#15-2-4-复制完整流程" class="headerlink" title="15.2.4 复制完整流程"></a>15.2.4 复制完整流程</h3><ol><li>从服务上设置主服务器的地址和端口</li><li>建立socket连接</li><li>发送ping命令</li><li>身份验证</li><li>从服务器发送端口信息</li><li>同步</li><li>命令传播</li></ol><h3 id="15-2-5-过期-key-处理"><a href="#15-2-5-过期-key-处理" class="headerlink" title="15.2.5 过期 key 处理"></a>15.2.5 过期 key 处理</h3><p>slave 不会过期 key，只会等待 master 过期 key。如果 master 过期了一个 key，或者通过 LRU 淘汰了一个 key，那么会模拟一条 del 命令发送给 slave。</p><h2 id="15-3-心跳检测"><a href="#15-3-心跳检测" class="headerlink" title="15.3 心跳检测"></a>15.3 心跳检测</h2><p>在命令传播阶段,从服务器会每秒向主服务器发送心跳检测,作用如下:</p><ul><li>检测主从服务器的网络连接状态 看延时多少，一般延时0-1秒</li><li>辅助实现min-slaves选项</li><li>检测命令丢失</li></ul><h3 id="15-3-1-辅助实现min-slaves选项"><a href="#15-3-1-辅助实现min-slaves选项" class="headerlink" title="15.3.1 辅助实现min-slaves选项"></a>15.3.1 辅助实现min-slaves选项</h3><p>Redis的<code>min-slaves-to-write</code>和<code>min-slaves-max-lag</code>两个选项可以防止主服务器在不安全的情况下执行写命令<br>举个例子，如果我们向主服务器提供以下设置：</p><pre><code class="ini">min-slaves-to-write 3min-slaves-max-lag 10</code></pre><p>那么在从服务器的数量少于3个，或者三个从服务器的延迟（lag）值都大于或等于10秒时，主服务器将拒绝执行写命令</p><h3 id="15-3-2-检测命令丢失"><a href="#15-3-2-检测命令丢失" class="headerlink" title="15.3.2 检测命令丢失"></a>15.3.2 检测命令丢失</h3><p>主服务器向从服务器补发缺失数据这一操作的原理和部分重同步操作的原理非常相似，这两个操作的区别在于：<strong>补发缺失数据操作在主从服务器没有断线的情况下执行，而部分重同步操作则在主从服务器断线并重连之后执行</strong></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>13.Redis持久化——AOF</title>
      <link href="/2020/02/21/13-Redis%E6%8C%81%E4%B9%85%E5%8C%96-AOF/"/>
      <url>/2020/02/21/13-Redis%E6%8C%81%E4%B9%85%E5%8C%96-AOF/</url>
      
        <content type="html"><![CDATA[<h2 id="13-1-AOF机制"><a href="#13-1-AOF机制" class="headerlink" title="13.1 AOF机制"></a>13.1 AOF机制</h2><p>AOF 机制对每条写入命令作为日志，以 append-only 的模式写入一个日志文件中，在 redis 重启的时候，可以通过回放 AOF 日志中的写入指令来重新构建整个数据集。</p><p>类似于mysql的<code>redo log</code></p><h2 id="13-2-配置"><a href="#13-2-配置" class="headerlink" title="13.2 配置"></a>13.2 配置</h2><pre><code class="ini">############ APPEND ONLY MODE ###########......#如果 appendonly 配置为 no，则不启用 AOF 方式进行备份。如果 appendonly 配置为 yes，则以 AOF 方式备份 Redis 数据，那么此时 Redis 会按照配置，在特定的时候执行追加命令，用以备份数据。appendonly no......#这里定义追加的写入文件为 appendonly.aofappendfilename &quot;appendonly.aof&quot;......#appendfsync always#每次有新命令追加到 AOF 文件时就执行一次 fsync ：非常慢，也非常安全。appendfsync everysec#每秒 fsync 一次：足够快（和使用 RDB 持久化差不多），并且在故障时只会丢失 1 秒钟的数据。#appendfsync no#从不 fsync ：将数据交给操作系统来处理。更快，也更不安全的选择。......#它指定 Redis 重写 AOF 文件的条件，默认为 100，表示与上次 rewrite 的 AOF 文件大小相比，当前 AOF 文件增长量超过上次 AOF 文件大小的 100% 时，就会触发 background rewrite。若配置为 0，则会禁用自动 rewriteauto-aof-rewrite-percentage 100#它指定触发 rewrite 的AOF文件大小。若AOF文件小于该值，即使当前文件的增量比例达到 auto-aof-rewrite-percentage的配置值，也不会触发自动rewrite。即这两个配置项同时满足时，才会触发rewrite。auto-aof-rewrite-min-size 64mb......#Redis 在恢复时会忽略最后一条可能存在问题的指令，默认为 yes。即在 AOF 写入时，可能存在指令写错的问题（突然断电、写了一半），这种情况下 yes 会 log 并继续，而 no 会直接恢复失败。aof-load-truncated yes......</code></pre><h2 id="13-3-AOF持久化过程"><a href="#13-3-AOF持久化过程" class="headerlink" title="13.3 AOF持久化过程"></a>13.3 AOF持久化过程</h2><pre><code class="c">#file: src/aof.c/*  * 将 AOF 缓存写入到文件中。 * * 因为程序需要在回复客户端之前对 AOF 执行写操作。 * 而客户端能执行写操作的唯一机会就是在事件 loop 中， * 因此，程序将所有 AOF 写累积到缓存中， * 并在重新进入事件 loop 之前，将缓存写入到文件中。 * * 关于 force 参数： * * 当 fsync 策略为每秒钟保存一次时，如果后台线程仍然有 fsync 在执行， * 那么我们可能会延迟执行冲洗（flush）操作， * 因为 Linux 上的 write(2) 会被后台的 fsync 阻塞。 * * 当这种情况发生时，说明需要尽快冲洗 aof 缓存， * 程序会尝试在 serverCron() 函数中对缓存进行冲洗。 * * 不过，如果 force 为 1 的话，那么不管后台是否正在 fsync ， * 程序都直接进行写入。 */#define AOF_WRITE_LOG_ERROR_RATE 30 /* Seconds between errors logging. */void flushAppendOnlyFile(int force) {    ssize_t nwritten;    int sync_in_progress = 0;    // 缓冲区中没有任何内容，直接返回    if (sdslen(server.aof_buf) == 0) return;    // 策略为每秒 FSYNC     if (server.aof_fsync == AOF_FSYNC_EVERYSEC)        // 是否有 SYNC 正在后台进行？        sync_in_progress = bioPendingJobsOfType(REDIS_BIO_AOF_FSYNC) != 0;    // 每秒 fsync ，并且强制写入为假    if (server.aof_fsync == AOF_FSYNC_EVERYSEC &amp;&amp; !force) {        /*         * 当 fsync 策略为每秒钟一次时， fsync 在后台执行。         *         * 如果后台仍在执行 FSYNC ，那么我们可以延迟写操作一两秒         * （如果强制执行 write 的话，服务器主线程将阻塞在 write 上面）         */        if (sync_in_progress) {            // 有 fsync 正在后台进行 。。。            if (server.aof_flush_postponed_start == 0) {                /*                 * 前面没有推迟过 write 操作，这里将推迟写操作的时间记录下来                 * 然后就返回，不执行 write 或者 fsync                 */                server.aof_flush_postponed_start = server.unixtime;                return;            } else if (server.unixtime - server.aof_flush_postponed_start &lt; 2) {                /*                 * 如果之前已经因为 fsync 而推迟了 write 操作                 * 但是推迟的时间不超过 2 秒，那么直接返回                 * 不执行 write 或者 fsync                 */                return;            }            /*              * 如果后台还有 fsync 在执行，并且 write 已经推迟 &gt;= 2 秒             * 那么执行写操作（write 将被阻塞）             */            server.aof_delayed_fsync++;            redisLog(REDIS_NOTICE,&quot;Asynchronous AOF fsync is taking too long (disk is busy?). Writing the AOF buffer without waiting for fsync to complete, this may slow down Redis.&quot;);        }    }    /*      * 执行到这里，程序会对 AOF 文件进行写入。     *     * 清零延迟 write 的时间记录     */    server.aof_flush_postponed_start = 0;    /*      * 执行单个 write 操作，如果写入设备是物理的话，那么这个操作应该是原子的     *     * 当然，如果出现像电源中断这样的不可抗现象，那么 AOF 文件也是可能会出现问题的     * 这时就要用 redis-check-aof 程序来进行修复。     */    nwritten = write(server.aof_fd,server.aof_buf,sdslen(server.aof_buf));    if (nwritten != (signed)sdslen(server.aof_buf)) {        static time_t last_write_error_log = 0;        int can_log = 0;        // 将日志的记录频率限制在每行 AOF_WRITE_LOG_ERROR_RATE 秒        if ((server.unixtime - last_write_error_log) &gt; AOF_WRITE_LOG_ERROR_RATE) {            can_log = 1;            last_write_error_log = server.unixtime;        }        // 如果写入出错，那么尝试将该情况写入到日志里面        if (nwritten == -1) {            if (can_log) {                redisLog(REDIS_WARNING,&quot;Error writing to the AOF file: %s&quot;,                    strerror(errno));                server.aof_last_write_errno = errno;            }        } else {            if (can_log) {                redisLog(REDIS_WARNING,&quot;Short write while writing to &quot;                                       &quot;the AOF file: (nwritten=%lld, &quot;                                       &quot;expected=%lld)&quot;,                                       (long long)nwritten,                                       (long long)sdslen(server.aof_buf));            }            // 尝试移除新追加的不完整内容            if (ftruncate(server.aof_fd, server.aof_current_size) == -1) {                if (can_log) {                    redisLog(REDIS_WARNING, &quot;Could not remove short write &quot;                             &quot;from the append-only file.  Redis may refuse &quot;                             &quot;to load the AOF the next time it starts.  &quot;                             &quot;ftruncate: %s&quot;, strerror(errno));                }            } else {                nwritten = -1;            }            server.aof_last_write_errno = ENOSPC;        }        // 处理写入 AOF 文件时出现的错误        if (server.aof_fsync == AOF_FSYNC_ALWAYS) {            redisLog(REDIS_WARNING,&quot;Can&#39;t recover from AOF write error when the AOF fsync policy is &#39;always&#39;. Exiting...&quot;);            exit(1);        } else {            server.aof_last_write_status = REDIS_ERR;            if (nwritten &gt; 0) {                server.aof_current_size += nwritten;                sdsrange(server.aof_buf,nwritten,-1);            }            return;         }    } else {        /* Successful write(2). If AOF was in error state, restore the         * OK state and log the event. */        // 写入成功，更新最后写入状态        if (server.aof_last_write_status == REDIS_ERR) {            redisLog(REDIS_WARNING,                &quot;AOF write error looks solved, Redis can write again.&quot;);            server.aof_last_write_status = REDIS_OK;        }    }    // 更新写入后的 AOF 文件大小    server.aof_current_size += nwritten;    /*     * 如果 AOF 缓存的大小足够小的话，那么重用这个缓存，     * 否则的话，释放 AOF 缓存。     */    if ((sdslen(server.aof_buf)+sdsavail(server.aof_buf)) &lt; 4000) {        // 清空缓存中的内容，等待重用        sdsclear(server.aof_buf);    } else {        // 释放缓存        sdsfree(server.aof_buf);        server.aof_buf = sdsempty();    }    /*      * 如果 no-appendfsync-on-rewrite 选项为开启状态，     * 并且有 BGSAVE 或者 BGREWRITEAOF 正在进行的话，     * 那么不执行 fsync      */    if (server.aof_no_fsync_on_rewrite &amp;&amp;        (server.aof_child_pid != -1 || server.rdb_child_pid != -1))            return;    // 总是执行 fsnyc    if (server.aof_fsync == AOF_FSYNC_ALWAYS) {        aof_fsync(server.aof_fd);         // 更新最后一次执行 fsnyc 的时间        server.aof_last_fsync = server.unixtime;    // 策略为每秒 fsnyc ，并且距离上次 fsync 已经超过 1 秒    } else if ((server.aof_fsync == AOF_FSYNC_EVERYSEC &amp;&amp;                server.unixtime &gt; server.aof_last_fsync)) {        // 放到后台执行        if (!sync_in_progress) aof_background_fsync(server.aof_fd);        // 更新最后一次执行 fsync 的时间        server.aof_last_fsync = server.unixtime;    }}</code></pre><h2 id="13-4-AOF重写"><a href="#13-4-AOF重写" class="headerlink" title="13.4 AOF重写"></a>13.4 AOF重写</h2><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/aofDuring.png" alt=""></p><p>AOF文件重写过程与RDB快照bgsave工作过程有点相似，都是通过fork子进程，由子进程完成相应的操作，同样的在fork子进程简短的时间内，redis是阻塞的。</p><p>（1）开始bgrewriteaof，判断当前有没有bgsave命令(RDB持久化)/bgrewriteaof在执行，倘若有，则这些命令执行完成以后在执行。</p><p>（2）主进程fork出子进程，在这一个短暂的时间内，redis是阻塞的。</p><p>（3）主进程fork完子进程继续接受客户端请求。此时，客户端的写请求不仅仅写入aof_buf缓冲区，还写入aof_rewrite_buf重写缓冲区。一方面是写入aof_buf缓冲区并根据appendfsync策略同步到磁盘，保证原有AOF文件完整和正确。另一方面写入aof_rewrite_buf重写缓冲区，保存fork之后的客户端的写请求，防止新AOF文件生成期间丢失这部分数据。</p><p>（4.1）子进程写完新的AOF文件后，向主进程发信号，父进程更新统计信息。</p><p>（4.2）主进程把aof_rewrite_buf中的数据写入到新的AOF文件。</p><p>（5）使用新的AOF文件覆盖旧的AOF文件，标志AOF重写完成。</p><h2 id="13-5-文件类型"><a href="#13-5-文件类型" class="headerlink" title="13.5 文件类型"></a>13.5 文件类型</h2><p>可读文本文件,但大小比RDB文件大的多</p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>14.Redis持久化总结</title>
      <link href="/2020/02/21/14-Redis%E6%8C%81%E4%B9%85%E5%8C%96%E6%80%BB%E7%BB%93/"/>
      <url>/2020/02/21/14-Redis%E6%8C%81%E4%B9%85%E5%8C%96%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<h2 id="14-1-持久化方式"><a href="#14-1-持久化方式" class="headerlink" title="14.1 持久化方式"></a>14.1 持久化方式</h2><p>Redis有两种持久化的方式：</p><ul><li>RDB持久化方式:在一个特定的间隔保存那个时间点的一个数据快照。</li><li>AOF持久化方式:记录每一个服务器收到的写操作。</li></ul><p>Redis的持久化是可以禁用的，就是说你可以让数据的生命周期只存在于服务器的运行时间里。<br>两种方式的持久化是可以同时存在的，但是当Redis重启时，<strong>AOF文件会被优先用于RDB</strong></p><h2 id="14-2-优缺点"><a href="#14-2-优缺点" class="headerlink" title="14.2 优缺点"></a>14.2 优缺点</h2><h3 id="14-2-1-RDB-优缺点"><a href="#14-2-1-RDB-优缺点" class="headerlink" title="14.2.1 RDB 优缺点"></a>14.2.1 RDB 优缺点</h3><ul><li>RDB 会生成多个数据文件，每个数据文件都代表了某一个时刻中 redis 的数据，这种多个数据文件的方式，非常适合做冷备，可以将这种完整的数据文件发送到一些远程的安全存储上去，比如说 Amazon 的 S3 云服务上去，在国内可以是阿里云的 ODPS 分布式存储上，以预定好的备份策略来定期备份 redis 中的数据。</li><li>RDB 对 redis 对外提供的读写服务，影响非常小，可以让 redis 保持高性能，因为 redis 主进程只需要 fork 一个子进程，让子进程执行磁盘 IO 操作来进行 RDB 持久化即可。</li><li>相对于 AOF 持久化机制来说，直接基于 RDB 数据文件来重启和恢复 redis 进程，更加快速。</li><li>如果想要在 redis 故障时，尽可能少的丢失数据，那么 RDB 没有 AOF 好。一般来说，RDB 数据快照文件，都是每隔 5 分钟，或者更长时间生成一次，这个时候就得接受一旦 redis 进程宕机，那么会丢失最近 5 分钟的数据。</li><li>RDB 每次在 fork 子进程来执行 RDB 快照数据文件生成的时候，如果数据文件特别大，可能会导致对客户端提供的服务暂停数毫秒，或者甚至数秒。</li></ul><h3 id="14-2-2-AOF-优缺点"><a href="#14-2-2-AOF-优缺点" class="headerlink" title="14.2.2 AOF 优缺点"></a>14.2.2 AOF 优缺点</h3><ul><li>AOF 可以更好的保护数据不丢失，一般 AOF 会每隔 1 秒，通过一个后台线程执行一次fsync操作，最多丢失 1 秒钟的数据。</li><li>AOF 日志文件以 append-only 模式写入，所以没有任何磁盘寻址的开销，写入性能非常高，而且文件不容易破损，即使文件尾部破损，也很容易修复。</li><li>AOF 日志文件即使过大的时候，出现后台重写操作，也不会影响客户端的读写。因为在 rewrite log 的时候，会对其中的指令进行压缩，创建出一份需要恢复数据的最小日志出来。在创建新日志文件的时候，老的日志文件还是照常写入。当新的 merge 后的日志文件 ready 的时候，再交换新老日志文件即可。</li><li>AOF 日志文件的命令通过非常可读的方式进行记录，这个特性非常适合做灾难性的误删除的紧急恢复。比如某人不小心用 flushall 命令清空了所有数据，只要这个时候后台 rewrite 还没有发生，那么就可以立即拷贝 AOF 文件，将最后一条 flushall 命令给删了，然后再将该 AOF 文件放回去，就可以通过恢复机制，自动恢复所有数据。</li><li>对于同一份数据来说，AOF 日志文件通常比 RDB 数据快照文件更大。</li><li>AOF 开启后，支持的写 QPS 会比 RDB 支持的写 QPS 低，因为 AOF 一般会配置成每秒 fsync 一次日志文件，当然，每秒一次 fsync，性能也还是很高的。（如果实时写入，那么 QPS 会大降，redis 性能会大大降低）</li><li>以前 AOF 发生过 bug，就是通过 AOF 记录的日志，进行数据恢复的时候，没有恢复一模一样的数据出来。所以说，类似 AOF 这种较为复杂的基于命令日志 / merge / 回放的方式，比基于 RDB 每次持久化一份完整的数据快照文件的方式，更加脆弱一些，容易有 bug。不过 AOF 就是为了避免 rewrite 过程导致的 bug，因此每次 rewrite 并不是基于旧的指令日志进行 merge 的，而是基于当时内存中的数据进行指令的重新构建，这样健壮性会好很多。</li></ul><h2 id="14-3-如何选择持久化方式"><a href="#14-3-如何选择持久化方式" class="headerlink" title="14.3 如何选择持久化方式"></a>14.3 如何选择持久化方式</h2><p>redis 支持同时开启开启两种持久化方式，我们可以综合使用 AOF 和 RDB 两种持久化机制，用 AOF 来保证数据不丢失，作为数据恢复的第一选择; 用 RDB 来做不同程度的冷备，在 AOF 文件都丢失或损坏不可用的时候，还可以使用 RDB 来进行快速的数据恢复。</p><h2 id="14-3-混合持久化"><a href="#14-3-混合持久化" class="headerlink" title="14.3 混合持久化"></a>14.3 混合持久化</h2><p>重启 Redis 时，我们很少使用 rdb 来恢复内存状态，因为会丢失大量数据。</p><p>如果使用 AOF 日志重放，性能则相对 rdb 来说要慢很多，这样在 Redis 实例很大的情况下，启动的时候需要花费很长的时间。</p><p>Redis 4.0 为了解决这个问题，带来了一个新的持久化选项——混合持久化。</p><p>混合持久化同样也是通过<code>bgrewriteaof</code>完成的，不同的是当开启混合持久化时，fork出的子进程先将共享的内存副本全量的以RDB方式写入aof文件，然后在将aof_rewrite_buf重写缓冲区的增量命令以AOF方式写入到文件，写入完成后通知主进程更新统计信息，并将新的含有RDB格式和AOF格式的AOF文件替换旧的的AOF文件。</p><p>简单的说：<strong>新的AOF文件前半段是RDB格式的全量数据后半段是AOF格式的增量数据</strong>，如下图：</p><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/redis40.png" alt=""></p><p>在redis重启的时候，加载 aof 文件进行恢复数据：先加载 rdb 内容再加载剩余的 aof。</p><p>混合持久化配置：</p><pre><code class="ini">aof-use-rdb-preamble yes  # yes：开启，no：关闭</code></pre><h2 id="14-4-云厂商的改进"><a href="#14-4-云厂商的改进" class="headerlink" title="14.4 云厂商的改进"></a>14.4 云厂商的改进</h2><p>不同云厂商为了<code>赚钱</code>都对Redis做了不同的二次开发,阿里云做了一个Redis基于AOF日志的增量同步机制设计方案还不错,具体可以参考此篇文章:</p><p><a href="https://yq.aliyun.com/articles/68350" target="_blank" rel="noopener">Redis内核基于时间点的备份恢复和基于AOF日志的增量同步机制设计</a></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>12.Redis持久化——RDB</title>
      <link href="/2020/02/21/12-Redis%E6%8C%81%E4%B9%85%E5%8C%96-RDB/"/>
      <url>/2020/02/21/12-Redis%E6%8C%81%E4%B9%85%E5%8C%96-RDB/</url>
      
        <content type="html"><![CDATA[<h2 id="12-1-RDB机制"><a href="#12-1-RDB机制" class="headerlink" title="12.1 RDB机制"></a>12.1 RDB机制</h2><p>RDB其实就是把数据以快照的形式保存在磁盘上。</p><p>RDB持久化是指在指定的时间间隔内将内存中的数据集快照写入磁盘。也是<code>默认的持久化方式</code>，这种方式是就是将内存中数据以快照的方式写入到二进制文件中,默认的文件名为dump.rdb。</p><h2 id="12-2-触发方式"><a href="#12-2-触发方式" class="headerlink" title="12.2 触发方式"></a>12.2 触发方式</h2><ul><li>手动触发：执行BGSAVE命令</li><li>自动触发：配置SAVE选项，在指定时间内发生指定次数的key修改，自动进行后台RDB SAVE</li></ul><pre><code class="c">#file: src/rdb.cvoid saveCommand(redisClient *c) {    // BGSAVE 已经在执行中，不能再执行 SAVE    // 否则将产生竞争条件    if (server.rdb_child_pid != -1) {        addReplyError(c,&quot;Background save already in progress&quot;);        return;    }    // 执行     if (rdbSave(server.rdb_filename) == REDIS_OK) {        addReply(c,shared.ok);    } else {        addReply(c,shared.err);    }}void bgsaveCommand(redisClient *c) {    // 不能重复执行 BGSAVE    if (server.rdb_child_pid != -1) {        addReplyError(c,&quot;Background save already in progress&quot;);    // 不能在 BGREWRITEAOF 正在运行时执行    } else if (server.aof_child_pid != -1) {        addReplyError(c,&quot;Can&#39;t BGSAVE while AOF log rewriting is in progress&quot;);    // 执行 BGSAVE    } else if (rdbSaveBackground(server.rdb_filename) == REDIS_OK) {        addReplyStatus(c,&quot;Background saving started&quot;);    } else {        addReply(c,shared.err);    }}int rdbSaveBackground(char *filename) {    pid_t childpid;    long long start;......    start = ustime();    if ((childpid = fork()) == 0) {        int retval;        /* Child */        // 关闭网络连接 fd        closeListeningSockets(0);        // 设置进程的标题，方便识别        redisSetProcTitle(&quot;redis-rdb-bgsave&quot;);        // 执行保存操作        retval = rdbSave(filename);......        // 向父进程发送信号        exitFromChild((retval == REDIS_OK) ? 0 : 1);    } else {......    }    return REDIS_OK; /* unreached */}/* Save the DB on disk. Return REDIS_ERR on error, REDIS_OK on success  * * 将数据库保存到磁盘上。 * * 保存成功返回 REDIS_OK ，出错/失败返回 REDIS_ERR 。 */int rdbSave(char *filename) {    dictIterator *di = NULL;    dictEntry *de;    char tmpfile[256];    char magic[10];    int j;    long long now = mstime();    FILE *fp;    rio rdb;    uint64_t cksum;    // 创建临时文件    snprintf(tmpfile,256,&quot;temp-%d.rdb&quot;, (int) getpid());    fp = fopen(tmpfile,&quot;w&quot;);    if (!fp) {        redisLog(REDIS_WARNING, &quot;Failed opening .rdb for saving: %s&quot;,            strerror(errno));        return REDIS_ERR;    }    // 初始化 I/O    rioInitWithFile(&amp;rdb,fp);    // 设置校验和函数    if (server.rdb_checksum)        rdb.update_cksum = rioGenericUpdateChecksum;    // 写入 RDB 版本号    snprintf(magic,sizeof(magic),&quot;REDIS%04d&quot;,REDIS_RDB_VERSION);    if (rdbWriteRaw(&amp;rdb,magic,9) == -1) goto werr;    // 遍历所有数据库    for (j = 0; j &lt; server.dbnum; j++) {        // 指向数据库        redisDb *db = server.db+j;        // 指向数据库键空间        dict *d = db-&gt;dict;        // 跳过空数据库        if (dictSize(d) == 0) continue;        // 创建键空间迭代器        di = dictGetSafeIterator(d);        if (!di) {            fclose(fp);            return REDIS_ERR;        }        /* Write the SELECT DB opcode          *         * 写入 DB 选择器         */        if (rdbSaveType(&amp;rdb,REDIS_RDB_OPCODE_SELECTDB) == -1) goto werr;        if (rdbSaveLen(&amp;rdb,j) == -1) goto werr;        /* Iterate this DB writing every entry          *         * 遍历数据库，并写入每个键值对的数据         */        while((de = dictNext(di)) != NULL) {            sds keystr = dictGetKey(de);            robj key, *o = dictGetVal(de);            long long expire;            // 根据 keystr ，在栈中创建一个 key 对象            initStaticStringObject(key,keystr);            // 获取键的过期时间            expire = getExpire(db,&amp;key);            // 保存键值对数据            if (rdbSaveKeyValuePair(&amp;rdb,&amp;key,o,expire,now) == -1) goto werr;        }        dictReleaseIterator(di);    }    di = NULL; /* So that we don&#39;t release it again on error. */    /* EOF opcode      *     * 写入 EOF 代码     */    if (rdbSaveType(&amp;rdb,REDIS_RDB_OPCODE_EOF) == -1) goto werr;    /*      * CRC64 校验和。     */    cksum = rdb.cksum;    memrev64ifbe(&amp;cksum);    rioWrite(&amp;rdb,&amp;cksum,8);    /* Make sure data will not remain on the OS&#39;s output buffers */    // 冲洗缓存，确保数据已写入磁盘    if (fflush(fp) == EOF) goto werr;    if (fsync(fileno(fp)) == -1) goto werr;    if (fclose(fp) == EOF) goto werr;    /*      * 使用 RENAME ，原子性地对临时文件进行改名，覆盖原来的 RDB 文件。     */    if (rename(tmpfile,filename) == -1) {        redisLog(REDIS_WARNING,&quot;Error moving temp DB file on the final destination: %s&quot;, strerror(errno));        unlink(tmpfile);        return REDIS_ERR;    }    // 写入完成，打印日志    redisLog(REDIS_NOTICE,&quot;DB saved on disk&quot;);    // 清零数据库脏状态    server.dirty = 0;    // 记录最后一次完成 SAVE 的时间    server.lastsave = time(NULL);    // 记录最后一次执行 SAVE 的状态    server.lastbgsave_status = REDIS_OK;    return REDIS_OK;werr:    // 关闭文件    fclose(fp);    // 删除文件    unlink(tmpfile);    redisLog(REDIS_WARNING,&quot;Write error saving DB on disk: %s&quot;, strerror(errno));    if (di) dictReleaseIterator(di);    return REDIS_ERR;}</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/rdbduring.png" alt=""></p><h2 id="12-3-配置"><a href="#12-3-配置" class="headerlink" title="12.3 配置"></a>12.3 配置</h2><pre><code class="ini">#file: redis.conf############SNAPSHOTTING#######......#当900秒执行1个写命令时，启用快照备份save 900 1#当300秒执行10个写命令时，启用快照备份save 300 10#当60秒内执行10000个写命令时，启用快照备份save 60 10000......#Redis 执行 save 命令的时候，将禁止写入命令#在默认情况下，如果 Redis 执行 bgsave 失败后，Redis 将停止接受写操作，这样以一种强硬的方式让用户知道数据不能正确的持久化到磁盘，否则就会没人注意到灾难的发生，如果后台保存进程重新启动工作了，Redis 也将自动允许写操作。然而如果安装了靠谱的监控，可能不希望 Redis 这样做，那么你可以将其修改为 no。stop-writes-on-bgsave-error yes......#这个命令意思是是否对 rbd 文件进行检验，如果是将对 rdb 文件检验。从 dbfilename 的配置可以知道，rdb 文件实际是 Redis 持久化的数据文件。rdbcompression yes......dbfilename dump.rdb</code></pre><h2 id="12-4-文件类型"><a href="#12-4-文件类型" class="headerlink" title="12.4 文件类型"></a>12.4 文件类型</h2><p>RDB保存的文件是一个二进制文件，可以通过redis自带的工具<code>redis-check-dump</code>来查看里面的内容</p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>11.Redis过期机制</title>
      <link href="/2020/02/20/11-Redis%E8%BF%87%E6%9C%9F%E6%9C%BA%E5%88%B6/"/>
      <url>/2020/02/20/11-Redis%E8%BF%87%E6%9C%9F%E6%9C%BA%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<h2 id="11-1-RedisDb结构"><a href="#11-1-RedisDb结构" class="headerlink" title="11.1 RedisDb结构"></a>11.1 RedisDb结构</h2><p>每个Redis服务都有多个Db库,每个库记录了不同应用的数据信息</p><p>RedisDb的结构如下:</p><pre><code class="c">#file : src/redis.htypedef struct redisDb {    // 数据库键空间，保存着数据库中的所有键值对    dict *dict;                 /* The keyspace for this DB */    // 键的过期时间，字典的键为键，字典的值为过期事件 UNIX 时间戳    dict *expires;              /* Timeout of keys with a timeout set */    // 正处于阻塞状态的键    dict *blocking_keys;        /* Keys with clients waiting for data (BLPOP) */    // 可以解除阻塞的键    dict *ready_keys;           /* Blocked keys that received a PUSH */    // 正在被 WATCH 命令监视的键    dict *watched_keys;         /* WATCHED keys for MULTI/EXEC CAS */    struct evictionPoolEntry *eviction_pool;    /* Eviction pool of keys */    // 数据库号码    int id;                     /* Database ID */    // 数据库的键的平均 TTL ，统计信息    long long avg_ttl;          /* Average TTL, just for stats */} redisDb;</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/redisdb.png" alt=""></p><p>redisDb结构的expires字典保存了数据库中所有键的过期时间:</p><ul><li>过期字典的键是一个指针,指向某个键对象</li><li>过期字典的值是一个long long 类型的整数,这个整数报错了键所指向数据库的过期时间,是一个毫秒精度的UNIX时间戳</li></ul><h2 id="11-2-设置过期时间"><a href="#11-2-设置过期时间" class="headerlink" title="11.2 设置过期时间"></a>11.2 设置过期时间</h2><pre><code class="c">#file : src/redis.cvoid expireCommand(redisClient *c) {    expireGenericCommand(c,mstime(),UNIT_SECONDS);}void expireatCommand(redisClient *c) {    expireGenericCommand(c,0,UNIT_SECONDS);}void pexpireCommand(redisClient *c) {    expireGenericCommand(c,mstime(),UNIT_MILLISECONDS);}void pexpireatCommand(redisClient *c) {    expireGenericCommand(c,0,UNIT_MILLISECONDS);}/*  * 这个函数是 EXPIRE 、 PEXPIRE 、 EXPIREAT 和 PEXPIREAT 命令的底层实现函数。 * * 命令的第二个参数可能是绝对值，也可能是相对值。 * 当执行 *AT 命令时， basetime 为 0 ，在其他情况下，它保存的就是当前的绝对时间。 * * unit 用于指定 argv[2] （传入过期时间）的格式， * 它可以是 UNIT_SECONDS 或 UNIT_MILLISECONDS ， * basetime 参数则总是毫秒格式的。 */void expireGenericCommand(redisClient *c, long long basetime, int unit) {    robj *key = c-&gt;argv[1], *param = c-&gt;argv[2];    long long when; /* unix time in milliseconds when the key will expire. */    // 取出 when 参数    if (getLongLongFromObjectOrReply(c, param, &amp;when, NULL) != REDIS_OK)        return;    // 如果传入的过期时间是以秒为单位的，那么将它转换为毫秒    if (unit == UNIT_SECONDS) when *= 1000;    when += basetime;    /* No key, return zero. */    // 取出键    if (lookupKeyRead(c-&gt;db,key) == NULL) {        addReply(c,shared.czero);        return;    }    /*      * 在载入数据时，或者服务器为附属节点时，     * 即使 EXPIRE 的 TTL 为负数，或者 EXPIREAT 提供的时间戳已经过期，     * 服务器也不会主动删除这个键，而是等待主节点发来显式的 DEL 命令。     *     * 程序会继续将（一个可能已经过期的 TTL）设置为键的过期时间，     * 并且等待主节点发来 DEL 命令。     */    if (when &lt;= mstime() &amp;&amp; !server.loading &amp;&amp; !server.masterhost) {        // when 提供的时间已经过期，服务器为主节点，并且没在载入数据        robj *aux;        redisAssertWithInfo(c,key,dbDelete(c-&gt;db,key));        server.dirty++;        // 传播 DEL 命令        aux = createStringObject(&quot;DEL&quot;,3);        rewriteClientCommandVector(c,2,aux,key);        decrRefCount(aux);        signalModifiedKey(c-&gt;db,key);        notifyKeyspaceEvent(REDIS_NOTIFY_GENERIC,&quot;del&quot;,key,c-&gt;db-&gt;id);        addReply(c, shared.cone);        return;    } else {        // 设置键的过期时间        // 如果服务器为附属节点，或者服务器正在载入，        // 那么这个 when 有可能已经过期的        setExpire(c-&gt;db,key,when);        addReply(c,shared.cone);        signalModifiedKey(c-&gt;db,key);        notifyKeyspaceEvent(REDIS_NOTIFY_GENERIC,&quot;expire&quot;,key,c-&gt;db-&gt;id);        server.dirty++;        return;    }}</code></pre><h2 id="11-3-过期键的删除策略"><a href="#11-3-过期键的删除策略" class="headerlink" title="11.3 过期键的删除策略"></a>11.3 过期键的删除策略</h2><ul><li>被动删除机制——惰性删除</li><li>主动删除机制——定期删除</li></ul><p>这两种删除机制下,如果内存满了需要释放,会走Redis的内存淘汰机制</p><h3 id="11-3-1-惰性删除"><a href="#11-3-1-惰性删除" class="headerlink" title="11.3.1 惰性删除"></a>11.3.1 惰性删除</h3><p>惰性删除: 放任过期键不管,但是每次从键空间获取建时,都检查取得的键是否过期,如果过期就删除该键,如果没过期就返回该键</p><p>优点:对CPU时间来说最友好</p><p>缺点:对内存最不友好,占用的内存一直不释放</p><p>实现代码：</p><pre><code class="c">#file: src/db.c/* * 检查 key 是否已经过期，如果是的话，将它从数据库中删除。 * 返回 0 表示键没有过期时间，或者键未过期。 * 返回 1 表示键已经因为过期而被删除了。 */int expireIfNeeded(redisDb *db, robj *key) {    // 取出键的过期时间    mstime_t when = getExpire(db,key);    mstime_t now;    // 没有过期时间    if (when &lt; 0) return 0; /* No expire for this key */    // 如果服务器正在进行载入，那么不进行任何过期检查    if (server.loading) return 0;    now = server.lua_caller ? server.lua_time_start : mstime();    // 当服务器运行在 replication 模式时    // 附属节点并不主动删除 key    // 它只返回一个逻辑上正确的返回值    // 真正的删除操作要等待主节点发来删除命令时才执行    // 从而保证数据的同步    if (server.masterhost != NULL) return now &gt; when;    // 运行到这里，表示键带有过期时间，并且服务器为主节点    // 如果未过期，返回 0    if (now &lt;= when) return 0;    /* Delete the key */    server.stat_expiredkeys++;    // 向 AOF 文件和附属节点传播过期信息    propagateExpire(db,key);    // 发送事件通知    notifyKeyspaceEvent(REDIS_NOTIFY_EXPIRED,        &quot;expired&quot;,key,db-&gt;id);    // 将过期键从数据库中删除    return dbDelete(db,key);}</code></pre><h3 id="11-3-2-定期删除"><a href="#11-3-2-定期删除" class="headerlink" title="11.3.2 定期删除"></a>11.3.2 定期删除</h3><p>定期删除:每隔一段时间,程序就会对数据库进行检查,删除里面的过期键，定期删除通过限制删除操作执行的时长和频率来减少删除操作对CPU的影响，通过定期删除可以有效的减少因为过期键而带来的内存浪费</p><p>定期删除策略是通过redis指定周期性函数<code>serverCron</code>时,调用对数据库执行的各种操作<code>databasesCron</code>,<code>databasesCron</code>调用<code>redis.c/activeExpireCycle</code>函数实现的,serverCron的调用频率是10HZ,所以定期删除`每100ms执行一次</p><blockquote><p>server.hz = 10 一秒钟执行10次</p><p>serverCron—-&gt;databasesCron—–&gt;activeExpireCycle</p></blockquote><pre><code class="c">#file: src/redis.c/*  * 函数尝试删除数据库中已经过期的键。 * 当带有过期时间的键比较少时，函数运行得比较保守， * 如果带有过期时间的键比较多，那么函数会以更积极的方式来删除过期键， * 从而可能地释放被过期键占用的内存。 * * 每次循环中被测试的数据库数目不会超过 REDIS_DBCRON_DBS_PER_CALL　默认16 。 * * * 如果 timelimit_exit 为真，那么说明还有更多删除工作要做， * 那么在 beforeSleep() 函数调用时，程序会再次执行这个函数。 * * * 过期循环的类型： * * 如果循环的类型为 ACTIVE_EXPIRE_CYCLE_FAST ， * 那么函数会以“快速过期”模式执行， * 执行的时间不会长过 EXPIRE_FAST_CYCLE_DURATION 毫秒， * 并且在 EXPIRE_FAST_CYCLE_DURATION 毫秒之内不会再重新执行。 * * 如果循环的类型为 ACTIVE_EXPIRE_CYCLE_SLOW ， * 那么函数会以“正常过期”模式执行， * 函数的执行时限为 REDIS_HS 常量的一个百分比， * 这个百分比由 REDIS_EXPIRELOOKUPS_TIME_PERC 定义。 */void activeExpireCycle(int type) {    // 静态变量，用来累积函数连续执行时的数据    static unsigned int current_db = 0; /* Last DB tested. */    static int timelimit_exit = 0;      /* Time limit hit in previous call? */    static long long last_fast_cycle = 0; /* When last fast cycle ran. */    unsigned int j, iteration = 0;    // 默认每次处理的数据库数量    unsigned int dbs_per_call = REDIS_DBCRON_DBS_PER_CALL;    // 函数开始的时间    long long start = ustime(), timelimit;    // 快速模式    if (type == ACTIVE_EXPIRE_CYCLE_FAST) {        // 如果上次函数没有触发 timelimit_exit ，那么不执行处理        if (!timelimit_exit) return;        // 如果距离上次执行未够一定时间，那么不执行处理        if (start &lt; last_fast_cycle + ACTIVE_EXPIRE_CYCLE_FAST_DURATION*2) return;        // 运行到这里，说明执行快速处理，记录当前时间        last_fast_cycle = start;    }    /*      * 一般情况下，函数只处理 REDIS_DBCRON_DBS_PER_CALL 个数据库，     * 除非：     *     * 1) 当前数据库的数量小于 REDIS_DBCRON_DBS_PER_CALL     * 2) 如果上次处理遇到了时间上限，那么这次需要对所有数据库进行扫描，     *     这可以避免过多的过期键占用空间     */    if (dbs_per_call &gt; server.dbnum || timelimit_exit)        dbs_per_call = server.dbnum;    // 函数处理的微秒时间上限    // ACTIVE_EXPIRE_CYCLE_SLOW_TIME_PERC 默认为 25 ，也即是 25 % 的 CPU 时间    timelimit = 1000000*ACTIVE_EXPIRE_CYCLE_SLOW_TIME_PERC/server.hz/100;    timelimit_exit = 0;    if (timelimit &lt;= 0) timelimit = 1;    // 如果是运行在快速模式之下    // 那么最多只能运行 FAST_DURATION 微秒     // 默认值为 1000 （微秒）    if (type == ACTIVE_EXPIRE_CYCLE_FAST)        timelimit = ACTIVE_EXPIRE_CYCLE_FAST_DURATION; /* in microseconds. */    // 遍历数据库    for (j = 0; j &lt; dbs_per_call; j++) {        int expired;        // 指向要处理的数据库        redisDb *db = server.db+(current_db % server.dbnum);        // 为 DB 计数器加一，如果进入 do 循环之后因为超时而跳出        // 那么下次会直接从下个 DB 开始处理        current_db++;        do {            unsigned long num, slots;            long long now, ttl_sum;            int ttl_samples;            // 获取数据库中带过期时间的键的数量            // 如果该数量为 0 ，直接跳过这个数据库            if ((num = dictSize(db-&gt;expires)) == 0) {                db-&gt;avg_ttl = 0;                break;            }            // 获取数据库中键值对的数量            slots = dictSlots(db-&gt;expires);            // 当前时间            now = mstime();            // 这个数据库的使用率低于 1% ，扫描起来太费力了（大部分都会 MISS）            // 跳过，等待字典收缩程序运行            if (num &amp;&amp; slots &gt; DICT_HT_INITIAL_SIZE &amp;&amp;                (num*100/slots &lt; 1)) break;            /*             * 样本计数器             */            // 已处理过期键计数器            expired = 0;            // 键的总 TTL 计数器            ttl_sum = 0;            // 总共处理的键计数器            ttl_samples = 0;            // 每次最多只能检查 LOOKUPS_PER_LOOP 个键            if (num &gt; ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP)                num = ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP;            // 开始遍历数据库            while (num--) {                dictEntry *de;                long long ttl;                // 从 expires 中随机取出一个带过期时间的键                if ((de = dictGetRandomKey(db-&gt;expires)) == NULL) break;                // 计算 TTL                ttl = dictGetSignedIntegerVal(de)-now;                // 如果键已经过期，那么删除它，并将 expired 计数器增一                if (activeExpireCycleTryExpire(db,de,now)) expired++;                if (ttl &lt; 0) ttl = 0;                // 累积键的 TTL                ttl_sum += ttl;                // 累积处理键的个数                ttl_samples++;            }            // 为这个数据库更新平均 TTL 统计数据            if (ttl_samples) {                // 计算当前平均值                long long avg_ttl = ttl_sum/ttl_samples;                // 如果这是第一次设置数据库平均 TTL ，那么进行初始化                if (db-&gt;avg_ttl == 0) db-&gt;avg_ttl = avg_ttl;                /* Smooth the value averaging with the previous one. */                // 取数据库的上次平均 TTL 和今次平均 TTL 的平均值                db-&gt;avg_ttl = (db-&gt;avg_ttl+avg_ttl)/2;            }            // 我们不能用太长时间处理过期键，            // 所以这个函数执行一定时间之后就要返回            // 更新遍历次数            iteration++;            // 每遍历 16 次执行一次            if ((iteration &amp; 0xf) == 0 &amp;&amp; /* check once every 16 iterations. */                (ustime()-start) &gt; timelimit)            {                // 如果遍历次数正好是 16 的倍数                // 并且遍历的时间超过了 timelimit                // 那么断开 timelimit_exit                timelimit_exit = 1;            }            // 已经超时了，返回            if (timelimit_exit) return;            // 如果已删除的过期键占当前总数据库带过期时间的键数量的 25 %            // 那么不再遍历        } while (expired &gt; ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP/4);    }}</code></pre><ol><li>设置每次遍历数据库数量的最大值:REDIS_DBCRON_DBS_PER_CALL(16)个</li><li>设置运行的最长时间:<ul><li>slow模式下最多运行25000微秒＝1000000*ACTIVE_EXPIRE_CYCLE_SLOW_TIME_PERC/server.hz/100</li><li>fast模式下最多运行1000微妙＝ACTIVE_EXPIRE_CYCLE_FAST_DURATION</li></ul></li><li>设置每遍历一个数据库最多取ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP(20)个键值</li><li>如果已删除的过期键占当前总数据库带过期时间的键数量的 25 %不再进行遍历</li></ol><h2 id="11-4-内存淘汰机制"><a href="#11-4-内存淘汰机制" class="headerlink" title="11.4 内存淘汰机制"></a>11.4 内存淘汰机制</h2><p>如果定期删除漏掉了很多键，惰性删除也没有进行,Redis会使用内存淘汰机制来释放内存</p><ul><li><p>noeviction：当内存不足以容纳新写入数据时，新写入操作会报错。<code>默认策略</code></p></li><li><p>allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key。</p></li><li><p>allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key。</p></li><li><p>volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key。</p></li><li><p>volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key。</p></li><li><p>volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除。</p></li><li><p>allkey-lfu: 获取所有key的访问频度删除访问最少的key</p></li><li><p>volatile-lfu:获取过期key的访问频度删除访问最少的key</p></li></ul><blockquote><p>如何选取合适的策略？</p><p>比较推荐的是两种lru策略。根据自己的业务需求。如果你使用Redis只是作为缓存，不作为DB持久化，那推荐选择allkeys-lru；如果你使用Redis同时用于缓存和数据持久化，那推荐选择volatile-lru。</p></blockquote><pre><code class="ini">#file : redis.conf# MAXMEMORY POLICY: how Redis will select what to remove when maxmemory# is reached. You can select among five behaviors:# # volatile-lru -&gt; remove the key with an expire set using an LRU algorithm# allkeys-lru -&gt; remove any key accordingly to the LRU algorithm# volatile-random -&gt; remove a random key with an expire set# allkeys-random -&gt; remove a random key, any key# volatile-ttl -&gt; remove the key with the nearest expire time (minor TTL)# noeviction -&gt; don&#39;t expire at all, just return an error on write operations## The default is:# maxmemory-policy noeviction</code></pre><h2 id="11-5-LRU算法"><a href="#11-5-LRU算法" class="headerlink" title="11.5 LRU算法"></a>11.5 LRU算法</h2><h3 id="11-5-1-什么是LRU"><a href="#11-5-1-什么是LRU" class="headerlink" title="11.5.1 什么是LRU"></a>11.5.1 什么是LRU</h3><p>就是一种缓存淘汰策略。</p><p>计算机的缓存容量有限，如果缓存满了就要删除一些内容，给新内容腾位置。但问题是，删除哪些内容呢？我们肯定希望删掉哪些没什么用的缓存，而把有用的数据继续留在缓存里，方便之后继续使用。那么，什么样的数据，我们判定为「有用的」的数据呢？</p><p>LRU 缓存淘汰算法就是一种常用策略。LRU 的全称是 Least Recently Used，也就是说我们认为最近使用过的数据应该是是「有用的」，很久都没用过的数据应该是无用的，内存满了就优先删那些很久没用过的数据。</p><h3 id="11-5-2-LRU的实现"><a href="#11-5-2-LRU的实现" class="headerlink" title="11.5.2 LRU的实现"></a>11.5.2 LRU的实现</h3><p>LRU 算法实际上是让你设计数据结构：首先要接收一个 capacity 参数作为缓存的最大容量，然后实现两个 API，一个是 put(key, val) 方法存入键值对，另一个是 get(key) 方法获取 key 对应的 val，如果 key 不存在则返回 -1。get 和 put 方法必须都是 O(1) 的时间复杂度</p><p>常用的方式是构造一个结构体包含一个HashMap和双链表</p><p>HashMap做取数据使用</p><p>双链表存访问的顺序</p><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/LRU.png" alt=""></p><p>我们看下go语言实现的LRU</p><pre><code class="go">type (    LRUCache struct {        Capacity int        HashMap  map[int]*Node        Head     *Node        Last     *Node    }    Node struct {        Val  int        Key  int        Pre  *Node        Next *Node    })func Constructor(capacity int) LRUCache {    cache := LRUCache{        Capacity: capacity,        HashMap:  make(map[int]*Node, capacity),        Head:     &amp;Node{},        Last:     &amp;Node{},    }    cache.Head.Next = cache.Last    cache.Last.Pre = cache.Head    return cache}func (this *LRUCache) Get(key int) int {    node, ok := this.HashMap[key]    if !ok {        return -1    }    this.remove(node)    this.setHead(node)    return node.Val}func (this *LRUCache) Put(key int, value int) {    node, ok := this.HashMap[key]    if ok {        node.Val = value        this.remove(node)    } else {        if len(this.HashMap) == this.Capacity {            delete(this.HashMap, this.Last.Pre.Key)            this.remove(this.Last.Pre)        }        node = &amp;Node{            Val:  value,            Key:  key,            Pre:  nil,            Next: nil,        }        this.HashMap[node.Key] = node    }    this.setHead(node)}func (this *LRUCache) setHead(node *Node) {    this.Head.Next.Pre = node    node.Next = this.Head.Next    this.Head.Next = node    node.Pre = this.Head}func (this *LRUCache) remove(node *Node) {    node.Pre.Next = node.Next    node.Next.Pre = node.Pre}/*============================*//*使用方法 * obj := Constructor(capacity); * param_1 := obj.Get(key); * obj.Put(key,value); */</code></pre><h3 id="11-5-3-Redis-LRU的实现"><a href="#11-5-3-Redis-LRU的实现" class="headerlink" title="11.5.3 Redis LRU的实现"></a>11.5.3 Redis LRU的实现</h3><pre><code class="c"># file: src/redis.cint freeMemoryIfNeeded(void) {....../* volatile-lru and allkeys-lru policy */            // 如果使用的是 LRU 策略，            // 那么从一集 sample 键中选出 IDLE 时间最长的那个键            else if (server.maxmemory_policy == REDIS_MAXMEMORY_ALLKEYS_LRU ||                server.maxmemory_policy == REDIS_MAXMEMORY_VOLATILE_LRU)            {                struct evictionPoolEntry *pool = db-&gt;eviction_pool;                while(bestkey == NULL) {                    evictionPoolPopulate(dict, db-&gt;dict, db-&gt;eviction_pool);                    /* Go backward from best to worst element to evict. */                    for (k = REDIS_EVICTION_POOL_SIZE-1; k &gt;= 0; k--) {                        if (pool[k].key == NULL) continue;                        de = dictFind(dict,pool[k].key);                        /* Remove the entry from the pool. */                        sdsfree(pool[k].key);                        /* Shift all elements on its right to left. */                        memmove(pool+k,pool+k+1,                            sizeof(pool[0])*(REDIS_EVICTION_POOL_SIZE-k-1));                        /* Clear the element on the right which is empty                         * since we shifted one position to the left.  */                        pool[REDIS_EVICTION_POOL_SIZE-1].key = NULL;                        pool[REDIS_EVICTION_POOL_SIZE-1].idle = 0;                        /* If the key exists, is our pick. Otherwise it is                         * a ghost and we need to try the next element. */                        if (de) {                            bestkey = dictGetKey(de);                            break;                        } else {                            /* Ghost... */                            continue;                        }                    }                }            }....../* This is an helper function for freeMemoryIfNeeded(), it is used in order * to populate the evictionPool with a few entries every time we want to * expire a key. Keys with idle time smaller than one of the current * keys are added. Keys are always added if there are free entries. * * We insert keys on place in ascending order, so keys with the smaller * idle time are on the left, and keys with the higher idle time on the * right. */#define EVICTION_SAMPLES_ARRAY_SIZE 16void evictionPoolPopulate(dict *sampledict, dict *keydict, struct evictionPoolEntry *pool) {    int j, k, count;    dictEntry *_samples[EVICTION_SAMPLES_ARRAY_SIZE];    dictEntry **samples;    /* Try to use a static buffer: this function is a big hit...     * Note: it was actually measured that this helps. */    if (server.maxmemory_samples &lt;= EVICTION_SAMPLES_ARRAY_SIZE) {        samples = _samples;    } else {        samples = zmalloc(sizeof(samples[0])*server.maxmemory_samples);    }#if 1 /* Use bulk get by default. */    count = dictGetRandomKeys(sampledict,samples,server.maxmemory_samples);#else    count = server.maxmemory_samples;    for (j = 0; j &lt; count; j++) samples[j] = dictGetRandomKey(sampledict);#endif    for (j = 0; j &lt; count; j++) {        unsigned long long idle;        sds key;        robj *o;        dictEntry *de;        de = samples[j];        key = dictGetKey(de);        /* If the dictionary we are sampling from is not the main         * dictionary (but the expires one) we need to lookup the key         * again in the key dictionary to obtain the value object. */        if (sampledict != keydict) de = dictFind(keydict, key);        o = dictGetVal(de);        idle = estimateObjectIdleTime(o);        /* Insert the element inside the pool.         * First, find the first empty bucket or the first populated         * bucket that has an idle time smaller than our idle time. */        k = 0;        while (k &lt; REDIS_EVICTION_POOL_SIZE &amp;&amp;               pool[k].key &amp;&amp;               pool[k].idle &lt; idle) k++;        if (k == 0 &amp;&amp; pool[REDIS_EVICTION_POOL_SIZE-1].key != NULL) {            /* Can&#39;t insert if the element is &lt; the worst element we have             * and there are no empty buckets. */            continue;        } else if (k &lt; REDIS_EVICTION_POOL_SIZE &amp;&amp; pool[k].key == NULL) {            /* Inserting into empty position. No setup needed before insert. */        } else {            /* Inserting in the middle. Now k points to the first element             * greater than the element to insert.  */            if (pool[REDIS_EVICTION_POOL_SIZE-1].key == NULL) {                /* Free space on the right? Insert at k shifting                 * all the elements from k to end to the right. */                memmove(pool+k+1,pool+k,                    sizeof(pool[0])*(REDIS_EVICTION_POOL_SIZE-k-1));            } else {                /* No free space on right? Insert at k-1 */                k--;                /* Shift all elements on the left of k (included) to the                 * left, so we discard the element with smaller idle time. */                sdsfree(pool[0].key);                memmove(pool,pool+1,sizeof(pool[0])*k);            }        }        pool[k].key = sdsdup(key);        pool[k].idle = idle;    }    if (samples != _samples) zfree(samples);}/* This is a version of dictGetRandomKey() that is modified in order to * return multiple entries by jumping at a random place of the hash table * and scanning linearly for entries. * * Returned pointers to hash table entries are stored into &#39;des&#39; that * points to an array of dictEntry pointers. The array must have room for * at least &#39;count&#39; elements, that is the argument we pass to the function * to tell how many random elements we need. * * The function returns the number of items stored into &#39;des&#39;, that may * be less than &#39;count&#39; if the hash table has less than &#39;count&#39; elements * inside. * * Note that this function is not suitable when you need a good distribution * of the returned items, but only when you need to &quot;sample&quot; a given number * of continuous elements to run some kind of algorithm or to produce * statistics. However the function is much faster than dictGetRandomKey() * at producing N elements, and the elements are guaranteed to be non * repeating. */int dictGetRandomKeys(dict *d, dictEntry **des, int count) {    int j; /* internal hash table id, 0 or 1. */    int stored = 0;    if (dictSize(d) &lt; count) count = dictSize(d);    while(stored &lt; count) {        for (j = 0; j &lt; 2; j++) {            /* Pick a random point inside the hash table 0 or 1. */            unsigned int i = random() &amp; d-&gt;ht[j].sizemask;            int size = d-&gt;ht[j].size;            /* Make sure to visit every bucket by iterating &#39;size&#39; times. */            while(size--) {                dictEntry *he = d-&gt;ht[j].table[i];                while (he) {                    /* Collect all the elements of the buckets found non                     * empty while iterating. */                    *des = he;                    des++;                    he = he-&gt;next;                    stored++;                    if (stored == count) return stored;                }                i = (i+1) &amp; d-&gt;ht[j].sizemask;            }            /* If there is only one table and we iterated it all, we should             * already have &#39;count&#39; elements. Assert this condition. */            assert(dictIsRehashing(d) != 0);        }    }    return stored; /* Never reached. */}typedef struct redisDb {......    struct evictionPoolEntry *eviction_pool;    /* Eviction pool of keys */......} redisDb;typedef struct redisObject {......    // 对象最后一次被访问的时间    unsigned lru:REDIS_LRU_BITS; /* lru time (relative to server.lruclock)......} robj;</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/LRUDuring.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>10.Redis数据结构——object</title>
      <link href="/2020/02/20/10-Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-object/"/>
      <url>/2020/02/20/10-Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-object/</url>
      
        <content type="html"><![CDATA[<h2 id="10-1-什么是object"><a href="#10-1-什么是object" class="headerlink" title="10.1 什么是object"></a>10.1 什么是object</h2><p>在前面的数个章节里， 我们陆续介绍了 Redis 用到的所有主要数据结构， 比如简单动态字符串（SDS）、双端链表、字典、压缩列表、整数集合， 等等。</p><p>Redis 并没有直接使用这些数据结构来实现键值对数据库， 而是基于这些数据结构创建了一个<code>对象系统</code>， 这个系统包含字符串对象、列表对象、哈希对象、集合对象和有序集合对象这五种类型的对象， 每种对象都用到了至少一种我们前面所介绍的数据结构。</p><p>通过这五种不同类型的对象， Redis 可以在执行命令之前， 根据对象的类型来判断一个对象是否可以执行给定的命令。 使用对象的另一个好处是， 我们可以针对不同的使用场景， 为对象设置多种不同的数据结构实现， 从而优化对象在不同场景下的使用效率</p><h2 id="10-2-数据结构"><a href="#10-2-数据结构" class="headerlink" title="10.2 数据结构"></a>10.2 数据结构</h2><pre><code class="c">#file : src/redis.ctypedef struct redisObject {    // 类型    unsigned type:4;    // 编码    unsigned encoding:4;    // 对象最后一次被访问的时间    unsigned lru:REDIS_LRU_BITS; /* lru time (relative to server.lruclock) */    // 引用计数    int refcount;    // 指向实际值的指针    void *ptr;} robj;</code></pre><p>Redis 使用对象来表示数据库中的键和值， 每次当我们在 Redis 的数据库中新创建一个键值对时， 我们至少会创建两个对象， 一个对象用作键值对的键（键对象）， 另一个对象用作键值对的值（值对象）。</p><h3 id="10-2-1-type"><a href="#10-2-1-type" class="headerlink" title="10.2.1 type"></a>10.2.1 type</h3><p>对象的 type 属性记录了对象的类型:</p><pre><code class="c">#file : src/redis.c// 对象类型#define REDIS_STRING 0  #字符串对象 &quot;string&quot;#define REDIS_LIST 1    #列表对象 &quot;list&quot;#define REDIS_SET 2     #哈希对象 &quot;hash&quot;#define REDIS_ZSET 3    #集合对象 &quot;set&quot;#define REDIS_HASH 4    #有序集合对象 &quot;zset&quot;</code></pre><h3 id="10-2-2-encoding"><a href="#10-2-2-encoding" class="headerlink" title="10.2.2 encoding"></a>10.2.2 encoding</h3><p>对象的 ptr 指针指向对象的底层实现数据结构， 而这些数据结构由对象的 encoding 属性决定。</p><p>encoding 属性记录了对象所使用的编码， 也即是说这个对象使用了什么数据结构作为对象的底层实现:</p><pre><code class="c">#file : src/redis.c// 对象编码#简单动态字符串#define REDIS_ENCODING_RAW 0     /* Raw representation */ #long 类型的整数#long 类型的整数#define REDIS_ENCODING_INT 1     /* Encoded as integer */#字典#define REDIS_ENCODING_HT 2      /* Encoded as hash table */#压缩字典#define REDIS_ENCODING_ZIPMAP 3  /* Encoded as zipmap */#双端链表#define REDIS_ENCODING_LINKEDLIST 4 /* Encoded as regular linked list */#压缩列表#define REDIS_ENCODING_ZIPLIST 5 /* Encoded as ziplist */#整数集合#define REDIS_ENCODING_INTSET 6  /* Encoded as intset */#跳表#define REDIS_ENCODING_SKIPLIST 7  /* Encoded as skiplist */#embstr编码的简单动态字符串#define REDIS_ENCODING_EMBSTR 8  /* Embedded sds string encoding */</code></pre><h2 id="10-3-Redis键的底层实现"><a href="#10-3-Redis键的底层实现" class="headerlink" title="10.3 Redis键的底层实现"></a>10.3 Redis键的底层实现</h2><p>对于 Redis 数据库保存的键值对来说， 键总是一个字符串对象， 而值则可以是字符串对象、列表对象、哈希对象、集合对象或者有序集合对象的其中一种</p><h2 id="10-4-Redis值的底层实现"><a href="#10-4-Redis值的底层实现" class="headerlink" title="10.4 Redis值的底层实现"></a>10.4 Redis值的底层实现</h2><h3 id="10-4-1-字符串对象"><a href="#10-4-1-字符串对象" class="headerlink" title="10.4.1 字符串对象"></a>10.4.1 字符串对象</h3><pre><code class="c">#file: src/t_string.c/* SET key value [NX] [XX] [EX &lt;seconds&gt;] [PX &lt;milliseconds&gt;] */void setCommand(redisClient *c) {    int j;    robj *expire = NULL;    int unit = UNIT_SECONDS;    int flags = REDIS_SET_NO_FLAGS;    // 设置选项参数    for (j = 3; j &lt; c-&gt;argc; j++) {        char *a = c-&gt;argv[j]-&gt;ptr;        robj *next = (j == c-&gt;argc-1) ? NULL : c-&gt;argv[j+1];        if ((a[0] == &#39;n&#39; || a[0] == &#39;N&#39;) &amp;&amp;            (a[1] == &#39;x&#39; || a[1] == &#39;X&#39;) &amp;&amp; a[2] == &#39;\0&#39;) {            flags |= REDIS_SET_NX;        } else if ((a[0] == &#39;x&#39; || a[0] == &#39;X&#39;) &amp;&amp;                   (a[1] == &#39;x&#39; || a[1] == &#39;X&#39;) &amp;&amp; a[2] == &#39;\0&#39;) {            flags |= REDIS_SET_XX;        } else if ((a[0] == &#39;e&#39; || a[0] == &#39;E&#39;) &amp;&amp;                   (a[1] == &#39;x&#39; || a[1] == &#39;X&#39;) &amp;&amp; a[2] == &#39;\0&#39; &amp;&amp; next) {            unit = UNIT_SECONDS;            expire = next;            j++;        } else if ((a[0] == &#39;p&#39; || a[0] == &#39;P&#39;) &amp;&amp;                   (a[1] == &#39;x&#39; || a[1] == &#39;X&#39;) &amp;&amp; a[2] == &#39;\0&#39; &amp;&amp; next) {            unit = UNIT_MILLISECONDS;            expire = next;            j++;        } else {            addReply(c,shared.syntaxerr);            return;        }    }    // 尝试对值对象进行编码    c-&gt;argv[2] = tryObjectEncoding(c-&gt;argv[2]);    setGenericCommand(c,flags,c-&gt;argv[1],c-&gt;argv[2],expire,unit,NULL,NULL);}void setnxCommand(redisClient *c) {    c-&gt;argv[2] = tryObjectEncoding(c-&gt;argv[2]);    setGenericCommand(c,REDIS_SET_NX,c-&gt;argv[1],c-&gt;argv[2],NULL,0,shared.cone,shared.czero);}void setexCommand(redisClient *c) {    c-&gt;argv[3] = tryObjectEncoding(c-&gt;argv[3]);    setGenericCommand(c,REDIS_SET_NO_FLAGS,c-&gt;argv[1],c-&gt;argv[3],c-&gt;argv[2],UNIT_SECONDS,NULL,NULL);}void psetexCommand(redisClient *c) {    c-&gt;argv[3] = tryObjectEncoding(c-&gt;argv[3]);    setGenericCommand(c,REDIS_SET_NO_FLAGS,c-&gt;argv[1],c-&gt;argv[3],c-&gt;argv[2],UNIT_MILLISECONDS,NULL,NULL);}void setGenericCommand(redisClient *c, int flags, robj *key, robj *val, robj *expire, int unit, robj *ok_reply, robj *abort_reply) {    long long milliseconds = 0; /* initialized to avoid any harmness warning */    // 取出过期时间    if (expire) {        // 取出 expire 参数的值        // T = O(N)        if (getLongLongFromObjectOrReply(c, expire, &amp;milliseconds, NULL) != REDIS_OK)            return;        // expire 参数的值不正确时报错        if (milliseconds &lt;= 0) {            addReplyError(c,&quot;invalid expire time in SETEX&quot;);            return;        }        // 不论输入的过期时间是秒还是毫秒        // Redis 实际都以毫秒的形式保存过期时间        // 如果输入的过期时间为秒，那么将它转换为毫秒        if (unit == UNIT_SECONDS) milliseconds *= 1000;    }    // 如果设置了 NX 或者 XX 参数，那么检查条件是否不符合这两个设置    // 在条件不符合时报错，报错的内容由 abort_reply 参数决定    if ((flags &amp; REDIS_SET_NX &amp;&amp; lookupKeyWrite(c-&gt;db,key) != NULL) ||        (flags &amp; REDIS_SET_XX &amp;&amp; lookupKeyWrite(c-&gt;db,key) == NULL))    {        addReply(c, abort_reply ? abort_reply : shared.nullbulk);        return;    }    // 将键值关联到数据库    setKey(c-&gt;db,key,val);    // 将数据库设为脏    server.dirty++;    // 为键设置过期时间    if (expire) setExpire(c-&gt;db,key,mstime()+milliseconds);    // 发送事件通知    notifyKeyspaceEvent(REDIS_NOTIFY_STRING,&quot;set&quot;,key,c-&gt;db-&gt;id);    // 发送事件通知    if (expire) notifyKeyspaceEvent(REDIS_NOTIFY_GENERIC,        &quot;expire&quot;,key,c-&gt;db-&gt;id);    // 设置成功，向客户端发送回复    // 回复的内容由 ok_reply 决定    addReply(c, ok_reply ? ok_reply : shared.ok);}#file:src/object// 尝试对字符串对象进行编码，以节约内存。robj *tryObjectEncoding(robj *o) {    long value;    sds s = o-&gt;ptr;    size_t len;    redisAssertWithInfo(NULL,o,o-&gt;type == REDIS_STRING);    // 只在字符串的编码为 RAW 或者 EMBSTR 时尝试进行编码    if (!sdsEncodedObject(o)) return o;     // 不对共享对象进行编码     if (o-&gt;refcount &gt; 1) return o;    // 对字符串进行检查    // 只对长度小于或等于 21 字节，并且可以被解释为整数的字符串进行编码    len = sdslen(s);    if (len &lt;= 21 &amp;&amp; string2l(s,len,&amp;value)) {        if (server.maxmemory == 0 &amp;&amp;            value &gt;= 0 &amp;&amp;            value &lt; REDIS_SHARED_INTEGERS)        {            decrRefCount(o);            incrRefCount(shared.integers[value]);            return shared.integers[value];        } else {            if (o-&gt;encoding == REDIS_ENCODING_RAW) sdsfree(o-&gt;ptr);            o-&gt;encoding = REDIS_ENCODING_INT;            o-&gt;ptr = (void*) value;            return o;        }    }    // 尝试将 RAW 编码的字符串编码为 EMBSTR 编码    if (len &lt;= REDIS_ENCODING_EMBSTR_SIZE_LIMIT) {        robj *emb;        if (o-&gt;encoding == REDIS_ENCODING_EMBSTR) return o;        emb = createEmbeddedStringObject(s,sdslen(s));        decrRefCount(o);        return emb;    }    // 这个对象没办法进行编码，尝试从 SDS 中移除所有空余空间    if (o-&gt;encoding == REDIS_ENCODING_RAW &amp;&amp;        sdsavail(s) &gt; len/10)    {        o-&gt;ptr = sdsRemoveFreeSpace(o-&gt;ptr);    }    /* Return the original object. */    return o;}</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/stringadd.png" alt=""></p><h3 id="10-4-2-列表对象"><a href="#10-4-2-列表对象" class="headerlink" title="10.4.2 列表对象"></a>10.4.2 列表对象</h3><pre><code class="c"># file : src/t_list.cvoid lpushxCommand(redisClient *c) {    c-&gt;argv[2] = tryObjectEncoding(c-&gt;argv[2]);    pushxGenericCommand(c,NULL,c-&gt;argv[2],REDIS_HEAD);}void rpushxCommand(redisClient *c) {    c-&gt;argv[2] = tryObjectEncoding(c-&gt;argv[2]);    pushxGenericCommand(c,NULL,c-&gt;argv[2],REDIS_TAIL);}void pushxGenericCommand(redisClient *c, robj *refval, robj *val, int where) {    robj *subject;    listTypeIterator *iter;    listTypeEntry entry;    int inserted = 0;    // 取出列表对象    if ((subject = lookupKeyReadOrReply(c,c-&gt;argv[1],shared.czero)) == NULL ||        checkType(c,subject,REDIS_LIST)) return;    // 执行的是 LINSERT 命令    if (refval != NULL) {        // 看保存值 value 是否需要将列表编码转换为双端链表        listTypeTryConversion(subject,val);        /* Seek refval from head to tail */        // 在列表中查找 refval 对象        iter = listTypeInitIterator(subject,0,REDIS_TAIL);        while (listTypeNext(iter,&amp;entry)) {            if (listTypeEqual(&amp;entry,refval)) {                // 找到了，将值插入到节点的前面或后面                listTypeInsert(&amp;entry,val,where);                inserted = 1;                break;            }        }        listTypeReleaseIterator(iter);        if (inserted) {            /* Check if the length exceeds the ziplist length threshold. */            // 查看插入之后是否需要将编码转换为双端链表            if (subject-&gt;encoding == REDIS_ENCODING_ZIPLIST &amp;&amp;                ziplistLen(subject-&gt;ptr) &gt; server.list_max_ziplist_entries)                    listTypeConvert(subject,REDIS_ENCODING_LINKEDLIST);            signalModifiedKey(c-&gt;db,c-&gt;argv[1]);            notifyKeyspaceEvent(REDIS_NOTIFY_LIST,&quot;linsert&quot;,                                c-&gt;argv[1],c-&gt;db-&gt;id);            server.dirty++;        } else {            /* Notify client of a failed insert */            // refval 不存在，插入失败            addReply(c,shared.cnegone);            return;        }    // 执行的是 LPUSHX 或 RPUSHX 命令    } else {        char *event = (where == REDIS_HEAD) ? &quot;lpush&quot; : &quot;rpush&quot;;        listTypePush(subject,val,where);        signalModifiedKey(c-&gt;db,c-&gt;argv[1]);        notifyKeyspaceEvent(REDIS_NOTIFY_LIST,event,c-&gt;argv[1],c-&gt;db-&gt;id);        server.dirty++;    }    addReplyLongLong(c,listTypeLength(subject));}/* * 将给定元素添加到列表的表头或表尾。 * * 参数 where 决定了新元素添加的位置： * *  - REDIS_HEAD 将新元素添加到表头 *  - REDIS_TAIL 将新元素添加到表尾 * * 调用者无须担心 value 的引用计数，因为这个函数会负责这方面的工作。 */void listTypePush(robj *subject, robj *value, int where) {    /* Check if we need to convert the ziplist */    // 是否需要转换编码？    listTypeTryConversion(subject,value);    if (subject-&gt;encoding == REDIS_ENCODING_ZIPLIST &amp;&amp;        ziplistLen(subject-&gt;ptr) &gt;= server.list_max_ziplist_entries)            listTypeConvert(subject,REDIS_ENCODING_LINKEDLIST);    // ZIPLIST    if (subject-&gt;encoding == REDIS_ENCODING_ZIPLIST) {        int pos = (where == REDIS_HEAD) ? ZIPLIST_HEAD : ZIPLIST_TAIL;        // 取出对象的值，因为 ZIPLIST 只能保存字符串或整数        value = getDecodedObject(value);        subject-&gt;ptr = ziplistPush(subject-&gt;ptr,value-&gt;ptr,sdslen(value-&gt;ptr),pos);        decrRefCount(value);    // 双端链表    } else if (subject-&gt;encoding == REDIS_ENCODING_LINKEDLIST) {        if (where == REDIS_HEAD) {            listAddNodeHead(subject-&gt;ptr,value);        } else {            listAddNodeTail(subject-&gt;ptr,value);        }        incrRefCount(value);    // 未知编码    } else {        redisPanic(&quot;Unknown list encoding&quot;);    }}/* * 对输入值 value 进行检查，看是否需要将 subject 从 ziplist 转换为双端链表， * 以便保存值 value 。 * * 函数只对 REDIS_ENCODING_RAW 编码的 value 进行检查， * 因为整数编码的值不可能超长。 */void listTypeTryConversion(robj *subject, robj *value) {    // 确保 subject 为 ZIPLIST 编码    if (subject-&gt;encoding != REDIS_ENCODING_ZIPLIST) return;    if (sdsEncodedObject(value) &amp;&amp;        // 看字符串是否过长        sdslen(value-&gt;ptr) &gt; server.list_max_ziplist_value)            // 将编码转换为双端链表            listTypeConvert(subject,REDIS_ENCODING_LINKEDLIST);}/* * 将列表的底层编码从 ziplist 转换成双端链表 */void listTypeConvert(robj *subject, int enc) {    listTypeIterator *li;    listTypeEntry entry;    redisAssertWithInfo(NULL,subject,subject-&gt;type == REDIS_LIST);    // 转换成双端链表    if (enc == REDIS_ENCODING_LINKEDLIST) {        list *l = listCreate();        listSetFreeMethod(l,decrRefCountVoid);        // 遍历 ziplist ，并将里面的值全部添加到双端链表中        li = listTypeInitIterator(subject,0,REDIS_TAIL);        while (listTypeNext(li,&amp;entry)) listAddNodeTail(l,listTypeGet(&amp;entry));        listTypeReleaseIterator(li);        // 更新编码        subject-&gt;encoding = REDIS_ENCODING_LINKEDLIST;        // 释放原来的 ziplist        zfree(subject-&gt;ptr);        // 更新对象值指针        subject-&gt;ptr = l;    } else {        redisPanic(&quot;Unsupported list conversion&quot;);    }}#file : src/object.c/* * 创建一个 ZIPLIST 编码的列表对象 */robj *createZiplistObject(void) {    unsigned char *zl = ziplistNew();    robj *o = createObject(REDIS_LIST,zl);    o-&gt;encoding = REDIS_ENCODING_ZIPLIST;    return o;}</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/listadd.png" alt=""></p><h3 id="10-4-3-哈希对象"><a href="#10-4-3-哈希对象" class="headerlink" title="10.4.3 哈希对象"></a>10.4.3 哈希对象</h3><pre><code class="c">#file src/t_hash.c/*----------------------------------------------------------------------------- * Hash type commands *----------------------------------------------------------------------------*/void hsetCommand(redisClient *c) {    int update;    robj *o;    // 取出或新创建哈希对象    if ((o = hashTypeLookupWriteOrCreate(c,c-&gt;argv[1])) == NULL) return;    // 如果需要的话，转换哈希对象的编码    hashTypeTryConversion(o,c-&gt;argv,2,3);    // 编码 field 和 value 对象以节约空间    hashTypeTryObjectEncoding(o,&amp;c-&gt;argv[2], &amp;c-&gt;argv[3]);    // 设置 field 和 value 到 hash    update = hashTypeSet(o,c-&gt;argv[2],c-&gt;argv[3]);    // 返回状态：显示 field-value 对是新添加还是更新    addReply(c, update ? shared.czero : shared.cone);    // 发送键修改信号    signalModifiedKey(c-&gt;db,c-&gt;argv[1]);    // 发送事件通知    notifyKeyspaceEvent(REDIS_NOTIFY_HASH,&quot;hset&quot;,c-&gt;argv[1],c-&gt;db-&gt;id);    // 将服务器设为脏    server.dirty++;}void hsetnxCommand(redisClient *c) {    robj *o;    // 取出或新创建哈希对象    if ((o = hashTypeLookupWriteOrCreate(c,c-&gt;argv[1])) == NULL) return;    // 如果需要的话，转换哈希对象的编码    hashTypeTryConversion(o,c-&gt;argv,2,3);    // 如果 field-value 对已经存在    // 那么回复 0     if (hashTypeExists(o, c-&gt;argv[2])) {        addReply(c, shared.czero);    // 否则，设置 field-value 对    } else {        // 对 field 和 value 对象编码，以节省空间        hashTypeTryObjectEncoding(o,&amp;c-&gt;argv[2], &amp;c-&gt;argv[3]);        // 设置        hashTypeSet(o,c-&gt;argv[2],c-&gt;argv[3]);        // 回复 1 ，表示设置成功        addReply(c, shared.cone);        // 发送键修改信号        signalModifiedKey(c-&gt;db,c-&gt;argv[1]);        // 发送事件通知        notifyKeyspaceEvent(REDIS_NOTIFY_HASH,&quot;hset&quot;,c-&gt;argv[1],c-&gt;db-&gt;id);       // 将数据库设为脏        server.dirty++;    }}void hmsetCommand(redisClient *c) {    int i;    robj *o;    // field-value 参数必须成对出现    if ((c-&gt;argc % 2) == 1) {        addReplyError(c,&quot;wrong number of arguments for HMSET&quot;);        return;    }    // 取出或新创建哈希对象    if ((o = hashTypeLookupWriteOrCreate(c,c-&gt;argv[1])) == NULL) return;    // 如果需要的话，转换哈希对象的编码    hashTypeTryConversion(o,c-&gt;argv,2,c-&gt;argc-1);    // 遍历并设置所有 field-value 对    for (i = 2; i &lt; c-&gt;argc; i += 2) {        // 编码 field-value 对，以节约空间        hashTypeTryObjectEncoding(o,&amp;c-&gt;argv[i], &amp;c-&gt;argv[i+1]);        // 设置        hashTypeSet(o,c-&gt;argv[i],c-&gt;argv[i+1]);    }    // 向客户端发送回复    addReply(c, shared.ok);    // 发送键修改信号    signalModifiedKey(c-&gt;db,c-&gt;argv[1]);    // 发送事件通知    notifyKeyspaceEvent(REDIS_NOTIFY_HASH,&quot;hset&quot;,c-&gt;argv[1],c-&gt;db-&gt;id);    // 将数据库设为脏    server.dirty++;}/* * 对 argv 数组中的多个对象进行检查， * 看是否需要将对象的编码从 REDIS_ENCODING_ZIPLIST 转换成 REDIS_ENCODING_HT * * 注意程序只检查字符串值，因为它们的长度可以在常数时间内取得。 */void hashTypeTryConversion(robj *o, robj **argv, int start, int end) {    int i;    // 如果对象不是 ziplist 编码，那么直接返回    if (o-&gt;encoding != REDIS_ENCODING_ZIPLIST) return;    // 检查所有输入对象，看它们的字符串值是否超过了指定长度    for (i = start; i &lt;= end; i++) {        if (sdsEncodedObject(argv[i]) &amp;&amp;            sdslen(argv[i]-&gt;ptr) &gt; server.hash_max_ziplist_value)        {            // 将对象的编码转换成 REDIS_ENCODING_HT            hashTypeConvert(o, REDIS_ENCODING_HT);            break;        }    }}/* * 对哈希对象 o 的编码方式进行转换 * * 目前只支持将 ZIPLIST 编码转换成 HT 编码 */void hashTypeConvert(robj *o, int enc) {    if (o-&gt;encoding == REDIS_ENCODING_ZIPLIST) {        hashTypeConvertZiplist(o, enc);    } else if (o-&gt;encoding == REDIS_ENCODING_HT) {        redisPanic(&quot;Not implemented&quot;);    } else {        redisPanic(&quot;Unknown hash encoding&quot;);    }}/*  * 将给定的 field-value 对添加到 hash 中， * 如果 field 已经存在，那么删除旧的值，并关联新值。 * 这个函数负责对 field 和 value 参数进行引用计数自增。 * * 返回 0 表示元素已经存在，这次函数调用执行的是更新操作。 * 返回 1 则表示函数执行的是新添加操作。 */int hashTypeSet(robj *o, robj *field, robj *value) {    int update = 0;    // 添加到 ziplist    if (o-&gt;encoding == REDIS_ENCODING_ZIPLIST) {        unsigned char *zl, *fptr, *vptr;        // 解码成字符串或者数字        field = getDecodedObject(field);        value = getDecodedObject(value);        // 遍历整个 ziplist ，尝试查找并更新 field （如果它已经存在的话）        zl = o-&gt;ptr;        fptr = ziplistIndex(zl, ZIPLIST_HEAD);        if (fptr != NULL) {            // 定位到域 field            fptr = ziplistFind(fptr, field-&gt;ptr, sdslen(field-&gt;ptr), 1);            if (fptr != NULL) {                /* Grab pointer to the value (fptr points to the field) */                // 定位到域的值                vptr = ziplistNext(zl, fptr);                redisAssert(vptr != NULL);                // 标识这次操作为更新操作                update = 1;                /* Delete value */                // 删除旧的键值对                zl = ziplistDelete(zl, &amp;vptr);                /* Insert new value */                // 添加新的键值对                zl = ziplistInsert(zl, vptr, value-&gt;ptr, sdslen(value-&gt;ptr));            }        }        // 如果这不是更新操作，那么这就是一个添加操作        if (!update) {            /* Push new field/value pair onto the tail of the ziplist */            // 将新的 field-value 对推入到 ziplist 的末尾            zl = ziplistPush(zl, field-&gt;ptr, sdslen(field-&gt;ptr), ZIPLIST_TAIL);            zl = ziplistPush(zl, value-&gt;ptr, sdslen(value-&gt;ptr), ZIPLIST_TAIL);        }        // 更新对象指针        o-&gt;ptr = zl;        // 释放临时对象        decrRefCount(field);        decrRefCount(value);        // 检查在添加操作完成之后，是否需要将 ZIPLIST 编码转换成 HT 编码        if (hashTypeLength(o) &gt; server.hash_max_ziplist_entries)            hashTypeConvert(o, REDIS_ENCODING_HT);    // 添加到字典    } else if (o-&gt;encoding == REDIS_ENCODING_HT) {        // 添加或替换键值对到字典        // 添加返回 1 ，替换返回 0        if (dictReplace(o-&gt;ptr, field, value)) { /* Insert */            incrRefCount(field);        } else { /* Update */            update = 1;        }        incrRefCount(value);    } else {        redisPanic(&quot;Unknown hash encoding&quot;);    }    // 更新/添加指示变量    return update;}#file: src/object.c/* * 创建一个 ZIPLIST 编码的哈希对象 */robj *createHashObject(void) {    unsigned char *zl = ziplistNew();    robj *o = createObject(REDIS_HASH, zl);    o-&gt;encoding = REDIS_ENCODING_ZIPLIST;    return o;}</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/hashadd.png" alt=""></p><h3 id="10-4-4-集合对象"><a href="#10-4-4-集合对象" class="headerlink" title="10.4.4 集合对象"></a>10.4.4 集合对象</h3><pre><code class="c">#file: src/t_set.cvoid saddCommand(redisClient *c) {    robj *set;    int j, added = 0;    // 取出集合对象    set = lookupKeyWrite(c-&gt;db,c-&gt;argv[1]);    // 对象不存在，创建一个新的，并将它关联到数据库    if (set == NULL) {        set = setTypeCreate(c-&gt;argv[2]);        dbAdd(c-&gt;db,c-&gt;argv[1],set);    // 对象存在，检查类型    } else {        if (set-&gt;type != REDIS_SET) {            addReply(c,shared.wrongtypeerr);            return;        }    }    // 将所有输入元素添加到集合中    for (j = 2; j &lt; c-&gt;argc; j++) {        c-&gt;argv[j] = tryObjectEncoding(c-&gt;argv[j]);        // 只有元素未存在于集合时，才算一次成功添加        if (setTypeAdd(set,c-&gt;argv[j])) added++;    }    // 如果有至少一个元素被成功添加，那么执行以下程序    if (added) {        // 发送键修改信号        signalModifiedKey(c-&gt;db,c-&gt;argv[1]);        // 发送事件通知        notifyKeyspaceEvent(REDIS_NOTIFY_SET,&quot;sadd&quot;,c-&gt;argv[1],c-&gt;db-&gt;id);    }    // 将数据库设为脏    server.dirty += added;    // 返回添加元素的数量    addReplyLongLong(c,added);}/*  * 返回一个可以保存值 value 的集合。 * 当对象的值可以被编码为整数时，返回 intset ， * 否则，返回普通的哈希表。 */robj *setTypeCreate(robj *value) {    if (isObjectRepresentableAsLongLong(value,NULL) == REDIS_OK)        return createIntsetObject();    return createSetObject();}/*  * 将集合对象 setobj 的编码转换为 REDIS_ENCODING_HT 。 * * 新创建的结果字典会被预先分配为和原来的集合一样大。 */void setTypeConvert(robj *setobj, int enc) {    setTypeIterator *si;    // 确认类型和编码正确    redisAssertWithInfo(NULL,setobj,setobj-&gt;type == REDIS_SET &amp;&amp;                             setobj-&gt;encoding == REDIS_ENCODING_INTSET);    if (enc == REDIS_ENCODING_HT) {        int64_t intele;        // 创建新字典        dict *d = dictCreate(&amp;setDictType,NULL);        robj *element;        /* Presize the dict to avoid rehashing */        // 预先扩展空间        dictExpand(d,intsetLen(setobj-&gt;ptr));        /* To add the elements we extract integers and create redis objects */        // 遍历集合，并将元素添加到字典中        si = setTypeInitIterator(setobj);        while (setTypeNext(si,NULL,&amp;intele) != -1) {            element = createStringObjectFromLongLong(intele);            redisAssertWithInfo(NULL,element,dictAdd(d,element,NULL) == DICT_OK);        }        setTypeReleaseIterator(si);        // 更新集合的编码        setobj-&gt;encoding = REDIS_ENCODING_HT;        zfree(setobj-&gt;ptr);        // 更新集合的值对象        setobj-&gt;ptr = d;    } else {        redisPanic(&quot;Unsupported set conversion&quot;);    }}/* * 多态 add 操作 * * 添加成功返回 1 ，如果元素已经存在，返回 0 。 */int setTypeAdd(robj *subject, robj *value) {    long long llval;    // 字典    if (subject-&gt;encoding == REDIS_ENCODING_HT) {        // 将 value 作为键， NULL 作为值，将元素添加到字典中        if (dictAdd(subject-&gt;ptr,value,NULL) == DICT_OK) {            incrRefCount(value);            return 1;        }    // intset    } else if (subject-&gt;encoding == REDIS_ENCODING_INTSET) {        // 如果对象的值可以编码为整数的话，那么将对象的值添加到 intset 中        if (isObjectRepresentableAsLongLong(value,&amp;llval) == REDIS_OK) {            uint8_t success = 0;            subject-&gt;ptr = intsetAdd(subject-&gt;ptr,llval,&amp;success);            if (success) {                /* Convert to regular set when the intset contains                 * too many entries. */                // 添加成功                // 检查集合在添加新元素之后是否需要转换为字典                if (intsetLen(subject-&gt;ptr) &gt; server.set_max_intset_entries)                    setTypeConvert(subject,REDIS_ENCODING_HT);                return 1;            }        // 如果对象的值不能编码为整数，那么将集合从 intset 编码转换为 HT 编码        // 然后再执行添加操作        } else {            /* Failed to get integer from object, convert to regular set. */            setTypeConvert(subject,REDIS_ENCODING_HT);            /* The set *was* an intset and this value is not integer             * encodable, so dictAdd should always work. */            redisAssertWithInfo(NULL,value,dictAdd(subject-&gt;ptr,value,NULL) == DICT_OK);            incrRefCount(value);            return 1;        }    // 未知编码    } else {        redisPanic(&quot;Unknown set encoding&quot;);    }    // 添加失败，元素已经存在    return 0;}#file: src/db.c/* * 为执行写入操作而取出键 key 在数据库 db 中的值。 * 和 lookupKeyRead 不同，这个函数不会更新服务器的命中/不命中信息。 * 找到时返回值对象，没找到返回 NULL 。 */robj *lookupKeyWrite(redisDb *db, robj *key) {    // 删除过期键    expireIfNeeded(db,key);    // 查找并返回 key 的值对象    return lookupKey(db,key);}</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/setadd.png" alt=""></p><h3 id="10-4-5-有序集合对象"><a href="#10-4-5-有序集合对象" class="headerlink" title="10.4.5 有序集合对象"></a>10.4.5 有序集合对象</h3><pre><code class="c">#file : src/t_zset.cvoid zaddCommand(redisClient *c) {    zaddGenericCommand(c,0);}void zincrbyCommand(redisClient *c) {    zaddGenericCommand(c,1);}/* This generic command implements both ZADD and ZINCRBY. */void zaddGenericCommand(redisClient *c, int incr) {    static char *nanerr = &quot;resulting score is not a number (NaN)&quot;;    robj *key = c-&gt;argv[1];    robj *ele;    robj *zobj;    robj *curobj;    double score = 0, *scores = NULL, curscore = 0.0;    int j, elements = (c-&gt;argc-2)/2;    int added = 0, updated = 0;    // 输入的 score - member 参数必须是成对出现的    if (c-&gt;argc % 2) {        addReply(c,shared.syntaxerr);        return;    }    // 取出所有输入的 score 分值    scores = zmalloc(sizeof(double)*elements);    for (j = 0; j &lt; elements; j++) {        if (getDoubleFromObjectOrReply(c,c-&gt;argv[2+j*2],&amp;scores[j],NULL)            != REDIS_OK) goto cleanup;    }    /* Lookup the key and create the sorted set if does not exist. */    // 取出有序集合对象    zobj = lookupKeyWrite(c-&gt;db,key);    if (zobj == NULL) {        // 有序集合不存在，创建新有序集合        if (server.zset_max_ziplist_entries == 0 ||            server.zset_max_ziplist_value &lt; sdslen(c-&gt;argv[3]-&gt;ptr))        {            zobj = createZsetObject();        } else {            zobj = createZsetZiplistObject();        }        // 关联对象到数据库        dbAdd(c-&gt;db,key,zobj);    } else {        // 对象存在，检查类型        if (zobj-&gt;type != REDIS_ZSET) {            addReply(c,shared.wrongtypeerr);            goto cleanup;        }    }    // 处理所有元素    for (j = 0; j &lt; elements; j++) {        score = scores[j];        // 有序集合为 ziplist 编码        if (zobj-&gt;encoding == REDIS_ENCODING_ZIPLIST) {            unsigned char *eptr;            /* Prefer non-encoded element when dealing with ziplists. */            // 查找成员            ele = c-&gt;argv[3+j*2];            if ((eptr = zzlFind(zobj-&gt;ptr,ele,&amp;curscore)) != NULL) {                // 成员已存在                // ZINCRYBY 命令时使用                if (incr) {                    score += curscore;                    if (isnan(score)) {                        addReplyError(c,nanerr);                        goto cleanup;                    }                }                // 执行 ZINCRYBY 命令时，                // 或者用户通过 ZADD 修改成员的分值时执行                if (score != curscore) {                    // 删除已有元素                    zobj-&gt;ptr = zzlDelete(zobj-&gt;ptr,eptr);                    // 重新插入元素                    zobj-&gt;ptr = zzlInsert(zobj-&gt;ptr,ele,score);                    // 计数器                    server.dirty++;                    updated++;                }            } else {                // 元素不存在，直接添加                zobj-&gt;ptr = zzlInsert(zobj-&gt;ptr,ele,score);                // 查看元素的数量，                // 看是否需要将 ZIPLIST 编码转换为有序集合                if (zzlLength(zobj-&gt;ptr) &gt; server.zset_max_ziplist_entries)                    zsetConvert(zobj,REDIS_ENCODING_SKIPLIST);                // 查看新添加元素的长度                // 看是否需要将 ZIPLIST 编码转换为有序集合                if (sdslen(ele-&gt;ptr) &gt; server.zset_max_ziplist_value)                    zsetConvert(zobj,REDIS_ENCODING_SKIPLIST);                server.dirty++;                added++;            }        // 有序集合为 SKIPLIST 编码        } else if (zobj-&gt;encoding == REDIS_ENCODING_SKIPLIST) {            zset *zs = zobj-&gt;ptr;            zskiplistNode *znode;            dictEntry *de;            // 编码对象            ele = c-&gt;argv[3+j*2] = tryObjectEncoding(c-&gt;argv[3+j*2]);            // 查看成员是否存在            de = dictFind(zs-&gt;dict,ele);            if (de != NULL) {                // 成员存在                // 取出成员                curobj = dictGetKey(de);                // 取出分值                curscore = *(double*)dictGetVal(de);                // ZINCRYBY 时执行                if (incr) {                    score += curscore;                    if (isnan(score)) {                        addReplyError(c,nanerr);                        /* Don&#39;t need to check if the sorted set is empty                         * because we know it has at least one element. */                        goto cleanup;                    }                }                // 执行 ZINCRYBY 命令时，                // 或者用户通过 ZADD 修改成员的分值时执行                if (score != curscore) {                    // 删除原有元素                    redisAssertWithInfo(c,curobj,zslDelete(zs-&gt;zsl,curscore,curobj));                    // 重新插入元素                    znode = zslInsert(zs-&gt;zsl,score,curobj);                    incrRefCount(curobj); /* Re-inserted in skiplist. */                    // 更新字典的分值指针                    dictGetVal(de) = &amp;znode-&gt;score; /* Update score ptr. */                    server.dirty++;                    updated++;                }            } else {                // 元素不存在，直接添加到跳跃表                znode = zslInsert(zs-&gt;zsl,score,ele);                incrRefCount(ele); /* Inserted in skiplist. */                // 将元素关联到字典                redisAssertWithInfo(c,NULL,dictAdd(zs-&gt;dict,ele,&amp;znode-&gt;score) == DICT_OK);                incrRefCount(ele); /* Added to dictionary. */                server.dirty++;                added++;            }        } else {            redisPanic(&quot;Unknown sorted set encoding&quot;);        }    }    if (incr) /* ZINCRBY */        addReplyDouble(c,score);    else /* ZADD */        addReplyLongLong(c,added);cleanup:    zfree(scores);    if (added || updated) {        signalModifiedKey(c-&gt;db,key);        notifyKeyspaceEvent(REDIS_NOTIFY_ZSET,            incr ? &quot;zincr&quot; : &quot;zadd&quot;, key, c-&gt;db-&gt;id);    }}/* * 将跳跃表对象 zobj 的底层编码转换为 encoding 。 */void zsetConvert(robj *zobj, int encoding) {    zset *zs;    zskiplistNode *node, *next;    robj *ele;    double score;    if (zobj-&gt;encoding == encoding) return;    // 从 ZIPLIST 编码转换为 SKIPLIST 编码    if (zobj-&gt;encoding == REDIS_ENCODING_ZIPLIST) {        unsigned char *zl = zobj-&gt;ptr;        unsigned char *eptr, *sptr;        unsigned char *vstr;        unsigned int vlen;        long long vlong;        if (encoding != REDIS_ENCODING_SKIPLIST)            redisPanic(&quot;Unknown target encoding&quot;);        // 创建有序集合结构        zs = zmalloc(sizeof(*zs));        // 字典        zs-&gt;dict = dictCreate(&amp;zsetDictType,NULL);        // 跳跃表        zs-&gt;zsl = zslCreate();        // 有序集合在 ziplist 中的排列：        //        // | member-1 | score-1 | member-2 | score-2 | ... |        //        // 指向 ziplist 中的首个节点（保存着元素成员）        eptr = ziplistIndex(zl,0);        redisAssertWithInfo(NULL,zobj,eptr != NULL);        // 指向 ziplist 中的第二个节点（保存着元素分值）        sptr = ziplistNext(zl,eptr);        redisAssertWithInfo(NULL,zobj,sptr != NULL);        // 遍历所有 ziplist 节点，并将元素的成员和分值添加到有序集合中        while (eptr != NULL) {            // 取出分值            score = zzlGetScore(sptr);            // 取出成员            redisAssertWithInfo(NULL,zobj,ziplistGet(eptr,&amp;vstr,&amp;vlen,&amp;vlong));            if (vstr == NULL)                ele = createStringObjectFromLongLong(vlong);            else                ele = createStringObject((char*)vstr,vlen);            /* Has incremented refcount since it was just created. */            // 将成员和分值分别关联到跳跃表和字典中            node = zslInsert(zs-&gt;zsl,score,ele);            redisAssertWithInfo(NULL,zobj,dictAdd(zs-&gt;dict,ele,&amp;node-&gt;score) == DICT_OK);            incrRefCount(ele); /* Added to dictionary. */            // 移动指针，指向下个元素            zzlNext(zl,&amp;eptr,&amp;sptr);        }        // 释放原来的 ziplist        zfree(zobj-&gt;ptr);        // 更新对象的值，以及编码方式        zobj-&gt;ptr = zs;        zobj-&gt;encoding = REDIS_ENCODING_SKIPLIST;    // 从 SKIPLIST 转换为 ZIPLIST 编码    } else if (zobj-&gt;encoding == REDIS_ENCODING_SKIPLIST) {        // 新的 ziplist        unsigned char *zl = ziplistNew();        if (encoding != REDIS_ENCODING_ZIPLIST)            redisPanic(&quot;Unknown target encoding&quot;);        /* Approach similar to zslFree(), since we want to free the skiplist at         * the same time as creating the ziplist. */        // 指向跳跃表        zs = zobj-&gt;ptr;        // 先释放字典，因为只需要跳跃表就可以遍历整个有序集合了        dictRelease(zs-&gt;dict);        // 指向跳跃表首个节点        node = zs-&gt;zsl-&gt;header-&gt;level[0].forward;        // 释放跳跃表表头        zfree(zs-&gt;zsl-&gt;header);        zfree(zs-&gt;zsl);        // 遍历跳跃表，取出里面的元素，并将它们添加到 ziplist        while (node) {            // 取出解码后的值对象            ele = getDecodedObject(node-&gt;obj);            // 添加元素到 ziplist            zl = zzlInsertAt(zl,NULL,ele,node-&gt;score);            decrRefCount(ele);            // 沿着跳跃表的第 0 层前进            next = node-&gt;level[0].forward;            zslFreeNode(node);            node = next;        }        // 释放跳跃表        zfree(zs);        // 更新对象的值，以及对象的编码方式        zobj-&gt;ptr = zl;        zobj-&gt;encoding = REDIS_ENCODING_ZIPLIST;    } else {        redisPanic(&quot;Unknown sorted set encoding&quot;);    }}</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/zsetadd.png" alt=""></p><h2 id="10-5-内存回收"><a href="#10-5-内存回收" class="headerlink" title="10.5 内存回收"></a>10.5 内存回收</h2><p>因为 C 语言并不具备自动的内存回收功能， 所以 Redis 在自己的对象系统中构建了一个引用计数（reference counting）技术实现的内存回收机制， 通过这一机制， 程序可以通过跟踪对象的引用计数信息， 在适当的时候自动释放对象并进行内存回收。</p><p>每个对象的引用计数信息由 redisObject 结构的 refcount 属性记录</p><p>对象的引用计数信息会随着对象的使用状态而不断变化：</p><ul><li>在创建一个新对象时， 引用计数的值会被初始化为 1 ；</li><li>当对象被一个新程序使用时， 它的引用计数值会被增一；</li><li>当对象不再被一个程序使用时， 它的引用计数值会被减一；</li><li>当对象的引用计数值变为 0 时， 对象所占用的内存会被释放。</li></ul><p>操作refcount的函数:</p><pre><code class="c">#file: src/object.c#incrRefCount 将对象的引用计数值增一。#decrRefCount 将对象的引用计数值减一，当对象的引用计数值等于0时，释放对象。#resetRefCount 将对象的引用计数值设置为0，但并不释放对象，这个函数通常在需要重新设置对象的引用计数值时使用/* * 为对象的引用计数增一 */void incrRefCount(robj *o) {    o-&gt;refcount++;}/* * 为对象的引用计数减一 * 当对象的引用计数降为 0 时，释放对象。 */void decrRefCount(robj *o) {    if (o-&gt;refcount &lt;= 0) redisPanic(&quot;decrRefCount against refcount &lt;= 0&quot;);    // 释放对象    if (o-&gt;refcount == 1) {        switch(o-&gt;type) {        case REDIS_STRING: freeStringObject(o); break;        case REDIS_LIST: freeListObject(o); break;        case REDIS_SET: freeSetObject(o); break;        case REDIS_ZSET: freeZsetObject(o); break;        case REDIS_HASH: freeHashObject(o); break;        default: redisPanic(&quot;Unknown object type&quot;); break;        }        zfree(o);    // 减少计数    } else {        o-&gt;refcount--;    }}robj *resetRefCount(robj *obj) {    obj-&gt;refcount = 0;    return obj;}</code></pre><h2 id="10-6-对象共享"><a href="#10-6-对象共享" class="headerlink" title="10.6 对象共享"></a>10.6 对象共享</h2><p>除了用于实现引用计数内存回收机制之外， 对象的引用计数属性还带有对象共享的作用。</p><p>在 Redis 中， 让多个键共享同一个值对象需要执行以下两个步骤：</p><ol><li>将数据库键的值指针指向一个现有的值对象；</li><li>将被共享的值对象的引用计数增一。</li></ol><p>目前来说， Redis 会在初始化服务器时， 创建一万个字符串对象， 这些对象包含了<code>从 0 到 9999 的所有整数值</code>， 当服务器需要用到值为 0 到 9999 的字符串对象时， 服务器就会使用这些共享对象， 而不是新创建对象。</p><p><code>【注意】redis只对包含整数值的字符串对象进行共享。</code></p><blockquote><p>尽管共享更复杂的对象可以节约更多的内存，但验证共享对象和目标对象是否相同所需的复杂度就会越高， 消耗的 CPU 时间也会越多</p></blockquote><h2 id="10-7-对象空转时长"><a href="#10-7-对象空转时长" class="headerlink" title="10.7 对象空转时长"></a>10.7 对象空转时长</h2><p>redisObject 结构包含一个属性为 lru 属性， 该属性记录了对象最后一次被命令程序访问的时间：</p><pre><code class="c">redis&gt; SET foo &quot;bar&quot;OKredis&gt; OBJECT IDLETIME foo(integer) 5redis&gt; OBJECT IDLETIME foo(integer) 15redis&gt; GET foo&quot;bar&quot;redis&gt; OBJECT IDLETIME foo(integer) 5</code></pre><p>如果服务器打开了 maxmemory 选项， 并且服务器用于回收内存的算法为 volatile-lru 或者 allkeys-lru ， 那么当服务器占用的内存数超过了 maxmemory 选项所设置的上限值时， 空转时长较高的那部分键会优先被服务器释放， 从而回收内存。</p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>9.Redis数据结构——zipmap</title>
      <link href="/2020/02/20/9-Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-zipmap/"/>
      <url>/2020/02/20/9-Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-zipmap/</url>
      
        <content type="html"><![CDATA[<p><code>【注意】注意，从 2.6 版本开始，Redis使用ziplist 来表示小Hash,而不再使用 zipmap</code></p><p>zipmap压缩字典为节约空间而实现的字符串到字符串映射结构<br>这个数据结构非常节约内存，并且支持复杂度为 O(N) 的查找操作。</p><p>Redis 使用这个数据结构来储存键值对数量不多的 Hash ，一旦键值对的数量超过某个给定值，Hash 的底层表示就会自动转换成哈希表。</p><p>因为很多时候，一个 Hash 都只保存少数几个 key-value 对，<br>所以使用 zipmap 比起直接使用真正的哈希表要节约不少内存。</p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>8.Redis数据结构——ziplist</title>
      <link href="/2020/02/20/8-Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-ziplist/"/>
      <url>/2020/02/20/8-Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-ziplist/</url>
      
        <content type="html"><![CDATA[<h2 id="8-1-什么是ziplist"><a href="#8-1-什么是ziplist" class="headerlink" title="8.1 什么是ziplist"></a>8.1 什么是ziplist</h2><p>压缩列表（ziplist）是列表键和哈希键的底层实现之一。</p><p>当一个列表键只包含少量列表项， 并且每个列表项要么就是小整数值， 要么就是长度比较短的字符串， 那么 Redis 就会使用压缩列表来做列表键的底层实现。</p><h2 id="8-2-数据结构"><a href="#8-2-数据结构" class="headerlink" title="8.2 数据结构"></a>8.2 数据结构</h2><p>在本质上就是一块连续的内存,逻辑上设计成了特殊编码的双端链表</p><pre><code class="c">#file: src/ziplist.c/*  * Ziplist 是为了尽可能地节约内存而设计的特殊编码双端链表。 * Ziplist 可以储存字符串值和整数值， * 其中，整数值被保存为实际的整数，而不是字符数组。 * Ziplist 允许在列表的两端进行 O(1) 复杂度的 push 和 pop 操作。 * 但是，因为这些操作都需要对整个 ziplist 进行内存重分配， * 所以实际的复杂度和 ziplist 占用的内存大小有关。 * ---------------------------------------------------------------------------- * * ZIPLIST OVERALL LAYOUT: * Ziplist 的整体布局： * * The general layout of the ziplist is as follows: * 以下是 ziplist 的一般布局： * * &lt;zlbytes&gt;&lt;zltail&gt;&lt;zllen&gt;&lt;entry&gt;&lt;entry&gt;&lt;zlend&gt; * * &lt;zlbytes&gt; 是一个无符号整数，保存着 ziplist 使用的内存数量。 * 通过这个值，程序可以直接对 ziplist 的内存大小进行调整， * 而无须为了计算 ziplist 的内存大小而遍历整个列表。 * * &lt;zltail&gt; 保存着到达列表中最后一个节点的偏移量。 * 这个偏移量使得对表尾的 pop 操作可以在无须遍历整个列表的情况下进行。 * * &lt;zllen&gt; 保存着列表中的节点数量。 *  * 当 zllen 保存的值大于 2**16-2 时， * 程序需要遍历整个列表才能知道列表实际包含了多少个节点。 * * &lt;zlend&gt; 的长度为 1 字节，值为 255 ，标识列表的末尾。 * * ZIPLIST 节点： * * 每个 ziplist 节点的前面都带有一个 header ，这个 header 包含两部分信息： * * 1)前置节点的长度，在程序从后向前遍历时使用。 * * 2)当前节点所保存的值的类型和长度。 * * 编码前置节点的长度的方法如下： * * 1) 如果前置节点的长度小于 254 字节，那么程序将使用 1 个字节来保存这个长度值。 * * 2) 如果前置节点的长度大于等于 254 字节，那么程序将使用 5 个字节来保存这个长度值： *    a) 第 1 个字节的值将被设为 254 ，用于标识这是一个 5 字节长的长度值。 *    b) 之后的 4 个字节则用于保存前置节点的实际长度。 * * * header 另一部分的内容和节点所保存的值有关。 * * 1) 如果节点保存的是字符串值， *    那么这部分 header 的头 2 个位将保存编码字符串长度所使用的类型， *    而之后跟着的内容则是字符串的实际长度。 * * |00pppppp| - 1 byte *      String value with length less than or equal to 63 bytes (6 bits). *      字符串的长度小于或等于 63 字节。 * |01pppppp|qqqqqqqq| - 2 bytes *      String value with length less than or equal to 16383 bytes (14 bits). *      字符串的长度小于或等于 16383 字节。 * |10______|qqqqqqqq|rrrrrrrr|ssssssss|tttttttt| - 5 bytes *      String value with length greater than or equal to 16384 bytes. *      字符串的长度大于或等于 16384 字节。 * * 2) 如果节点保存的是整数值， *    那么这部分 header 的头 2 位都将被设置为 1 ， *    而之后跟着的 2 位则用于标识节点所保存的整数的类型。 * * |11000000| - 1 byte *      Integer encoded as int16_t (2 bytes). *      节点的值为 int16_t 类型的整数，长度为 2 字节。 * |11010000| - 1 byte *      Integer encoded as int32_t (4 bytes). *      节点的值为 int32_t 类型的整数，长度为 4 字节。 * |11100000| - 1 byte *      Integer encoded as int64_t (8 bytes). *      节点的值为 int64_t 类型的整数，长度为 8 字节。 * |11110000| - 1 byte *      Integer encoded as 24 bit signed (3 bytes). *      节点的值为 24 位（3 字节）长的整数。 * |11111110| - 1 byte *      Integer encoded as 8 bit signed (1 byte). *      节点的值为 8 位（1 字节）长的整数。 * |1111xxxx| - (with xxxx between 0000 and 1101) immediate 4 bit integer. *      Unsigned integer from 0 to 12. The encoded value is actually from *      1 to 13 because 0000 and 1111 can not be used, so 1 should be *      subtracted from the encoded 4 bit value to obtain the right value. *      节点的值为介于 0 至 12 之间的无符号整数。 *      因为 0000 和 1111 都不能使用，所以位的实际值将是 1 至 13 。 *      程序在取得这 4 个位的值之后，还需要减去 1 ，才能计算出正确的值。 *      比如说，如果位的值为 0001 = 1 ，那么程序返回的值将是 1 - 1 = 0 。 * |11111111| - End of ziplist. *      ziplist 的结尾标识 * * All the integers are represented in little endian byte order. * * 所有整数都表示为小端字节序。 *</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/ziplist.png" alt=""></p><h2 id="8-3-数据插入"><a href="#8-3-数据插入" class="headerlink" title="8.3 数据插入"></a>8.3 数据插入</h2><pre><code class="c">#file: src/ziplist.c/* * 根据指针 p 所指定的位置，将长度为 slen 的字符串 s 插入到 zl 中。 * 函数的返回值为完成插入操作之后的 ziplist * T = O(N^2) */static unsigned char *__ziplistInsert(unsigned char *zl, unsigned char *p, unsigned char *s, unsigned int slen) {    // 记录当前 ziplist 的长度    size_t curlen = intrev32ifbe(ZIPLIST_BYTES(zl)), reqlen, prevlen = 0;    size_t offset;    int nextdiff = 0;    unsigned char encoding = 0;    long long value = 123456789; /* initialized to avoid warning. Using a value                                    that is easy to see if for some reason                                    we use it uninitialized. */    zlentry entry, tail;    /* Find out prevlen for the entry that is inserted. */    if (p[0] != ZIP_END) {        // 如果 p[0] 不指向列表末端，说明列表非空，并且 p 正指向列表的其中一个节点        // 那么取出 p 所指向节点的信息，并将它保存到 entry 结构中        // 然后用 prevlen 变量记录前置节点的长度        // （当插入新节点之后 p 所指向的节点就成了新节点的前置节点）        // T = O(1)        entry = zipEntry(p);        prevlen = entry.prevrawlen;    } else {        // 如果 p 指向表尾末端，那么程序需要检查列表是否为：        // 1)如果 ptail 也指向 ZIP_END ，那么列表为空；        // 2)如果列表不为空，那么 ptail 将指向列表的最后一个节点。        unsigned char *ptail = ZIPLIST_ENTRY_TAIL(zl);        if (ptail[0] != ZIP_END) {            // 表尾节点为新节点的前置节点            // 取出表尾节点的长度            // T = O(1)            prevlen = zipRawEntryLength(ptail);        }    }    // 尝试看能否将输入字符串转换为整数，如果成功的话：    // 1)value 将保存转换后的整数值    // 2)encoding 则保存适用于 value 的编码方式    // 无论使用什么编码， reqlen 都保存节点值的长度    // T = O(N)    if (zipTryEncoding(s,slen,&amp;value,&amp;encoding)) {        /* &#39;encoding&#39; is set to the appropriate integer encoding */        reqlen = zipIntSize(encoding);    } else {        /* &#39;encoding&#39; is untouched, however zipEncodeLength will use the         * string length to figure out how to encode it. */        reqlen = slen;    }    /* We need space for both the length of the previous entry and     * the length of the payload. */    // 计算编码前置节点的长度所需的大小    // T = O(1)    reqlen += zipPrevEncodeLength(NULL,prevlen);    // 计算编码当前节点值所需的大小    // T = O(1)    reqlen += zipEncodeLength(NULL,encoding,slen);    // 只要新节点不是被添加到列表末端，    // 那么程序就需要检查看 p 所指向的节点（的 header）能否编码新节点的长度。    // nextdiff 保存了新旧编码之间的字节大小差，如果这个值大于 0     // 那么说明需要对 p 所指向的节点（的 header ）进行扩展    // T = O(1)    nextdiff = (p[0] != ZIP_END) ? zipPrevLenByteDiff(p,reqlen) : 0;    // 因为重分配空间可能会改变 zl 的地址    // 所以在分配之前，需要记录 zl 到 p 的偏移量，然后在分配之后依靠偏移量还原 p     offset = p-zl;    // curlen 是 ziplist 原来的长度    // reqlen 是整个新节点的长度    // nextdiff 是新节点的后继节点扩展 header 的长度（要么 0 字节，要么 4 个字节）    // T = O(N)    zl = ziplistResize(zl,curlen+reqlen+nextdiff);    p = zl+offset;    /* Apply memory move when necessary and update tail offset. */    if (p[0] != ZIP_END) {        // 新元素之后还有节点，因为新元素的加入，需要对这些原有节点进行调整        /* Subtract one because of the ZIP_END bytes */        // 移动现有元素，为新元素的插入空间腾出位置        // T = O(N)        memmove(p+reqlen,p-nextdiff,curlen-offset-1+nextdiff);        /* Encode this entry&#39;s raw length in the next entry. */        // 将新节点的长度编码至后置节点        // p+reqlen 定位到后置节点        // reqlen 是新节点的长度        // T = O(1)        zipPrevEncodeLength(p+reqlen,reqlen);        /* Update offset for tail */        // 更新到达表尾的偏移量，将新节点的长度也算上        ZIPLIST_TAIL_OFFSET(zl) =            intrev32ifbe(intrev32ifbe(ZIPLIST_TAIL_OFFSET(zl))+reqlen);        // 如果新节点的后面有多于一个节点        // 那么程序需要将 nextdiff 记录的字节数也计算到表尾偏移量中        // 这样才能让表尾偏移量正确对齐表尾节点        // T = O(1)        tail = zipEntry(p+reqlen);        if (p[reqlen+tail.headersize+tail.len] != ZIP_END) {            ZIPLIST_TAIL_OFFSET(zl) =                intrev32ifbe(intrev32ifbe(ZIPLIST_TAIL_OFFSET(zl))+nextdiff);        }    } else {        // 新元素是新的表尾节点        ZIPLIST_TAIL_OFFSET(zl) = intrev32ifbe(p-zl);    }    // 当 nextdiff != 0 时，新节点的后继节点的（header 部分）长度已经被改变，    // 所以需要级联地更新后续的节点    if (nextdiff != 0) {        offset = p-zl;        // T  = O(N^2)        zl = __ziplistCascadeUpdate(zl,p+reqlen);        p = zl+offset;    }    // 一切搞定，将前置节点的长度写入新节点的 header    p += zipPrevEncodeLength(p,prevlen);    // 将节点值的长度写入新节点的 header    p += zipEncodeLength(p,encoding,slen);    // 写入节点值    if (ZIP_IS_STR(encoding)) {        // T = O(N)        memcpy(p,s,slen);    } else {        // T = O(1)        zipSaveInteger(p,value,encoding);    }    // 更新列表的节点数量计数器    // T = O(1)    ZIPLIST_INCR_LENGTH(zl,1);    return zl;}</code></pre><h2 id="8-4-数据删除"><a href="#8-4-数据删除" class="headerlink" title="8.4 数据删除"></a>8.4 数据删除</h2><pre><code class="c">#file: src/ziplist.c/*  * 从位置 p 开始，连续删除 num 个节点。 * 函数的返回值为处理删除操作之后的 ziplist 。 * * T = O(N^2) */static unsigned char *__ziplistDelete(unsigned char *zl, unsigned char *p, unsigned int num) {    unsigned int i, totlen, deleted = 0;    size_t offset;    int nextdiff = 0;    zlentry first, tail;    // 计算被删除节点总共占用的内存字节数    // 以及被删除节点的总个数    // T = O(N)    first = zipEntry(p);    for (i = 0; p[0] != ZIP_END &amp;&amp; i &lt; num; i++) {        p += zipRawEntryLength(p);        deleted++;    }    // totlen 是所有被删除节点总共占用的内存字节数    totlen = p-first.p;    if (totlen &gt; 0) {        if (p[0] != ZIP_END) {            // 执行这里，表示被删除节点之后仍然有节点存在            // 因为位于被删除范围之后的第一个节点的 header 部分的大小            // 可能容纳不了新的前置节点，所以需要计算新旧前置节点之间的字节数差            // T = O(1)            nextdiff = zipPrevLenByteDiff(p,first.prevrawlen);            // 如果有需要的话，将指针 p 后退 nextdiff 字节，为新 header 空出空间            p -= nextdiff;            // 将 first 的前置节点的长度编码至 p 中            // T = O(1)            zipPrevEncodeLength(p,first.prevrawlen);            // 更新到达表尾的偏移量            // T = O(1)            ZIPLIST_TAIL_OFFSET(zl) =                intrev32ifbe(intrev32ifbe(ZIPLIST_TAIL_OFFSET(zl))-totlen);            // 如果被删除节点之后，有多于一个节点            // 那么程序需要将 nextdiff 记录的字节数也计算到表尾偏移量中            // 这样才能让表尾偏移量正确对齐表尾节点            // T = O(1)            tail = zipEntry(p);            if (p[tail.headersize+tail.len] != ZIP_END) {                ZIPLIST_TAIL_OFFSET(zl) =                   intrev32ifbe(intrev32ifbe(ZIPLIST_TAIL_OFFSET(zl))+nextdiff);            }            // 从表尾向表头移动数据，覆盖被删除节点的数据            // T = O(N)            memmove(first.p,p,                intrev32ifbe(ZIPLIST_BYTES(zl))-(p-zl)-1);        } else {            // 执行这里，表示被删除节点之后已经没有其他节点了            // T = O(1)            ZIPLIST_TAIL_OFFSET(zl) =                intrev32ifbe((first.p-zl)-first.prevrawlen);        }        // 缩小并更新 ziplist 的长度        offset = first.p-zl;        zl = ziplistResize(zl, intrev32ifbe(ZIPLIST_BYTES(zl))-totlen+nextdiff);        ZIPLIST_INCR_LENGTH(zl,-deleted);        p = zl+offset;        // 如果 p 所指向的节点的大小已经变更，那么进行级联更新        // 检查 p 之后的所有节点是否符合 ziplist 的编码要求        // T = O(N^2)        if (nextdiff != 0)            zl = __ziplistCascadeUpdate(zl,p);    }    return zl;}</code></pre><h2 id="8-5-联级更新"><a href="#8-5-联级更新" class="headerlink" title="8.5 联级更新"></a>8.5 联级更新</h2><p>我们看到插入和删除的时候都调用了<code>__ziplistCascadeUpdate</code>函数来更新后面节点的大小</p><pre><code class="c">#file: src/ziplist.c/* * 当将一个新节点添加到某个节点之前的时候， * 如果原节点的 header 空间不足以保存新节点的长度， * 那么就需要对原节点的 header 空间进行扩展（从 1 字节扩展到 5 字节）。 * * 但是，当对原节点进行扩展之后，原节点的下一个节点的 prevlen 可能出现空间不足， * 这种情况在多个连续节点的长度都接近 ZIP_BIGLEN 时可能发生。 * * 这个函数就用于检查并修复后续节点的空间问题。 * * 反过来说， * 因为节点的长度变小而引起的连续缩小也是可能出现的， * 不过，为了避免扩展-缩小-扩展-缩小这样的情况反复出现（flapping，抖动）， * 我们不处理这种情况，而是任由 prevlen 比所需的长度更长。 * * 注意，程序的检查是针对 p 的后续节点，而不是 p 所指向的节点。 * 因为节点 p 在传入之前已经完成了所需的空间扩展工作。 * * T = O(N^2) */static unsigned char *__ziplistCascadeUpdate(unsigned char *zl, unsigned char *p) {    size_t curlen = intrev32ifbe(ZIPLIST_BYTES(zl)), rawlen, rawlensize;    size_t offset, noffset, extra;    unsigned char *np;    zlentry cur, next;    // T = O(N^2)    while (p[0] != ZIP_END) {        // 将 p 所指向的节点的信息保存到 cur 结构中        cur = zipEntry(p);        // 当前节点的长度        rawlen = cur.headersize + cur.len;        // 计算编码当前节点的长度所需的字节数        // T = O(1)        rawlensize = zipPrevEncodeLength(NULL,rawlen);        // 如果已经没有后续空间需要更新了，跳出        if (p[rawlen] == ZIP_END) break;        // 取出后续节点的信息，保存到 next 结构中        // T = O(1)        next = zipEntry(p+rawlen);        // 后续节点编码当前节点的空间已经足够，无须再进行任何处理，跳出        // 可以证明，只要遇到一个空间足够的节点，        // 那么这个节点之后的所有节点的空间都是足够的        if (next.prevrawlen == rawlen) break;        if (next.prevrawlensize &lt; rawlensize) {            // 执行到这里，表示 next 空间的大小不足以编码 cur 的长度            // 所以程序需要对 next 节点的（header 部分）空间进行扩展            // 记录 p 的偏移量            offset = p-zl;            // 计算需要增加的节点数量            extra = rawlensize-next.prevrawlensize;            // 扩展 zl 的大小            // T = O(N)            zl = ziplistResize(zl,curlen+extra);            // 还原指针 p            p = zl+offset;            // 记录下一节点的偏移量            np = p+rawlen;            noffset = np-zl;            // 当 next 节点不是表尾节点时，更新列表到表尾节点的偏移量            //             // 不用更新的情况（next 为表尾节点）：            //            // |     | next |      ==&gt;    |     | new next          |            //       ^                          ^            //       |                          |            //     tail                        tail            //            // 需要更新的情况（next 不是表尾节点）：            //            // | next |     |   ==&gt;     | new next          |     |            //        ^                        ^            //        |                        |            //    old tail                 old tail            //             // 更新之后：            //            // | new next          |     |            //                     ^            //                     |            //                  new tail            // T = O(1)            if ((zl+intrev32ifbe(ZIPLIST_TAIL_OFFSET(zl))) != np) {                ZIPLIST_TAIL_OFFSET(zl) =                    intrev32ifbe(intrev32ifbe(ZIPLIST_TAIL_OFFSET(zl))+extra);            }            /* Move the tail to the back. */            // 向后移动 cur 节点之后的数据，为 cur 的新 header 腾出空间            //            // 示例：            //            // | header | value |  ==&gt;  | header |    | value |  ==&gt;  | header      | value |            //                                   |&lt;--&gt;|            //                            为新 header 腾出的空间            // T = O(N)            memmove(np+rawlensize,                np+next.prevrawlensize,                curlen-noffset-next.prevrawlensize-1);            // 将新的前一节点长度值编码进新的 next 节点的 header            // T = O(1)            zipPrevEncodeLength(np,rawlen);            /* Advance the cursor */            // 移动指针，继续处理下个节点            p += rawlen;            curlen += extra;        } else {            if (next.prevrawlensize &gt; rawlensize) {                /* This would result in shrinking, which we want to avoid.                 * So, set &quot;rawlen&quot; in the available bytes. */                // 执行到这里，说明 next 节点编码前置节点的 header 空间有 5 字节                // 而编码 rawlen 只需要 1 字节                // 但是程序不会对 next 进行缩小，                // 所以这里只将 rawlen 写入 5 字节的 header 中就算了。                // T = O(1)                zipPrevEncodeLengthForceLarge(p+rawlen,rawlen);            } else {                // 运行到这里，                // 说明 cur 节点的长度正好可以编码到 next 节点的 header 中                // T = O(1)                zipPrevEncodeLength(p+rawlen,rawlen);            }            /* Stop here, as the raw length of &quot;next&quot; has not changed. */            break;        }    }    return zl;}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>6.Redis数据结构——跳表</title>
      <link href="/2020/02/19/6-Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E8%B7%B3%E8%A1%A8/"/>
      <url>/2020/02/19/6-Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E8%B7%B3%E8%A1%A8/</url>
      
        <content type="html"><![CDATA[<h2 id="6-1-什么是跳表"><a href="#6-1-什么是跳表" class="headerlink" title="6.1 什么是跳表"></a>6.1 什么是跳表</h2><p>跳表全称叫做跳跃表，简称跳表。是redis有序集合的底层实现</p><p>redis 的跳跃表实现由 zskiplist 和 zskiplistNode 两个结构组成， 其中 zskiplist 用于保存跳跃表信息（比如表头节点、表尾节点、长度）， 而 zskiplistNode 则用于表示跳跃表节点。<br>每个跳跃表节点的层高都是 1 至 32 之间的随机数。<br>在同一个跳跃表中， 多个节点可以包含相同的分值， 但每个节点的成员对象必须是唯一的。<br>跳跃表中的节点按照分值大小进行排序， 当分值相同时， 节点按照成员对象的大小进行排序。</p><h2 id="6-2-跳表的数据结构"><a href="#6-2-跳表的数据结构" class="headerlink" title="6.2 跳表的数据结构"></a>6.2 跳表的数据结构</h2><pre><code class="c">#file : reids.htypedef struct zskiplistNode {    // 成员对象    robj *obj;    // 分值   double score;    // 后退指针    struct zskiplistNode *backward;    // 层    struct zskiplistLevel {        // 前进指针        struct zskiplistNode *forward;        // 跨度        unsigned int span;    } level[];} zskiplistNode;/* * 跳跃表 */typedef struct zskiplist {    // 表头节点和表尾节点    struct zskiplistNode *header, *tail;    // 表中节点的数量    unsigned long length;    // 表中层数最大的节点的层数    int level;} zskiplist;</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/skipnode.png" alt=""></p><h2 id="6-3-跳表的初始化与插入"><a href="#6-3-跳表的初始化与插入" class="headerlink" title="6.3 跳表的初始化与插入"></a>6.3 跳表的初始化与插入</h2><pre><code class="c">#file : src/t_zset.c#define ZSKIPLIST_MAXLEVEL 32/* * 创建并返回一个新的跳跃表 * T = O(1) */zskiplist *zslCreate(void) {    int j;    zskiplist *zsl;    // 分配空间    zsl = zmalloc(sizeof(*zsl));    // 设置高度和起始层数    zsl-&gt;level = 1;    zsl-&gt;length = 0;    // 初始化表头节点    // T = O(1)    zsl-&gt;header = zslCreateNode(ZSKIPLIST_MAXLEVEL,0,NULL);    for (j = 0; j &lt; ZSKIPLIST_MAXLEVEL; j++) {        zsl-&gt;header-&gt;level[j].forward = NULL;        zsl-&gt;header-&gt;level[j].span = 0;    }    zsl-&gt;header-&gt;backward = NULL;    // 设置表尾    zsl-&gt;tail = NULL;    return zsl;}/* * 创建一个层数为 level 的跳跃表节点， * 并将节点的成员对象设置为 obj ，分值设置为 score 。 * 返回值为新创建的跳跃表节点 * T = O(1) */zskiplistNode *zslCreateNode(int level, double score, robj *obj) {    // 分配空间    zskiplistNode *zn = zmalloc(sizeof(*zn)+level*sizeof(struct zskiplistLevel));    // 设置属性    zn-&gt;score = score;    zn-&gt;obj = obj;    return zn;}/* * 创建一个成员为 obj ，分值为 score 的新节点， * 并将这个新节点插入到跳跃表 zsl 中。 * 函数的返回值为新节点。 * T_wrost = O(N^2), T_avg = O(NlogN) */zskiplistNode *zslInsert(zskiplist *zsl, double score, robj *obj) {    zskiplistNode *update[ZSKIPLIST_MAXLEVEL], *x;    unsigned int rank[ZSKIPLIST_MAXLEVEL];    int i, level;    //判断给的分值是够合理    redisAssert(!isnan(score));    // 在各个层查找节点的插入位置    // T_wrost = O(N^2), T_avg = O(N log N)    x = zsl-&gt;header;    for (i = zsl-&gt;level-1; i &gt;= 0; i--) {        // 如果 i 不是 zsl-&gt;level-1 层        // 那么 i 层的起始 rank 值为 i+1 层的 rank 值        // 各个层的 rank 值一层层累积        // 最终 rank[0] 的值加一就是新节点的前置节点的排位        // rank[0] 会在后面成为计算 span 值和 rank 值的基础        rank[i] = i == (zsl-&gt;level-1) ? 0 : rank[i+1];        // 沿着前进指针遍历跳跃表        // T_wrost = O(N^2), T_avg = O(N log N)        while (x-&gt;level[i].forward &amp;&amp;            (x-&gt;level[i].forward-&gt;score &lt; score ||                // 比对分值                (x-&gt;level[i].forward-&gt;score == score &amp;&amp;                // 比对成员， T = O(N)                compareStringObjects(x-&gt;level[i].forward-&gt;obj,obj) &lt; 0))) {            // 记录沿途跨越了多少个节点            rank[i] += x-&gt;level[i].span;            // 移动至下一指针            x = x-&gt;level[i].forward;        }        // 记录将要和新节点相连接的节点        update[i] = x;    }    /*      * zslInsert() 的调用者会确保同分值且同成员的元素不会出现，     * 所以这里不需要进一步进行检查，可以直接创建新元素。     */    // 获取一个随机值作为新节点的层数    // T = O(N)    level = zslRandomLevel();    // 如果新节点的层数比表中其他节点的层数都要大    // 那么初始化表头节点中未使用的层，并将它们记录到 update 数组中    // 将来也指向新节点    if (level &gt; zsl-&gt;level) {        // 初始化未使用层        // T = O(1)        for (i = zsl-&gt;level; i &lt; level; i++) {            rank[i] = 0;            update[i] = zsl-&gt;header;            update[i]-&gt;level[i].span = zsl-&gt;length;        }        // 更新表中节点最大层数        zsl-&gt;level = level;    }    // 创建新节点    x = zslCreateNode(level,score,obj);    // 将前面记录的指针指向新节点，并做相应的设置    // T = O(1)    for (i = 0; i &lt; level; i++) {        // 设置新节点的 forward 指针        x-&gt;level[i].forward = update[i]-&gt;level[i].forward;        // 将沿途记录的各个节点的 forward 指针指向新节点        update[i]-&gt;level[i].forward = x;        /* update span covered by update[i] as x is inserted here */        // 计算新节点跨越的节点数量        x-&gt;level[i].span = update[i]-&gt;level[i].span - (rank[0] - rank[i]);        // 更新新节点插入之后，沿途节点的 span 值        // 其中的 +1 计算的是新节点        update[i]-&gt;level[i].span = (rank[0] - rank[i]) + 1;    }    /* increment span for untouched levels */    // 未接触的节点的 span 值也需要增一，这些节点直接从表头指向新节点    // T = O(1)    for (i = level; i &lt; zsl-&gt;level; i++) {        update[i]-&gt;level[i].span++;    }    // 设置新节点的后退指针    x-&gt;backward = (update[0] == zsl-&gt;header) ? NULL : update[0];    if (x-&gt;level[0].forward)        x-&gt;level[0].forward-&gt;backward = x;    else        zsl-&gt;tail = x;    // 跳跃表的节点计数增一    zsl-&gt;length++;    return x;}</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/skiplist.png" alt=""></p><h2 id="6-4-跳表的层数确定"><a href="#6-4-跳表的层数确定" class="headerlink" title="6.4 跳表的层数确定"></a>6.4 跳表的层数确定</h2><p>理论上每层的比例为1:2,但是在实际使用中，我们的链表是通过多次插入/删除形成的，换句话说是“动态”的。这个比例就被被破坏了。因此跳表（skip list）表示，我们就不强制要求 1:2 了，一个节点要不要被索引，建几层的索引，都在节点插入时由<code>zslRandomLevel</code>决定:</p><pre><code class="c">#file : src/t_zset.c/*  * 返回一个随机值，用作新跳跃表节点的层数。 * 返回值介乎 1 和 ZSKIPLIST_MAXLEVEL 之间（包含 ZSKIPLIST_MAXLEVEL）， * 根据随机算法所使用的幂次定律，越大的值生成的几率越小。 * T = O(N) */int zslRandomLevel(void) {    int level = 1;    while ((random()&amp;0xFFFF) &lt; (ZSKIPLIST_P * 0xFFFF))        level += 1;    return (level&lt;ZSKIPLIST_MAXLEVEL) ? level : ZSKIPLIST_MAXLEVEL;}</code></pre><h2 id="6-5-删除跳表节点"><a href="#6-5-删除跳表节点" class="headerlink" title="6.5 删除跳表节点"></a>6.5 删除跳表节点</h2><pre><code class="c">#file : src/t_zset.c/*  * 内部删除函数， * 被 zslDelete 、 zslDeleteRangeByScore 和 zslDeleteByRank 等函数调用。 * T = O(1) */void zslDeleteNode(zskiplist *zsl, zskiplistNode *x, zskiplistNode **update) {    int i;    // 更新所有和被删除节点 x 有关的节点的指针，解除它们之间的关系    // T = O(1)    for (i = 0; i &lt; zsl-&gt;level; i++) {        if (update[i]-&gt;level[i].forward == x) {            update[i]-&gt;level[i].span += x-&gt;level[i].span - 1;            update[i]-&gt;level[i].forward = x-&gt;level[i].forward;        } else {            update[i]-&gt;level[i].span -= 1;        }    }    // 更新被删除节点 x 的前进和后退指针    if (x-&gt;level[0].forward) {        x-&gt;level[0].forward-&gt;backward = x-&gt;backward;    } else {        zsl-&gt;tail = x-&gt;backward;    }    // 更新跳跃表最大层数（只在被删除节点是跳跃表中最高的节点时才执行）    // T = O(1)    while(zsl-&gt;level &gt; 1 &amp;&amp; zsl-&gt;header-&gt;level[zsl-&gt;level-1].forward == NULL)        zsl-&gt;level--;    // 跳跃表节点计数器减一    zsl-&gt;length--;}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>7.Redis数据结构——iniset</title>
      <link href="/2020/02/19/7-Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-iniset/"/>
      <url>/2020/02/19/7-Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-iniset/</url>
      
        <content type="html"><![CDATA[<h2 id="7-1-什么是iniset"><a href="#7-1-什么是iniset" class="headerlink" title="7.1 什么是iniset"></a>7.1 什么是iniset</h2><p>整数集合（intset）是集合键的底层实现之一,当一个集合只包含整数值元素,并且这个集合的元素数量不多时,Redis就会使用整数集合作为集合键的底层实现</p><h2 id="7-1-数据结构"><a href="#7-1-数据结构" class="headerlink" title="7.1 数据结构"></a>7.1 数据结构</h2><pre><code class="c">#file: src/intset.htypedef struct intset {    // 编码方式    uint32_t encoding;    // 集合包含的元素数量    uint32_t length;    // 保存元素的数组    int8_t contents[];} intset;/* * encoding的取值　intset 的编码方式 */#define INTSET_ENC_INT16 (sizeof(int16_t))#define INTSET_ENC_INT32 (sizeof(int32_t))#define INTSET_ENC_INT64 (sizeof(int64_t))</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/intsetadd.png" alt=""></p><h2 id="7-2-centent类型"><a href="#7-2-centent类型" class="headerlink" title="7.2 centent类型"></a>7.2 centent类型</h2><p><code>struct iniset</code>里的<code>content</code>数据的真正类型取决于encoding的属性值</p><pre><code class="c">#file: src/intset.c/*  * 返回适用于传入值 v 的编码方式 * T = O(1) */static uint8_t _intsetValueEncoding(int64_t v) {    if (v &lt; INT32_MIN || v &gt; INT32_MAX)        return INTSET_ENC_INT64;    else if (v &lt; INT16_MIN || v &gt; INT16_MAX)        return INTSET_ENC_INT32;    else        return INTSET_ENC_INT16;}</code></pre><ul><li>如果 encoding 属性的值为 INTSET_ENC_INT16 ， 那么 contents 就是一个 int16_t 类型的数组， 数组里的每个项都是一个 int16_t 类型的整数值 （最小值为 -32,768 ，最大值为 32,767 ）。</li><li>如果 encoding 属性的值为 INTSET_ENC_INT32 ， 那么 contents 就是一个 int32_t 类型的数组， 数组里的每个项都是一个 int32_t 类型的整数值 （最小值为 -2,147,483,648 ，最大值为 2,147,483,647 ）。</li><li>如果 encoding 属性的值为 INTSET_ENC_INT64 ， 那么 contents 就是一个 int64_t 类型的数组， 数组里的每个项都是一个 int64_t 类型的整数值 （最小值为 -9,223,372,036,854,775,808 ，最大值为 9,223,372,036,854,775,807 ）。</li></ul><h2 id="7-3-类型升级"><a href="#7-3-类型升级" class="headerlink" title="7.3 类型升级"></a>7.3 类型升级</h2><p>每当我们要将一个新元素添加到整数集合里面， 并且新元素的类型比整数集合现有所有元素的类型都要长时， 整数集合需要先进行升级（upgrade）， 然后才能将新元素添加到整数集合里面。</p><p>升级整数集合并添加新元素共分为三步进行：</p><ul><li>根据新元素的类型， 扩展整数集合底层数组的空间大小， 并为新元素分配空间。</li><li>将底层数组现有的所有元素都转换成与新元素相同的类型， 并将类型转换后的元素放置到正确的位上， 而且在放置元素的过程中，需要继续维持底层数组的有序性质不变。</li><li>将新元素添加到底层数组里面。</li></ul><pre><code class="c">#file: src/intset.c/*  * 根据值 value 所使用的编码方式，对整数集合的编码进行升级， * 并将值 value 添加到升级后的整数集合中。 * 返回值：添加新元素之后的整数集合 * T = O(N) */static intset *intsetUpgradeAndAdd(intset *is, int64_t value) {    // 当前的编码方式    uint8_t curenc = intrev32ifbe(is-&gt;encoding);    // 新值所需的编码方式    uint8_t newenc = _intsetValueEncoding(value);    // 当前集合的元素数量    int length = intrev32ifbe(is-&gt;length);    // 根据 value 的值，决定是将它添加到底层数组的最前端还是最后端    // 注意，因为 value 的编码比集合原有的其他元素的编码都要大    // 所以 value 要么大于集合中的所有元素，要么小于集合中的所有元素    // 因此，value 只能添加到底层数组的最前端或最后端    int prepend = value &lt; 0 ? 1 : 0;    /* First set new encoding and resize */    // 更新集合的编码方式    is-&gt;encoding = intrev32ifbe(newenc);    // 根据新编码对集合（的底层数组）进行空间调整    // T = O(N)    is = intsetResize(is,intrev32ifbe(is-&gt;length)+1);    // 根据集合原来的编码方式，从底层数组中取出集合元素    // 然后再将元素以新编码的方式添加到集合中    // 当完成了这个步骤之后，集合中所有原有的元素就完成了从旧编码到新编码的转换    // 因为新分配的空间都放在数组的后端，所以程序先从后端向前端移动元素    // 举个例子，假设原来有 curenc 编码的三个元素，它们在数组中排列如下：    // | x | y | z |     // 当程序对数组进行重分配之后，数组就被扩容了（符号 ？ 表示未使用的内存）：    // | x | y | z | ? |   ?   |   ?   |    // 这时程序从数组后端开始，重新插入元素：    // | x | y | z | ? |   z   |   ?   |    // | x | y |   y   |   z   |   ?   |    // |   x   |   y   |   z   |   ?   |    // 最后，程序可以将新元素添加到最后 ？ 号标示的位置中：    // |   x   |   y   |   z   |  new  |    // 上面演示的是新元素比原来的所有元素都大的情况，也即是 prepend == 0    // 当新元素比原来的所有元素都小时（prepend == 1），调整的过程如下：    // | x | y | z | ? |   ?   |   ?   |    // | x | y | z | ? |   ?   |   z   |    // | x | y | z | ? |   y   |   z   |    // | x | y |   x   |   y   |   z   |    // 当添加新值时，原本的 | x | y | 的数据将被新值代替    // |  new  |   x   |   y   |   z   |    // T = O(N)    while(length--)        _intsetSet(is,length+prepend,_intsetGetEncoded(is,length,curenc));    /* Set the value at the beginning or the end. */    // 设置新值，根据 prepend 的值来决定是添加到数组头还是数组尾    if (prepend)        _intsetSet(is,0,value);    else        _intsetSet(is,intrev32ifbe(is-&gt;length),value);    // 更新整数集合的元素数量    is-&gt;length = intrev32ifbe(intrev32ifbe(is-&gt;length)+1);    return is;}</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/intsetupgrade.png" alt=""></p><h2 id="7-4-类型降级"><a href="#7-4-类型降级" class="headerlink" title="7.4 类型降级"></a>7.4 类型降级</h2><p>我们在起删除给定元素的代码中可以发现:<code>intset不支持降级操作!</code></p><pre><code class="c">/* * 从整数集合中删除值 value 。 * *success 的值指示删除是否成功： * - 因值不存在而造成删除失败时该值为 0 。 * - 删除成功时该值为 1 。 * T = O(N) */intset *intsetRemove(intset *is, int64_t value, int *success) {    // 计算 value 的编码方式    uint8_t valenc = _intsetValueEncoding(value);    uint32_t pos;    // 默认设置标识值为删除失败    if (success) *success = 0;    // 当 value 的编码大小小于或等于集合的当前编码方式（说明 value 有可能存在于集合）    // 并且 intsetSearch 的结果为真，那么执行删除    // T = O(log N)    if (valenc &lt;= intrev32ifbe(is-&gt;encoding) &amp;&amp; intsetSearch(is,value,&amp;pos)) {        // 取出集合当前的元素数量        uint32_t len = intrev32ifbe(is-&gt;length);        /* We know we can delete */        // 设置标识值为删除成功        if (success) *success = 1;        /* Overwrite value with tail and update length */        // 如果 value 不是位于数组的末尾        // 那么需要对原本位于 value 之后的元素进行移动        //        // 举个例子，如果数组表示如下，而 b 为删除的目标        // | a | b | c | d |        // 那么 intsetMoveTail 将 b 之后的所有数据向前移动一个元素的空间，        // 覆盖 b 原来的数据        // | a | c | d | d |        // 之后 intsetResize 缩小内存大小时，        // 数组末尾多出来的一个元素的空间将被移除        // | a | c | d |        if (pos &lt; (len-1)) intsetMoveTail(is,pos+1,pos);        // 缩小数组的大小，移除被删除元素占用的空间        // T = O(N)        is = intsetResize(is,len-1);        // 更新集合的元素数量        is-&gt;length = intrev32ifbe(len-1);    }    return is;}</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/intsetdel.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>5.Redis数据结构——字典</title>
      <link href="/2020/02/19/5-Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E5%AD%97%E5%85%B8/"/>
      <url>/2020/02/19/5-Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E5%AD%97%E5%85%B8/</url>
      
        <content type="html"><![CDATA[<h2 id="5-1-什么是字典"><a href="#5-1-什么是字典" class="headerlink" title="5.1 什么是字典"></a>5.1 什么是字典</h2><p>字典经常作为一种数据结构内置在很多高级编程语言里面， 但 Redis 所使用的 C 语言并没有内置这种数据结构， 因此 Redis 构建了自己的字典实现。</p><p>字典在 Redis 中的应用相当广泛， 比如 Redis 的数据库就是使用字典来作为底层实现的， 对数据库的增、删、查、改操作也是构建在对字典的操作之上的。</p><p>Redis 的字典使用哈希表作为底层实现， 一个哈希表里面可以有多个哈希表节点， 而每个哈希表节点就保存了字典中的一个键值对。</p><h2 id="5-2-dict-hash-dictEntry数据结构"><a href="#5-2-dict-hash-dictEntry数据结构" class="headerlink" title="5.2 dict hash dictEntry数据结构"></a>5.2 dict hash dictEntry数据结构</h2><pre><code class="c">#file: src/dict.h/* * 字典 */typedef struct dict {    // 类型特定函数    dictType *type;    // 私有数据    void *privdata;    // 哈希表    dictht ht[2];    // rehash 索引    // 当 rehash 不在进行时，值为 -1    int rehashidx; /* rehashing not in progress if rehashidx == -1 */    // 目前正在运行的安全迭代器的数量    int iterators; /* number of iterators currently running */} dict;/* * 哈希表 * 每个字典都使用两个哈希表，从而实现渐进式 rehash 。 */typedef struct dictht {       // 哈希表数组    dictEntry **table;    // 哈希表大小    // 哈希表的大小总是 2 的某个次方，并且哈希表使用链表来解决冲突    unsigned long size;    // 哈希表大小掩码，用于计算索引值    // 总是等于 size - 1    unsigned long sizemask;    // 该哈希表已有节点的数量    unsigned long used;} dictht;/* * 哈希表节点 */typedef struct dictEntry {    // 键    void *key;    // 值    union {        void *val;        uint64_t u64;        int64_t s64;    } v;    // 指向下个哈希表节点，形成链表    struct dictEntry *next;} dictEntry;</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/dict.png" alt=""></p><h2 id="5-3-添加字典"><a href="#5-3-添加字典" class="headerlink" title="5.3 添加字典"></a>5.3 添加字典</h2><pre><code class="c"># file:src/dict.c/* * 尝试将给定键值对添加到字典中 * 只有给定键key不存在于字典时,添加操作才会成功 * 添加成功返回DICT_OK ，失败返回 DICT_ERR * 最坏T=O(N),平均O(1)  */int dictAdd(dict *d, void *key, void *val){    // 尝试添加键到字典，并返回包含了这个键的新哈希节点    dictEntry *entry = dictAddRaw(d,key);    // 键已存在，添加失败    if (!entry) return DICT_ERR;    // 键不存在，设置节点的值    // T = O(1)    dictSetVal(d, entry, val);    // 添加成功    return DICT_OK;}/* * 尝试将键插入到字典中 * 如果键已经在字典存在，那么返回 NULL * 如果键不存在，那么程序创建新的哈希节点， * 将节点和键关联，并插入到字典，然后返回节点本身 */dictEntry *dictAddRaw(dict *d, void *key){    int index;    dictEntry *entry;    dictht *ht;    // 如果条件允许的话，进行单步 rehash    if (dictIsRehashing(d)) _dictRehashStep(d);    // 计算键在哈希表中的索引值 使用MurmurHash算法    // 如果值为 -1 ，那么表示键已经存在    // T = O(N)    if ((index = _dictKeyIndex(d, key)) == -1)        return NULL;    // T = O(1)    // 如果字典正在 rehash ，那么将新键添加到 1 号哈希表    // 否则，将新键添加到 0 号哈希表    ht = dictIsRehashing(d) ? &amp;d-&gt;ht[1] : &amp;d-&gt;ht[0];    // 为新节点分配空间    entry = zmalloc(sizeof(*entry));    // 将新节点插入到链表表头    entry-&gt;next = ht-&gt;table[index];    ht-&gt;table[index] = entry;    // 更新哈希表已使用节点数量    ht-&gt;used++;    // 设置新节点的键    // T = O(1)    dictSetKey(d, entry, key);    return entry;}</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/dictadd.png" alt=""></p><h2 id="5-3-Rehash"><a href="#5-3-Rehash" class="headerlink" title="5.3 Rehash"></a>5.3 Rehash</h2><pre><code class="c"># file:src/dict.c/*  * 执行 N 步渐进式 rehash 。 * 返回 1 表示仍有键需要从 0 号哈希表移动到 1 号哈希表， * 返回 0 则表示所有键都已经迁移完毕。 * * 注意，每步 rehash 都是以一个哈希表索引（桶）作为单位的， * 一个桶里可能会有多个节点， * 被 rehash 的桶里的所有节点都会被移动到新哈希表。 * T = O(N) */int dictRehash(dict *d, int n) {    // 只可以在 rehash 进行中时执行    if (!dictIsRehashing(d)) return 0;    // 进行 N 步迁移    // T = O(N)    while(n--) {        dictEntry *de, *nextde;        /* Check if we already rehashed the whole table... */        // 如果 0 号哈希表为空，那么表示 rehash 执行完毕        // T = O(1)        if (d-&gt;ht[0].used == 0) {            // 释放 0 号哈希表            zfree(d-&gt;ht[0].table);            // 将原来的 1 号哈希表设置为新的 0 号哈希表            d-&gt;ht[0] = d-&gt;ht[1];            // 重置旧的 1 号哈希表            _dictReset(&amp;d-&gt;ht[1]);            // 关闭 rehash 标识            d-&gt;1rehashidx = -1;            // 返回 0 ，向调用者表示 rehash 已经完成            return 0;        }        /* Note that rehashidx can&#39;t overflow as we are sure there are more         * elements because ht[0].used != 0 */        // 确保 rehashidx 没有越界        assert(d-&gt;ht[0].size &gt; (unsigned)d-&gt;rehashidx);        // 略过数组中为空的索引，找到下一个非空索引        while(d-&gt;ht[0].table[d-&gt;rehashidx] == NULL) d-&gt;rehashidx++;        // 指向该索引的链表表头节点        de = d-&gt;ht[0].table[d-&gt;rehashidx];        /* Move all the keys in this bucket from the old to the new hash HT */        // 将链表中的所有节点迁移到新哈希表        // T = O(1)        while(de) {            unsigned int h;            // 保存下个节点的指针            nextde = de-&gt;next;            /* Get the index in the new hash table */            // 计算新哈希表的哈希值，以及节点插入的索引位置            h = dictHashKey(d, de-&gt;key) &amp; d-&gt;ht[1].sizemask;            // 插入节点到新哈希表            de-&gt;next = d-&gt;ht[1].table[h];            d-&gt;ht[1].table[h] = de;            // 更新计数器            d-&gt;ht[0].used--;            d-&gt;ht[1].used++;            // 继续处理下个节点            de = nextde;        }        // 将刚迁移完的哈希表索引的指针设为空        d-&gt;ht[0].table[d-&gt;rehashidx] = NULL;        // 更新 rehash 索引        d-&gt;rehashidx++;    }    return 1;}/* * 在给定毫秒数内，以 100 步为单位，对字典进行 rehash 。 * * T = O(N) */int dictRehashMilliseconds(dict *d, int ms) {    // 记录开始时间    long long start = timeInMilliseconds();    int rehashes = 0;    while(dictRehash(d,100)) {        rehashes += 100;        // 如果时间已过，跳出        if (timeInMilliseconds()-start &gt; ms) break;    }    return rehashes;}/* * 创建一个新的哈希表，并根据字典的情况，选择以下其中一个动作来进行： * 1) 如果字典的 0 号哈希表为空，那么将新哈希表设置为 0 号哈希表 * 2) 如果字典的 0 号哈希表非空，那么将新哈希表设置为 1 号哈希表， *    并打开字典的 rehash 标识，使得程序可以开始对字典进行 rehash * size 参数不够大，或者 rehash 已经在进行时，返回 DICT_ERR 。 * 成功创建 0 号哈希表，或者 1 号哈希表时，返回 DICT_OK 。 */int dictExpand(dict *d, unsigned long size){    // 新哈希表    dictht n; /* the new hash table */    // 根据 size 参数，计算哈希表的大小    // T = O(1)    unsigned long realsize = _dictNextPower(size);    /* the size is invalid if it is smaller than the number of     * elements already inside the hash table */    // 不能在字典正在 rehash 时进行    // size 的值也不能小于 0 号哈希表的当前已使用节点    if (dictIsRehashing(d) || d-&gt;ht[0].used &gt; size)        return DICT_ERR;    /* Allocate the new hash table and initialize all pointers to NULL */    // 为哈希表分配空间，并将所有指针指向 NULL    n.size = realsize;    n.sizemask = realsize-1;    // T = O(N)    n.table = zcalloc(realsize*sizeof(dictEntry*));    n.used = 0;    /* Is this the first initialization? If so it&#39;s not really a rehashing     * we just set the first hash table so that it can accept keys. */    // 如果 0 号哈希表为空，那么这是一次初始化：    // 程序将新哈希表赋给 0 号哈希表的指针，然后字典就可以开始处理键值对了。    if (d-&gt;ht[0].table == NULL) {        d-&gt;ht[0] = n;        return DICT_OK;    }    /* Prepare a second hash table for incremental rehashing */    // 如果 0 号哈希表非空，那么这是一次 rehash ：    // 程序将新哈希表设置为 1 号哈希表，    // 并将字典的 rehash 标识打开，让程序可以开始对字典进行 rehash    d-&gt;ht[1] = n;    d-&gt;rehashidx = 0;    return DICT_OK;}/* * 计算第一个大于等于 size 的 2 的 N 次方，用作哈希表的值 * T = O(1) */static unsigned long _dictNextPower(unsigned long size){    unsigned long i = DICT_HT_INITIAL_SIZE;    if (size &gt;= LONG_MAX) return LONG_MAX;    while(1) {        if (i &gt;= size)            return i;        i *= 2;    }}</code></pre><p>随着操作的不断执行， 哈希表保存的键值对会逐渐地增多或者减少， 为了让哈希表的负载因子（load factor）维持在一个合理的范围之内， 当哈希表保存的键值对数量太多或者太少时， 程序需要对哈希表的大小进行相应的扩展或者收缩。</p><p>扩展和收缩哈希表的工作可以通过执行 rehash （重新散列）操作来完成， Redis 对字典的哈希表执行 rehash 的步骤如下：</p><ul><li><p>为字典的 ht[1] 哈希表分配空间(使用函数dictExpand)， 这个哈希表的空间大小(使用_dictNextPower计算大小)取决于要执行的操作， 以及 ht[0] 当前包含的键值对数量 （也即是 ht[0].used 属性的值）：</p><ul><li><p>如果执行的是扩展操作， 那么 ht[1] 的大小为第一个大于等于 ht[0].used * 2 的 2^n</p></li><li><p>如果执行的是收缩操作， 那么 ht[1] 的大小为第一个大于等于 ht[0].used 的 2^n </p></li></ul></li><li><p>将保存在 ht[0] 中的所有键值对 rehash 到 ht[1] 上面： rehash 指的是重新计算键的哈希值和索引值， 然后将键值对放置到 ht[1] 哈希表的指定位置上</p></li><li><p>当 ht[0] 包含的所有键值对都迁移到了 ht[1] 之后 （ht[0] 变为空表）, 释放 ht[0] ,将 ht[1] 设置为 ht[0] ， 并在 ht[1] 新创建一个空白哈希表，为下一次 rehash 做准备</p></li></ul><p>实际过程大多通过渐进式rehash来将数据做转移:</p><ul><li>为 ht[1] 分配空间， 让字典同时持有 ht[0] 和 ht[1] 两个哈希表。</li><li>在字典中维持一个索引计数器变量 rehashidx ， 并将它的值设置为 0 ， 表示 rehash 工作正式开始。</li><li>在 rehash 进行期间， 每次对字典执行添加、删除、查找或者更新操作时， 程序除了执行指定的操作以外， 还会顺带将 ht[0] 哈希表在 rehashidx 索引上的所有键值对 rehash 到 ht[1] ， 当 rehash 工作完成之后， 程序将 rehashidx 属性的值增一。</li><li>随着字典操作的不断执行， 最终在某个时间点上， ht[0] 的所有键值对都会被 rehash 至 ht[1] ， 这时程序将 rehashidx 属性的值设为 -1 ， 表示 rehash 操作已完成。</li></ul><p>另外， 在渐进式 rehash 执行期间， 新添加到字典的键值对一律会被保存到 ht[1] 里面， 而 ht[0] 则不再进行任何添加操作： 这一措施保证了 ht[0] 包含的键值对数量会只减不增， 并随着 rehash 操作的执行而最终变成空表。</p><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/rehash0.png" alt=""><br><img src="http://cache410.oss-cn-beijing.aliyuncs.com/rehash1.png" alt=""><br><img src="http://cache410.oss-cn-beijing.aliyuncs.com/rehash2.png" alt=""><br><img src="http://cache410.oss-cn-beijing.aliyuncs.com/rehash3.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>11.Mysql日志</title>
      <link href="/2020/02/18/11-Mysql%E6%97%A5%E5%BF%97/"/>
      <url>/2020/02/18/11-Mysql%E6%97%A5%E5%BF%97/</url>
      
        <content type="html"><![CDATA[<p>主要包括:</p><ol><li>错误日志 Error Log</li><li>慢查询日志 Slow Query Log</li><li>二进制日志 Bin Log</li><li>重做日志 Redo log</li><li>回滚日志 Undo Log</li><li>中继日志 Relay Log</li><li>一般查询日志 Gerneral Log</li></ol><h2 id="11-1-Error-Log"><a href="#11-1-Error-Log" class="headerlink" title="11.1 Error Log"></a>11.1 Error Log</h2><h3 id="11-1-1-作用"><a href="#11-1-1-作用" class="headerlink" title="11.1.1 作用"></a>11.1.1 作用</h3><p>用来记录从服务器启动和关闭过程中的信息（未必是错误信息，如mysql如何启动InnoDB的表空间文件的、如何初始化自己的存储引擎的等等）、服务器运行过程中的错误信息、事件调度器运行一个事件时产生的信息、在从服务器上启动服务器进程时产生的信息</p><p>在mysql数据库中，错误日志功能是默认开启的</p><p>默认情况下，错误日志存储在mysql数据库的数据文件中。</p><p>错误日志文件通常的名称为hostname.err。其中，hostname表示服务器主机名。</p><h3 id="11-1-2-相关参数"><a href="#11-1-2-相关参数" class="headerlink" title="11.1.2 相关参数"></a>11.1.2 相关参数</h3><pre><code class="mysql">#错误日志存储的位置以及名称mysql&gt; select @@log_error;+-----------------+| @@log_error     |+-----------------+| ./centos7-1.err |+-----------------+1 row in set (0.00 sec)#错误级别mysql&gt; select @@log_error_verbosity;+-----------------------+| @@log_error_verbosity |+-----------------------+|                     3 |+-----------------------+1 row in set (0.00 sec)#错误级别　已废弃不推荐使用的　等同于log_error_verbositymysql&gt; select @@log_warnings;+----------------+| @@log_warnings |+----------------+|              2 |+----------------+1 row in set, 1 warning (0.00 sec)</code></pre><h3 id="11-1-3-修改记录级别"><a href="#11-1-3-修改记录级别" class="headerlink" title="11.1.3 修改记录级别"></a>11.1.3 修改记录级别</h3><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/error_verbosity.png" alt=""></p><h3 id="11-1-4-清空归档日志"><a href="#11-1-4-清空归档日志" class="headerlink" title="11.1.4 清空归档日志"></a>11.1.4 清空归档日志</h3><pre><code class="shell">mv host_name.err host_name.err-oldmysqladmin flush-logsmv host_name.err-old backup-directory</code></pre><h2 id="11-2-Slow-Query-Log"><a href="#11-2-Slow-Query-Log" class="headerlink" title="11.2 Slow Query Log"></a>11.2 Slow Query Log</h2><h3 id="11-2-1-作用"><a href="#11-2-1-作用" class="headerlink" title="11.2.1 作用"></a>11.2.1 作用</h3><p>查询日志是用来记录执行时间超过指定时间的查询语句。通过慢查询日志，可以查找出哪些查询语句的执行效率很低，以便进行优化。一般建议开启，它对服务器性能的影响微乎其微，但是可以记录mysql服务器上执行了很长时间的查询语句。可以帮助我们定位性能问题</p><h3 id="11-2-2-相关参数"><a href="#11-2-2-相关参数" class="headerlink" title="11.2.2 相关参数"></a>11.2.2 相关参数</h3><pre><code class="mysql">#是否开启慢查询 1开启 0关闭mysql&gt; select @@slow_query_log;+------------------+| @@slow_query_log |+------------------+|                1 |+------------------+1 row in set (0.00 sec)# 慢查询文件位置mysql&gt; select @@slow_query_log_file;+----------------------------+| @@slow_query_log_file      |+----------------------------+| /log/3306/slowlog/slow.log |+----------------------------+1 row in set (0.00 sec)# 慢查询时间阀值　单位为秒mysql&gt; select @@long_query_time;+-------------------+| @@long_query_time |+-------------------+|          5.000000 |+-------------------+1 row in set (0.00 sec)# 1开启　０关闭# 运行的SQL语句没有使用索引，则MySQL数据库同样会将这条SQL语句记录到慢查询日志文件mysql&gt; select @@log_queries_not_using_indexes;+---------------------------------+| @@log_queries_not_using_indexes |+---------------------------------+|                               1 |+---------------------------------+1 row in set (0.00 sec)</code></pre><h3 id="11-2-3-查看slow-log"><a href="#11-2-3-查看slow-log" class="headerlink" title="11.2.3 查看slow.log"></a>11.2.3 查看slow.log</h3><p>slow.log属于文本日志,我们可以通过linux命令查看slow.log</p><pre><code class="shell">[root@centos7-1 slowlog]# tail -f slow.log # Time: 2019-07-09T02:00:48.300499Z# User@Host: root[root] @ localhost []  Id:     5# Query_time: 5.075423  Lock_time: 0.000123 Rows_sent: 174  Rows_examined: 4994309SET timestamp=1562637648;select * from t_scrm_pet_info where pet_name =&quot;Winter&quot;;</code></pre><p>含义如下:</p><ul><li>SQL 的执行时间：# Time: 2019-07-09T02:00:48.300499Z</li><li>SQL 的执行主机：# User@Host: root[root] @ localhost []  Id:     5</li><li>SQL 的执行信息：# Query_time: 5.075423  Lock_time: 0.000123 Rows_sent: 174  Rows_examined: 4994309</li><li>SQL 的执行时间：SET timestamp=1562637648;</li><li>SQL 的执行内容：select * from t_scrm_pet_info where pet_name =”Winter”;</li></ul><h3 id="11-2-4-mysqldumpslow"><a href="#11-2-4-mysqldumpslow" class="headerlink" title="11.2.4 mysqldumpslow"></a>11.2.4 mysqldumpslow</h3><p>mysqldumpslow 是一个针对于 MySQL 慢查询的命令行程序。可以通过 mysqldumpslow 查找出查询较慢的 SQL 语句。</p><pre><code class="shell">[root@centos7-1 slowlog]# mysqldumpslow --helpUsage: mysqldumpslow [ OPTS... ] [ LOGS... ]Parse and summarize the MySQL slow query log. Options are  --verbose    verbose  --debug      debug  --help       write this text to standard output  -v           verbose  -d           debug  -s ORDER     what to sort by (al, at, ar, c, l, r, t), &#39;at&#39; is default                al: average lock time                ar: average rows sent                at: average query time                 c: count                 l: lock time                 r: rows sent                 t: query time    -r           reverse the sort order (largest last instead of first)  -t NUM       just show the top n queries  -a           don&#39;t abstract all numbers to N and strings to &#39;S&#39;  -n NUM       abstract numbers with at least n digits within names  -g PATTERN   grep: only consider stmts that include this string  -h HOSTNAME  hostname of db server for *-slow.log filename (can be wildcard),               default is &#39;*&#39;, i.e. match all  -i NAME      name of server instance (if using mysql.server startup script)  -l           don&#39;t subtract lock time from total time</code></pre><p>通过mysqldumpslow  查看慢日志：</p><pre><code class="shell">[root@centos7-1 slowlog]# mysqldumpslow slow.log Reading mysql slow query log from slow.logCount: 3  Time=5.12s (15s)  Lock=0.00s (0s)  Rows=1661.3 (4984), root[root]@localhost  select * from t_scrm_pet_info where pet_name =&quot;S&quot;</code></pre><ul><li>Count：出现次数,</li><li>Time：执行最长时间和累计总耗费时间</li><li>Lock：等待锁的时间</li><li>Rows：返回客户端行总数和扫描行总数</li></ul><h2 id="11-3-Binlog"><a href="#11-3-Binlog" class="headerlink" title="11.3 Binlog"></a>11.3 Binlog</h2><h3 id="11-3-1-作用"><a href="#11-3-1-作用" class="headerlink" title="11.3.1 作用"></a>11.3.1 作用</h3><p>主要记录数据库变化(DDL,DCL,DML)性质的日志,是逻辑层性质日志</p><p>主要有以下作用:</p><ul><li>恢复(recovery)： 对于误删除的数据可以通过binlog恢复</li><li>复制(replication) :可以通过binlog做主从同步</li><li>审计(audit)：可以通过抓取binlog日志来满足审计需求</li></ul><h3 id="11-3-2-相关参数"><a href="#11-3-2-相关参数" class="headerlink" title="11.3.2 相关参数"></a>11.3.2 相关参数</h3><pre><code class="ini">cat /etc/my.cnf....#主机编号　主从同步的时候使用　开启binlog需要加此参数server_id=1            #日志存放的目录＋日志名前缀 :mysql-bin.000001 mysql-bin.000002 ...log_bin=/log/3306/binlog/mysql-bin#binlog日志刷盘策略【重要】sync_binlog=1#binlig的记录格式binlog_format=row#指定单个binlog文件的大小(默认1G)max_binlog_size=200M</code></pre><h4 id="11-3-2-1-binglog-format"><a href="#11-3-2-1-binglog-format" class="headerlink" title="11.3.2.1 binglog_format"></a>11.3.2.1 binglog_format</h4><p>二进制日志有以下几种格式可选:</p><ul><li><p>STATEMENT模式（SBR）</p><p>每一条会修改数据的sql语句会记录到binlog中。优点是并不需要记录每一条sql语句和每一行的数据变化，减少了binlog日志量，节约IO，提高性能。缺点是在某些情况下会导致master-slave中的数据不一致(如sleep()函数， last_insert_id()，以及user-defined functions(udf)等会出现问题</p></li><li><p>ROW模式（RBR）(<code>5.7版本默认</code>)</p><p>不记录每条sql语句的上下文信息，仅需记录哪条数据被修改了，修改成什么样了。而且不会出现某些特定情况下的存储过程、或function、或trigger的调用和触发无法被正确复制的问题。缺点是会产生大量的日志，尤其是alter table的时候会让日志暴涨。</p></li><li><p>MIXED模式（MBR）</p><p>以上两种模式的混合使用，一般的复制使用STATEMENT模式保存binlog，对于STATEMENT模式无法复制的操作使用ROW模式保存binlog，MySQL会根据执行的SQL语句选择日志保存方式。</p></li></ul><table><thead><tr><th align="center">模式</th><th align="left">优点</th><th align="center">缺点</th></tr></thead><tbody><tr><td align="center">SBR</td><td align="left">可读性高,日志量少,主从版本可以不一样</td><td align="center">不够严禁</td></tr><tr><td align="center">RBR</td><td align="left">可读性底,日志量大,主从版本需要统一</td><td align="center">足够严禁</td></tr></tbody></table><h2 id="11-4-Redo-Log"><a href="#11-4-Redo-Log" class="headerlink" title="11.4 Redo Log"></a>11.4 Redo Log</h2><h2 id="11-5-Undo-Log"><a href="#11-5-Undo-Log" class="headerlink" title="11.5 Undo Log"></a>11.5 Undo Log</h2>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> Mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>10.MysqlInnodb存储引擎</title>
      <link href="/2020/02/18/10-MysqlInnodb%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/"/>
      <url>/2020/02/18/10-MysqlInnodb%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/</url>
      
        <content type="html"><![CDATA[<h2 id="10-1-关键特性"><a href="#10-1-关键特性" class="headerlink" title="10.1 关键特性"></a>10.1 关键特性</h2><ul><li>B-tree索引+聚簇索引</li><li>数据缓存与加密</li><li>外键支持</li><li>行级锁</li><li>事务和MVCC</li><li>复制和备份恢复</li></ul><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/InnoDBStorageEngineFeatures.png" alt=""></p><h2 id="10-2-Innodb逻辑结构图"><a href="#10-2-Innodb逻辑结构图" class="headerlink" title="10.2 Innodb逻辑结构图"></a>10.2 Innodb逻辑结构图</h2><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/innodb-architecture5.7.png" alt=""></p><h2 id="10-3-Innodb内存结构"><a href="#10-3-Innodb内存结构" class="headerlink" title="10.3 Innodb内存结构"></a>10.3 Innodb内存结构</h2><p>主要包括以下几部分:</p><ul><li>Buffer Pool</li><li>Change Buffer</li><li>AHI</li><li>Log Buffer</li></ul><h3 id="10-3-1-Buffer-Pool"><a href="#10-3-1-Buffer-Pool" class="headerlink" title="10.3.1 Buffer Pool"></a>10.3.1 Buffer Pool</h3><h4 id="10-3-1-1-作用"><a href="#10-3-1-1-作用" class="headerlink" title="10.3.1.1 作用"></a>10.3.1.1 作用</h4><p>前面的文章Mysql索引介绍中,我们知道Innodb是以页为储存单位来保存数据的,<code>读取和处理数据的时候同样需要已页为单位将数据加载到内存中</code> </p><p>如果没有Buffer Pool会进行频繁的磁盘IO,这样会大大拉低Mysql的性能,因此Mysql使用Buffer Pool来做存储数据和索引的缓存,容许在内存中直接操作表数据,提高处理速度</p><blockquote><p>Buffer Pool 的功能就是 缓存“页” ，减少磁盘IO,提高读写效率。</p></blockquote><h4 id="10-3-1-2-Buffer-Pool结构"><a href="#10-3-1-2-Buffer-Pool结构" class="headerlink" title="10.3.1.2 Buffer Pool结构"></a>10.3.1.2 Buffer Pool结构</h4><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/buffer_pool1.png" alt=""></p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/bufferpoolself.png" alt=""></p><p>Buffer Poll是由一个个Instance组成,每个instance都有自己的锁，信号量，物理块(Buffer chunks)以及逻辑链表(下面的各种List)，即<code>各个instance之间没有竞争关系，可以并发读取与写入</code>。所有instance的物理块(Buffer chunks)在数据库启动的时候被分配，直到数据库关闭内存才予以释放</p><pre><code>innodb_buffer_pool_instances = innodb_buffer_pool_size/innodb_buffer_pool_instanceInstance实例数目=BufferPool总大小/每个Instance的大小【注意】当innodb_buffer_pool_size小于1GB时候，innodb_buffer_pool_instances被重置为1，主要是防止有太多小的instance从而导致性能问题</code></pre><p>每个Buffer Pool Instance有一个page hash链表，通过它，使用space_id和page_no就能快速找到已经被读入内存的数据页，而不用线性遍历LRU List去查找。</p><p>注意这个hash表不是InnoDB的自适应哈希(AHI)，自适应哈希是为了减少Btree的扫描，而page hash是为了避免扫描LRU List。</p><p><code>Buffer Pool会通过三种Page和链表来管理这些经常访问的数据，保证热数据不被置换出Buffer Pool</code></p><h4 id="10-3-1-3-Page的分类"><a href="#10-3-1-3-Page的分类" class="headerlink" title="10.3.1.3 Page的分类"></a>10.3.1.3 Page的分类</h4><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/pageclass.png" alt=""></p><h4 id="10-3-1-4-链表的分类"><a href="#10-3-1-4-链表的分类" class="headerlink" title="10.3.1.4 链表的分类"></a>10.3.1.4 链表的分类</h4><p>链表节点是数据页的控制体(控制体中有指针指向真正的数据页)，链表中的所有节点都有同一的属性，引入其的目的是方便管理</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/listclass.png" alt=""></p><ul><li><p>Free List</p><p>Free 链表 存放的是空闲页面，初始化的时候申请一定数量的页面</p><p>在执行SQL的过程中，每次成功load 页面到内存后，会判断Free 链表的页面是否够用。如果不够用的话，就flush LRU 链表和Flush 链表来释放空闲页。如果够用，就从Free 链表里面删除对应的页面，在LRU 链表增加页面，保持总数不变。</p></li><li><p>LRU List</p><p>默认情况下：</p><ol><li><p>Old 链表占整个LRU 链表的比例是3/8。该比例由<code>innodb_old_blocks_pct</code>控制，默认值是37（3/8*100）。该值取值范围为5~95，为全局动态变量。</p></li><li><p>当新的页被读取到Buffer Pool里面的时候，和<code>传统的LRU算法插入到LRU链表头部不同，Innodb LRU算法是将新的页面插入到Yong 链表的尾部和Old 链表的头部中间的位置，这个位置叫做Mid Point</code>，如下图所示</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/lrulist.png" alt=""></p></li></ol></li></ul><ol start="3"><li><p>频繁访问一个Buffer Pool的页面，会促使页面往Young链表的头部移动。如果一个Page在被读到Buffer Pool后很快就被访问(需要超过innodb_old_block_time)，那么该Page会往Young List的头部移动，但是如果一个页面是通过预读的方式读到Buffer Pool，且之后短时间内没有被访问，那么很可能在下次访问之前就被移动到Old List的尾部，而被驱逐了。</p></li><li><p>随着数据库的持续运行，新的页面被不断的插入到LRU链表的Mid Point，Old 链表里的页面会逐渐的被移动Old链表的尾部。同时，当经常被访问的页面移动到LRU链表头部的时候，那些没有被访问的页面会逐渐的被移动到链表的尾部。最终，位于Old 链表尾部的页面将被驱逐。</p></li><li><p>如果一个数据页已经处于Young 链表，当它再次被访问的时候，<code>只有当其处于Young 链表长度的1/4(大约值)之后，才会被移动到Young 链表的头部</code>。这样做的目的是减少对LRU 链表的修改，因为LRU 链表的目标是保证经常被访问的数据页不会被驱逐出去。</p></li><li><p>innodb_old_blocks_time 控制的Old 链表头部页面的转移策略。<code>该Page需要在Old 链表停留超过innodb_old_blocks_time 时间，之后再次被访问，才会移动到Young 链表</code>。这么操作是避免Young 链表被那些只在innodb_old_blocks_time时间间隔内频繁访问，之后就不被访问的页面塞满，从而有效的保护Young 链表。</p></li><li><p>在全表扫描或者全索引扫描的时候，Innodb会将大量的页面写入LRU 链表的Mid Point位置，并且只在短时间内访问几次之后就不再访问了。设置innodb_old_blocks_time的时间窗口可以有效的保护Young List，保证了真正的频繁访问的页面不被驱逐。<code>innodb_old_blocks_time 单位是毫秒，默认值是1000，即１秒。调大该值提高了从Old链表移动到Young链表的难度，会促使更多页面被移动到Old 链表，老化，从而被驱逐</code></p></li><li><p>当扫描的表很大，Buffer Pool都放不下时，可以将innodb_old_blocks_pct设置为较小的值，这样只读取一次的数据页就不会占据大部分的Buffer Pool。例如，设置innodb_old_blocks_pct = 5，会将仅读取一次的数据页在Buffer Pool的占用限制为5％。当经常扫描一些小表时，这些页面在Buffer Pool移动的开销较小，我们可以适当的调大innodb_old_blocks_pct，例如设置innodb_old_blocks_pct = 50</p></li></ol><p>  在SHOW ENGINE INNODB STATUS 里面提供了Buffer Pool一些监控指标，有几个我们需要关注一下：</p><pre><code class="mysql">  =====================================  mysql&gt; show engine innnodb status\G  ……  Pages made young 0, not young 0  0.00 youngs/s, 0.00 non-youngs/s  ======================================  数据页从冷到热，称为young；not young就是数据在没有成为热数据情况下就被刷走的量(累计值)。</code></pre><table><thead><tr><th align="left">指标</th><th align="left">场景</th><th align="left">处理方法</th><th>作用</th></tr></thead><tbody><tr><td align="left">youngs/s很小</td><td align="left">都是一些小事务，没有大表全扫描</td><td align="left">调大innodb_old_blocks_pct，减小innodb_old_blocks_time</td><td>使Old List 的长度更长，到Old List 的尾部消耗的时间会更久，提升下一次访问到Old List里面的页面的可能性</td></tr><tr><td align="left">youngs/s很大</td><td align="left"></td><td align="left">可以调小innodb_old_blocks_pct，同时调大innodb_old_blocks_time</td><td>保护热数据</td></tr><tr><td align="left">non-youngs/s很大</td><td align="left">大量的全表扫描</td><td align="left">可以调小innodb_old_blocks_pct，同时调大innodb_old_blocks_time</td><td>保护young list</td></tr><tr><td align="left">non-youngs/s不大</td><td align="left">存在大量全表扫描</td><td align="left">调大innodb_old_blocks_time</td><td>使得这些短时间频繁访问的页面保留在Old 链表里面</td></tr></tbody></table><p>  每隔1秒钟，Page Cleaner线程执行LRU List Flush的操作，来释放足够的Free Page。innodb_lru_scan_depth 变量控制每个Buffer Pool实例每次扫描LRU List的长度，来寻找对应的脏页，执行Flush操作。</p><ul><li><p>Flush List</p><ol><li>Flush 链表里面保存的都是脏页，也会存在于LRU 链表。</li><li>Flush 链表是按照oldest_modification排序，值大的在头部，值小的在尾部</li><li>当有页面访被修改的时候，使用mini-transaction，对应的page进入Flush 链表</li><li>如果当前页面已经是脏页，就不需要再次加入Flush list，否则是第一次修改，需要加入Flush 链表</li><li>当Page Cleaner线程执行flush操作的时候，从尾部开始scan，将一定的脏页写入磁盘，推进检查点，减少recover的时间</li></ol></li></ul><blockquote><p>LRU链表和FLUSH链表的区别 </p></blockquote><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/lru-flush-diff.png" alt=""></p><h3 id="10-3-2-Change-Buffer"><a href="#10-3-2-Change-Buffer" class="headerlink" title="10.3.2 Change Buffer"></a>10.3.2 Change Buffer</h3><h4 id="10-3-2-1-作用"><a href="#10-3-2-1-作用" class="headerlink" title="10.3.2.1 作用"></a>10.3.2.1 作用</h4><p>Change buffer的主要目的是将对<code>二级索引</code>的数据操作缓存下来，以此减少二级索引的随机IO，并达到操作合并的效果。</p><p>对表执行 INSERT，UPDATE和 DELETE操作时， 索引列的值（尤其是secondary keys的值）通常按未排序顺序排列，需要大量I / O才能使二级索引更新。Change Buffer会缓存这个更新当相关页面不在Buffer Pool中，从而磁盘上的相关页面不会立即被读避免了昂贵的I / O操作</p><h4 id="10-3-2-2-参数"><a href="#10-3-2-2-参数" class="headerlink" title="10.3.2.2 参数"></a>10.3.2.2 参数</h4><ul><li><p>参数：innodb_change_buffer_max_size</p><p>介绍：配置写缓冲的大小，占整个缓冲池的比例，默认值是25%，最大值是50%。</p><p><code>写多读少的业务，才需要调大这个值，读多写少的业务，25%其实也多了</code></p></li><li><p>参数：innodb_change_buffering<br>介绍：配置哪些写操作启用写缓冲，可以设置成all/none/inserts/deletes等</p></li></ul><pre><code class="mysql">mysql&gt; select @@innodb_change_buffer_max_size;+---------------------------------+| @@innodb_change_buffer_max_size |+---------------------------------+|                              25 |+---------------------------------+1 row in set (0.00 sec)mysql&gt; select @@innodb_change_buffering;+---------------------------+| @@innodb_change_buffering |+---------------------------+| all                       |+---------------------------+1 row in set (0.00 sec)</code></pre><h3 id="10-3-3-Adaptive-Hash-Index-AHI"><a href="#10-3-3-Adaptive-Hash-Index-AHI" class="headerlink" title="10.3.3 Adaptive Hash Index(AHI)"></a>10.3.3 Adaptive Hash Index(AHI)</h3><p>哈希(hash)是一种非常快的查找方法,在一般情况下这种查找的时间复杂度为O(1),即一般仅需要一次查找就能定位数据。而B+树的查找次数,取决于B+树的高度,在生产环境中,B+树的高度一般为3-4层,故需要3-4次的查询。</p><p>InnoDB存储引擎会监控对表上各索引页的查询。如果观察到建立哈希索引可以带来速度提升,则建立哈希索引,称之为<code>自适应哈希索引(Adaptive Hash Index,AHI)</code> AHI是通过缓冲池的B+树页构造而来,因此建立的速度很快,而且不需要对整张表构建哈希索引。 InnoDB存储引擎会自动根据访问的频率和模式来自动地为某些热点页建立哈希索引。</p><p>我们可以认为：<code>AHI是建立在B+Tree数索引上的索引</code>,是Innodb内部用来自身提高查询速度的自优化功能</p><h3 id="10-3-4-Log-Buffer"><a href="#10-3-4-Log-Buffer" class="headerlink" title="10.3.4 Log Buffer"></a>10.3.4 Log Buffer</h3><h4 id="10-3-4-1-功能"><a href="#10-3-4-1-功能" class="headerlink" title="10.3.4.1 功能"></a>10.3.4.1 功能</h4><p><code>负责redo日志的缓冲</code></p><p>redo log日志作用后面的文章将会介绍</p><h4 id="10-3-4-2-刷盘时机"><a href="#10-3-4-2-刷盘时机" class="headerlink" title="10.3.4.2 刷盘时机"></a>10.3.4.2 刷盘时机</h4><ul><li>redo log buffer 空间不足的时候</li><li>事务提交的时候</li><li>后台线程在不停的刷</li><li>服务正常关闭的时候</li><li>checkpoint的时候</li></ul><h4 id="10-3-4-3-关键参数"><a href="#10-3-4-3-关键参数" class="headerlink" title="10.3.4.3 关键参数"></a>10.3.4.3 关键参数</h4><ul><li>innodb_flush_log_at_trx_commit</li></ul><pre><code class="mysql">mysql&gt; select @@innodb_flush_log_at_trx_commit;+----------------------------------+| @@innodb_flush_log_at_trx_commit |+----------------------------------+|                                1 |+----------------------------------+1 row in set (0.00 sec)作用:主要控制了innodb将log buffer中的数据写入日志文件并flush磁盘的时间点取值分别为0、1、2三个参数说明:1.每次事物的提交都会引起日志文件写入、flush磁盘的操作，确保了事务的ACID；flush  到操作系统的文件系统缓存,fsync到物理磁盘.0.表示当事务提交时，不做日志写入操作，而是每秒钟将log buffer中的数据写入文件系统缓存并且秒fsync磁盘一次；2.每次事务提交引起写入文件系统缓存,但每秒钟完成一次fsync磁盘操作。</code></pre><ul><li>Innodb_flush_method</li></ul><pre><code class="mysql">mysql&gt; select @@Innodb_flush_method;+-----------------------+| @@Innodb_flush_method |+-----------------------+| NULL                  |+-----------------------+1 row in set (0.00 sec)</code></pre><p>可选模式:</p><ul><li><p>FSYNC(默认值):</p><ul><li>buffer pool的数据写磁盘时,要先经历os cache,然后再写到磁盘</li><li>log buffer的数据写磁盘时,要先经历os cache,然后再写到磁盘</li></ul></li><li><p>O_DSYNC:</p><ul><li>buffer pool的数据写磁盘时,要先经历os cache,然后再写到磁盘</li><li>log buffer 的数据写磁盘时,直接写到写到磁盘,跨过os cache</li></ul></li><li><p>O_DIRECT：</p><ul><li><p>buffer pool的数据写磁盘时,直接写到写到磁盘,跨过os cache</p></li><li><p>log buffer的数据写磁盘时,要先经历os cache,然后再写到磁盘</p></li></ul></li></ul><p>建议使用:O_DIRECT+固态硬盘</p><h2 id="10-4-Innodb物理存储结构"><a href="#10-4-Innodb物理存储结构" class="headerlink" title="10.4 Innodb物理存储结构"></a>10.4 Innodb物理存储结构</h2><p>​    主要包含以下几部分:</p><ul><li>系统表空间 System Tablespace</li><li>Undo日志</li><li>Redo日志</li><li>临时表空间</li><li>用户表空间</li><li>ib_buffer_pool</li></ul><h3 id="10-4-1-System-Tablespace"><a href="#10-4-1-System-Tablespace" class="headerlink" title="10.4.1 System Tablespace"></a>10.4.1 System Tablespace</h3><p>5.7版本的Mysql系统表空间用来存储以下信息:</p><ul><li>Innodb的数据字典</li><li>double buffer</li><li>change buffer</li><li>undo log</li></ul><p>5.6版本的Mysql系统表空间还存储是临时表数据</p><p>8.8版本的Mysql系统表空间取消存储数据字典信息并将undo log独立了出来</p><p>Mysql在慢慢瘦身系统表空间,把比较关键的数据独立出来了</p><h4 id="10-4-1-1-ibdata文件"><a href="#10-4-1-1-ibdata文件" class="headerlink" title="10.4.1.1 ibdata文件"></a>10.4.1.1 ibdata文件</h4><p>默认情况下,系统表空间在磁盘上的文件名为<code>ibdata1</code>,存在<code>/data</code>文件夹下</p><p>我们可以通过<code>innodb_data_file_path</code>参数修改系统表空间文件的数量</p><pre><code class="mysql">innodb_data_file_path=ibdata1:1G:ibdata2:1G:autoextend含义:有多个ibdata 第一个名称为ibdata1大小1G 第二个名称为ibdata2大小1Gautoextend意思是以此类推的生成ibdata</code></pre><p><code>innodb_data_file_path</code>参数通常要在初始化的时候加入到my.cnf文件下配置好</p><p>如果是在已运行的数据库上扩展多个ibdata文件,在设置<code>innodb_data_file_path</code>参数时,已有的ibdata1文件大小应该和磁盘上真正运行的ibdata1大小一致,而不是随便指定</p><h4 id="10-4-1-2-缩小系统表空间大小"><a href="#10-4-1-2-缩小系统表空间大小" class="headerlink" title="10.4.1.2 缩小系统表空间大小"></a>10.4.1.2 缩小系统表空间大小</h4><p>我们不能从系统表空间中删除数据,如果想减小系统表空间的大小我们只能做如下操作:</p><ol><li>mysqldump数据</li><li>关闭服务</li><li>删除所有 .ibd文件,ibdata文件ib_log文件</li><li>删除所有.frm文件</li><li>配置新系统表空间</li><li>重启服务</li><li>导入数据</li></ol><h3 id="10-4-2-Redo-log"><a href="#10-4-2-Redo-log" class="headerlink" title="10.4.2 Redo log"></a>10.4.2 Redo log</h3><p>Redo log　重做日志</p><h4 id="10-4-2-1-功能"><a href="#10-4-2-1-功能" class="headerlink" title="10.4.2.1 功能"></a>10.4.2.1 功能</h4><p>用户存储Mysql在做修改类操作时的数据页变化过程和版本号(LSN),属于物理日志</p><p>默认用两个文件存储redo log,是循环覆盖使用的</p><h4 id="10-4-2-2-文件位置"><a href="#10-4-2-2-文件位置" class="headerlink" title="10.4.2.2 文件位置"></a>10.4.2.2 文件位置</h4><p>一般也是存储在<code>/data</code>目录下,文件名为ib_logfile0 和 ib_logfile1</p><h4 id="10-4-2-3-控制参数"><a href="#10-4-2-3-控制参数" class="headerlink" title="10.4.2.3 控制参数"></a>10.4.2.3 控制参数</h4><pre><code class="ini">innodb_log_file_size=50331648    #设置文件大小innodb_log_files_in_group=2      #设置文件个数innodb_log_group_home_dir=./     #设置存储位置</code></pre><h3 id="10-4-3-Undo-log"><a href="#10-4-3-Undo-log" class="headerlink" title="10.4.3 Undo log"></a>10.4.3 Undo log</h3><p>Undo log　回滚日志</p><h4 id="10-4-3-1-功能"><a href="#10-4-3-1-功能" class="headerlink" title="10.4.3.1 功能"></a>10.4.3.1 功能</h4><p>用来存储回滚日志,记录每次操作的反操作,属于逻辑日志</p><ol><li>使用快照功能,提供Innodb多版本并发读写</li><li>通过记录的反操作,提供回滚功能</li></ol><h4 id="10-4-3-2-文件位置"><a href="#10-4-3-2-文件位置" class="headerlink" title="10.4.3.2 文件位置"></a>10.4.3.2 文件位置</h4><p>ibdataN里和ibtmp1里</p><h4 id="10-4-3-3-控制参数"><a href="#10-4-3-3-控制参数" class="headerlink" title="10.4.3.3 控制参数"></a>10.4.3.3 控制参数</h4><pre><code class="ini"> innodb_rollback_segments=128 #回滚段的个数</code></pre>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> Mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>4.Redis数据结构——listNode</title>
      <link href="/2020/02/18/4-Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-listNode/"/>
      <url>/2020/02/18/4-Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-listNode/</url>
      
        <content type="html"><![CDATA[<h2 id="4-1-什么是listNode"><a href="#4-1-什么是listNode" class="headerlink" title="4.1 什么是listNode"></a>4.1 什么是listNode</h2><p>listNode就是常规数据结构的一种——链表</p><p>Redis没有引用第三方的库来实现链表,而是自己手撸了一个</p><h2 id="4-2-list-amp-node数据结构"><a href="#4-2-list-amp-node数据结构" class="headerlink" title="4.2 list&amp;node数据结构"></a>4.2 list&amp;node数据结构</h2><pre><code class="c">#file:src/adlist.h/* * 双端链表节点 */typedef struct listNode {    // 前置节点    struct listNode *prev;    // 后置节点    struct listNode *next;    // 节点的值    void *value;} listNode;/* * 双端链表结构 */typedef struct list {   // 表头节点    listNode *head;    // 表尾节点    listNode *tail;    // 节点值复制函数    void *(*dup)(void *ptr);    // 节点值释放函数    void (*free)(void *ptr);    // 节点值对比函数    int (*match)(void *ptr, void *key);    // 链表所包含的节点数量    unsigned long len;} list;</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/listnode.png" alt=""></p><h2 id="4-3-新增结点"><a href="#4-3-新增结点" class="headerlink" title="4.3 新增结点"></a>4.3 新增结点</h2><p>没啥说的　就是双链表的新增</p><pre><code class="c">#file:src/adlist.c/* * 创建一个包含值 value 的新节点，并将它插入到 old_node 的之前或之后 * 如果 after 为 0 ，将新节点插入到 old_node 之前。 * 如果 after 为 1 ，将新节点插入到 old_node 之后。 * T = O(1) */list *listInsertNode(list *list, listNode *old_node, void *value, int after) {    listNode *node;    // 创建新节点    if ((node = zmalloc(sizeof(*node))) == NULL)        return NULL;    // 保存值    node-&gt;value = value;    // 将新节点添加到给定节点之后    if (after) {        node-&gt;prev = old_node;        node-&gt;next = old_node-&gt;next;        // 给定节点是原表尾节点        if (list-&gt;tail == old_node) {            list-&gt;tail = node;        }    // 将新节点添加到给定节点之前    } else {        node-&gt;next = old_node;        node-&gt;prev = old_node-&gt;prev;        // 给定节点是原表头节点        if (list-&gt;head == old_node) {            list-&gt;head = node;        }    }    // 更新新节点的前置指针    if (node-&gt;prev != NULL) {        node-&gt;prev-&gt;next = node;    }    // 更新新节点的后置指针    if (node-&gt;next != NULL) {        node-&gt;next-&gt;prev = node;    }    // 更新链表节点数    list-&gt;len++;    return list;}</code></pre><h2 id="4-4-删除结点"><a href="#4-4-删除结点" class="headerlink" title="4.4 删除结点"></a>4.4 删除结点</h2><p>也没啥说的,链表的删除操作</p><pre><code class="c">#file:src/adlist.c/* * 从链表 list 中删除给定节点 node  * T = O(1) */void listDelNode(list *list, listNode *node){    // 调整前置节点的指针    if (node-&gt;prev)        node-&gt;prev-&gt;next = node-&gt;next;    else        list-&gt;head = node-&gt;next;    // 调整后置节点的指针    if (node-&gt;next)        node-&gt;next-&gt;prev = node-&gt;prev;    else        list-&gt;tail = node-&gt;prev;    // 释放值    //对节点私有值的释放工作由list进行    if (list-&gt;free) list-&gt;free(node-&gt;value);    // 释放节点    zfree(node);    // 链表数减一    list-&gt;len--;}</code></pre><h2 id="4-5-查找结点"><a href="#4-5-查找结点" class="headerlink" title="4.5 查找结点"></a>4.5 查找结点</h2><pre><code class="c">#file:src/adlist.c/*  * 查找链表 list 中值和 key 匹配的节点。 * T = O(N) */listNode *listSearchKey(list *list, void *key){    listIter *iter;    listNode *node;    // 迭代整个链表    iter = listGetIterator(list, AL_START_HEAD);    while((node = listNext(iter)) != NULL) {        // 对比,对比操作由链表的 match 函数负责进行，        //如果没有设置 match 函数，那么直接通过对比值的指针来决定是否匹配        if (list-&gt;match) {            if (list-&gt;match(node-&gt;value, key)) {                listReleaseIterator(iter);                // 找到                return node;            }        } else {            if (key == node-&gt;value) {                listReleaseIterator(iter);                // 找到                return node;            }        }    }    listReleaseIterator(iter);    // 未找到    return NULL;}</code></pre><h2 id="4-6-修改结点"><a href="#4-6-修改结点" class="headerlink" title="4.6 修改结点"></a>4.6 修改结点</h2><p>在Redis实现的双链表里,<code>结点的值不能被修改只能被删除</code></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>3.Redis数据结构——SDS</title>
      <link href="/2020/02/18/3-Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-SDS/"/>
      <url>/2020/02/18/3-Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-SDS/</url>
      
        <content type="html"><![CDATA[<h2 id="3-1-什么是SDS"><a href="#3-1-什么是SDS" class="headerlink" title="3.1 什么是SDS"></a>3.1 什么是SDS</h2><p>C语言中有定义好的String字符串,但是Redis并没有使用String字符串来作为默认的字符串存储格式,而是定义了一个结构体SDS(简单动态字符串)来实现</p><p>Redis中的每一个键都是一个SDS,String类型的每一个值也都是SDS</p><h2 id="3-2-SDS结构"><a href="#3-2-SDS结构" class="headerlink" title="3.2 SDS结构"></a>3.2 SDS结构</h2><pre><code class="c">#file: /src/sds.h/* * 保存SDS对象的结构 */struct sdshdr {    // buf 中已占用空间的长度    int len;    // buf 中剩余可用空间的长度    int free;    // 数据空间    char buf[];};</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/sdsstruct.png" alt=""></p><h2 id="3-3-新建SDS"><a href="#3-3-新建SDS" class="headerlink" title="3.3 新建SDS"></a>3.3 新建SDS</h2><pre><code class="c">#dep/hiredis/sds.c#创建SDS对象　根据字符串指针获取其长度　传给sdsnewlensds sdsnew(const char *init) {    size_t initlen = (init == NULL) ? 0 : strlen(init);    return sdsnewlen(init, initlen);}#被sdsnew调用sds sdsnewlen(const void *init, size_t initlen) {    struct sdshdr *sh;    if (init) {        sh = zmalloc(sizeof(struct sdshdr)+initlen+1);    } else {        sh = zcalloc(sizeof(struct sdshdr)+initlen+1);    }    if (sh == NULL) return NULL;    sh-&gt;len = initlen;  //sds-&gt;len = 字符串长度    sh-&gt;free = 0;　　　　//sds-&gt;free = 0    if (initlen &amp;&amp; init)        memcpy(sh-&gt;buf, init, initlen);    sh-&gt;buf[initlen] = &#39;\0&#39;;    return (char*)sh-&gt;buf;}</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/sdsnew.png" alt=""></p><h2 id="3-4-修改SDS"><a href="#3-4-修改SDS" class="headerlink" title="3.4 修改SDS"></a>3.4 修改SDS</h2><pre><code class="c">#dep/hiredis/sds.csds sdscpy(sds s, const char *t) {    return sdscpylen(s, t, strlen(t));}sds sdscpylen(sds s, const char *t, size_t len) {    struct sdshdr *sh = (void*) (s-(sizeof(struct sdshdr)));    size_t totlen = sh-&gt;free+sh-&gt;len;    if (totlen &lt; len) {        # 特别注意sdsMakeRoomFor函数　是对sds的扩容操作        s = sdsMakeRoomFor(s,len-sh-&gt;len);        if (s == NULL) return NULL;        sh = (void*) (s-(sizeof(struct sdshdr)));        totlen = sh-&gt;free+sh-&gt;len;    }    memcpy(s, t, len);    s[len] = &#39;\0&#39;;    sh-&gt;len = len;    sh-&gt;free = totlen-len;    return s;}</code></pre><p>整体代码写的很清晰,没什么过多解释的,我们特别注意下<code>sdsMakeRoomFor</code>这个函数,是对sds的扩容操作：</p><pre><code class="c">#dep/hiredis/sds.c#define SDS_MAX_PREALLOC (1024*1024)  #1MBsds sdsMakeRoomFor(sds s, size_t addlen) {    struct sdshdr *sh, *newsh;    size_t free = sdsavail(s);    size_t len, newlen;    if (free &gt;= addlen) return s;    len = sdslen(s);    sh = (void*) (s-(sizeof(struct sdshdr)));    newlen = (len+addlen);    if (newlen &lt; SDS_MAX_PREALLOC)        newlen *= 2;    else        newlen += SDS_MAX_PREALLOC;    newsh = zrealloc(sh, sizeof(struct sdshdr)+newlen+1);    if (newsh == NULL) return NULL;    newsh-&gt;free = newlen - len;    return newsh-&gt;buf;}</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/sdsedit.png" alt=""></p><p>我们注意到:</p><ul><li>修改sds时redis会进行<code>空间预分配</code>,用以减少连续字符串增长操作所需的内存重新分配次数</li><li>如果将sds字符串缩短,sds的空间也不会立即释放,采用<code>惰性空间释放的方式</code>使用free属性将这些字节数量记录下来，将来使用<code>sdsRemoveFreeSpace</code>进行释放</li></ul><pre><code class="c">#dep/hiredis/sds.csds sdsRemoveFreeSpace(sds s) {    struct sdshdr *sh;    sh = (void*) (s-(sizeof(struct sdshdr)));    sh = zrealloc(sh, sizeof(struct sdshdr)+sh-&gt;len+1);    sh-&gt;free = 0;    return sh-&gt;buf;}</code></pre><h2 id="3-5-SDS与C字符串区别"><a href="#3-5-SDS与C字符串区别" class="headerlink" title="3.5 SDS与C字符串区别"></a>3.5 SDS与C字符串区别</h2><table><thead><tr><th align="center">序号</th><th>C 字符串</th><th>SDS</th></tr></thead><tbody><tr><td align="center">１</td><td>获取字符串长度的复杂度为 O(N)</td><td>获取字符串长度的复杂度为 O(1) 。</td></tr><tr><td align="center">２</td><td>API 是不安全的，可能会造成缓冲区溢出</td><td>API 是安全的，不会造成缓冲区溢出</td></tr><tr><td align="center">３</td><td>修改字符串长度 N 次必然需要执行 N 次内存重分配</td><td>修改字符串长度 N 次最多需要执行 N 次内存重分配</td></tr><tr><td align="center">４</td><td>只能保存文本数据</td><td>可以保存文本或者二进制数据</td></tr><tr><td align="center">５</td><td>可以使用所有 &lt;string.h&gt; 库中的函数</td><td>可以使用一部分 &lt;string.h&gt; 库中的函数</td></tr></tbody></table><p>区别①②④主要是因为sds结构的<code>len</code>属性,不依靠<code>\0</code>来判断结尾</p><p>区别③主要因为sds的空间预分配算法</p><p>区别⑤sds本质上还是一个封装了的string</p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2.Redis数据操作</title>
      <link href="/2020/02/18/2-Redis%E6%95%B0%E6%8D%AE%E6%93%8D%E4%BD%9C/"/>
      <url>/2020/02/18/2-Redis%E6%95%B0%E6%8D%AE%E6%93%8D%E4%BD%9C/</url>
      
        <content type="html"><![CDATA[<h2 id="2-1-String命令"><a href="#2-1-String命令" class="headerlink" title="2.1 String命令"></a>2.1 String命令</h2><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/string.png" alt=""></p><h2 id="2-2-List命令"><a href="#2-2-List命令" class="headerlink" title="2.2 List命令"></a>2.2 List命令</h2><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/list.png" alt=""></p><h2 id="2-3-Hash命令"><a href="#2-3-Hash命令" class="headerlink" title="2.3 Hash命令"></a>2.3 Hash命令</h2><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/hash.png" alt=""></p><h2 id="2-4-Set命令"><a href="#2-4-Set命令" class="headerlink" title="2.4 Set命令"></a>2.4 Set命令</h2><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/set.png" alt=""></p><h2 id="2-5-ZSet命令"><a href="#2-5-ZSet命令" class="headerlink" title="2.5 ZSet命令"></a>2.5 ZSet命令</h2><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/zset.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>1.Redis简介</title>
      <link href="/2020/02/18/1-Redis%E7%AE%80%E4%BB%8B/"/>
      <url>/2020/02/18/1-Redis%E7%AE%80%E4%BB%8B/</url>
      
        <content type="html"><![CDATA[<h2 id="1-1-Redis特点"><a href="#1-1-Redis特点" class="headerlink" title="1.1 Redis特点"></a>1.1 Redis特点</h2><ul><li>Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用。</li><li>Redis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。</li><li>Redis支持数据的备份，即master-slave模式的数据备份</li><li>Redis有原生的集群模式</li><li>Redis是单线程模式</li></ul><h2 id="1-2-与Memcache对比"><a href="#1-2-与Memcache对比" class="headerlink" title="1.2 与Memcache对比"></a>1.2 与Memcache对比</h2><table><thead><tr><th align="center">名称</th><th align="center">持久化</th><th align="center">数据类型</th><th>集群支持</th></tr></thead><tbody><tr><td align="center">Redis</td><td align="center">可持久化</td><td align="center">五种</td><td>原生支持cluster模式</td></tr><tr><td align="center">Memcached</td><td align="center">不可持久化</td><td align="center">一种</td><td>没有原生的集群模式,需要依靠客户端来实现往集群中分片写入数据</td></tr></tbody></table><h2 id="1-3-Redis线程模型"><a href="#1-3-Redis线程模型" class="headerlink" title="1.3 Redis线程模型"></a>1.3 Redis线程模型</h2><p>redis 基于 <code>reactor 模式</code>开发了网络事件处理器，这个处理器叫做文件事件处理器，file event handler，这个文件事件处理器是单线程的，所以redis 是单线程的模型，采用 io多路复用机制同时监听多个 socket,根据socket上的事件来选择对应的事件处理器来处理这个事件</p><p>文件事件处理器的结构包含 4 个部分：</p><ul><li>多个 Socket</li><li>IO 多路复用程序</li><li>文件事件分派器</li><li>事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）</li></ul><p>多个 Socket 可能会并发产生不同的操作，每个操作对应不同的文件事件，但是 IO 多路复用程序会监听多个 Socket，会将 Socket 产生的事件放入队列中排队，事件分派器每次从队列中取出一个事件，把该事件交给对应的事件处理器进行处理。</p><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/even.png" alt=""></p><h2 id="1-4-Redis为什么效率高"><a href="#1-4-Redis为什么效率高" class="headerlink" title="1.4 Redis为什么效率高"></a>1.4 Redis为什么效率高</h2><ul><li>纯内存操作</li><li>核心是基于非堵塞的IO多路复用机制</li><li>单线程反而避免了多线程的频繁上下文切换问题</li></ul><h2 id="1-5-Redis-数据结构"><a href="#1-5-Redis-数据结构" class="headerlink" title="1.5 Redis 数据结构"></a>1.5 Redis 数据结构</h2><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/datastruct.png" alt=""></p><p>​    </p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>9.MysqlProfile介绍</title>
      <link href="/2020/02/16/9-MysqlProfile%E4%BB%8B%E7%BB%8D/"/>
      <url>/2020/02/16/9-MysqlProfile%E4%BB%8B%E7%BB%8D/</url>
      
        <content type="html"><![CDATA[<h2 id="9-1-相关参数"><a href="#9-1-相关参数" class="headerlink" title="9.1 相关参数"></a>9.1 相关参数</h2><pre><code class="mysql">mysql&gt; show variables like &#39;%profil%&#39;;+------------------------+-------+| Variable_name          | Value |+------------------------+-------+| have_profiling         | YES   || profiling              | OFF   || profiling_history_size | 15    |+------------------------+-------+3 rows in set (0.01 sec)have_profiling： 当前版本是否支持profiling功能profiling： 是否开启profiling功能profiling_history_size： 保留profiling的数目，默认是15，范围为0~100，为0时代表禁用profiling</code></pre><h2 id="9-2-开启profile"><a href="#9-2-开启profile" class="headerlink" title="9.2 开启profile"></a>9.2 开启profile</h2><pre><code class="mysql">session级别开启:mysql&gt; SET profiling = 1;全局开启echo &quot;profiling=1&quot; &gt;&gt; my.cnf</code></pre><h2 id="9-3-help-profile"><a href="#9-3-help-profile" class="headerlink" title="9.3 help profile"></a>9.3 help profile</h2><p>我们可以通过help profile查看profile的用法,官方的解释已经很好了</p><pre><code class="mysql">mysql&gt; help profile;Name: &#39;SHOW PROFILE&#39;Description:Syntax:SHOW PROFILE [type [, type] ... ]    [FOR QUERY n]    [LIMIT row_count [OFFSET offset]]type: {    ALL  | BLOCK IO  | CONTEXT SWITCHES  | CPU  | IPC  | MEMORY  | PAGE FAULTS  | SOURCE  | SWAPS}The SHOW PROFILE and SHOW PROFILES statements display profilinginformation that indicates resource usage for statements executedduring the course of the current session.*Note*:The SHOW PROFILE and SHOW PROFILES statements are deprecated and willbe removed in a future MySQL release. Use the Performance Schemainstead; seehttp://dev.mysql.com/doc/refman/5.7/en/performance-schema-query-profiling.html.To control profiling, use the profiling session variable, which has adefault value of 0 (OFF). Enable profiling by setting profiling to 1 orON:mysql&gt; SET profiling = 1;SHOW PROFILES displays a list of the most recent statements sent to theserver. The size of the list is controlled by theprofiling_history_size session variable, which has a default value of15. The maximum value is 100. Setting the value to 0 has the practicaleffect of disabling profiling.All statements are profiled except SHOW PROFILE and SHOW PROFILES, soyou will find neither of those statements in the profile list.Malformed statements are profiled. For example, SHOW PROFILING is anillegal statement, and a syntax error occurs if you try to execute it,but it will show up in the profiling list.SHOW PROFILE displays detailed information about a single statement.Without the FOR QUERY n clause, the output pertains to the mostrecently executed statement. If FOR QUERY n is included, SHOW PROFILEdisplays information for statement n. The values of n correspond to theQuery_ID values displayed by SHOW PROFILES.The LIMIT row_count clause may be given to limit the output torow_count rows. If LIMIT is given, OFFSET offset may be added to beginthe output offset rows into the full set of rows.By default, SHOW PROFILE displays Status and Duration columns. TheStatus values are like the State values displayed by SHOW PROCESSLIST,although there might be some minor differences in interpretion for thetwo statements for some status values (seehttp://dev.mysql.com/doc/refman/5.7/en/thread-information.html).Optional type values may be specified to display specific additionaltypes of information:o ALL displays all informationo BLOCK IO displays counts for block input and output operationso CONTEXT SWITCHES displays counts for voluntary and involuntary  context switcheso CPU displays user and system CPU usage timeso IPC displays counts for messages sent and receivedo MEMORY is not currently implementedo PAGE FAULTS displays counts for major and minor page faultso SOURCE displays the names of functions from the source code, together  with the name and line number of the file in which the function  occurso SWAPS displays swap countsProfiling is enabled per session. When a session ends, its profilinginformation is lost.URL: http://dev.mysql.com/doc/refman/5.7/en/show-profile.htmlExamples:mysql&gt; SELECT @@profiling;+-------------+| @@profiling |+-------------+|           0 |+-------------+1 row in set (0.00 sec)mysql&gt; SET profiling = 1;Query OK, 0 rows affected (0.00 sec)mysql&gt; DROP TABLE IF EXISTS t1;Query OK, 0 rows affected, 1 warning (0.00 sec)mysql&gt; CREATE TABLE T1 (id INT);Query OK, 0 rows affected (0.01 sec)mysql&gt; SHOW PROFILES;+----------+----------+--------------------------+| Query_ID | Duration | Query                    |+----------+----------+--------------------------+|        0 | 0.000088 | SET PROFILING = 1        ||        1 | 0.000136 | DROP TABLE IF EXISTS t1  ||        2 | 0.011947 | CREATE TABLE t1 (id INT) |+----------+----------+--------------------------+3 rows in set (0.00 sec)mysql&gt; SHOW PROFILE;+----------------------+----------+| Status               | Duration |+----------------------+----------+| checking permissions | 0.000040 || creating table       | 0.000056 || After create         | 0.011363 || query end            | 0.000375 || freeing items        | 0.000089 || logging slow query   | 0.000019 || cleaning up          | 0.000005 |+----------------------+----------+7 rows in set (0.00 sec)mysql&gt; SHOW PROFILE FOR QUERY 1;+--------------------+----------+| Status             | Duration |+--------------------+----------+| query end          | 0.000107 || freeing items      | 0.000008 || logging slow query | 0.000015 || cleaning up        | 0.000006 |+--------------------+----------+4 rows in set (0.00 sec)mysql&gt; SHOW PROFILE CPU FOR QUERY 2;+----------------------+----------+----------+------------+| Status               | Duration | CPU_user | CPU_system |+----------------------+----------+----------+------------+| checking permissions | 0.000040 | 0.000038 |   0.000002 || creating table       | 0.000056 | 0.000028 |   0.000028 || After create         | 0.011363 | 0.000217 |   0.001571 || query end            | 0.000375 | 0.000013 |   0.000028 || freeing items        | 0.000089 | 0.000010 |   0.000014 || logging slow query   | 0.000019 | 0.000009 |   0.000010 || cleaning up          | 0.000005 | 0.000003 |   0.000002 |+----------------------+----------+----------+------------+7 rows in set (0.00 sec)</code></pre><h2 id="9-4-type类型"><a href="#9-4-type类型" class="headerlink" title="9.4 type类型"></a>9.4 type类型</h2><p>这里我们主要关注两个指标　</p><ul><li><code>ALL</code>:显示所性能信息</li><li><code>BLOCK IO</code>:显示块(页)IO的数量<ul><li>BLOCK_OPS_IN:输入页数量</li><li>BLOCK_OPS_OUT:输出页数量</li></ul></li><li><code>CONTEXT SWITCHES</code>:上下文切换相关开销</li><li><code>CPU</code>:显示CPU相关开销信息<ul><li>CPU_user:用户所用时间,秒单位 </li><li>CPU_system:系统所用时间,秒单位 </li></ul></li><li><code>IPC</code>:显示发送和接收相关开销信息</li><li><code>MEMORY</code>:显示内存相关开销信息</li><li><code>PAGE FAULTS</code> :显示页面错误相关开销信息</li><li><code>SOURCE</code> :显示和Source_function，Source_file，Source_line相关的开销信息</li><li><code>SWAPS</code> :显示交换次数相关开销的信息</li></ul><h2 id="9-5-profile过程"><a href="#9-5-profile过程" class="headerlink" title="9.5 profile过程"></a>9.5 profile过程</h2><pre><code class="mysql">mysql&gt; show profile for query 4;+----------------------+-----------+| Status               | Duration  |+----------------------+-----------+| starting             |  0.000083 || checking permissions |  0.000013 || Opening tables       |  0.000019 || init                 |  0.000036 || System lock          |  0.000014 || optimizing           |  0.000012 || statistics           |  0.000021 || preparing            |  0.000018 || executing            |  0.000006 || Sending data         | 87.327560 || end                  |  0.000016 || query end            |  0.000013 || closing tables       |  0.000011 || freeing items        |  0.000027 || logging slow query   |  0.000057 || cleaning up          |  0.000017 |+----------------------+-----------+16 rows in set, 1 warning (0.00 sec)starting：开始checking permissions：检查权限Opening tables：打开表init ： 初始化System lock ：系统锁optimizing ： 优化statistics ： 统计preparing ：准备executing ：执行Sending data ：发送数据Sorting result ：排序end ：结束query end ：查询 结束closing tables ： 关闭表 ／去除TMP 表freeing items ： 释放事件cleaning up ：清理profile只能列出使用到的环节　没有使用的环节不显示</code></pre><h3 id="9-5-1-重点环节"><a href="#9-5-1-重点环节" class="headerlink" title="9.5.1 重点环节"></a>9.5.1 重点环节</h3><ul><li><code>preparing</code> ：准备</li><li><code>executing</code> ：执行</li><li><code>Sending data</code> ：发送数据  一般这个环节时间最长</li><li><code>Sorting result</code> ：排序</li></ul><h3 id="9-5-2-不应-减少出现的环节"><a href="#9-5-2-不应-减少出现的环节" class="headerlink" title="9.5.2 不应/减少出现的环节"></a>9.5.2 不应/减少出现的环节</h3><ul><li><code>converting HEAP to MyISAM</code>： 查询结果太大，内存都不够用了，往磁盘上搬了</li><li><code>creating tmp table</code> ：创建临时表，拷贝数据到临时表，然后再删除</li><li><code>copying to tmp table on disk</code> ：把内存中临时表复制到磁盘</li><li><code>locked</code>: 被锁喉了~</li></ul><h2 id="9-6-日常常用指令"><a href="#9-6-日常常用指令" class="headerlink" title="9.6 日常常用指令"></a>9.6 日常常用指令</h2><pre><code class="mysql">SHOW PROFILE block io,cpu FOR QUERY N;多注意CPU和IOmysql&gt; SHOW PROFILE block io,cpu FOR QUERY 4\G;*************************** 1. row ***************************       Status: starting     Duration: 0.000083     CPU_user: 0.000049   CPU_system: 0.000025 Block_ops_in: 0Block_ops_out: 0*************************** 2. row ***************************       Status: checking permissions     Duration: 0.000013     CPU_user: 0.000006   CPU_system: 0.000003 Block_ops_in: 0Block_ops_out: 0*************************** 3. row ***************************       Status: Opening tables     Duration: 0.000019     CPU_user: 0.000012   CPU_system: 0.000006 Block_ops_in: 0Block_ops_out: 0*************************** 4. row ***************************       Status: init     Duration: 0.000036     CPU_user: 0.000022   CPU_system: 0.000012 Block_ops_in: 0Block_ops_out: 0*************************** 5. row ***************************       Status: System lock     Duration: 0.000014     CPU_user: 0.000008   CPU_system: 0.000004 Block_ops_in: 0Block_ops_out: 0*************************** 6. row ***************************       Status: optimizing     Duration: 0.000012     CPU_user: 0.000007   CPU_system: 0.000003 Block_ops_in: 0Block_ops_out: 0*************************** 7. row ***************************       Status: statistics     Duration: 0.000021     CPU_user: 0.000013   CPU_system: 0.000007 Block_ops_in: 0Block_ops_out: 0*************************** 8. row ***************************       Status: preparing     Duration: 0.000018     CPU_user: 0.000011   CPU_system: 0.000006 Block_ops_in: 0Block_ops_out: 0*************************** 9. row ***************************       Status: executing     Duration: 0.000006     CPU_user: 0.000003   CPU_system: 0.000002 Block_ops_in: 0Block_ops_out: 0*************************** 10. row ***************************       Status: Sending data     Duration: 87.327560     CPU_user: 37.617680   CPU_system: 32.943640 Block_ops_in: 2591264Block_ops_out: 0*************************** 11. row ***************************       Status: end     Duration: 0.000016     CPU_user: 0.000006   CPU_system: 0.000004 Block_ops_in: 0Block_ops_out: 0*************************** 12. row ***************************       Status: query end     Duration: 0.000013     CPU_user: 0.000007   CPU_system: 0.000005 Block_ops_in: 0Block_ops_out: 0*************************** 13. row ***************************       Status: closing tables     Duration: 0.000011     CPU_user: 0.000006   CPU_system: 0.000004 Block_ops_in: 0Block_ops_out: 0*************************** 14. row ***************************       Status: freeing items     Duration: 0.000027     CPU_user: 0.000015   CPU_system: 0.000010 Block_ops_in: 0Block_ops_out: 0*************************** 15. row ***************************       Status: logging slow query     Duration: 0.000057     CPU_user: 0.000032   CPU_system: 0.000021 Block_ops_in: 0Block_ops_out: 8*************************** 16. row ***************************       Status: cleaning up     Duration: 0.000017     CPU_user: 0.000009   CPU_system: 0.000006 Block_ops_in: 0Block_ops_out: 016 rows in set, 1 warning (0.00 sec)ERROR: No query specified</code></pre><h2 id="9-7-使用Performance查看profi"><a href="#9-7-使用Performance查看profi" class="headerlink" title="9.7  使用Performance查看profi"></a>9.7  使用Performance查看profi</h2><p>通过help profile我们知道show proflie相关指令即将废弃,可以使用如下指令进行查询</p><p>在使用以下两个命令前需要做一些设置角色的操作:具体请参考官方文档:</p><p><a href="https://dev.mysql.com/doc/refman/5.7/en/performance-schema-query-profiling.html" target="_blank" rel="noopener">25.19.1 Query Profiling Using Performance Schema</a></p><h3 id="9-7-1-查看所有语句"><a href="#9-7-1-查看所有语句" class="headerlink" title="9.7.1 查看所有语句"></a>9.7.1 查看所有语句</h3><pre><code class="mysql">mysql&gt; SELECT EVENT_ID, TRUNCATE(TIMER_WAIT/1000000000000,6) as Duration, SQL_TEXT        FROM performance_schema.events_statements_history_long\G;*************************** 1. row ***************************EVENT_ID: 146Duration: 0.000842SQL_TEXT: UPDATE performance_schema.setup_consumers       SET ENABLED = &#39;YES&#39;       WHERE NAME LIKE &#39;%events_statements_%&#39;*************************** 2. row ***************************EVENT_ID: 147Duration: 0.000376SQL_TEXT: UPDATE performance_schema.setup_consumers       SET ENABLED = &#39;YES&#39;       WHERE NAME LIKE &#39;%events_stages_%&#39;*************************** 3. row ***************************EVENT_ID: 154Duration: 2.089741SQL_TEXT: select count(*) from t_scrm_pet_info where pet_birthday &gt; &#39;2019-01-01 00:00:01&#39; and pet_birthday &lt; &#39;2019-03-01 00:00:01&#39;*************************** 4. row ***************************EVENT_ID: 171Duration: 0.003488SQL_TEXT: SELECT EVENT_ID, TRUNCATE(TIMER_WAIT/1000000000000,6) as Duration, SQL_TEXT       FROM performance_schema.events_statements_history_long*************************** 5. row ***************************EVENT_ID: 188Duration: 0.000899SQL_TEXT: SELECT event_name AS Stage, TRUNCATE(TIMER_WAIT/1000000000000,6) AS Duration       FROM performance_schema.events_stages_history_long WHERE NESTING_EVENT_ID=154*************************** 6. row ***************************EVENT_ID: 205Duration: 0.000480SQL_TEXT: SELECT event_name AS Stage, TRUNCATE(TIMER_WAIT/1000000000000,6) AS Duration        FROM performance_schema.events_stages_history_long WHERE NESTING_EVENT_ID=154*************************** 7. row ***************************EVENT_ID: 222Duration: 0.000669SQL_TEXT: SELECT EVENT_ID, TRUNCATE(TIMER_WAIT/1000000000000,6) as Duration, SQL_TEXT        FROM performance_schema.events_statements_history_long7 rows in set (0.00 sec)ERROR: No query specified</code></pre><h3 id="9-7-2-查看指定语句"><a href="#9-7-2-查看指定语句" class="headerlink" title="9.7.2 查看指定语句"></a>9.7.2 查看指定语句</h3><pre><code class="mysql">mysql&gt; SELECT event_name AS Stage, TRUNCATE(TIMER_WAIT/1000000000000,6) AS Duration        FROM performance_schema.events_stages_history_long WHERE NESTING_EVENT_ID=154\G;*************************** 1. row ***************************   Stage: stage/sql/startingDuration: 0.000105*************************** 2. row ***************************   Stage: stage/sql/checking permissionsDuration: 0.000008*************************** 3. row ***************************   Stage: stage/sql/Opening tablesDuration: 0.000021*************************** 4. row ***************************   Stage: stage/sql/initDuration: 0.000059*************************** 5. row ***************************   Stage: stage/sql/System lockDuration: 0.000016*************************** 6. row ***************************   Stage: stage/sql/optimizingDuration: 0.000014*************************** 7. row ***************************   Stage: stage/sql/statisticsDuration: 0.000023*************************** 8. row ***************************   Stage: stage/sql/preparingDuration: 0.000017*************************** 9. row ***************************   Stage: stage/sql/executingDuration: 0.000002*************************** 10. row ***************************   Stage: stage/sql/Sending dataDuration: 2.089357*************************** 11. row ***************************   Stage: stage/sql/endDuration: 0.000005*************************** 12. row ***************************   Stage: stage/sql/query endDuration: 0.000012*************************** 13. row ***************************   Stage: stage/sql/closing tablesDuration: 0.000009*************************** 14. row ***************************   Stage: stage/sql/freeing itemsDuration: 0.000027*************************** 15. row ***************************   Stage: stage/sql/logging slow queryDuration: 0.000055*************************** 16. row ***************************   Stage: stage/sql/cleaning upDuration: 0.00000116 rows in set (0.00 sec)ERROR: No query specified</code></pre>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> Mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>8.MysqlExplain介绍</title>
      <link href="/2020/02/16/8-MysqlExplain%E4%BB%8B%E7%BB%8D/"/>
      <url>/2020/02/16/8-MysqlExplain%E4%BB%8B%E7%BB%8D/</url>
      
        <content type="html"><![CDATA[<h2 id="8-1-Explain各列意义"><a href="#8-1-Explain各列意义" class="headerlink" title="8.1 Explain各列意义"></a>8.1 Explain各列意义</h2><p>EXPLAIN 命令的输出内容大致如下:</p><pre><code class="mysql">mysql&gt; explain select *  from t_scrm_user_info where bigdata_user_id &gt; &#39;A1001036&#39; and bigdata_user_id &lt; &#39;A2100000&#39;\G;*************************** 1. row ***************************           id: 1  select_type: SIMPLE        table: t_scrm_user_info   partitions: NULL         type: rangepossible_keys: UQ_CUSTOMER_ID          key: UQ_CUSTOMER_ID      key_len: 130          ref: NULL         rows: 168902     filtered: 100.00        Extra: Using index condition1 row in set, 1 warning (0.00 sec)</code></pre><table><thead><tr><th align="center">列名称</th><th align="center">含义</th></tr></thead><tbody><tr><td align="center">id</td><td align="center">SELECT 查询的标识符. 每个 SELECT 都会自动分配一个唯一的标识符.</td></tr><tr><td align="center">select_type</td><td align="center">SELECT 查询的类型.</td></tr><tr><td align="center">table</td><td align="center">查询的是哪个表</td></tr><tr><td align="center">partitions</td><td align="center">匹配的分区</td></tr><tr><td align="center">type</td><td align="center">join 类型</td></tr><tr><td align="center">possible_keys</td><td align="center">此次查询中可能选用的索引</td></tr><tr><td align="center">key</td><td align="center">此次查询中确切使用到的索引.</td></tr><tr><td align="center">ref</td><td align="center">哪个字段或常数与 key 一起被使用</td></tr><tr><td align="center">rows</td><td align="center">显示此查询一共扫描了多少行. 这个是一个估计值.</td></tr><tr><td align="center">filtered</td><td align="center">表示此查询条件所过滤的数据的百分比</td></tr><tr><td align="center">extra</td><td align="center">额外的信息</td></tr></tbody></table><h2 id="8-2-id"><a href="#8-2-id" class="headerlink" title="8.2 id"></a>8.2 id</h2><p>表示select标识符，同时表明执行顺序，也就是说id是一个查询的序列号，查询序号即为sql语句执行的顺序。</p><ol><li>当id值相同时，按从上到下的顺序执行</li><li>当id全部不同时，按id从大到小执行</li><li>当id部分不同时，先执行id大的，id相同的，按从上到下的顺序执行</li></ol><h2 id="8-3-select-type"><a href="#8-3-select-type" class="headerlink" title="8.3 select_type"></a>8.3 select_type</h2><ol><li>SIMPLE 简单的select查询，查询中不包含子查询或者UNION</li><li>PRIMARY 查询中若包含任何复杂的子部分，最外层查询则被标记为PRIMARY</li><li>SUBQUERY 在SELECT或WHERE列表中包含了子查询</li><li>DERIVED 在FROM列表中包含的子查询被标记为DERIVED（衍生），MySQL会递归执行这些子查询，把结果放在临时表中</li><li>UNION 若第二个SELECT出现在UNION之后，则被标记为UNION：若UNION包含在FROM子句的子查询中，外层SELECT将被标记为：DERIVED</li><li>UNION RESULT 从UNION表获取结果的SELECT</li></ol><pre><code class="mysql">mysql&gt; explain select * from t_scrm_user_info where  id = 1\G;*************************** 1. row ***************************           id: 1  select_type: SIMPLE        table: t_scrm_user_info   partitions: NULL         type: constpossible_keys: PRIMARY,IX_ID_CREATE_TIME          key: PRIMARY      key_len: 4          ref: const         rows: 1     filtered: 100.00        Extra: NULL1 row in set, 1 warning (0.00 sec)ERROR: No query specified==================================================================================mysql&gt; explain select * from (select * from t_scrm_pet_info limit 20) t where  t.id = (select id from t_scrm_map limit 1)\G;*************************** 1. row ***************************           id: 1  select_type: PRIMARY        table: &lt;derived2&gt;   partitions: NULL         type: refpossible_keys: &lt;auto_key0&gt;          key: &lt;auto_key0&gt;      key_len: 4          ref: const         rows: 2     filtered: 100.00        Extra: Using where*************************** 2. row ***************************           id: 3  select_type: SUBQUERY        table: t_scrm_map   partitions: NULL         type: indexpossible_keys: NULL          key: IX_CREATE_TIME      key_len: 5          ref: NULL         rows: 11271619     filtered: 100.00        Extra: Using index*************************** 3. row ***************************           id: 2  select_type: DERIVED        table: t_scrm_pet_info   partitions: NULL         type: ALLpossible_keys: NULL          key: NULL      key_len: NULL          ref: NULL         rows: 4578062     filtered: 100.00        Extra: NULL3 rows in set, 1 warning (0.00 sec)ERROR: No query specified==================================================================================mysql&gt; explain select * from t_scrm_map where id =10 union select * from t_scrm_map where id = 20\G;*************************** 1. row ***************************           id: 1  select_type: PRIMARY        table: t_scrm_map   partitions: NULL         type: constpossible_keys: PRIMARY          key: PRIMARY      key_len: 4          ref: const         rows: 1     filtered: 100.00        Extra: NULL*************************** 2. row ***************************           id: 2  select_type: UNION        table: t_scrm_map   partitions: NULL         type: constpossible_keys: PRIMARY          key: PRIMARY      key_len: 4          ref: const         rows: 1     filtered: 100.00        Extra: NULL*************************** 3. row ***************************           id: NULL  select_type: UNION RESULT        table: &lt;union1,2&gt;   partitions: NULL         type: ALLpossible_keys: NULL          key: NULL      key_len: NULL          ref: NULL         rows: NULL     filtered: NULL        Extra: Using temporary3 rows in set, 1 warning (0.00 sec)</code></pre><h2 id="8-4-table"><a href="#8-4-table" class="headerlink" title="8.4 table"></a>8.4 table</h2><p>这一列表示 explain 的一行正在访问哪个表。</p><p>当 from 子句中有子查询时，table列是 <derivenN> 格式，表示当前查询依赖 id=N 的查询，于是先执行 id=N 的查询。当有 union 时，UNION RESULT 的 table 列的值为 &lt;union1,2&gt;，1和2表示参与 union 的 select 行id。</p><h2 id="8-5-partitions"><a href="#8-5-partitions" class="headerlink" title="8.5 partitions"></a>8.5 partitions</h2><p>使用的哪些分区（对于非分区表值为null）</p><h2 id="8-6-type"><a href="#8-6-type" class="headerlink" title="8.6 type"></a>8.6 type</h2><p>type所显示的是查询使用了哪种类型，type包含的类型包括如下图所示的几种：</p><p>从最好到最差依次是：</p><pre><code>system &gt; const &gt; eq_ref &gt; ref &gt; range &gt; index &gt; all</code></pre><p>一般来说，得保证查询至少达到range级别，最好能达到ref。</p><ul><li><code>const, system</code>：mysql能对查询的某部分进行优化并将其转化成一个常量。用于 primary key 或 unique key 的所有列与常数比较时，所以表最多有一个匹配行，读取1次，速度比较快。</li></ul><pre><code class="mysql">mysql&gt; explain select * from t_scrm_user_info where bigdata_user_id = &#39;B13470427&#39;\G;*************************** 1. row ***************************           id: 1  select_type: SIMPLE        table: t_scrm_user_info   partitions: NULL         type: constpossible_keys: UQ_CUSTOMER_ID          key: UQ_CUSTOMER_ID      key_len: 130          ref: const         rows: 1     filtered: 100.00        Extra: NULL1 row in set, 1 warning (0.00 sec)</code></pre><ul><li><code>eq_ref</code>：primary key 或 unique key 索引的所有部分被连接使用 ，最多只会返回一条符合条件的记录。这可能是在 const 之外最好的<code>联接类型</code>了，简单的 select 查询不会出现这种 type。</li></ul><pre><code class="mysql">mysql&gt; explain select * from t_scrm_user_info u left join t_scrm_map m on u.bigdata_user_id = m.bigdata_id where u.bigdata_user_id = &#39;B13470427&#39;\G;*************************** 1. row ***************************           id: 1  select_type: SIMPLE        table: u   partitions: NULL         type: constpossible_keys: UQ_CUSTOMER_ID          key: UQ_CUSTOMER_ID      key_len: 130          ref: const         rows: 1     filtered: 100.00        Extra: NULL*************************** 2. row ***************************           id: 1  select_type: SIMPLE        table: m   partitions: NULL         type: refpossible_keys: UQ_ID          key: UQ_ID      key_len: 258          ref: const         rows: 1     filtered: 100.00        Extra: Using where2 rows in set, 1 warning (0.00 sec)</code></pre><ul><li>ref：相比 eq_ref，不使用唯一索引，而是使用普通索引或者唯一性索引的部分前缀，索引要和某个值相比较，可能会找到多个符合条件的行。</li></ul><pre><code class="mysql">mysql&gt; explain select * from t_scrm_map where target_id = &#39;11255964&#39;\G;*************************** 1. row ***************************           id: 1  select_type: SIMPLE        table: t_scrm_map   partitions: NULL         type: refpossible_keys: IX_TRAGET_ID          key: IX_TRAGET_ID      key_len: 130          ref: const         rows: 1     filtered: 100.00        Extra: NULL1 row in set, 1 warning (0.00 sec)</code></pre><ul><li><code>ref_or_null</code>：类似ref，但是可以搜索值为NULL的行。</li><li><code>range</code>：范围扫描通常出现在 in(), between ,&gt; ,&lt;, &gt;= 等操作中。使用一个索引来检索给定范围的行。</li></ul><pre><code class="mysql">mysql&gt; explain select * from t_scrm_map where id &gt; 10 and id  &lt;20\G;*************************** 1. row ***************************           id: 1  select_type: SIMPLE        table: t_scrm_map   partitions: NULL         type: rangepossible_keys: PRIMARY          key: PRIMARY      key_len: 4          ref: NULL         rows: 9     filtered: 100.00        Extra: Using where1 row in set, 1 warning (0.00 sec)ERROR: No query specified</code></pre><ul><li><code>index</code>：和ALL一样，不同就是mysql只需扫描索引树，这通常比ALL快一些。</li></ul><pre><code class="mysql">mysql&gt; explain select count(*) from t_scrm_map\G;*************************** 1. row ***************************           id: 1  select_type: SIMPLE        table: t_scrm_map   partitions: NULL         type: indexpossible_keys: NULL          key: IX_CREATE_TIME      key_len: 5          ref: NULL         rows: 11271619     filtered: 100.00        Extra: Using index1 row in set, 1 warning (0.00 sec)ERROR: No query specified</code></pre><ul><li><code>ALL</code>：即全表扫描，意味着mysql需要从头到尾去查找所需要的行。通常情况下这需要增加索引来进行优化了</li></ul><pre><code class="mysql">mysql&gt; explain select * from t_scrm_map\G;*************************** 1. row ***************************           id: 1  select_type: SIMPLE        table: t_scrm_map   partitions: NULL         type: ALLpossible_keys: NULL          key: NULL      key_len: NULL          ref: NULL         rows: 11271619     filtered: 100.00        Extra: NULL1 row in set, 1 warning (0.00 sec)ERROR: No query specified</code></pre><h2 id="8-7-possible-keys"><a href="#8-7-possible-keys" class="headerlink" title="8.7  possible_keys"></a>8.7  possible_keys</h2><p>这一列显示查询可能使用哪些索引来查找。 </p><p>explain 时可能出现 possible_keys 有列，而 key 显示 NULL 的情况，这种情况是因为表中数据不多，mysql认为索引对此查询帮助不大，选择了全表查询。 </p><p>如果该列是NULL，则没有相关的索引。在这种情况下，可以通过检查 where 子句看是否可以创造一个适当的索引来提高查询性能，然后用 explain 查看效果。</p><h2 id="8-8-key"><a href="#8-8-key" class="headerlink" title="8.8 key"></a>8.8 key</h2><p>这一列显示mysql实际采用哪个索引来优化对该表的访问。</p><p>如果没有使用索引，则该列是 NULL。如果想强制mysql使用或忽视possible_keys列中的索引，在查询中使用 force index、ignore index。</p><h2 id="8-9-key-len列"><a href="#8-9-key-len列" class="headerlink" title="8.9 key_len列"></a>8.9 key_len列</h2><p>这一列显示了mysql在索引里使用的字节数，通过这个值可以算出具体使用了索引中的哪些列。 </p><pre><code class="mysql">key_len 的计算规则如下:字符串char(n): n 字节长度varchar(n): 如果是 utf8 编码, 则是 3 n + 2字节; 如果是 utf8mb4 编码, 则是 4n +2 字节.数值类型:TINYINT: 1字节SMALLINT: 2字节MEDIUMINT: 3字节INT: 4字节BIGINT: 8字节时间类型DATE: 3字节TIMESTAMP: 4字节DATETIME: 8字节字段属性: NULL 属性 占用一个字节. 如果一个字段是 NOT NULL 的, 则没有此属性.</code></pre><pre><code class="mysql">mysql&gt; explain select count(*) from t_scrm_map where target_id  = &#39;11255964&#39;\G;*************************** 1. row ***************************           id: 1  select_type: SIMPLE        table: t_scrm_map   partitions: NULL         type: refpossible_keys: IX_TRAGET_ID          key: IX_TRAGET_ID      key_len: 130          ref: const         rows: 1     filtered: 100.00        Extra: Using index1 row in set, 1 warning (0.00 sec)/**| t_scrm_map | CREATE TABLE `t_scrm_map` (  `id` int(10) unsigned NOT NULL AUTO_INCREMENT,  `bigdata_id` varchar(64) NOT NULL COMMENT &#39;唯一ID&#39;,  `type` tinyint(3) NOT NULL COMMENT &#39;关联类型&#39;,  PRIMARY KEY (`id`),  UNIQUE KEY `UQ_ID` (`bigdata_id`,`type`),  KEY `IX_MAP_ID` (`scrm_id`),) ENGINE=InnoDB AUTO_INCREMENT=11962156 DEFAULT CHARSET=utf8mb4 ROW_FORMAT=DYNAMIC COMMENT=&#39;关系表&#39; |*/mysql&gt; explain select count(*) from t_scrm_map where bigdata_id  = &#39;11255964&#39;\G;*************************** 1. row ***************************           id: 1  select_type: SIMPLE        table: t_scrm_map   partitions: NULL         type: refpossible_keys: UQ_ID          key: UQ_ID      key_len: 258          ref: const         rows: 1     filtered: 100.00        Extra: Using index1 row in set, 1 warning (0.04 sec)可以看到key_len = 258---&gt; 64*4+2;即只使用了索引UQ_ID的bigdata_id部分mysql&gt; explain select * from t_scrm_map where bigdata_id  = &#39;B11255964&#39; and type = 1\G;*************************** 1. row ***************************           id: 1  select_type: SIMPLE        table: t_scrm_map   partitions: NULL         type: constpossible_keys: UQ_ID          key: UQ_ID      key_len: 259          ref: const,const         rows: 1     filtered: 100.00        Extra: NULL1 row in set, 1 warning (0.04 sec)可以看到key_len = 258---&gt; 64*4+2+1;即使用了索引UQ_ID的bigdata_id和type部分</code></pre><h2 id="8-10-ref列"><a href="#8-10-ref列" class="headerlink" title="8.10 ref列"></a>8.10 ref列</h2><p>这一列显示了在key列记录的索引中，表查找值所用到的列或常量，常见的有：</p><ul><li><p>const（常量）</p></li><li><p>func</p></li><li><p>NULL</p></li><li><p>字段名</p></li></ul><h2 id="8-11-rows列rows"><a href="#8-11-rows列rows" class="headerlink" title="8.11 rows列rows"></a>8.11 rows列rows</h2><p>rows 也是一个重要的字段. MySQL 查询优化器根据统计信息, 估算 SQL 要查找到结果集需要扫描读取的数据行数. 这个值非常直观显示 SQL 的效率好坏, 原则上 rows 越少越好.</p><h2 id="8-12-Extra列"><a href="#8-12-Extra列" class="headerlink" title="8.12 Extra列"></a>8.12 Extra列</h2><p>这一列展示的是额外信息。常见的重要值如下： </p><h3 id="8-12-1-Using-filesort"><a href="#8-12-1-Using-filesort" class="headerlink" title="8.12.1 Using filesort"></a>8.12.1 Using filesort</h3><p>mysql 会对结果使用一个外部索引排序，而不是按索引次序从表里读取行。此时mysql会根据联接类型浏览所有符合条件的记录，并保存排序关键字和行指针，然后排序关键字并按顺序检索行信息。</p><p><code>这种情况是要考虑使用索引来优化的</code></p><pre><code class="mysql">mysql&gt; explain select * from t_scrm_map order by type asc\G;*************************** 1. row ***************************           id: 1  select_type: SIMPLE        table: t_scrm_map   partitions: NULL         type: ALLpossible_keys: NULL          key: NULL      key_len: NULL          ref: NULL         rows: 11271619     filtered: 100.00        Extra: Using filesort1 row in set, 1 warning (0.00 sec)</code></pre><h3 id="8-12-2-Using-temporary"><a href="#8-12-2-Using-temporary" class="headerlink" title="8.12.2 Using temporary"></a>8.12.2 Using temporary</h3><p>使用临时表保存中间结果，常用于GROUP BY 和 ORDER BY,DISTINCT操作中。</p><p>出现这种情况一般是要进行优化的，首先是想到用索引来优化。</p><pre><code class="mysql">mysql&gt; explain select distinct(type) from t_scrm_map order by type asc\G;*************************** 1. row ***************************           id: 1  select_type: SIMPLE        table: t_scrm_map   partitions: NULL         type: indexpossible_keys: UQ_ID          key: UQ_ID      key_len: 259          ref: NULL         rows: 11271619     filtered: 100.00        Extra: Using index; Using temporary; Using filesort1 row in set, 1 warning (0.00 sec)</code></pre><h3 id="8-12-3-Using-where"><a href="#8-12-3-Using-where" class="headerlink" title="8.12.3 Using where"></a>8.12.3 Using where</h3><p>在查找使用索引的情况下，需要回表去查询所需的数据</p><pre><code class="mysql">mysql&gt; explain select * from t_scrm_map where target_id  = &#39;11255964&#39; and type =2\G;*************************** 1. row ***************************           id: 1  select_type: SIMPLE        table: t_scrm_map   partitions: NULL         type: refpossible_keys: IX_TRAGET_ID          key: IX_TRAGET_ID      key_len: 130          ref: const         rows: 1     filtered: 10.00        Extra: Using where1 row in set, 1 warning (0.00 sec)</code></pre><h3 id="8-12-4-Using-index"><a href="#8-12-4-Using-index" class="headerlink" title="8.12.4 Using index"></a>8.12.4 Using index</h3><p>这发生在对表的请求列都是同一索引的部分的时候，返回的列数据只使用了索引中的信息，而没有再去访问表中的行记录。是性能高的表现。</p><pre><code class="mysql">mysql&gt; explain select count(*) from t_scrm_map\G;*************************** 1. row ***************************           id: 1  select_type: SIMPLE        table: t_scrm_map   partitions: NULL         type: indexpossible_keys: NULL          key: IX_CREATE_TIME      key_len: 5          ref: NULL         rows: 11271619     filtered: 100.00        Extra: Using index1 row in set, 1 warning (0.00 sec)</code></pre><h3 id="8-12-5-Using-index-condition"><a href="#8-12-5-Using-index-condition" class="headerlink" title="8.12.5 Using index condition"></a>8.12.5 Using index condition</h3><p>这是MySQL 5.6出来的新特性，叫做“索引条件推送”。</p><p>简单说一点就是MySQL原来在索引上是不能执行如like这样的操作的，但是现在可以了，这样减少了不必要的IO操作，但是只能用在二级索引上。</p><pre><code class="mysql">mysql&gt; explain select * from t_scrm_map where bigdata_id  = &#39;B11255964&#39; or bigdata_id like &#39;B125294%&#39;\G;*************************** 1. row ***************************           id: 1  select_type: SIMPLE        table: t_scrm_map   partitions: NULL         type: rangepossible_keys: UQ_ID          key: UQ_ID      key_len: 258          ref: NULL         rows: 8     filtered: 100.00        Extra: Using index condition1 row in set, 1 warning (0.00 sec)</code></pre><h3 id="8-12-6-Using-join-buffer"><a href="#8-12-6-Using-join-buffer" class="headerlink" title="8.12.6 Using join buffer"></a>8.12.6 Using join buffer</h3><p>使用了连接缓存：</p><ul><li>Block Nested Loop，连接算法是块嵌套循环连接;</li><li>Batched Key Access，连接算法是批量索引连接</li></ul><h3 id="8-12-7-Using-MRR"><a href="#8-12-7-Using-MRR" class="headerlink" title="8.12.7 Using MRR"></a>8.12.7 Using MRR</h3><p>使用了MRR优化算法</p><pre><code class="mysql">mysql&gt; explain select *  from t_scrm_user_info where bigdata_user_id &gt; &#39;A1001036&#39; and bigdata_user_id &lt; &#39;A2100000&#39;\G;*************************** 1. row ***************************           id: 1  select_type: SIMPLE        table: t_scrm_user_info   partitions: NULL         type: rangepossible_keys: UQ_CUSTOMER_ID          key: UQ_CUSTOMER_ID      key_len: 130          ref: NULL         rows: 168902     filtered: 100.00        Extra: Using index condition; Using MRR1 row in set, 1 warning (0.00 sec)</code></pre>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> Mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>7.Mysql优化器算法</title>
      <link href="/2020/02/16/7-Mysql%E4%BC%98%E5%8C%96%E5%99%A8%E7%AE%97%E6%B3%95/"/>
      <url>/2020/02/16/7-Mysql%E4%BC%98%E5%8C%96%E5%99%A8%E7%AE%97%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<p>除了我们自己手动进行优化外,根据之前的章节,我们可以知道,Mysql内部自己有优化器,对SQL语句进行一些内部的优化,本章介绍几个常用的优化算法:</p><ul><li>MRR</li><li>ICP</li><li>BKA</li></ul><h2 id="7-1-MRR"><a href="#7-1-MRR" class="headerlink" title="7.1 MRR"></a>7.1 MRR</h2><p>MRR——Multi Range Read</p><h3 id="7-1-1作用"><a href="#7-1-1作用" class="headerlink" title="7.1.1作用"></a>7.1.1作用</h3><p>减少磁盘的随机访问，并将随机访问转化为顺序的数据访问</p><h3 id="7-1-2-原理"><a href="#7-1-2-原理" class="headerlink" title="7.1.2 原理"></a>7.1.2 原理</h3><p>在不使用 MRR 时，优化器需要根据二级索引返回的记录来进行“回表”，这个过程一般会有较多的随机 IO, 使用 MRR 时，SQL 语句的执行过程是这样的：</p><ol><li>优化器将二级索引查询到的记录放到一块缓冲区中；</li><li>如果二级索引扫描到文件的末尾或者缓冲区已满，则使用<code>快速排序对缓冲区中的内容按照主键进行排序</code>；</li><li>用户线程调用 MRR 接口取 cluster index，然后根据cluster index 取行数据；</li><li>当根据缓冲区中的 cluster index 取完数据，则继续调用过程 2) 3)，直至扫描结束；</li></ol><p>通过上述过程，优化器将二级索引随机的 IO 进行排序，转化为主键的有序排列，从而实现了随机 IO 到顺序 IO 的转化，提升性能</p><p>在未开启MRR时,查询方式如图所示:</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/no-mrr-access-pattern.png" alt=""></p><p>开启MRR后,查询方式如下图所示:</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/mrr-access-pattern.png" alt=""></p><h3 id="7-1-3-开关MRR"><a href="#7-1-3-开关MRR" class="headerlink" title="7.1.3 开关MRR"></a>7.1.3 开关MRR</h3><p>我们可以通过 以下命令查看和开启MRR,5.6以后默认是开启的</p><pre><code class="mysql">查看MRR是否开启mysql&gt; select @@optimizer_switch\G*************************** 1. row ***************************@@optimizer_switch: index_merge=on,index_merge_union=on,index_merge_sort_union=on,index_merge_intersection=on,engine_condition_pushdown=on,index_condition_pushdown=on,mrr=on,mrr_cost_based=on,block_nested_loop=on,batched_key_access=off,materialization=on,semijoin=on,loosescan=on,firstmatch=on,duplicateweedout=on,subquery_materialization_cost_based=on,use_index_extensions=on,condition_fanout_filter=on,derived_merge=on1 row in set (0.00 sec)注意上面的mrr=on关闭MRRmysql&gt; set optimizer_switch=&#39;mrr=off&#39;;开启MRRmysql&gt; set optimizer_switch=&#39;mrr=on&#39;;相关参数当mrr=on,mrr_cost_based=on，则表示cost base的方式还选择启用MRR优化,当发现优化后的代价过高时就会不使用该项优化当mrr=on,mrr_cost_based=off，则表示总是开启MRR优化尽量设置 mrr_cost_based=ON，毕竟大多数情况下优化器是对的</code></pre><h3 id="7-1-4-开关对比"><a href="#7-1-4-开关对比" class="headerlink" title="7.1.4 开关对比"></a>7.1.4 开关对比</h3><pre><code class="mysql">mysql&gt; explain select *  from t_scrm_user_info where bigdata_user_id &gt; &#39;A1001036&#39; and bigdata_user_id &lt; &#39;A2100000&#39;;</code></pre><p>当<code>mrr=off</code>时</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/mrroffexplain.png" alt=""></p><p>当<code>mrr=on</code>时</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/mrrontime.png" alt=""></p><p>可以看到当mrr开启时, extra 的输出中多了 “Using MRR” 信息，即使用了 MRR Optimization IO 层面进行了优化，减少 IO 方面的开销</p><p>在时间上理论上可以查一个数量级,但是要在缓存池中没有预热以及查询的数据不在缓冲池中才可以</p><p>我测试的时候时间都差不多 (⊙﹏⊙)b</p><h2 id="7-2-ICP"><a href="#7-2-ICP" class="headerlink" title="7.2 ICP"></a>7.2 ICP</h2><p>ICP——Index Condition Pushdown</p><h3 id="7-2-1作用"><a href="#7-2-1作用" class="headerlink" title="7.2.1作用"></a>7.2.1作用</h3><p>在mysql数据库取出索引的同时,判断是否可以进行WHERE条件的过滤,也就是讲WHERE条件的过滤放到了存储引擎层,大大减少了上层SQL层对记录的fetch索取,以提高性能</p><h3 id="7-2-2-原理"><a href="#7-2-2-原理" class="headerlink" title="7.2.2 原理"></a>7.2.2 原理</h3><p>5.6 之前，在 SQL 语句的执行过程中，server 层通过 engine 的 api 获取数据，然后再进行 where_cond 的判断（具体判断逻辑在: evaluate_join_record），每一条数据都需要从engine层返回server层做判断。我们回顾一下上面把 ICP 关掉的测试，可以看到 Handler_read_next 的值陡增，其原因是第 1 个字段区分度不高，且 memo 字段无法使用索引，造成了类似 index 扫描的的情况，性能较低。</p><p>5.6 之后，在利用索引扫描的过程中，如果发现 where_cond 中含有这个 index 相关的条件，则将此条件记录在 handler 接口中，在索引扫描的过程中，只有满足索引与handler接口的条件时，才会返回到 server 层做进一步的处理，在前缀索引区分度不够，其它字段区分度高的情况下可以有效的减少 server &amp; engine之间的开销，提升查询性能。</p><p>开启ICP前查询方式如图所示:</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/index-access-2phases.png" alt=""></p><p>开启ICP后查询方式如图所示:</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/index-access-with-icp.png" alt=""></p><h3 id="7-2-3-开关ICP"><a href="#7-2-3-开关ICP" class="headerlink" title="7.2.3 开关ICP"></a>7.2.3 开关ICP</h3><pre><code class="mysql">默认是开启的查看MRR是否开启mysql&gt; select @@optimizer_switch\G*************************** 1. row ***************************@@optimizer_switch: index_merge=on,index_merge_union=on,index_merge_sort_union=on,index_merge_intersection=on,engine_condition_pushdown=on,index_condition_pushdown=on,mrr=on,mrr_cost_based=on,block_nested_loop=on,batched_key_access=off,materialization=on,semijoin=on,loosescan=on,firstmatch=on,duplicateweedout=on,subquery_materialization_cost_based=on,use_index_extensions=on,condition_fanout_filter=on,derived_merge=on1 row in set (0.00 sec)注意上面的index_condition_pushdown=onSET optimizer_switch=&#39;index_condition_pushdown=on&#39;SET optimizer_switch=&#39;index_condition_pushdown=off&#39;</code></pre><h3 id="7-2-4-开关对比"><a href="#7-2-4-开关对比" class="headerlink" title="7.2.4 开关对比"></a>7.2.4 开关对比</h3><p>开启ICP时,使用explain语句时extra字段有<code>Using index condition</code>关键字</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/mrroffexplain.png" alt=""></p><h3 id="7-2-5-使用场景"><a href="#7-2-5-使用场景" class="headerlink" title="7.2.5 使用场景"></a>7.2.5 使用场景</h3><ul><li><p>只支持 select 语句；</p></li><li><p>MyISAM 与 InnoDB 引擎都起作用;</p></li><li><p>ICP的优化策略可用于range、ref、eq_ref、ref_or_null 类型的访问数据方法；</p></li><li><p>不支持主建索引，只支持辅助索引；</p></li><li><p>涉及子查询的不能起作用</p></li><li><p>作用于多列索引的情况最为明显</p><pre><code class="mysql">SELECT * FROM people  WHERE zipcode=&#39;95054&#39;  AND lastname LIKE &#39;%etrunia%&#39;  AND address LIKE &#39;%Main Street%&#39;;</code></pre></li></ul><h2 id="7-3-BKA"><a href="#7-3-BKA" class="headerlink" title="7.3 BKA"></a>7.3 BKA</h2><p>BKA——Batched Key Access</p><p>BKA的前辈是BNL:</p><h3 id="7-3-1-Block-Nested-Loop-Join算法"><a href="#7-3-1-Block-Nested-Loop-Join算法" class="headerlink" title="7.3.1 Block Nested-Loop Join算法"></a>7.3.1 Block Nested-Loop Join算法</h3><p>将外层循环的行/结果集存入join buffer, 内层循环的每一行与整个buffer中的记录做比较，从而减少内层循环的次数。主要用于当被join的表上无索引。</p><h3 id="7-3-2-Batched-Key-Access算法"><a href="#7-3-2-Batched-Key-Access算法" class="headerlink" title="7.3.2 Batched Key Access算法"></a>7.3.2 Batched Key Access算法</h3><p>当被join的表能够使用索引时，就先好顺序，然后再去检索被join的表。对这些行按照索引字段进行排序，因此减少了随机IO。如果被Join的表上没有索引，则使用老版本的BNL策略(BLOCK Nested-loop)。</p><h3 id="7-3-3-BKA和BNL标识"><a href="#7-3-3-BKA和BNL标识" class="headerlink" title="7.3.3 BKA和BNL标识"></a>7.3.3 BKA和BNL标识</h3><p>Explain下的Extra显示不同：</p><ul><li><p>Using join buffer (Batched Key Access)</p></li><li><p>Using join buffer (Block Nested Loop)</p></li></ul><pre><code class="mysql">相关参数BAK使用了MRR，要想使用BAK必须打开MRR功能，而MRR基于mrr_cost_based的成本估算并不能保证总是使用MRR，官方推荐设置mrr_cost_based=off来总是开启MRR功能。打开BAK功能(BAK默认OFF)：SET optimizer_switch=&#39;mrr=on,mrr_cost_based=off,batched_key_access=on&#39;;BKA使用join buffer size来确定buffer的大小，buffer越大，访问被join的表/内部表就越顺序。BNL默认是开启的，设置BNL相关参数：SET optimizer_switch=’block_nested_loop’支持inner join, outer join, semi-join operations,including nested outer joins</code></pre><p><code>BKA主要适用于join的表上有索引可利用，无索引只能使用BNL</code></p><h3 id="7-3-4-BKA-BNL-MRR的关系"><a href="#7-3-4-BKA-BNL-MRR的关系" class="headerlink" title="7.3.4 BKA BNL MRR的关系"></a>7.3.4 BKA BNL MRR的关系</h3><p>BKA = BNL + MRR</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/bka.jpg" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> Mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>6.Mysql索引介绍</title>
      <link href="/2020/02/16/6-Mysql%E7%B4%A2%E5%BC%95%E4%BB%8B%E7%BB%8D/"/>
      <url>/2020/02/16/6-Mysql%E7%B4%A2%E5%BC%95%E4%BB%8B%E7%BB%8D/</url>
      
        <content type="html"><![CDATA[<p>【注意】主要介绍Innodb的索引结构</p><h2 id="6-1-Innodb索引组织表"><a href="#6-1-Innodb索引组织表" class="headerlink" title="6.1 Innodb索引组织表"></a>6.1 Innodb索引组织表</h2><p>和MyISAM的一个大区别,在Innodb的存储引擎中,表都是根据<code>主键</code>顺序组织存放的.我们把这种存储方式的表成为<code>索引组织表(index origanized table)</code>即大家常说的<code>IOT</code>方式</p><p>Innodb规定每一个表必须需要有主键(PK),主键的选择方式按照如下顺序选择:</p><ol><li>如有有定义主键 则选择此主键</li><li>如果为定义主键 选择<code>第一个定义的非空唯一索引</code>做主键:这里注意有三个条件:<code>非空</code>,<code>唯一</code>,<code>第一个满足以上两个条件的索引</code></li><li>如果以上两个都没有,Innodb会自动创建一个6字节大小的指针:隐式的创建,平时查询不能看到</li></ol><pre><code class="mysql">我们可以通过以下语句查看每一行的主键id,select *,_rowid form table;_rowid表示表的主键 需要注意的是 _rowid只能用于查看单个列为主键的情况 对于多列组成的主键就不好使了</code></pre><h2 id="6-1-Innodb逻辑存储结构"><a href="#6-1-Innodb逻辑存储结构" class="headerlink" title="6.1 Innodb逻辑存储结构"></a>6.1 Innodb逻辑存储结构</h2><p>之间介绍过Innodb库表的文件结构为两个:</p><pre><code>${tablename}.frm   #表结构文件${tablename}.idb   #表索引及数据文件</code></pre><p>所有的数据都被逻辑的存放在一个空间中(.idb文件中),我们称这个空间为<code>表空间(tablespace)</code></p><p>表空间的组成结构如下图所示:</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/innodb_engine_struct.png" alt=""></p><p>这样看可能不明显 再看一个:</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/tablespace.png" alt=""></p><pre><code>可以看到:表空间  ↓段segment  ↓区extent  ↓页page/块block   &lt;---最小储存单元而页里面包含了一个一个的行数据</code></pre><h3 id="6-2-1-表空间"><a href="#6-2-1-表空间" class="headerlink" title="6.2.1 表空间"></a>6.2.1 表空间</h3><p>在5.6以前所有的数据都存在共享表空间ibdata1中，在5.6以后加入了<code>innodb_file_per_table</code>参数默认是开启的,建议也是开启的,开启了这个参数后,每张表内的数据会单独放到一个表空间内</p><p>需要注意的是:每张表空间内存放的只有:</p><ul><li>数据</li><li>索引</li><li>插入缓存Bitmap</li></ul><p>其他的一些信息如:undo操作,插入缓存索引页,失误信息,double write buffer还是存在ibdata里</p><p>ibdata的具体介绍会在innodb索引章节进行介绍说明</p><h3 id="6-2-2-段"><a href="#6-2-2-段" class="headerlink" title="6.2.2 段"></a>6.2.2 段</h3><p>常见的段分类如下:</p><ul><li>数据段</li><li>索引段</li><li>回滚段</li></ul><h3 id="6-2-3-区"><a href="#6-2-3-区" class="headerlink" title="6.2.3 区"></a>6.2.3 区</h3><p>区是由<code>连续的页</code>组成的空间,<code>在任何情况下每个区的大小都为1MB</code></p><p>为了保证区的连续性,每次存储引擎都会从磁盘申请四五个区</p><p>默认情况下,Innodb页的大小为16KB,即一个区共有64个页  =&gt; (2^10) / (2^4)</p><p>页的大小可以在初始化的时候进行调整,但是区的大小总为1MB</p><h3 id="6-2-4-页"><a href="#6-2-4-页" class="headerlink" title="6.2.4 页"></a>6.2.4 页</h3><p>页是InnoDB存储引擎磁盘管理的最小单位，每个页默认16KB</p><p>可以通过参数<code>innodb_page_size</code>将页的大小设置为4K、8K、16K</p><p>若设置完成，则所有表中页的大小都为innodb_page_size，不可以再次对其进行修改</p><p>除非通过mysqldump导入和导出操作来产生新的库</p><p>innodb的所有数据文件（后缀为ibd的文件），他的大小始终都是<code>innodb_page_size</code> (16384(16k))的整数倍</p><pre><code>[root@centos7-1 baseinfo]# ll|grep &#39;ibd&#39; -rw-r-----. 1 mysql mysql 2663383040 xxx.ibd  =&gt; 2663383040 = 16384*162560-rw-r-----. 1 mysql mysql  868220928 ccc.ibd  =&gt; 868220928 = 16384*52992</code></pre><p><code>innodb_page_size</code>的大小限制了tablespace表空间的大小:</p><p>Table 14.25 InnoDB Maximum Tablespace Size</p><table><thead><tr><th>InnoDB Page Size</th><th>Maximum Tablespace Size</th></tr></thead><tbody><tr><td>4KB</td><td>16TB</td></tr><tr><td>8KB</td><td>32TB</td></tr><tr><td>16KB</td><td>64TB</td></tr><tr><td>32KB</td><td>128TB</td></tr><tr><td>64KB</td><td>256TB</td></tr></tbody></table><h3 id="6-2-5-行"><a href="#6-2-5-行" class="headerlink" title="6.2.5 行"></a>6.2.5 行</h3><p>Innodb存储引擎是面向列的,也就是数据是按行存放的,每个页存放行的记录也是有硬性规定的</p><p>最多允许存放16KB/2-200行记录,即7992行</p><p>但实际上互联网公司一行的数据大概为1KB,即一个page可以存放16行数据</p><h2 id="6-3-B-树结构"><a href="#6-3-B-树结构" class="headerlink" title="6.3 B+树结构"></a>6.3 B+树结构</h2><p>无论是MyISAM还是Innodb 他们在存储数据时,都用到了B+树结构</p><h3 id="6-3-1-B-树结构"><a href="#6-3-1-B-树结构" class="headerlink" title="6.3.1 B+树结构"></a>6.3.1 B+树结构</h3><p>(1) 原理图:</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/BTree.png" alt=""></p><p>(2)特点：</p><ul><li>非叶子节点只存储键值信息</li><li>所有叶子节点之间都有一个链指针</li><li>叶子节点也多存储了指向下一个叶子节点的指针，更方便叶子节点的范围遍历</li><li>数据记录都存放在叶子节点中</li><li>所有的叶子节点组成一个循环双向链表</li></ul><h3 id="6-3-2-MyISAM实现B-Tree"><a href="#6-3-2-MyISAM实现B-Tree" class="headerlink" title="6.3.2 MyISAM实现B+Tree"></a>6.3.2 MyISAM实现B+Tree</h3><p>(1)原理图：</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/MtISAMBTree.png" alt=""></p><p>(2)特点：</p><ul><li>索引文件和数据文件是分离的</li><li>索引文件仅保存数据行记录的地址（行指针）</li><li>主索引与二级索引无区别</li><li>二级索引也存储的是行指针</li></ul><h3 id="6-3-3-Innodb实现B-Tree"><a href="#6-3-3-Innodb实现B-Tree" class="headerlink" title="6.3.3 Innodb实现B+Tree"></a>6.3.3 Innodb实现B+Tree</h3><p>(1)原理图：</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/InnodbBtree.png" alt=""></p><p>(2)特点：</p><ul><li>主键索引既存储索引值，又在叶子节点中存储整行的数据</li><li>二级索引存储索引列值+主键信息</li><li>必须有主键 主键的选择如前文所释</li></ul><h2 id="6-4-索引分类"><a href="#6-4-索引分类" class="headerlink" title="6.4 索引分类"></a>6.4 索引分类</h2><p>我们根据索引文件是否和数据文件共同存储,可讲索引分为:</p><ul><li>聚簇索引(聚集索引)</li><li>非聚簇索引(辅助索引)</li></ul><p>不管是聚簇索引还是非聚簇索引我们看到他们内部都是B+树的,即高度平衡的,他们之间的区别是叶子节点是否存放的是一整行数据信息</p><h3 id="6-4-1-聚簇索引"><a href="#6-4-1-聚簇索引" class="headerlink" title="6.4.1 聚簇索引"></a>6.4.1 聚簇索引</h3><p>Innodb的数据页同B+树数据结构一样,每个页都通过一个双向链表来进行链接。</p><p>由于实际的数据页只能按照一颗B+树进行排序,因此每张表只能拥有一个<code>聚簇索引</code></p><p>在多数情况下,查询优化器倾向与采用聚簇索引:</p><ul><li>聚簇索引能够在叶子节点上直接找到数据</li><li>由于定义了数据的逻辑顺序,聚簇索引能够特别快的访问针对范围值的查询</li></ul><p>【注意】聚簇索引的存储并不是物理上连续的,而是逻辑上连续的:</p><ul><li>页通过双向链表链接,页按照主键的顺序排序</li><li>每个页的记录也是通过双向链表进行维护的,物理储存上可以同样不按照主键存储</li></ul><h3 id="6-4-1-非聚集索引"><a href="#6-4-1-非聚集索引" class="headerlink" title="6.4.1 非聚集索引"></a>6.4.1 非聚集索引</h3><p>对于非聚集索引,叶子节点不包含行记录的全部数据。叶子节点除了包含主键值以外,每个叶子节点的索引行还包含了一个书签(bookmark),在Innodb数据引擎中,这个bookmark就代表相应行数据的聚集索引键</p><p>他们之间的关系如下:</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/IndexRelat.jpg" alt=""></p><p>辅助索引的存在并不影响数据在聚集索引中的组织，因此<code>每张表上可以有多个辅助索引，但只能有一个聚集索引</code>。当通过辅助索引来寻找数据时，InnoDB存储引擎会遍历辅助索引并通过叶子级别的指针获得只想主键索引的主键，然后再通过主键索引来找到一个完整的行记录。</p><p>举例来说，如果在一棵高度为3的辅助索引树种查找数据，那需要对这个辅助索引树遍历3次找到指定主键，如果聚集索引树的高度同样为3，那么还需要对聚集索引树进行3次查找，最终找到一个完整的行数据所在的页，因此一共需要6次逻辑IO访问才能得到最终的一个数据页。</p><p>当然后面优化器部分会有相应的优化算法来优化IO次数</p><h2 id="6-4-索引作用"><a href="#6-4-索引作用" class="headerlink" title="6.4 索引作用"></a>6.4 索引作用</h2><blockquote><p>索引是存储引擎用于快速找到记录的一种数据结构,这是索引的基本功能</p></blockquote><h3 id="6-4-1-索引的优点"><a href="#6-4-1-索引的优点" class="headerlink" title="6.4.1 索引的优点"></a>6.4.1 索引的优点</h3><ul><li>索引大大检索了服务器需要扫描的数据量</li><li>索引可以帮助服务器避免排序和临时表</li><li>索引可以将随机IO变为顺序IO</li></ul><h3 id="6-4-2-索引平衡"><a href="#6-4-2-索引平衡" class="headerlink" title="6.4.2 索引平衡"></a>6.4.2 索引平衡</h3><p>索引太多,应用程序的性能可能受到影响,索引太少,对查询性能又会产生影响,要找到一个平衡点至关重要。</p><p>不要总是在事后才想起添加索引,设计表时要知道数据的使用,从一开始就应该在需要处添加索引</p><p>当然索引并不一定是最好的解决方案:</p><ul><li><p>在创建索引，更新数据表的时候，会给数据库带来额外的消耗。总的来说，只有当索引帮助存储引擎快速查找到记录带来的好处大于其带来的额外工作时，索引才是有效的。</p></li><li><p>对于非常小的表，大部分情况下全表扫描更高效。</p></li><li><p>对于中到大型的表，索引特别有效</p></li><li><p>但是对于特大型的表，建立和使用索引带来的代价将随之增长，这种情况下，需要使用一种技术可以直接区分出查询需要的一组数据，而不是一条记录一条记录的匹配。例如分区表技术;</p></li></ul><h2 id="6-5-索引种类"><a href="#6-5-索引种类" class="headerlink" title="6.5 索引种类"></a>6.5 索引种类</h2><ul><li>聚簇索引<ul><li>主键索引</li></ul></li><li>非聚簇索引<ul><li>普通单列索引</li><li>唯一索引</li><li>前缀索引</li><li>多列索引</li></ul></li></ul><h3 id="6-5-1-主键索引"><a href="#6-5-1-主键索引" class="headerlink" title="6.5.1 主键索引"></a>6.5.1 主键索引</h3><p>必须要有的索引，用于构建聚簇索引的基本条件</p><p>一个表只能有一个主键，不允许有空值。一般是在建表的时候同时创建主键索引。</p><p>关键字及创建方式:</p><pre><code class="mysql">  PRIMARY KEY (`id`)</code></pre><h3 id="6-5-2-普通单列索引"><a href="#6-5-2-普通单列索引" class="headerlink" title="6.5.2 普通单列索引"></a>6.5.2 普通单列索引</h3><p>普通索引是最基本的索引类型，唯一的任务是加快对数据的访问速度，没有任何限制。</p><p>关键字及创建方式:</p><pre><code class="mysql">CREATE INDEX index_name ON TABLE(column_name);ALTER TABLE table_name ADD INDEX index_name(column_name);INDEX index_name (name(length))</code></pre><h3 id="6-5-3-唯一索引"><a href="#6-5-3-唯一索引" class="headerlink" title="6.5.3 唯一索引"></a>6.5.3 唯一索引</h3><p>索引列的值必须唯一，但允许有空值。如果是组合索引，则列值的组合必须唯一。</p><p>关键字及创建方式:</p><pre><code class="mysql">UNIQUE INDEX index_name (column_name)CREATE UNIQUE INDEX index_name ON mytable(column_name)ALTER TABLE table_name ADD UNIQUE indexName(column_name)</code></pre><h3 id="6-5-4-前缀索引"><a href="#6-5-4-前缀索引" class="headerlink" title="6.5.4 前缀索引"></a>6.5.4 前缀索引</h3><p>有时候需要索引很长的字符列，这会让索引变得大且慢。</p><p>通常可以索引开始的部分字符，这样可以大大节约索引空间，从而提高索引效率。但这样也会降低索引的选择性。索引的选择性是指不重复的索引值（也称为基数，cardinality)和数据表的记录总数的比值，范围从1/#T到1之间。索引的选择性越高则查询效率越高，因为选择性高的索引可以让MySQL在查找时过滤掉更多的行。唯一索引的选择性是1，这是最好的索引选择性，性能也是最好的。</p><p>一般情况下某个前缀的选择性也是足够高的，足以满足查询性能。对于BLOB，TEXT，或者很长的VARCHAR类型的列，必须使用前缀索引，因为MySQL不允许索引这些列的完整长度。</p><p>诀窍在于要选择足够长的前缀以保证较高的选择性，同时又不能太长（以便节约空间）。前缀应该足够长，以使得前缀索引的选择性接近于索引的整个列。</p><p>换句话说，<code>前缀的”基数“应该接近于完整的列的”基数“</code>。</p><p>【注意】前缀索引只能作用在普通索引上 不能作用在唯一索引上</p><p>那就是计算完整列的选择性，并使其前缀的选择性接近于完整列的选择性。下面显示如何计算完整列的选择性：</p><pre><code class="mysql">mysql&gt; select count(distinct city) / count(*) from city_demo;+---------------------------------+| count(distinct city) / count(*) |+---------------------------------+|                          0.4283 |+---------------------------------+1 row in set (0.05 sec)</code></pre><p>可以在一个查询中针对不同前缀长度的选择性进行计算，这对于大表非常有用，下面给出如何在同一个查询中计算不同前缀长度的选择性：</p><pre><code class="mysql">mysql&gt; select count(distinct left(city,3))/count(*) as sel3,    -&gt; count(distinct left(city,4))/count(*) as sel4,    -&gt; count(distinct left(city,5))/count(*) as sel5,     -&gt; count(distinct left(city,6))/count(*) as sel6     -&gt; from city_demo;+--------+--------+--------+--------+| sel3   | sel4   | sel5   | sel6   |+--------+--------+--------+--------+| 0.3367 | 0.4075 | 0.4208 | 0.4267 |+--------+--------+--------+--------+1 row in set (0.01 sec)</code></pre><p>可以看见当索引前缀为6时的基数是0.4267，已经接近完整列选择性0.4283。</p><p>在上面的示例中，已经找到了合适的前缀长度，下面创建前缀索引：</p><pre><code class="mysql">mysql&gt; alter table city_demo add key (city(6));Query OK, 0 rows affected (0.19 sec)Records: 0  Duplicates: 0  Warnings: 0</code></pre><p>前缀索引是一种能使索引更小，更快的有效办法，但另一方面也有其<code>缺点</code>：</p><ul><li>mysql无法使用其前缀索引做ORDER BY和GROUP BY</li><li>无法使用前缀索引做覆盖扫描。</li></ul><h3 id="6-5-5-多列索引"><a href="#6-5-5-多列索引" class="headerlink" title="6.5.5 多列索引"></a>6.5.5 多列索引</h3><p>指多个字段上创建的索引，只有在查询条件中使用了创建索引时的第一个字段，索引才会被使用。使用组合索引时遵循最左前缀集合。</p><p>关键字及创建方式:</p><pre><code class="mysql">ALTER TABLE table ADD INDEX name_city_age (name,city,age);</code></pre><p>联合索引在内部的结构图如下图所示:</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/unionindex.png" alt=""></p><p>对于联合索引（a,b），where a =xxx and b =xxx，和where a=xxx 可以使用此联合索引，但是对于where b = xxx不能使用，因为b列数据在此联合索引上不是有序的。具体的索引是否生效会在以后章节介绍。</p><h2 id="6-6-覆盖索引"><a href="#6-6-覆盖索引" class="headerlink" title="6.6 覆盖索引"></a>6.6 覆盖索引</h2><h3 id="6-6-1-定义"><a href="#6-6-1-定义" class="headerlink" title="6.6.1 定义"></a>6.6.1 定义</h3><p>SQL只需要通过索引就可以返回查询所需要的数据，而不必通过二级索引查到主键之后再去查询数据。</p><p>这样可以减少大量的IO操作,无需进行回表操作。</p><h3 id="6-6-2-判断标准"><a href="#6-6-2-判断标准" class="headerlink" title="6.6.2 判断标准"></a>6.6.2 判断标准</h3><p>使用explain，可以通过输出的extra列来判断，对于一个索引覆盖查询，显示为<code>using index</code>,MySQL查询优化器在执行查询前会决定是否有索引覆盖查询</p><h3 id="6-6-3-优点"><a href="#6-6-3-优点" class="headerlink" title="6.6.3 优点"></a>6.6.3 优点</h3><p>覆盖索引是一种非常强大的工具，能大大提高查询性能，只需要读取索引而不用读取数据有以下一些优点<br>1、索引项通常比记录要小，所以MySQL访问更少的数据<br>2、索引都按值的大小顺序存储，相对于随机访问记录，需要更少的I/O<br>3、大多数据引擎能更好的缓存索引，比如MyISAM只缓存索引<br>4、覆盖索引对于InnoDB表尤其有用，因为InnoDB使用聚集索引组织数据，如果二级索引中包含查询所需的数据，就不再需要在聚集索引中查找了</p><h2 id="6-7-索引管理"><a href="#6-7-索引管理" class="headerlink" title="6.7 索引管理"></a>6.7 索引管理</h2><p>我们可以通过<code>SHOW INDEX FROM table</code>查看表的索引情况</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/showindex.png" alt=""></p><p>具体每个字段的含义如下:</p><p>下面我们一起了解下返回的这张表的含义：</p><ol><li>Table: 表名</li><li>Non_unique: 如果索引不能包括重复值则为0，如果可以则为1。也就是平时所说的唯一索引。</li><li>Key_name 索引名称，如果名字相同则表明是同一个索引，而并不是重复，比如上图中的而三条数据，其实是一个联合索引。</li><li>Seq_in_index 索引中的列序列号，从1开始。上图中的二、三数据，Seq_in_index一个是1一个是2，就是表明在联合索引中的顺序，我们就能推断出联合索引中索引的前后顺序。</li><li>Column_name 索引的列名。</li><li>Collation指的是列以什么方式存储在索引中，可是A或NULL,Btree总是A,即排序的。</li><li>Cardinality 是基数的意思，表示索引中唯一值的数目的估计值。我们知道某个字段的重复值越少越适合建索引，所以我们一般都是根据Cardinality来判断索引是否具有高选择性，如果这个值非常小，那就需要重新评估这个字段是否适合建立索引。</li><li>Sub_part 前置索引的意思，如果列只是被部分地编入索引，则为被编入索引的字符的数目。如果整列被编入索引，则为NULL。</li><li>Packed 指示关键字如何被压缩。如果没有被压缩，则为NULL。压缩一般包括压缩传输协议、压缩列解决方案和压缩表解决方案。</li><li>.Null 如果列含有NULL，则含有YES。</li><li>.Index_type表示索引类型，Mysql目前主要有以下几种索引类型：FULLTEXT，HASH，BTREE，RTREE。</li><li>.Comment Index_comment 注释的意思。</li></ol><h3 id="6-7-1-什么是Cardinality"><a href="#6-7-1-什么是Cardinality" class="headerlink" title="6.7.1 什么是Cardinality"></a>6.7.1 什么是Cardinality</h3><p>不是所有的查询条件出现的列都需要添加索引。对于什么时候添加B+树索引。一般的经验是，在访问表中很少一部分时使用B+树索引才有意义。对于性别字段、地区字段、类型字段，他们可取值范围很小，称为低选择性。如</p><pre><code class="mysql">SELECT * FROM student WHERE sex=&#39;M&#39;</code></pre><p>按性别进行查询时，可取值一般只有M、F。</p><p>因此SQL语句得到的结果可能是该表50%的数据(加入男女比例1:1)这时添加B+树索引是完全没有必要的。</p><p>相反，如果某个字段的取值范围很广，几乎没有重复，属于高选择性。则此时使用B+树的索引是最合适的。</p><p>例如对于姓名字段，基本上在一个应用中不允许重名的出现</p><h3 id="6-7-2-查看高选择性"><a href="#6-7-2-查看高选择性" class="headerlink" title="6.7.2 查看高选择性"></a>6.7.2 查看高选择性</h3><p>怎样查看索引是否有高选择性？通过SHOW INDEX结果中的列Cardinality来观察。非常关键，表示所以中不重复记录的预估值，需要注意的是Cardinality是一个预估值，而不是一个准确值基本上用户也不可能得到一个准确的值</p><p>在实际应用中，<code>Cardinality/n_row_in_table应尽可能的接近1</code>，如果非常小,那用户需要考虑是否还有必要创建这个索引。故在访问高选择性属性的字段并从表中取出很少一部分数据时，对于字段添加B+树索引是非常有必要的。如</p><pre><code class="mysql">SELECT * FROM member WHERE usernick=&#39;David&#39;;</code></pre><p>表member大约有500W行数据,usernick字段上有一个唯一索引。这也符号提到的高选择性</p><h3 id="6-7-3-Cardinality统计"><a href="#6-7-3-Cardinality统计" class="headerlink" title="6.7.3 Cardinality统计"></a>6.7.3 Cardinality统计</h3><p>Cardinality统计时放在存储引擎层进行的</p><p>在生成环境中，索引的更新操作可能非常频繁。如果每次索引在发生操作时就对其进行Cardinality统计，那么将会对数据库带来很大的负担。另外需要考虑的是，如果一张表的数据非常大，如一张表有50G的数据，那么统计一次Cardinality信息所需要的时间可能非常长。这样的环境下，是不能接受的。因此，数据库对于Cardinality信息的统计都是通过采样的方法完成</p><p>在InnoDB存储引擎中，Cardinality统计信息的更新发生在两个操作中：insert和update。InnoDB存储引擎内部对更新Cardinality信息的策略为:</p><ul><li>表中1/16的数据已发生了改变</li><li>stat_modified_counter&gt;2000 000 000</li></ul><p>接着考虑InnoDB存储引擎内部是怎样进行Cardinality信息统计和更新操作呢？同样是通过采样的方法。默认的InnoDB存储引擎对8个叶子节点Leaf Page进行采用。采用过程如下</p><ol><li>取得B+树索引中叶子节点的数量，记为A</li><li>随机取得B+树索引中的8个叶子节点，统计每个页不同记录的个数，即为P1，P2….P8</li><li>通过采样信息给出Cardinality的预估值:Cardinality=(P1+P2+…+P8)*A/8</li></ol><p>根据上述的说明可以发现，在InnoDB存储引擎中，Cardinality值通过对8个叶子节点预估而得的。而<code>不是一个实际精确的值</code>。再者，每次对Cardinality值的统计，都是通过随机取8个叶子节点得到的，这同时有暗示了另外一个Cardinality现象，即每次得到的Cardinality值可能不同的;</p><p>当然，有一种情况可以使得用户每次观察到的索引Cardinality值是一样的。那就是表足够小，表的叶子节点树小于或者等于8个</p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> Mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>5.MysqlSQL基础</title>
      <link href="/2020/02/15/5-MysqlSQL%E5%9F%BA%E7%A1%80/"/>
      <url>/2020/02/15/5-MysqlSQL%E5%9F%BA%E7%A1%80/</url>
      
        <content type="html"><![CDATA[<h2 id="5-1-常用数据类型"><a href="#5-1-常用数据类型" class="headerlink" title="5.1 常用数据类型"></a>5.1 常用数据类型</h2><h3 id="5-1-1-整型"><a href="#5-1-1-整型" class="headerlink" title="5.1.1 整型"></a>5.1.1 整型</h3><table><thead><tr><th align="center">类型</th><th align="center">字节</th><th align="center">范围(有符号位)</th></tr></thead><tbody><tr><td align="center">TINYINT</td><td align="center">1Byte</td><td align="center">0~2^8 OR  -2^7 ~ 2^7-1</td></tr><tr><td align="center">INT</td><td align="center">4Byte</td><td align="center">0~2^32 OR  -2^31 ~ 2^31-1</td></tr><tr><td align="center">BIGINT</td><td align="center">8Byte</td><td align="center">0~2^64 OR -2^63 ~ 2^63-1</td></tr></tbody></table><ul><li>int(M)  M表示总位数<ul><li>如果某个数不够定义字段时设置的位数，则前面以0补填，zerofill 属性修改</li><li>例：int(5)   插入一个数’123’，补填后为’00123’</li></ul></li><li>默认存在符号位，unsigned 属性修改</li><li>在满足要求的情况下，越小越好</li><li>1表示bool值真，0表示bool值假。MySQL没有布尔类型，通过整型0和1表示。常用tinyint(1)表示布尔型</li></ul><h3 id="5-1-2-小数"><a href="#5-1-2-小数" class="headerlink" title="5.1.2 小数"></a>5.1.2 小数</h3><table><thead><tr><th align="center">类型</th><th align="center">字节</th><th align="center">范围(有符号位)</th></tr></thead><tbody><tr><td align="center">float(单精度)</td><td align="center">4Byte</td><td align="center">自定义，表示近似值</td></tr><tr><td align="center">double(双精度)</td><td align="center">8Byte</td><td align="center">自定义，表示近似值</td></tr><tr><td align="center">decimal</td><td align="center">自定义</td><td align="center">自定义,表示精确数值</td></tr></tbody></table><ul><li><p>浮点型既支持符号位 unsigned 属性，也支持显示宽度 zerofill 属性，不同于整型，前后均会补填0</p></li><li><p>支持科学计数法表示。</p></li><li><p>定义浮点型时，需指定总位数和小数位数。</p><blockquote><p>float(M, D)     double(M, D)</p><p>M表示总位数，D表示小数位数</p><p>M和D的大小会决定浮点数的范围 不同于整型的固定范围</p><p>M既表示总位数（不包括小数点和正负号），也表示显示宽度（所有显示符号均包括）</p><p>decimal(M, D)   M也表示总位数，D表示小数位数</p><p>保存一个精确的数值，不会发生数据的改变，不同于浮点数的四舍五入<br>将浮点数转换为字符串来保存，每9位数字保存为4个字节</p></blockquote></li></ul><h3 id="5-1-3-字符"><a href="#5-1-3-字符" class="headerlink" title="5.1.3 字符"></a>5.1.3 字符</h3><table><thead><tr><th align="center">类型</th><th align="left">说明</th></tr></thead><tbody><tr><td align="center">CHAR</td><td align="left">定长字符串最多255个字符</td></tr><tr><td align="center">VARCHAR</td><td align="left">变长字符串最多65535个字符</td></tr><tr><td align="center">TEXT</td><td align="left">变长字符串最多65535个字符类型，在定义时,不需要定义长度<br/>也不会计算总长度不可给default值</td></tr><tr><td align="center">BLOB</td><td align="left">二进制字符串（字节字符串）</td></tr><tr><td align="center">ENUM</td><td align="left">枚举类型 smallint 存储</td></tr><tr><td align="center">SET</td><td align="left">集合类型 bigint存储</td></tr></tbody></table><pre><code>char(11) ：定长字符串类型,在存储字符串时，最大字符长度11个，立即分配11个字符长度的存储空间，如果存不满，空格填充varchar(11):变长的字符串类型看，最大字符长度11个。在存储字符串时，自动判断字符长度，按需分配存储空间。M表示能存储的最大长度，此长度是字符数，非字节数。不同的编码，所占用的空间不同。char,最多255个字符，与编码无关。varchar,最多65535字符，与编码有关。一条有效记录最大不能超过65535个字节。utf8 最大为21844个字符，gbk 最大为32766个字符，latin1 最大为65532个字符【注】varchar 是变长的，需要利用存储空间保存 varchar 的长度，如果数据小于255个字节，则采用一个字节来保存长度，反之需要两个字节来保存。varchar 的最大有效长度由最大行大小和使用的字符集确定。最大有效长度是65532字节，因为在varchar存字符串时，第一个字节是空的，不存在任何数据，然后还需两个字节来存放字符串的长度，所以有效长度是64432-1-2=65532字节。例：若一个表定义为 CREATE TABLE tb(c1 int, c2 char(30), c3 varchar(N)) charset=utf8; 问N的最大值是多少？答：(65535-1-2-4-30*3)/3</code></pre><pre><code>枚举类型说明enum(val1, val2, val3...)在已知的值中进行单选。最大数量为65535.枚举值在保存时，以2个字节的整型(smallint)保存。每个枚举值，按保存的位置顺序，从1开始逐一递增。表现为字符串类型，存储却是整型。NULL值的索引是NULL。空字符串错误值的索引值是0枚举类型，比较适合于将来此列的值是固定范围内的特点，可以使用enum,可以很大程度的优化我们的索引结构</code></pre><pre><code class="mysql">集合类型说明set(val1, val2, val3...)create table tab ( gender set(&#39;男&#39;, &#39;女&#39;, &#39;无&#39;) );insert into tab values (&#39;男, 女&#39;);最多可以有64个不同的成员。以bigint存储，共8个字节。采取位运算的形式当创建表时，SET成员值的尾部空格将自动被删除</code></pre><h3 id="5-1-4-时间"><a href="#5-1-4-时间" class="headerlink" title="5.1.4 时间"></a>5.1.4 时间</h3><table><thead><tr><th align="center">类型</th><th align="center">字节</th><th align="center">说明</th><th align="center">范围</th></tr></thead><tbody><tr><td align="center">datetime</td><td align="center">8Byte</td><td align="center">日期及时间</td><td align="center">1000-01-01 00:00:00 到 9999-12-31 23:59:59</td></tr><tr><td align="center">date</td><td align="center">3Byte</td><td align="center">日期</td><td align="center">1000-01-01 到 9999-12-31</td></tr><tr><td align="center">timestamp</td><td align="center">4Byte</td><td align="center">时间戳</td><td align="center">19700101000000 到 2038-01-19 03:14:07</td></tr><tr><td align="center">time</td><td align="center">3Byte</td><td align="center">时间</td><td align="center">-838:59:59 到 838:59:59</td></tr><tr><td align="center">year</td><td align="center">1Byte</td><td align="center">年份</td><td align="center">1901 - 2155</td></tr></tbody></table><h2 id="5-2-列属性"><a href="#5-2-列属性" class="headerlink" title="5.2 列属性"></a>5.2 列属性</h2><h3 id="5-2-1-PRIMARY"><a href="#5-2-1-PRIMARY" class="headerlink" title="5.2.1 PRIMARY"></a>5.2.1 PRIMARY</h3><ul><li>能唯一标识记录的字段，可以作为主键。</li><li>一个表只能有一个主键。</li><li>主键具有唯一性。</li><li>声明字段时，用 primary key 标识。</li><li>也可以在字段列表之后声明：create table tab ( id int, stu varchar(10), primary key (id));</li><li>主键字段的值不能为null。</li><li>主键可以由多个字段共同组成。此时需要在字段列表后声明的方法。<br>  例：create table tab ( id int, stu varchar(10), age int, primary key (stu, age));</li></ul><h3 id="5-2-2-UNIQUE"><a href="#5-2-2-UNIQUE" class="headerlink" title="5.2.2 UNIQUE"></a>5.2.2 UNIQUE</h3><p>唯一索引,使得某字段的值也不能重复。</p><h3 id="5-2-3-NULL"><a href="#5-2-3-NULL" class="headerlink" title="5.2.3 NULL"></a>5.2.3 NULL</h3><ul><li>null不是数据类型，是列的一个属性。</li><li>表示当前列是否可以为null，表示什么都没有。</li><li>null, 允许为空。默认；not null, 不允许为空。</li><li>insert into tab values (null, ‘val’); – 此时表示将第一个字段的值设为null, 取决于该字段是否允许为null</li></ul><h3 id="5-2-4-DEFAULT"><a href="#5-2-4-DEFAULT" class="headerlink" title="5.2.4 DEFAULT"></a>5.2.4 DEFAULT</h3><ul><li>当前字段的默认值。<pre><code class="mysql">#表示强制使用默认值insert into tab values (default, &#39;val&#39;);#表示将当前时间的时间戳 设为默认值create table tab ( add_time timestamp default current_timestamp )</code></pre></li></ul><h3 id="5-2-5-AUTO-INCREMENT"><a href="#5-2-5-AUTO-INCREMENT" class="headerlink" title="5.2.5 AUTO_INCREMENT"></a>5.2.5 AUTO_INCREMENT</h3><ul><li>自动增长约束</li><li>自动增长必须为索引（主键或unique）</li><li>只能存在一个字段为自动增长。</li><li>默认为1开始自动增长。可以通过表属性 auto_increment = x进行设置，或 alter table tbl auto_increment = x;</li></ul><h3 id="5-2-6-COMMENT"><a href="#5-2-6-COMMENT" class="headerlink" title="5.2.6 COMMENT"></a>5.2.6 COMMENT</h3><p>注释<br>例：create table tab ( id int ) comment ‘注释内容’;</p><h3 id="5-2-7-FOREIGN-KEY"><a href="#5-2-7-FOREIGN-KEY" class="headerlink" title="5.2.7 FOREIGN KEY"></a>5.2.7 FOREIGN KEY</h3><p>外键约束 高并发下不建议使用 ERP中常用</p><h2 id="5-3-表属性"><a href="#5-3-表属性" class="headerlink" title="5.3 表属性"></a>5.3 表属性</h2><h3 id="5-3-1-engine"><a href="#5-3-1-engine" class="headerlink" title="5.3.1 engine"></a>5.3.1 engine</h3><p>使用的存储引擎 建议都是用Innodb</p><h3 id="5-3-2-charset"><a href="#5-3-2-charset" class="headerlink" title="5.3.2 charset"></a>5.3.2 charset</h3><p>使用的字符集 这个参数也可以在列属性里设置,但是不建议这样做,整表设置相同字符集即可</p><p>常用的有:</p><ul><li>utf8 推荐使用** </li><li>utf8mb4 推荐使用***</li><li>gbk</li></ul><p>建议默认使用utf8mb4格式:</p><blockquote><p>MySQL在5.5.3之后增加了utf8mb4的编码，mb4即4-Byte UTF-8 Unicode Encoding，专门用来兼容四字节的unicode。utf8mb4为utf8的超集并兼容utf8，比utf8能表示更多的字符。</p><p>低版本的MySQL支持的utf8编码，最大字符长度为 3 字节，如果遇到 4 字节的字符就会出现错误了。</p><p>常见的四字节就是Emoji 表情（Emoji 是一种特殊的 Unicode 编码，常见于 ios 和 android 手机上），和一些不常用的汉字，以及任何新增的 Unicode 字符等等。</p></blockquote><h2 id="5-4-常用SQL分类"><a href="#5-4-常用SQL分类" class="headerlink" title="5.4 常用SQL分类"></a>5.4 常用SQL分类</h2><ul><li>DDL：数据定义语言</li><li>DML：数据操作语言</li><li>DCL：数据控制语言</li><li>DQL：数据的查询语言</li></ul><h2 id="5-5-DDL语句"><a href="#5-5-DDL语句" class="headerlink" title="5.5 DDL语句"></a>5.5 DDL语句</h2><h3 id="5-5-1-数据库操作"><a href="#5-5-1-数据库操作" class="headerlink" title="5.5.1 数据库操作"></a>5.5.1 数据库操作</h3><pre><code class="mysql"># 创建demo数据库mysql&gt; create database demo charset utf8mb4mysql&gt; create database if not exists demo charset utf8mb4;# 删除demo数据库mysql&gt; drop database demo;mysql&gt; drop database if exists demo;# 修改database字符集mysql&gt; alter database demo charset=utf8;</code></pre><h3 id="5-5-2-表操作"><a href="#5-5-2-表操作" class="headerlink" title="5.5.2 表操作"></a>5.5.2 表操作</h3><pre><code class="mysql"># 创建表CREATE TABLE `t_scrm_user_info`(  `id`          INT(10) UNSIGNED NOT NULL AUTO_INCREMENT,  `user_id`     VARCHAR(32)      NOT NULL COMMENT &#39;用户ID作为唯一标示&#39;,  `user_name`   VARCHAR(32)      NOT NULL DEFAULT &#39;&#39; COMMENT &#39;用户姓名&#39;,  `user_sex`    TINYINT(3)       NOT NULL DEFAULT 0 COMMENT &#39;用户性别 0未知 1男 2女&#39;,  `user_mobile` VARCHAR(16)      NOT NULL DEFAULT &#39;&#39; COMMENT &#39;用户手机号&#39;,  `user_status` TINYINT(3)       NOT NULL DEFAULT 0 COMMENT &#39;用户状态 0正常 1锁定 -1删除&#39;,  `user_avatar` varchar(256)     NOT NULL DEFAULT &#39;&#39; COMMENT &#39;用户头像&#39;,  `create_time` DATETIME         NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#39;创建时间&#39;,  PRIMARY KEY (`id`),  UNIQUE KEY `UQ_USER_ID` (`user_id`)) ENGINE = InnoDB  DEFAULT CHARSET = utf8mb4 COMMENT =&#39;用户信息表&#39;;# 删除表mysql&gt; drop table t_scrm_user_info;# 重命名表mysql&gt; RENAME TABLE t_scrm_user_info to demo;# 复制表mysql&gt; CREATE table t_scrm_user_info like demo;# 清空表mysql&gt; truncate table t_scrm_user_info;# 添加列——添加update_time列ALTER TABLE t_scrm_user_info ADD update_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT &#39;更新时间&#39;;# 添加列——在user_avatar列后添加user_remark列ALTER TABLE t_scrm_user_info ADD `user_remark` VARCHAR(128) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;用户备注&#39; AFTER user_avatar;# 更新列mysql&gt; ALTER TABLE t_scrm_user_info MODIFY user_name VARCHAR(64);注意上面语句更新的时候 会把user_name列上的其他属性更新没 如not null属性和comment属性所以建议写成如下：mysql&gt; ALTER TABLE t_scrm_user_info MODIFY user_name VARCHAR(32)      NOT NULL DEFAULT &#39;&#39; COMMENT &#39;用户姓名&#39;;# 更新列名mysql&gt; ALTER TABLE t_scrm_user_info CHANGE user_name u_name VARCHAR(32)      NOT NULL DEFAULT &#39;&#39; COMMENT &#39;用户姓名&#39;;# 删除列ALTER TABLE t_scrm_user_info DROP user_avatar;#添加索引ALTER TABLE tbl_name ADD INDEX index_name (column_list): 添加普通索引，索引值可出现多次。#删除索引DROP INDEX [indexName] ON mytable;</code></pre><h2 id="5-6-DML语句"><a href="#5-6-DML语句" class="headerlink" title="5.6 DML语句"></a>5.6 DML语句</h2><pre><code class="mysql"># 插入INSERT INTO t_scrm_user_info(user_id,user_name,user_sex,user_mobile,user_status) VALUES(&quot;123&quot;,&#39;nihao&#39;,1,&#39;18611111111&#39;,&#39;0&#39;),(&quot;345&quot;,&#39;hahah&#39;,1,&#39;18611111111&#39;,&#39;0&#39;);# 更新UPDATE t_scrm_user_info set user_id=&quot;444&quot; WHERE user_id=&quot;123&quot;;# 删除mysql&gt; DELETE FROM t_scrm_user_info where user_id =&quot;444&quot;;# 全表删除mysql&gt; DELETE FROM t_scrm_user_info;与truncate区别delete:         DML操作, 是逻辑性质删除,逐行进行删除,速度慢. 还在文件里 文件大小不会改变        主键继续原来的增长计数truncate:         DDL操作,对与表段中的数据页进行清空,速度快. 从文件里删除 文件大小改变        主键从1开始计数</code></pre><h2 id="5-7-DCL语句"><a href="#5-7-DCL语句" class="headerlink" title="5.7 DCL语句"></a>5.7 DCL语句</h2><pre><code class="mysql"># 管理用户通配符：%表示可以在任意主机使用用户登录数据库【注意】在mysql里面用户的定义为:用户名+主机名【注意】在mysql8.0中添加用户和授权必须是两步进行 不能用一条语句# 添加用户mysql&gt; CREATE USER &#39;read&#39;@&#39;10.15.2.%&#39; identified by &#39;123&#39;;# 删除用户mysql&gt; DROP USER &#39;read&#39;@&#39;10.15.2.%&#39;;#修改用户密码mysql&gt; set password for &#39;read&#39;@&#39;10.15.2.%&#39; = password(&#39;456&#39;);# 授权# 查看授权mysql&gt; show grants for &#39;read&#39;@&#39;10.15.2.%&#39;;+------------------------------------------+| Grants for read@10.15.2.%                |+------------------------------------------+| GRANT USAGE ON *.* TO &#39;read&#39;@&#39;10.15.2.%&#39; |+------------------------------------------+1 row in set (0.00 sec)# 添加授权grant 权限列表 on 数据库.表名  to  &#39;用户名&#39;@&#39;主机名&#39;;mysql&gt; GRANT CREATE,ALTER,DROP,INSERT,UPDATE,DELETE,SELECT ON demo.* TO &#39;read&#39;@&#39;10.15.2.%&#39;;# 授权所有权限mysql&gt; grant all privileges on demo.* to &#39;read&#39;@&#39;10.15.2.%&#39;;# 删除授权revoke 权限列表  on  数据库.表名  from  &#39;用户名&#39;@&#39;主机名&#39;;mysql&gt; revoke DROP,DELETE  on  demo.* from &#39;read&#39;@&#39;10.15.2.%&#39;;# 让授权生效FLUSH PRIVILEGES;</code></pre><h2 id="5-8-DQL语句"><a href="#5-8-DQL语句" class="headerlink" title="5.8 DQL语句"></a>5.8 DQL语句</h2><h3 id="5-8-1-SELECT"><a href="#5-8-1-SELECT" class="headerlink" title="5.8.1 SELECT"></a>5.8.1 SELECT</h3><pre><code class="mysql">SELECT [ALL|DISTINCT] select_expr FROM -&gt; WHERE -&gt; GROUP BY [合计函数] -&gt; HAVING -&gt; ORDER BY -&gt; LIMITa. select_expr    -- 可以用 * 表示所有字段。        select * from tb;    -- 可以使用表达式（计算公式、函数调用、字段也是个表达式）        select stu, 29+25, now() from tb;    -- 可以为每个列使用别名。适用于简化列标识，避免多个列标识符重复。        - 使用 as 关键字，也可省略 as.        select stu+10 as add10 from tb;b. FROM 子句    用于标识查询来源。    -- 可以为表起别名。使用as关键字。        SELECT * FROM tb1 AS tt, tb2 AS bb;    -- from子句后，可以同时出现多个表。        -- 多个表会横向叠加到一起，而数据会形成一个笛卡尔积。        SELECT * FROM tb1, tb2;    -- 向优化符提示如何选择索引        USE INDEX、IGNORE INDEX、FORCE INDEX        SELECT * FROM table1 USE INDEX (key1,key2) WHERE key1=1 AND key2=2 AND key3=3;        SELECT * FROM table1 IGNORE INDEX (key3) WHERE key1=1 AND key2=2 AND key3=3;c. WHERE 子句    -- 从from获得的数据源中进行筛选。    -- 整型1表示真，0表示假。    -- 表达式由运算符和运算数组成。        -- 运算数：变量（字段）、值、函数返回值        -- 运算符：            =, &lt;=&gt;, &lt;&gt;, !=, &lt;=, &lt;, &gt;=, &gt;, !, &amp;&amp;, ||,            in (not) null, (not) like, (not) in, (not) between and, is (not), and, or, not, xor            is/is not 加上ture/false/unknown，检验某个值的真假            &lt;=&gt;与&lt;&gt;功能相同，&lt;=&gt;可用于null比较d. GROUP BY 子句, 分组子句    GROUP BY 字段/别名 [排序方式]    分组后会进行排序。升序：ASC，降序：DESC    以下[合计函数]需配合 GROUP BY 使用：    count 返回不同的非NULL值数目  count(*)、count(字段)    sum 求和    max 求最大值    min 求最小值    avg 求平均值    group_concat 返回带有来自一个组的连接的非NULL值的字符串结果。组内字符串连接。e. HAVING 子句，条件子句    与 where 功能、用法相同，执行时机不同。    where 在开始时执行检测数据，对原数据进行过滤。    having 对筛选出的结果再次进行过滤。    having 字段必须是查询出来的，where 字段必须是数据表存在的。    where 不可以使用字段的别名，having 可以。因为执行WHERE代码时，可能尚未确定列值。    where 不可以使用合计函数。一般需用合计函数才会用 having    SQL标准要求HAVING必须引用GROUP BY子句中的列或用于合计函数中的列。f. ORDER BY 子句，排序子句    order by 排序字段/别名 排序方式 [,排序字段/别名 排序方式]...    升序：ASC，降序：DESC    支持多个字段的排序。g. LIMIT 子句，限制结果数量子句    仅对处理好的结果进行数量限制。将处理好的结果的看作是一个集合，按照记录出现的顺序，索引从0开始。    limit 起始位置, 获取条数    省略第一个参数，表示从索引0开始。limit 获取条数h. DISTINCT, ALL 选项    distinct 去除重复记录    默认为 all, 全部记录</code></pre><h3 id="5-8-2-多表查询"><a href="#5-8-2-多表查询" class="headerlink" title="5.8.2 多表查询"></a>5.8.2 多表查询</h3><p>多表查询使用join关键字进行连接</p><p>连接方式分为四种:</p><ul><li>INNER JOIN：如果表中有至少一个匹配，则返回行</li><li>LEFT JOIN：即使右表中没有匹配，也从左表返回所有的行</li><li>RIGHT JOIN：即使左表中没有匹配，也从右表返回所有的行</li><li>FULL JOIN：只要其中一个表中存在匹配，则返回行</li></ul><p>这里不详细介绍 看图理解</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/sql-join.png" alt=""></p><p>也可参考此篇<a href="https://www.runoob.com/sql/sql-join.html" target="_blank" rel="noopener">文档</a></p><h3 id="5-8-3-SHOW"><a href="#5-8-3-SHOW" class="headerlink" title="5.8.3 SHOW"></a>5.8.3 SHOW</h3><pre><code class="mysql">show  databases;                          #查看所有数据库show tables;                              #查看当前库的所有表SHOW TABLES FROM                          #查看某个指定库下的表show create database world                #查看建库语句show create table world.city              #查看建表语句show  grants for  root@&#39;localhost&#39;        #查看用户的权限信息show  charset；                            #查看字符集show collation                             #查看校对规则show processlist;                          #查看数据库连接情况show index from                            #表的索引情况show status                                 #数据库状态查看SHOW STATUS LIKE &#39;%lock%&#39;;                 #模糊查询数据库某些状态SHOW VARIABLES                             #查看所有配置信息SHOW variables LIKE &#39;%lock%&#39;;              #查看部分配置信息show engines                                #查看支持的所有的存储引擎show engine innodb status                  #查看InnoDB引擎相关的状态信息show binary logs                            #列举所有的二进制日志show master status                           #查看数据库的日志位置信息show binlog events;                          #查看二进制日志事件show slave status                           #查看从库状态SHOW RELAYLOG EVENTS                        #查看从库relaylog事件信息desc  (show colums from city)               #查看表的列定义信息</code></pre><h3 id="5-8-4其它关键字"><a href="#5-8-4其它关键字" class="headerlink" title="5.8.4其它关键字"></a>5.8.4其它关键字</h3><pre><code class="mysql"># distinct：去重复SELECT countrycode FROM city ;SELECT DISTINCT(countrycode) FROM city  ;# 联合查询- union allSELECT * FROM city WHERE countrycode IN (&#39;CHN&#39; ,&#39;USA&#39;);SELECT * FROM city WHERE countrycode=&#39;CHN&#39;UNION ALLSELECT * FROM city WHERE countrycode=&#39;USA&#39;# 联合查询- union SELECT * FROM city WHERE countrycode=&#39;CHN&#39;UNION SELECT * FROM city WHERE countrycode=&#39;USA&#39;说明:一般情况下,我们会将 IN 或者 OR 语句 改写成 UNION (ALL),来提高性能UNION     去重复UNION ALL 不去重复</code></pre>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> Mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>4.MySQL体系结构</title>
      <link href="/2020/02/15/4-Mysql%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/"/>
      <url>/2020/02/15/4-Mysql%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/</url>
      
        <content type="html"><![CDATA[<h2 id="4-1-Mysql整体结构图"><a href="#4-1-Mysql整体结构图" class="headerlink" title="4. 1 Mysql整体结构图"></a>4. 1 Mysql整体结构图</h2><p>下图是Mysql官方给出的结构图:</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/Mysql%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84.png" alt="Mysql体系结构"></p><p>从上图可以发现Mysql由以下几部分组成</p><ul><li>客户端</li><li>连接层</li><li>SQL层</li><li>存储引擎层</li><li>文件系统</li><li>服务管理(非必须)</li></ul><h3 id="4-1-1-客户端"><a href="#4-1-1-客户端" class="headerlink" title="4.1.1 客户端"></a>4.1.1 客户端</h3><p>即Mysql提供给不同语言的API链接方式,支持的语言有很过Go,PHP,Java等等 没啥好说的哈</p><h3 id="4-1-2-连接层"><a href="#4-1-2-连接层" class="headerlink" title="4.1.2 连接层"></a>4.1.2 连接层</h3><p>主要负责以下功能:</p><ul><li>提供链接协议,两种: <code>socket连接&amp;TCP/IP连接</code></li><li>授权认证</li><li>提供专用的连接线程</li><li>最大连接数限制</li></ul><h3 id="4-1-3-SQL层"><a href="#4-1-3-SQL层" class="headerlink" title="4.1.3  SQL层"></a>4.1.3  SQL层</h3><p>主要负责以下功能:</p><ul><li>SQL语法检查</li><li>语义检查(DML,DCL,DQL,DTL)</li><li>权限判断</li><li>解析器:解析预处理,执行计划(是全表扫描还是走哪个索引)</li><li>优化分析器:帮我们选择最优的方案</li><li>执行器:执行SQL语句</li><li>查询缓存(QC)<ul><li>【注】这个不要开启,在许多情况下它会失效并且会拉低数据库性能</li><li>可以使用Redis来替代</li></ul></li></ul><h3 id="4-1-4-存储引擎层"><a href="#4-1-4-存储引擎层" class="headerlink" title="4.1.4 存储引擎层"></a>4.1.4 存储引擎层</h3><p>提供不同的存储引擎以供选择,类似于Linux的文件系统,和磁盘模块进行数据交互</p><p>我们可以通过show engine指令查看目前数据库支持的存储引擎</p><pre><code>[root@centos7-1 3306]# mysql -e&#39;show engines&#39;|awk &#39;{print $1}&#39;EngineCSVMRG_MYISAMMyISAM        ***BLACKHOLEPERFORMANCE_SCHEMAMEMORY          ARCHIVEInnoDB          *****FEDERATED</code></pre><p>经常提到的存储引擎有两个:</p><ul><li>InnoDB</li><li>MyISAM</li></ul><p>在早期使用的默认存储引擎为MyISAM,目前默认都是用InnoDB,他们之间的区别稍后会在存储引擎一篇中详细介绍</p><h3 id="4-1-5-文件系统"><a href="#4-1-5-文件系统" class="headerlink" title="4.1.5 文件系统"></a>4.1.5 文件系统</h3><p>用于存储数据文件和不同类型的日志</p><h2 id="4-2-MySQL文件结构"><a href="#4-2-MySQL文件结构" class="headerlink" title="4.2 MySQL文件结构"></a>4.2 MySQL文件结构</h2><p>目前我们的Mysql数据库下有以下几个库:</p><pre><code>mysql&gt; show databases;+--------------------+| Database           |+--------------------+| information_schema || baseinfo           || mysql              || performance_schema || sys                || test               |+--------------------+6 rows in set (0.00 sec)</code></pre><p>我们查看MySQL的数据存储文件夹下会看到如下文件:</p><pre><code>[root@centos7-1 3306]# tree -L 1.├── auto.cnf├── baseinfo├── centos7-1.err├── centos7-1.pid├── ib_buffer_pool├── ibdata1├── ib_logfile0├── ib_logfile1├── ibtmp1├── mysql├── performance_schema├── sys└── test</code></pre><p>意义如下:</p><pre><code>[root@centos7-1 3306]# tree -L 1.├── auto.cnf               #Mysql自动生成的一些配置文件├── baseinfo            #baseinfo库里的文件【自建库】├── centos7-1.err       #数据库错误日志 命名方式为 主机名+“.err”├── centos7-1.pid       #数据里的进程id文件├── ib_buffer_pool      #一些持久化了的buffer pool文件├── ibdata1             #ibddata文件存储临时表数据+用户数据├── ib_logfile0         #ib_logfile0～N为 redo log日志├── ib_logfile1├── ibtmp1              #临时表空间文件├── mysql               #Mysql库文件├── performance_schema  #performance_schema库文件夹【系统库】├── sys                    #sys库文件夹【系统库】└── test                #自建test库文件夹【自建库】</code></pre><p>我们看到baseinfo库为Innodb存储引擎库,而test为MyISAM存储引擎库, 他们在文件存储上又有不同之处:</p><pre><code>[root@centos7-1 3306]# tree testtest├── db.opt├── t1.frm├── t1.MYD└── t1.MYI0 directories, 4 files[root@centos7-1 3306]# tree baseinfo/baseinfo/├── db.opt├── t_scrm_map.frm├── t_scrm_map.ibd├── t_scrm_pet_info.frm├── t_scrm_pet_info.ibd├── t_scrm_user_info.frm└── t_scrm_user_info.ibd[root@centos7-1 test]# cat db.opt default-character-set=utf8mb4default-collation=utf8mb4_general_ci#db.opt的作用1、create database时会自动生成一个文件db.opt，存放的数据库的默认字符集，show create database时显示数据库默认字符集即db.opt中字符集2、这个文件丢失不影响数据库运行，该文件丢失之后新建表时，找不到数据库的默认字符集，就把character_set_server当成数据库的默认字符集，show create database时显示character_set_server字符集</code></pre><p>可以看到MyISAM库表的文件结构为三个:</p><pre><code>${tablename}.frm   #表结构文件${tablename}.MYI   #表索引文件 MyISAM Index${tablename}.MYD   #表数据文件 MyISAM Data</code></pre><p>而Innodb库表的文件结构为两个:</p><pre><code>${tablename}.frm   #表结构文件${tablename}.idb   #表索引及数据文件</code></pre><p>可以看到在文件存储上 MyISAM和Innodb就有截然不同的结构 从而造成了数据引擎上的巨大差异</p><h2 id="4-3-MySQL运行模式"><a href="#4-3-MySQL运行模式" class="headerlink" title="4.3  MySQL运行模式"></a>4.3  MySQL运行模式</h2><p>MySQL被设计成一个单进程多线程架构的数据库,这一点与SQL Server比较类似,但与Oracle多进程的架构不同</p><p><code>MySQL数据库实例在系统上表现就是一个进程</code></p><p>已Innodb存储引擎为例,包含的后台线程主要有四种（具体含义会在存储引擎章节做解释）:</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/Mysqld%E8%BF%9B%E7%A8%8B.png" alt=""></p><p>我们可以在mysql中执行以下语句看查看所有mysql的进程数,具体含义在innodb章节解释吧:</p><pre><code class="mysql">mysql&gt; select thread_id,name,type FROM performance_schema.threads;+-----------+----------------------------------------+------------+| thread_id | name                                   | type       |+-----------+----------------------------------------+------------+|         1 | thread/sql/main                        | BACKGROUND ||         2 | thread/sql/thread_timer_notifier       | BACKGROUND ||         3 | thread/innodb/io_ibuf_thread           | BACKGROUND ||         4 | thread/innodb/io_log_thread            | BACKGROUND ||         5 | thread/innodb/io_read_thread           | BACKGROUND ||         6 | thread/innodb/io_read_thread           | BACKGROUND ||         7 | thread/innodb/io_read_thread           | BACKGROUND ||         8 | thread/innodb/io_read_thread           | BACKGROUND ||         9 | thread/innodb/io_write_thread          | BACKGROUND ||        10 | thread/innodb/io_write_thread          | BACKGROUND ||        11 | thread/innodb/io_write_thread          | BACKGROUND ||        12 | thread/innodb/io_write_thread          | BACKGROUND ||        13 | thread/innodb/page_cleaner_thread      | BACKGROUND ||        16 | thread/innodb/srv_lock_timeout_thread  | BACKGROUND ||        17 | thread/innodb/srv_error_monitor_thread | BACKGROUND ||        18 | thread/innodb/srv_monitor_thread       | BACKGROUND ||        19 | thread/innodb/srv_master_thread        | BACKGROUND ||        20 | thread/innodb/srv_worker_thread        | BACKGROUND ||        21 | thread/innodb/srv_purge_thread         | BACKGROUND ||        22 | thread/innodb/srv_worker_thread        | BACKGROUND ||        23 | thread/innodb/srv_worker_thread        | BACKGROUND ||        24 | thread/innodb/buf_dump_thread          | BACKGROUND ||        25 | thread/innodb/dict_stats_thread        | BACKGROUND ||        26 | thread/sql/signal_handler              | BACKGROUND ||        27 | thread/sql/compress_gtid_table         | FOREGROUND ||        36 | thread/sql/one_connection              | FOREGROUND |+-----------+----------------------------------------+------------+26 rows in set (0.00 sec)</code></pre>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> Mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>3.Mysql安装及初始化</title>
      <link href="/2020/02/14/3-Mysql%E5%AE%89%E8%A3%85%E5%8F%8A%E5%88%9D%E5%A7%8B%E5%8C%96/"/>
      <url>/2020/02/14/3-Mysql%E5%AE%89%E8%A3%85%E5%8F%8A%E5%88%9D%E5%A7%8B%E5%8C%96/</url>
      
        <content type="html"><![CDATA[<p>环境:Centos8 64位<br>版本:5.7.26 通用二级制版本<br>下载地址:   <a href="https://downloads.mysql.com/archives/get/p/23/file/mysql-5.7.26-linux-glibc2.12-x86_64.tar.gz" target="_blank" rel="noopener">https://downloads.mysql.com/archives/get/p/23/file/mysql-5.7.26-linux-glibc2.12-x86_64.tar.gz</a></p><h2 id="3-1-下载通用二进制包"><a href="#3-1-下载通用二进制包" class="headerlink" title="3.1 下载通用二进制包"></a>3.1 下载通用二进制包</h2><pre><code class="shell">[root@localhost Downloads]# wget  https://downloads.mysql.com/archives/get/p/23/file/mysql-5.7.26-linux-glibc2.12-x86_64.tar.gz</code></pre><h2 id="3-2-创建用户用户"><a href="#3-2-创建用户用户" class="headerlink" title="3.2 创建用户用户"></a>3.2 创建用户用户</h2><pre><code>[root@localhost ken]# useradd mysql</code></pre><h2 id="3-3-创建相应文件夹"><a href="#3-3-创建相应文件夹" class="headerlink" title="3.3 创建相应文件夹"></a>3.3 创建相应文件夹</h2><pre><code>#创建数据存放目录[root@localhost ken]# mkdir -p /data/3306#创建mysql程序存放的目录[root@localhost ken]# mkdir -p /app/database#创建日志存放的目录[root@localhost ken]# mkdir -p /log/3306</code></pre><h2 id="3-4-更改所属目录"><a href="#3-4-更改所属目录" class="headerlink" title="3.4 更改所属目录"></a>3.4 更改所属目录</h2><pre><code>[root@localhost ken]# chown -R mysql.mysql /data/3306  /app/database/ /log/3306/</code></pre><h2 id="3-5-解压mysql并放到指定目录"><a href="#3-5-解压mysql并放到指定目录" class="headerlink" title="3.5 解压mysql并放到指定目录"></a>3.5 解压mysql并放到指定目录</h2><pre><code>[ken@localhost Downloads]$ tar -zxvf mysql-5.7.26-linux-glibc2.12-i686.tar.gz [ken@localhost Downloads]$ lsmysql-5.7.26-linux-glibc2.12-i686  mysql-5.7.26-linux-glibc2.12-i686.tar.gz[ken@localhost Downloads]$ sudo mv mysql-5.7.26-linux-glibc2.12-i686 /app/database/mysql[ken@localhost Downloads]$ sudo chown -R mysql.mysql /app/database/mysql</code></pre><h2 id="3-6设置环境变量"><a href="#3-6设置环境变量" class="headerlink" title="3.6设置环境变量"></a>3.6设置环境变量</h2><pre><code>[ken@localhost ~]$ suPassword: [root@localhost ken]# echo &quot;export PATH=/app/database/mysql/bin:$PATH&quot; &gt;&gt; /etc/profile[root@localhost ken]# exitexit[ken@localhost ~]$ source /etc/profile#显示以下内容即可完成此安装步骤[ken@localhost bin]$ mysql -Vmysql  Ver 14.14 Distrib 5.7.26, for linux-glibc2.12 (x86_64) using  EditLine wrapper【注意】在centos8中 经常会报libncurses.so.5这个文件不存在 但是已经安装了libncurses库还是有报错的话主要是再ceontos中有它的升级版文件/lib64/libncurses.so.6.1 我们做一个软连接即可ln -s /lib64/libncurses.so.6.1 /lib64/libncurses.so.5</code></pre><h2 id="3-7-初始化Mysql"><a href="#3-7-初始化Mysql" class="headerlink" title="3.7 初始化Mysql"></a>3.7 初始化Mysql</h2><pre><code>[root@localhost ken]# mysqld --initialize-insecure --user=mysql --basedir=/app/database/mysql --datadir=/data/3306</code></pre><h2 id="3-8-配置文件设置"><a href="#3-8-配置文件设置" class="headerlink" title="3.8 配置文件设置"></a>3.8 配置文件设置</h2><pre><code>cat &gt; /etc/my.cnf &lt;&lt;EOF[mysqld]user=mysqlbasedir=/app/database/mysqldatadir=/data/3306socket=/tmp/mysql3306.sock[mysql]socket=/tmp/mysql3306.sockEOF</code></pre><h2 id="3-9-准备Mysql启动脚本"><a href="#3-9-准备Mysql启动脚本" class="headerlink" title="3.9 准备Mysql启动脚本"></a>3.9 准备Mysql启动脚本</h2><pre><code>root@localhost support-files]# pwd/app/database/mysql/support-files[root@localhost support-files]# cp mysql.server /etc/init.d/mysqld[root@localhost support-files]# service mysqld startStarting MySQL. SUCCESS! </code></pre><h2 id="3-10-验证是否可以连接成功"><a href="#3-10-验证是否可以连接成功" class="headerlink" title="3.10 验证是否可以连接成功"></a>3.10 验证是否可以连接成功</h2><pre><code>[root@localhost support-files]# mysqlWelcome to the MySQL monitor.  Commands end with ; or \g.Your MySQL connection id is 2Server version: 5.7.26 MySQL Community Server (GPL)Copyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type &#39;help;&#39; or &#39;\h&#39; for help. Type &#39;\c&#39; to clear the current input statement.mysql&gt; </code></pre>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> Mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2.Mysql产品线</title>
      <link href="/2020/02/13/2-Mysql%E4%BA%A7%E5%93%81%E7%BA%BF/"/>
      <url>/2020/02/13/2-Mysql%E4%BA%A7%E5%93%81%E7%BA%BF/</url>
      
        <content type="html"><![CDATA[<h2 id="2-1-Mysql主流厂家"><a href="#2-1-Mysql主流厂家" class="headerlink" title="2.1 Mysql主流厂家"></a>2.1 Mysql主流厂家</h2><ul><li>Oracle:MySQL官方版</li><li>红帽 :MariaDB</li><li>Percona: PerconaDB</li><li>阿里云做的也很好</li></ul><h2 id="2-2-Mysql主流版本"><a href="#2-2-Mysql主流版本" class="headerlink" title="2.2 Mysql主流版本"></a>2.2 Mysql主流版本</h2><ul><li>5.6—–5.6.36 5.6.38 5.6.40 5.6.46</li><li>5.7—–5.7.20 5.7.22 5.7.24 5.7.28</li><li>8.0—–8.0.11</li></ul><p><code>建议选择GA稳定版下半年发布的产品</code></p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> Mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>1.数据库分类</title>
      <link href="/2020/02/12/1-%E6%95%B0%E6%8D%AE%E5%BA%93%E5%88%86%E7%B1%BB/"/>
      <url>/2020/02/12/1-%E6%95%B0%E6%8D%AE%E5%BA%93%E5%88%86%E7%B1%BB/</url>
      
        <content type="html"><![CDATA[<p>我们可以从 <a href="https://db-engines.com/en/ranking" target="_blank" rel="noopener">https://db-engines.com/en/ranking</a>  这个网站查看数据库在互联网上的<code>流行程度</code>:<br><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/database.png" alt="数据库流行程度"></p><h2 id="1-1-关系型数据库"><a href="#1-1-关系型数据库" class="headerlink" title="1.1 关系型数据库"></a>1.1 关系型数据库</h2><p>英文简称为RDMS,最常见的数据库,其核心思想是将复杂的数据结构归结成简单的二元关系<br>常见的关系型数据库为:Mysql,SqlServer,Oracle</p><h2 id="1-2-键值存储数据库"><a href="#1-2-键值存储数据库" class="headerlink" title="1.2  键值存储数据库"></a>1.2  键值存储数据库</h2><p>键值数据库是一种非关系数据库，它使用简单的键值方法来存储数据<br>键值数据库将数据存储为键值对集合，其中键作为唯一标识符<br>常见的键值存储数据库为：Redis和memcached</p><h2 id="1-3-列存储数据库"><a href="#1-3-列存储数据库" class="headerlink" title="1.3 列存储数据库"></a>1.3 列存储数据库</h2><p>列式存储(column-based)是相对于传统关系型数据库的行式存储(Row-basedstorage)来说的<br>简单来说两者的区别就是对表中数据的存储形式的差异<br>常见的列存储数据库为：HBase</p><h2 id="1-4-面向文档数据库"><a href="#1-4-面向文档数据库" class="headerlink" title="1.4 面向文档数据库"></a>1.4 面向文档数据库</h2><p>此类数据库可存放并获取文档，可以是XML、JSON、BSON等格式，这些文档具备可述性（self-describing），呈现分层的树状结构（hierarchical tree data structure），可以包含映射表、集合和纯量值。数据库中的文档彼此相似，但不必完全相同。文档数据库所存放的文档，就相当于键值数据库所存放的“值”。文档数据库可视为其值可查的键值数据库。<br>常见的面向文档数据库为：MongoDB</p><h2 id="1-5-图形数据库"><a href="#1-5-图形数据库" class="headerlink" title="1.5 图形数据库"></a>1.5 图形数据库</h2><p>故名思意就是存储图形关系的数据库,也是Nosql的一种<br>常见的图形数据库为:Neo4J、ArangoDB、OrientDB、FlockDB、GraphDB、InfiniteGraph、Titan和Cayley等</p><h2 id="1-6-搜索引擎存储"><a href="#1-6-搜索引擎存储" class="headerlink" title="1.6 搜索引擎存储"></a>1.6 搜索引擎存储</h2><p>搜索引擎数据库是应用在搜索引擎领域的数据存储形式，由于搜索引擎会爬取大量的数据，并以特定的格式进行存储，这样在检索的时候才能保证性能最优。<br>常见的搜索引擎存储为:Elasticsearch,solr</p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> Mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mysql </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
