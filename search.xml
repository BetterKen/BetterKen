<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>20.Redis缓存数据库读写一致性</title>
      <link href="/2020/02/23/20-Redis%E7%BC%93%E5%AD%98%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AF%BB%E5%86%99%E4%B8%80%E8%87%B4%E6%80%A7/"/>
      <url>/2020/02/23/20-Redis%E7%BC%93%E5%AD%98%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AF%BB%E5%86%99%E4%B8%80%E8%87%B4%E6%80%A7/</url>
      
        <content type="html"><![CDATA[<h2 id="20-1-Cache-Aside-Pattern"><a href="#20-1-Cache-Aside-Pattern" class="headerlink" title="20.1 Cache Aside Pattern"></a>20.1 Cache Aside Pattern</h2><p>最经典的缓存+数据库读写的模式:Cache Aside Pattern 　旁路缓存</p><p>有几个原则:</p><ul><li>读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。</li><li>更新的时候，先<strong>删除缓存</strong>，然后再更新数据库。</li></ul><h3 id="20-1-1-删除缓存"><a href="#20-1-1-删除缓存" class="headerlink" title="20.1.1 删除缓存"></a>20.1.1 删除缓存</h3><p>更新时是删除缓存，而不是更新缓存</p><ul><li><p>缓存有的时候不但是从数据库里取出的一个简单值,可能会经过复杂计算</p></li><li><p>更新的数据不一定会被频繁访问到,如果去更新缓存可能会<strong>造成大量的冷数据</strong></p></li><li><p>懒加载思想:<strong>用到缓存才去算缓存</strong></p></li></ul><h2 id="20-2-双写不一致问题"><a href="#20-2-双写不一致问题" class="headerlink" title="20.2 双写不一致问题"></a>20.2 双写不一致问题</h2><h3 id="20-2-1-更新顺序颠倒情形"><a href="#20-2-1-更新顺序颠倒情形" class="headerlink" title="20.2.1 更新顺序颠倒情形"></a>20.2.1 更新顺序颠倒情形</h3><p>问题描述: <strong>先修改数据库,再删除缓存</strong>,当删除缓存失败了,会导致数据库中是新数据,缓存中是旧数据</p><p>解决思路: <strong>先删除缓存,再更新数据库</strong>,如果删除缓存成功了,修改数据库失败了,那么数据库中是旧数据,缓存中是空的,那么数据不会不一致,因为读的时候缓存没有,则读数据库中的旧数据,然后更新到缓存中</p><h3 id="20-2-2-更新数据库并发读情形"><a href="#20-2-2-更新数据库并发读情形" class="headerlink" title="20.2.2 更新数据库并发读情形"></a>20.2.2 更新数据库并发读情形</h3><p>问题描述:数据发生了变更,先删除了缓存,然后要去修改数据库,<strong>此时还没有修改数据库</strong>,一个请求过来去读缓存,没有读到,去查数据库,<strong>查到了修改前的旧数据,放到缓存中</strong>,数据变更的程序完成了数据库的修改,此时数据库和缓存的数据不一致了</p><p>解决思路:　更新数据的时候，根据数据的唯一标识，hash之后，<strong>发送到一个队列中,队列可是redis的队列,Java的内存队列</strong>等,读取数据的时候，如果发现数据不在缓存中，那么将重新执行“读取数据+更新缓存”的操作，根据唯一标识路由之后，也发送到同一个队列中。</p><p>一个队列对应一个工作线程，每个工作线程串行拿到对应的操作，然后一条一条的执行。这样的话，一个数据变更的操作，先删除缓存，然后再去更新数据库，但是还没完成更新。此时如果一个读请求过来，没有读到缓存，那么可以先将缓存更新的请求发送到队列中，此时会在队列中积压，然后同步等待缓存更新完成。</p><p>这里有一个<strong>优化点</strong>，一个队列中，<strong>其实多个更新缓存请求串在一起是没意义的</strong>，因此可以做过滤，如果发现队列中已经有一个更新缓存的请求了，那么就不用再放个更新请求操作进去了，直接等待前面的更新操作请求完成即可。</p><p>待那个队列对应的工作线程完成了上一个操作的数据库的修改之后，才会去执行下一个操作，也就是缓存更新的操作，此时会从数据库中读取最新的值，然后写入缓存中。</p><p>如果请求还在等待时间范围内，不断轮询发现可以取到值了，那么就直接返回；如果请求等待的时间超过一定时长，那么这一次直接从数据库中读取当前的旧值</p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>19.Redis雪崩击穿穿透</title>
      <link href="/2020/02/23/19-Redis%E9%9B%AA%E5%B4%A9%E5%87%BB%E7%A9%BF%E7%A9%BF%E9%80%8F/"/>
      <url>/2020/02/23/19-Redis%E9%9B%AA%E5%B4%A9%E5%87%BB%E7%A9%BF%E7%A9%BF%E9%80%8F/</url>
      
        <content type="html"><![CDATA[<h2 id="19-1-雪崩"><a href="#19-1-雪崩" class="headerlink" title="19.1 雪崩"></a>19.1 雪崩</h2><h3 id="19-1-1-定义"><a href="#19-1-1-定义" class="headerlink" title="19.1.1 定义"></a>19.1.1 定义</h3><p>缓存同一时间大面积的失效，后面的请求都会落到数据库上，造成数据库短时间内承受大量请求而崩掉。</p><h3 id="19-1-2-解决方式"><a href="#19-1-2-解决方式" class="headerlink" title="19.1.2 解决方式"></a>19.1.2 解决方式</h3><ul><li><p>事前:尽量保证整个 redis 集群的高可用性，发现机器宕机尽快补上。选择合适的内存淘汰策略</p><ul><li><strong>缓存预热</strong>:数据加热的含义就是在正式部署之前，把可能的数据先预先访问一遍，这样部分可能大量访问的数据就会加载到缓存中。可以使用阿里开源的<strong>canal</strong></li><li><strong>设置热点数据永远不过期</strong>，有更新操作就更新缓存就好了</li><li>往Redis存数据的时候，把每个Key的<strong>失效时间都加个随机值</strong>就好了，这样可以保证数据不会在同一时间大面积失效</li></ul><pre><code class="java">setRedis（Key，value，time + Math.random() * 10000）；</code></pre></li><li><p>事中：本地ehcache缓存 + hystrix限流&amp;降级，避免MySQL崩掉</p></li><li><p>事后：利用 redis 持久化机制保存的数据尽快恢复缓存</p></li></ul><h2 id="19-2-击穿"><a href="#19-2-击穿" class="headerlink" title="19.2 击穿"></a>19.2 击穿</h2><h3 id="19-2-1-定义"><a href="#19-2-1-定义" class="headerlink" title="19.2.1 定义"></a>19.2.1 定义</h3><p>缓存击穿，就是说某个 key 非常热点，访问非常频繁，处于集中式高并发访问的情况，当这个 key 在失效的瞬间，大量的请求就击穿了缓存，直接请求数据库，就像是在一道屏障上凿开了一个洞。</p><h3 id="19-2-2-解决方式"><a href="#19-2-2-解决方式" class="headerlink" title="19.2.2 解决方式"></a>19.2.2 解决方式</h3><p>不同场景下的解决方式可如下：</p><ul><li>若缓存的数据是基本不会发生更新的，则可尝试将该热点数据设置为永不过期。</li><li>若缓存的数据更新不频繁，且缓存刷新的整个流程耗时较少的情况下，则可以采用基于 redis、zookeeper 等分布式中间件的分布式互斥锁，或者本地互斥锁以保证仅少量的请求能请求数据库并重新构建缓存，其余线程则在锁释放后能访问到新缓存。</li><li>若缓存的数据更新频繁或者缓存刷新的流程耗时较长的情况下，可以利用定时线程在缓存过期前主动的重新构建缓存或者延后缓存的过期时间，以保证所有的请求能一直访问到对应的缓存。</li></ul><h2 id="19-3-穿透"><a href="#19-3-穿透" class="headerlink" title="19.3 穿透"></a>19.3 穿透</h2><h3 id="19-3-1-定义"><a href="#19-3-1-定义" class="headerlink" title="19.3.1 定义"></a>19.3.1 定义</h3><p>对于系统A，假设一秒 5000 个请求，结果其中 4000 个请求是黑客发出的恶意攻击。</p><p>黑客发出的那 4000 个攻击，缓存中查不到，每次你去数据库里查，也查不到。</p><p>举个栗子。数据库 id 是从 1 开始的，结果黑客发过来的请求 id 全部都是负数。这样的话，缓存中不会有，请求每次都“视缓存于无物”，直接查询数据库。这种恶意攻击场景的缓存穿透就会直接把数据库给打死。</p><h3 id="19-3-2-解决方式"><a href="#19-3-2-解决方式" class="headerlink" title="19.3.2 解决方式"></a>19.3.2 解决方式</h3><ul><li><strong>初级</strong>:每次系统 A 从数据库中只要没查到，就<strong>写一个空值到缓存</strong>里去，比如 <code>set -999 UNKNOWN</code>。然后设置一个过期时间，这样的话，下次有相同的 key 来访问的时候，在缓存失效之前，都可以直接从缓存中取数据。</li><li><strong>进阶</strong>: <strong>在接口层增加校验</strong>，比如用户鉴权校验，参数做校验，不合法的参数直接代码Return，比如：id 做基础校验，id &lt;=0的直接拦截等。</li><li><strong>高级</strong>: 使用<strong>布隆过滤器（Bloom Filter）</strong>这个也能很好的防止缓存穿透的发生，他的原理也很简单就是利用高效的数据结构和算法快速<strong>判断出你这个Key是否在数据库中存在，不存在你return就好了，存在你就去查了DB刷新KV再return</strong>。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>18.Redis高可用模式总结</title>
      <link href="/2020/02/23/18-Redis%E9%AB%98%E5%8F%AF%E7%94%A8%E6%A8%A1%E5%BC%8F%E6%80%BB%E7%BB%93/"/>
      <url>/2020/02/23/18-Redis%E9%AB%98%E5%8F%AF%E7%94%A8%E6%A8%A1%E5%BC%8F%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<h2 id="18-1-Redis的三种高可用模式"><a href="#18-1-Redis的三种高可用模式" class="headerlink" title="18.1 Redis的三种高可用模式"></a>18.1 Redis的三种高可用模式</h2><ul><li>Redis主从模式</li><li>Redis哨兵模式</li><li>Redis cluster模式</li></ul><h2 id="18-2-使用场景"><a href="#18-2-使用场景" class="headerlink" title="18.2 使用场景"></a>18.2 使用场景</h2><h3 id="18-2-1-Redis主从"><a href="#18-2-1-Redis主从" class="headerlink" title="18.2.1 Redis主从"></a>18.2.1 Redis主从</h3><p>单机Redis无法支撑较大的QPS，如果业务类型是读多写少类型，需要采用多个只读节点的部署方式来突破Redis单线程的性能瓶颈。</p><h3 id="18-2-2-Redis哨兵"><a href="#18-2-2-Redis哨兵" class="headerlink" title="18.2.2 Redis哨兵"></a>18.2.2 Redis哨兵</h3><p>通常搭建了主从之后建议再配合哨兵模式使用,去保证redis主从架构的高可用性</p><h3 id="18-2-3-Redis-cluster"><a href="#18-2-3-Redis-cluster" class="headerlink" title="18.2.3 Redis cluster"></a>18.2.3 Redis cluster</h3><p>redis cluster 主要是针对海量数据+高并发+高可用的场景，如果是海量数据，如果你的数据量很大，那么建议就用redis cluster</p><h2 id="18-3-应用连接方式"><a href="#18-3-应用连接方式" class="headerlink" title="18.3 应用连接方式"></a>18.3 应用连接方式</h2><p>不同的高可用模式,应用的连接方式会发生改变,下面以python代码示例:</p><h3 id="18-3-1-连接-sentinel"><a href="#18-3-1-连接-sentinel" class="headerlink" title="18.3.1 连接 sentinel"></a>18.3.1 连接 sentinel</h3><pre><code class="python">&gt;&gt;&gt; from redis.sentinel import Sentinel&gt;&gt;&gt; sentinel = Sentinel([(&#39;localhost&#39;, 26379)], socket_timeout=0.1)&gt;&gt;&gt; master = sentinel.master_for(&#39;mymaster&#39;, socket_timeout=0.1)&gt;&gt;&gt; master.set(&#39;foo&#39;, &#39;bar&#39;)&gt;&gt;&gt; slave = sentinel.slave_for(&#39;mymaster&#39;, socket_timeout=0.1)&gt;&gt;&gt; slave.get(&#39;foo&#39;)&#39;bar&#39;</code></pre><h3 id="18-3-2-连接cluster"><a href="#18-3-2-连接cluster" class="headerlink" title="18.3.2 连接cluster"></a>18.3.2 连接cluster</h3><pre><code class="python">&gt;&gt;&gt; from rediscluster import RedisCluster&gt;&gt;&gt; # Requires at least one node for cluster discovery. Multiple nodes is recommended.&gt;&gt;&gt; startup_nodes = [{&quot;host&quot;: &quot;127.0.0.1&quot;, &quot;port&quot;: &quot;7000&quot;}]&gt;&gt;&gt; rc = RedisCluster(startup_nodes=startup_nodes, decode_responses=True)&gt;&gt;&gt; rc.set(&quot;foo&quot;, &quot;bar&quot;)True&gt;&gt;&gt; print(rc.get(&quot;foo&quot;))&#39;bar&#39;</code></pre><h2 id="18-4-Redis云产品"><a href="#18-4-Redis云产品" class="headerlink" title="18.4 Redis云产品"></a>18.4 Redis云产品</h2><p>阿里云的云产品Redis提供三类产品:</p><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/alredis.png" alt=""></p><p>我之前用过读写分离版本很稳定,<strong>实践证明了花钱真香～</strong>,推荐开发进度紧张,没时间运维的公司可以尝试使用下</p><h3 id="18-4-1-优势"><a href="#18-4-1-优势" class="headerlink" title="18.4.1 优势"></a>18.4.1 优势</h3><p>相比自己搭建Redis数据库，云数据库Redis版在数据安全、运维投入、内核优化等方面都有一定的优势。</p><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/alredisdiff.png" alt=""></p><h3 id="18-4-2-劣势"><a href="#18-4-2-劣势" class="headerlink" title="18.4.2 劣势"></a>18.4.2 劣势</h3><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/money.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>17.RedisCluster</title>
      <link href="/2020/02/22/17-RedisCluster/"/>
      <url>/2020/02/22/17-RedisCluster/</url>
      
        <content type="html"><![CDATA[<h2 id="17-1-redis-cluster介绍"><a href="#17-1-redis-cluster介绍" class="headerlink" title="17.1 redis cluster介绍"></a>17.1 redis cluster介绍</h2><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/rediscluster.png" alt=""></p><ul><li>自动将数据进行分片,每个master上放一部分数据</li><li>提供内置的高可用支持,部分master不可用时,还是可以继续工作的，因为每个master都有salve节点，那么如果mater挂掉，redis cluster这套机制，就会自动将某个slave切换成master；</li><li>支持读写分离：对于每个master来说，都负责写请求，写就写到master，然后读就从mater对应的slave去读；</li></ul><p>redisCluster是Redis的官方分布式解决方案,解决了上一章提到的Redis主从模式的1,2,3缺陷</p><p>redisCluster = 多master+读写分离+sentinal</p><h2 id="17-2-分区规则"><a href="#17-2-分区规则" class="headerlink" title="17.2 分区规则"></a>17.2 分区规则</h2><h3 id="17-2-1-常见分区规则"><a href="#17-2-1-常见分区规则" class="headerlink" title="17.2.1 常见分区规则"></a>17.2.1 常见分区规则</h3><p>分布式数据库首要解决把整个数据集按照分区规则映射到多个节点的问题，即把数据集划分到多个节点上，每个节点负责整个数据的一个子集。</p><p>常见的分区规则有<code>哈希分区和顺序分区</code>。Redis Cluster采用哈希分区规则，因此接下来会讨论哈希分区规则。常见的哈希分区有以下几种：</p><ul><li>节点取余分区</li><li>一致性哈希分区</li><li>虚拟槽分区</li></ul><p>Redis Cluster采用虚拟槽分区</p><h3 id="17-2-2-hash算法"><a href="#17-2-2-hash算法" class="headerlink" title="17.2.2 hash算法"></a>17.2.2 hash算法</h3><p>来了一个 key，首先计算 hash 值，然后对节点数取模。然后打在不同的 master 节点上。一旦某一个 master 节点宕机，所有请求过来，都会基于最新的剩余 master 节点数去取模，尝试去取数据。这会<strong>导致大部分的请求过来，全部无法拿到有效的缓存，导致大量的流量涌入数据库</strong></p><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/hash-1.png" alt=""></p><h3 id="17-2-3-一致性-hash-算法"><a href="#17-2-3-一致性-hash-算法" class="headerlink" title="17.2.3 一致性 hash 算法"></a>17.2.3 一致性 hash 算法</h3><p>一致性 hash 算法将整个 hash 值空间组织成一个虚拟的圆环，整个空间按顺时针方向组织，下一步将各个 master 节点（使用服务器的 ip 或主机名）进行 hash。这样就能确定每个节点在其哈希环上的位置。</p><p>来了一个 key，首先计算 hash 值，并确定此数据在环上的位置，从此位置沿环<strong>顺时针“行走”</strong>，遇到的第一个 master 节点就是 key 所在位置。</p><p>在一致性哈希算法中，如果<strong>一个节点挂了，受影响的数据仅仅是此节点到环空间前一个节点（沿着逆时针方向行走遇到的第一个节点）之间的数据，其它不受影响</strong>。增加一个节点也同理。</p><p>燃鹅，一致性哈希算法在节点太少时，容易因为节点分布不均匀而造成<strong>缓存热点</strong>的问题。为了解决这种热点问题，<strong>一致性 hash 算法引入了虚拟节点机制，即对每一个节点计算多个 hash，每个计算结果位置都放置一个虚拟节点</strong>。这样就实现了数据的均匀分布，负载均衡。</p><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/consistent-hashing-algorithm.png" alt=""></p><h3 id="17-2-2-redis使用的hash-slot"><a href="#17-2-2-redis使用的hash-slot" class="headerlink" title="17.2.2 redis使用的hash slot"></a>17.2.2 redis使用的hash slot</h3><p>虚拟槽分区巧妙地使用了哈希空间，使用分散度良好的哈希函数把所有的数据映射到一个固定范围内的整数集合，整数定义为槽（slot）。</p><p>redis cluster有固定的16384个hash slot，对每个key计算CRC16值，然后对16384取模，可以获取key对应的hash slot<br>redis cluster中每个master都会持有部分slot，比如有3个master，那么可能每个master持有5000多个hash slot<br>hash slot让node的增加和移除很简单，增加一个master，就将其他master的hash slot移动部分过去，减少一个master，就将它的hash slot移动到其他master上去<br>移动hash slot的成本是非常低的<br>客户端的api，可以对指定的数据，让他们走同一个hash slot，通过hash tag来实现出处。</p><h2 id="17-3-节点间的通信协议"><a href="#17-3-节点间的通信协议" class="headerlink" title="17.3 节点间的通信协议"></a>17.3 节点间的通信协议</h2><h3 id="17-3-1-基本通信原理"><a href="#17-3-1-基本通信原理" class="headerlink" title="17.3.1 基本通信原理"></a>17.3.1 基本通信原理</h3><p>集群元数据的维护有两种方式：</p><ul><li>集中式协议</li><li>Gossip 协议</li></ul><p>redis cluster 节点间采用 gossip 协议进行通信。</p><h3 id="17-3-2-集中式协议"><a href="#17-3-2-集中式协议" class="headerlink" title="17.3.2 集中式协议"></a>17.3.2 集中式协议</h3><p>集中式是将集群元数据（节点信息、故障等等）几种存储在某个节点上。集中式元数据集中存储的一个典型代表，就是大数据领域的 storm。它是分布式的大数据实时计算引擎，是集中式的元数据存储的结构，底层基于 zookeeper（分布式协调的中间件）对所有元数据进行存储维护。</p><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/zookeeper-centralized-storage.png" alt=""></p><ul><li>集中式的好处: 元数据的读取和更新，时效性非常好，一旦元数据出现了变更，就立即更新到集中式的存储中，其它节点读取的时候就可以感知到</li><li>不好在于，所有的元数据的更新压力全部集中在一个地方，可能会导致元数据的存储有压力。</li></ul><h3 id="17-3-3-gossip-协议"><a href="#17-3-3-gossip-协议" class="headerlink" title="17.3.3 gossip 协议"></a>17.3.3 gossip 协议</h3><p>gossip 协议包含多种消息，包含 ping,pong,meet,fail 等等。</p><ul><li><p>meet：某个节点发送 meet 给新加入的节点，让新节点加入集群中，然后新节点就会开始与其它节点进行通信。</p><pre><code>aredis-trib.rb add-node其实内部就是发送了一个 gossip meet 消息给新加入的节点，通知那个节点去加入我们的集群</code></pre></li><li><p>ping：每个节点都会频繁给其它节点发送 ping，其中包含自己的状态还有自己维护的集群元数据，互相通过 ping 交换元数据。</p></li><li><p>pong：返回 ping 和 meeet，包含自己的状态和其它信息，也用于信息广播和更新。</p></li><li><p>fail：某个节点判断另一个节点 fail 之后，就发送 fail 给其它节点，通知其它节点说，某个节点宕机啦。</p></li></ul><p>gossip协议优缺点:</p><ul><li>gossip 好处在于，元数据的更新比较分散，不是集中在一个地方，更新请求会陆陆续续打到所有节点上去更新，降低了压力</li><li>不好在于，元数据的更新有延时，可能导致集群中的一些操作会有一些滞后。</li></ul><h3 id="17-3-4-Redis中的gossip协议"><a href="#17-3-4-Redis中的gossip协议" class="headerlink" title="17.3.4 Redis中的gossip协议"></a>17.3.4 Redis中的gossip协议</h3><p>redis 维护集群元数据采用另一个方式， gossip 协议，所有节点都持有一份元数据，不同的节点如果出现了元数据的变更，就不断将元数据发送给其它的节点，让其它节点也进行元数据的变更。</p><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/redis-gossip.png" alt=""></p><ul><li>10000 端口：每个节点都有一个专门用于节点间通信的端口，就是自己提供服务的端口号+10000，比如 7001，那么用于节点间通信的就是 17001 端口。每个节点每隔一段时间都会往另外几个节点发送 ping 消息，同时其它几个节点接收到 ping 之后返回 pong。</li><li>交换的信息：信息包括故障信息，节点的增加和删除，hash slot 信息等等。</li></ul><h2 id="17-4Redis-cluster功能限制"><a href="#17-4Redis-cluster功能限制" class="headerlink" title="17.4Redis cluster功能限制"></a>17.4Redis cluster功能限制</h2><p>Redis集群相对单机在功能上有一定限制:</p><ul><li>key批量操作支持有限。如：MSET,MGET，目前只支持具有相同slot值的key执行批量操作。</li><li>key事务操作支持有限。支持多key在同一节点上的事务操作，不支持分布在多个节点的事务功能。</li><li>key作为数据分区的最小粒度，因此不能将一个大的键值对象映射到不同的节点。如：hash、list。</li><li>不支持多数据库空间。单机下Redis支持16个数据库，集群模式下只能使用一个数据库空间，即db0。</li><li>复制结构只支持一层，不支持嵌套树状复制结构。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>16.Redis哨兵模式</title>
      <link href="/2020/02/22/16-Redis%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F/"/>
      <url>/2020/02/22/16-Redis%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<p>类似与Mysql的主备切换，Sentinel是Redis的高可用性解决方案之一</p><h2 id="16-1-主从复制的问题"><a href="#16-1-主从复制的问题" class="headerlink" title="16.1 主从复制的问题"></a>16.1 主从复制的问题</h2><ul><li>一旦 主节点宕机，从节点 晋升成 主节点，同时需要修改 应用方 的 主节点地址，还需要命令所有 从节点去复制 新的主节点，整个过程需要人工干预。</li><li>主节点的写能力受到 单机的限制。</li><li>主节点的存储能力受到单机的限制。</li></ul><h2 id="16-2-哨兵模式作用"><a href="#16-2-哨兵模式作用" class="headerlink" title="16.2 哨兵模式作用"></a>16.2 哨兵模式作用</h2><p>哨兵模式可以解决主从的第一个问题</p><ul><li>集群监控：负责监控 redis master 和 slave 进程是否正常工作</li><li>消息通知：如果某个 redis 实例有故障，那么哨兵负责发送消息作为报警通知给管理员</li><li>故障转移：如果 master node 挂掉了，会自动转移到 slave node 上</li><li>配置中心：如果故障转移发生了，通知 client 客户端新的 master 地址</li><li>应用透明 : 应用不需要重启改配置文件</li></ul><h2 id="16-3-哨兵模式架构"><a href="#16-3-哨兵模式架构" class="headerlink" title="16.3 哨兵模式架构"></a>16.3 哨兵模式架构</h2><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/sentinel.png" alt=""></p><ul><li><p>哨兵至少需要 3 个实例，来保证自己的健壮性。(分布式quorum选举)</p></li><li><p>哨兵 + redis 主从的部署架构，是<strong>不保证数据零丢失的，只能保证 redis 集群的高可用性</strong>。</p></li></ul><h2 id="16-4-工作原理"><a href="#16-4-工作原理" class="headerlink" title="16.4 工作原理"></a>16.4 工作原理</h2><p>每个 Sentinel 节点都需要 定期执行 以下任务：</p><ul><li>每个 Sentinel 以 每秒钟 一次的频率，向它所知的 主服务器、从服务器 以及其他 Sentinel 实例 发送一个 PING 命令。</li><li>如果一个 实例（instance）距离 最后一次 有效回复 PING 命令的时间超过 down-after-milliseconds 所指定的值，那么这个实例会被 Sentinel 标记为 主观下线。</li><li>如果一个 主服务器 被标记为 主观下线，那么正在 监视 这个 主服务器 的所有 Sentinel 节点，要以 每秒一次 的频率确认 主服务器 的确进入了 主观下线 状态。</li><li>如果一个 主服务器 被标记为 主观下线，并且有 足够数量 的 Sentinel（至少要达到 配置文件 指定的数量）在指定的 时间范围 内同意这一判断，那么这个 主服务器 被标记为 客观下线。</li><li>在一般情况下， 每个 Sentinel 会以每 10 秒一次的频率，向它已知的所有 主服务器 和 从服务器 发送 INFO 命令。当一个 主服务器 被 Sentinel 标记为 客观下线 时，Sentinel 向 下线主服务器 的所有 从服务器 发送 INFO 命令的频率，会从 10 秒一次改为 每秒一次</li><li>Sentinel 和其他 Sentinel 协商 主节点 的状态，如果 主节点 处于 SDOWN 状态，则投票自动选出新的 主节点。将剩余的 从节点 指向 新的主节点 进行 数据复制。</li><li>当没有足够数量的 Sentinel 同意 主服务器 下线时， 主服务器 的 客观下线状态 就会被移除。当 主服务器 重新向 Sentinel 的 PING 命令返回 有效回复 时，主服务器 的 主观下线状态 就会被移除。</li></ul><h3 id="16-4-1-sdown-和-odown-转换机制"><a href="#16-4-1-sdown-和-odown-转换机制" class="headerlink" title="16.4.1 sdown 和 odown 转换机制"></a>16.4.1 sdown 和 odown 转换机制</h3><ul><li>sdown 是主观宕机，就一个哨兵如果自己觉得一个 master 宕机了，那么就是主观宕机</li><li>odown 是客观宕机，如果 quorum 数量的哨兵都觉得一个 master 宕机了，那么就是客观宕机</li></ul><p>sdown 达成的条件很简单，如果一个哨兵 ping 一个 master，超过了 is-master-down-after-milliseconds 指定的毫秒数之后，就主观认为 master 宕机了；如果一个哨兵在指定时间内，收到了 quorum 数量的其它哨兵也认为那个 master 是 sdown 的，那么就认为是 odown 了。</p><h3 id="16-4-2-哨兵集群的自动发现机制"><a href="#16-4-2-哨兵集群的自动发现机制" class="headerlink" title="16.4.2 哨兵集群的自动发现机制"></a>16.4.2 哨兵集群的自动发现机制</h3><p>哨兵互相之间的发现，是通过 redis 的 pub/sub 系统实现的，每个哨兵都会往 <strong>sentinel</strong>:hello 这个 channel 里发送一个消息，这时候所有其他哨兵都可以消费到这个消息，并感知到其他的哨兵的存在。</p><p>每隔两秒钟，每个哨兵都会往自己监控的某个 master+slaves 对应的 <strong>sentinel</strong>:hello channel 里发送一个消息，内容是自己的 host、ip 和 runid 还有对这个 master 的监控配置。</p><p>每个哨兵也会去监听自己监控的每个 master+slaves 对应的 <strong>sentinel</strong>:hello channel，然后去感知到同样在监听这个 master+slaves 的其他哨兵的存在。</p><p>每个哨兵还会跟其他哨兵交换对 master 的监控配置，互相进行监控配置的同步。</p><h3 id="16-4-3-选举算法"><a href="#16-4-3-选举算法" class="headerlink" title="16.4.3 选举算法"></a>16.4.3 选举算法</h3><p>如果一个 master 被认为 odown 了，而且 majority 数量的哨兵都允许主备切换，那么某个哨兵就会执行主备切换操作，此时首先要选举一个 slave 来，会考虑 slave 的一些信息：</p><ul><li>跟 master 断开连接的时长</li><li>slave 优先级</li><li>复制 offset</li><li>run id</li></ul><p>如果一个 slave 跟 master 断开连接的时间已经超过了 down-after-milliseconds 的 10 倍，外加 master 宕机的时长，那么 slave 就被认为不适合选举为 master。</p><p>接下来会对 slave 进行排序：</p><ul><li>按照 slave 优先级进行排序，slave priority 越低，优先级就越高。</li><li>如果 slave priority 相同，那么看 replica offset，哪个 slave 复制了越多的数据，offset 越靠后，优先级就越高。</li><li>如果上面两个条件都相同，那么选择一个 run id 比较小的那个 slave。</li></ul><h3 id="16-4-4-configuration传播"><a href="#16-4-4-configuration传播" class="headerlink" title="16.4.4 configuration传播"></a>16.4.4 configuration传播</h3><p>执行切换的那个哨兵，会从要切换到的新 master（salve-&gt;master）那里得到一个 configuration epoch，这就是一个 version 号，每次切换的 <code>version</code>号都必须是唯一的。</p><p>如果第一个选举出的哨兵切换失败了，那么其他哨兵，会等待 failover-timeout 时间，然后接替继续执行切换，此时会重新获取一个新的 configuration epoch，作为新的 <code>version</code> 号。</p><p>哨兵完成切换之后，会在自己本地更新生成最新的 master 配置，然后同步给其他的哨兵，就是通过之前说的 pub/sub 消息机制。</p><p>这里之前的 version 号就很重要了，因为各种消息都是通过一个 channel 去发布和监听的，所以一个哨兵完成一次新的切换之后，新的 master 配置是跟着新的<code>version</code> 号的。其他的哨兵都是根据版本号的大小来更新自己的 master 配置的。</p><h2 id="16-5-主备切换数据丢失问题"><a href="#16-5-主备切换数据丢失问题" class="headerlink" title="16.5 主备切换数据丢失问题"></a>16.5 主备切换数据丢失问题</h2><p>主备切换的过程，可能会导致数据丢失：</p><ul><li>异步复制导致的数据丢失</li><li>脑裂导致的数据丢失</li></ul><h3 id="16-5-1-异步复制导致的数据丢失"><a href="#16-5-1-异步复制导致的数据丢失" class="headerlink" title="16.5.1 异步复制导致的数据丢失"></a>16.5.1 异步复制导致的数据丢失</h3><p>因为 master-&gt;slave 的复制是异步的，所以可能有部分数据还没复制到 slave，master 就宕机了，此时这部分数据就丢失了</p><h3 id="16-5-2-脑裂导致的数据丢失"><a href="#16-5-2-脑裂导致的数据丢失" class="headerlink" title="16.5.2 脑裂导致的数据丢失"></a>16.5.2 脑裂导致的数据丢失</h3><p>脑裂，也就是说，某个 master 所在机器突然脱离了正常的网络，跟其他 slave 机器不能连接，但是实际上 master 还运行着。此时哨兵可能就会认为 master 宕机了，然后开启选举，将其他 slave 切换成了 master。这个时候，集群里就会有两个 master ，也就是所谓的<strong>脑裂</strong>。</p><p>此时虽然某个 slave 被切换成了 master，但是可能 client 还没来得及切换到新的 master，还继续向旧 master 写数据。因此旧 master 再次恢复的时候，会被作为一个 slave 挂到新的 master 上去，自己的数据会清空，重新从新的 master 复制数据。而新的 master 并没有后来 client 写入的数据，因此，这部分数据也就丢失了。</p><h3 id="16-5-3-数据丢失问题的解决方案"><a href="#16-5-3-数据丢失问题的解决方案" class="headerlink" title="16.5.3 数据丢失问题的解决方案"></a>16.5.3 数据丢失问题的解决方案</h3><p><strong>注意：数据丢失只能说减少丢失不能完全规避丢失</strong></p><p>进行如下配置：</p><pre><code class="ini">min-slaves-to-write 1min-slaves-max-lag 10</code></pre><p>表示，要求至少有 1 个 slave，数据复制和同步的延迟不能超过 10 秒。</p><p>如果说一旦所有的 slave，数据复制和同步的延迟都超过了 10 秒钟，那么这个时候，master 就不会再接收任何请求了。</p><ul><li>减少异步复制数据的丢失</li></ul><p>有了 min-slaves-max-lag 这个配置，就可以确保说，一旦 slave 复制数据和 ack 延时太长，就认为可能 master 宕机后损失的数据太多了，那么就拒绝写请求，这样可以把 master 宕机时由于部分数据未同步到 slave 导致的数据丢失降低的可控范围内。</p><ul><li>减少脑裂的数据丢失</li></ul><p>如果一个 master 出现了脑裂，跟其他 slave 丢了连接，那么上面两个配置可以确保说，如果不能继续给指定数量的 slave 发送数据，而且 slave 超过 10 秒没有给自己 ack 消息，那么就直接拒绝客户端的写请求。因此在脑裂场景下，最多就丢失 10 秒的数据</p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>15.Redis主从架构</title>
      <link href="/2020/02/22/15-Redis%E4%B8%BB%E4%BB%8E%E6%9E%B6%E6%9E%84/"/>
      <url>/2020/02/22/15-Redis%E4%B8%BB%E4%BB%8E%E6%9E%B6%E6%9E%84/</url>
      
        <content type="html"><![CDATA[<p>在Redis中,用户可以使用<code>SLAVE OF</code>命令或者设置<code>slave of</code>选项,让一个Redis服务去复制另一个Redis服务,从而来实现类似于Mysql的读写分离</p><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/slave.png" alt=""></p><p>同样的Redis也可以和Mysql一样,做级联模式</p><h2 id="15-1-旧版复制功能实现"><a href="#15-1-旧版复制功能实现" class="headerlink" title="15.1 旧版复制功能实现"></a>15.1 旧版复制功能实现</h2><p>Redis2.8之前Redis的复制分为两个阶段 ： </p><ul><li>同步</li><li>命令传播</li></ul><h3 id="15-1-1-同步"><a href="#15-1-1-同步" class="headerlink" title="15.1.1 同步"></a>15.1.1 同步</h3><ul><li>从服务器向主服务器发送SYNC命令</li><li>收到SYNC命令后，主服务器开始执行BGSAVE操作生成RDB文件，并使用一个缓冲区记录现在开始执行的所有写命令（用于命令传播阶段保持数据库一致性）</li><li>当主服务器的BGSAVE操作执行完时，主服务器会将BGSAVE命令生成的RDB文件发送给从服务器，从服务器接收并载入这个RDB文件，将自己的数据库状态更新至主服务器执行BGSAVE命令时的数据库状态</li><li>主服务器将记录在缓冲区里面的所有写命令发送给从服务器，从服务器执行这些写命令。将自己数据库状态更新至主服务器数据库当前状态</li></ul><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/sync.jpg" alt=""></p><h3 id="15-1-2-命令传播"><a href="#15-1-2-命令传播" class="headerlink" title="15.1.2 命令传播"></a>15.1.2 命令传播</h3><p>主服务器将执行的写命令，发送给从服务器执行，当从服务器执行了相同写命令后，主从服务器将再次回到一致性状态</p><h3 id="15-1-3-旧版复制功能的缺陷"><a href="#15-1-3-旧版复制功能的缺陷" class="headerlink" title="15.1.3 旧版复制功能的缺陷"></a>15.1.3 旧版复制功能的缺陷</h3><p><strong>为了让从服务器补足一小部分缺失的数据，而让主服务器重新执行一次BGSAVE操作，造成断线重连后的效率会很低</strong></p><h2 id="15-2-新版复制功能的实现"><a href="#15-2-新版复制功能的实现" class="headerlink" title="15.2 新版复制功能的实现"></a>15.2 新版复制功能的实现</h2><h3 id="15-2-1-SYNC命令换成PSYNC"><a href="#15-2-1-SYNC命令换成PSYNC" class="headerlink" title="15.2.1 SYNC命令换成PSYNC"></a>15.2.1 SYNC命令换成PSYNC</h3><p>PSYNC命令具有完整重同步和部分重同步两种模式：</p><ul><li>完整重同步用于处理初次复制的情况：与SYNC命令的执行步骤基本一致 ， 都是通过让主服务器创建并发送RDB文件，以及向从服务器发送保存在缓冲区里面的写命令来进行同步。</li><li>部分重同步用于处理断线后重复制的情况：当从服务器在断线后重新连接主服务器时，如果条件允许，主服务器可以将主从服务器连接断开期间执行的写命令发送给从服务器，从服务器只要接收并执行这些写命令，就可以将数据库更新至主服务器当前所在状态了。</li></ul><h3 id="15-2-2-部分重同步的实现"><a href="#15-2-2-部分重同步的实现" class="headerlink" title="15.2.2 部分重同步的实现"></a>15.2.2 部分重同步的实现</h3><ul><li><p>主从服务器的复制偏移量</p></li><li><p>主服务器的复制积压缓冲区,默认大小为1MB，为安全期间建议按照如下公式设置</p><pre><code>复制积压缓冲区大小 :    2 * second * writer_size_per_secondsecond: 从服务断线重连需要的秒数writer_size_per_second: 主服务器每秒写书的数据量</code></pre></li></ul><ul><li>从服务器记录主服务器运行ID</li></ul><h3 id="15-2-3-主从复制核心原理"><a href="#15-2-3-主从复制核心原理" class="headerlink" title="15.2.3 主从复制核心原理"></a>15.2.3 主从复制核心原理</h3><p>当启动一个 slave node 的时候，它会发送一个 PSYNC 命令给 master node。</p><p>如果这是 slave node 初次连接到 master node，那么会触发一次<code>full resynchronization</code> 全量复制。此时 master 会启动一个后台线程，开始生成一份 RDB 快照文件，同时还会将从客户端 client 新收到的所有写命令缓存在内存中。RDB 文件生成完毕后， master 会将这个 RDB 发送给 slave，slave 会先<strong>写入本地磁盘，然后再从本地磁盘加载到内存中</strong>，接着 master 会将内存中缓存的写命令发送到 slave，slave 也会同步这些数据。slave node 如果跟 master node 有网络故障，断开了连接，会自动重连，连接之后 master node 仅会复制给 slave 部分缺少的数据。</p><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/redis-master-slave-replication.png" alt=""></p><h3 id="15-2-4-复制完整流程"><a href="#15-2-4-复制完整流程" class="headerlink" title="15.2.4 复制完整流程"></a>15.2.4 复制完整流程</h3><ol><li>从服务上设置主服务器的地址和端口</li><li>建立socket连接</li><li>发送ping命令</li><li>身份验证</li><li>从服务器发送端口信息</li><li>同步</li><li>命令传播</li></ol><h3 id="15-2-5-过期-key-处理"><a href="#15-2-5-过期-key-处理" class="headerlink" title="15.2.5 过期 key 处理"></a>15.2.5 过期 key 处理</h3><p>slave 不会过期 key，只会等待 master 过期 key。如果 master 过期了一个 key，或者通过 LRU 淘汰了一个 key，那么会模拟一条 del 命令发送给 slave。</p><h2 id="15-3-心跳检测"><a href="#15-3-心跳检测" class="headerlink" title="15.3 心跳检测"></a>15.3 心跳检测</h2><p>在命令传播阶段,从服务器会每秒向主服务器发送心跳检测,作用如下:</p><ul><li>检测主从服务器的网络连接状态 看延时多少，一般延时0-1秒</li><li>辅助实现min-slaves选项</li><li>检测命令丢失</li></ul><h3 id="15-3-1-辅助实现min-slaves选项"><a href="#15-3-1-辅助实现min-slaves选项" class="headerlink" title="15.3.1 辅助实现min-slaves选项"></a>15.3.1 辅助实现min-slaves选项</h3><p>Redis的<code>min-slaves-to-write</code>和<code>min-slaves-max-lag</code>两个选项可以防止主服务器在不安全的情况下执行写命令<br>举个例子，如果我们向主服务器提供以下设置：</p><pre><code class="ini">min-slaves-to-write 3min-slaves-max-lag 10</code></pre><p>那么在从服务器的数量少于3个，或者三个从服务器的延迟（lag）值都大于或等于10秒时，主服务器将拒绝执行写命令</p><h3 id="15-3-2-检测命令丢失"><a href="#15-3-2-检测命令丢失" class="headerlink" title="15.3.2 检测命令丢失"></a>15.3.2 检测命令丢失</h3><p>主服务器向从服务器补发缺失数据这一操作的原理和部分重同步操作的原理非常相似，这两个操作的区别在于：<strong>补发缺失数据操作在主从服务器没有断线的情况下执行，而部分重同步操作则在主从服务器断线并重连之后执行</strong></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>14.Redis持久化总结</title>
      <link href="/2020/02/21/14-Redis%E6%8C%81%E4%B9%85%E5%8C%96%E6%80%BB%E7%BB%93/"/>
      <url>/2020/02/21/14-Redis%E6%8C%81%E4%B9%85%E5%8C%96%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<h2 id="14-1-持久化方式"><a href="#14-1-持久化方式" class="headerlink" title="14.1 持久化方式"></a>14.1 持久化方式</h2><p>Redis有两种持久化的方式：</p><ul><li>RDB持久化方式:在一个特定的间隔保存那个时间点的一个数据快照。</li><li>AOF持久化方式:记录每一个服务器收到的写操作。</li></ul><p>Redis的持久化是可以禁用的，就是说你可以让数据的生命周期只存在于服务器的运行时间里。<br>两种方式的持久化是可以同时存在的，但是当Redis重启时，<strong>AOF文件会被优先用于RDB</strong></p><h2 id="14-2-优缺点"><a href="#14-2-优缺点" class="headerlink" title="14.2 优缺点"></a>14.2 优缺点</h2><h3 id="14-2-1-RDB-优缺点"><a href="#14-2-1-RDB-优缺点" class="headerlink" title="14.2.1 RDB 优缺点"></a>14.2.1 RDB 优缺点</h3><ul><li>RDB 会生成多个数据文件，每个数据文件都代表了某一个时刻中 redis 的数据，这种多个数据文件的方式，非常适合做冷备，可以将这种完整的数据文件发送到一些远程的安全存储上去，比如说 Amazon 的 S3 云服务上去，在国内可以是阿里云的 ODPS 分布式存储上，以预定好的备份策略来定期备份 redis 中的数据。</li><li>RDB 对 redis 对外提供的读写服务，影响非常小，可以让 redis 保持高性能，因为 redis 主进程只需要 fork 一个子进程，让子进程执行磁盘 IO 操作来进行 RDB 持久化即可。</li><li>相对于 AOF 持久化机制来说，直接基于 RDB 数据文件来重启和恢复 redis 进程，更加快速。</li><li>如果想要在 redis 故障时，尽可能少的丢失数据，那么 RDB 没有 AOF 好。一般来说，RDB 数据快照文件，都是每隔 5 分钟，或者更长时间生成一次，这个时候就得接受一旦 redis 进程宕机，那么会丢失最近 5 分钟的数据。</li><li>RDB 每次在 fork 子进程来执行 RDB 快照数据文件生成的时候，如果数据文件特别大，可能会导致对客户端提供的服务暂停数毫秒，或者甚至数秒。</li></ul><h3 id="14-2-2-AOF-优缺点"><a href="#14-2-2-AOF-优缺点" class="headerlink" title="14.2.2 AOF 优缺点"></a>14.2.2 AOF 优缺点</h3><ul><li>AOF 可以更好的保护数据不丢失，一般 AOF 会每隔 1 秒，通过一个后台线程执行一次fsync操作，最多丢失 1 秒钟的数据。</li><li>AOF 日志文件以 append-only 模式写入，所以没有任何磁盘寻址的开销，写入性能非常高，而且文件不容易破损，即使文件尾部破损，也很容易修复。</li><li>AOF 日志文件即使过大的时候，出现后台重写操作，也不会影响客户端的读写。因为在 rewrite log 的时候，会对其中的指令进行压缩，创建出一份需要恢复数据的最小日志出来。在创建新日志文件的时候，老的日志文件还是照常写入。当新的 merge 后的日志文件 ready 的时候，再交换新老日志文件即可。</li><li>AOF 日志文件的命令通过非常可读的方式进行记录，这个特性非常适合做灾难性的误删除的紧急恢复。比如某人不小心用 flushall 命令清空了所有数据，只要这个时候后台 rewrite 还没有发生，那么就可以立即拷贝 AOF 文件，将最后一条 flushall 命令给删了，然后再将该 AOF 文件放回去，就可以通过恢复机制，自动恢复所有数据。</li><li>对于同一份数据来说，AOF 日志文件通常比 RDB 数据快照文件更大。</li><li>AOF 开启后，支持的写 QPS 会比 RDB 支持的写 QPS 低，因为 AOF 一般会配置成每秒 fsync 一次日志文件，当然，每秒一次 fsync，性能也还是很高的。（如果实时写入，那么 QPS 会大降，redis 性能会大大降低）</li><li>以前 AOF 发生过 bug，就是通过 AOF 记录的日志，进行数据恢复的时候，没有恢复一模一样的数据出来。所以说，类似 AOF 这种较为复杂的基于命令日志 / merge / 回放的方式，比基于 RDB 每次持久化一份完整的数据快照文件的方式，更加脆弱一些，容易有 bug。不过 AOF 就是为了避免 rewrite 过程导致的 bug，因此每次 rewrite 并不是基于旧的指令日志进行 merge 的，而是基于当时内存中的数据进行指令的重新构建，这样健壮性会好很多。</li></ul><h2 id="14-3-如何选择持久化方式"><a href="#14-3-如何选择持久化方式" class="headerlink" title="14.3 如何选择持久化方式"></a>14.3 如何选择持久化方式</h2><p>redis 支持同时开启开启两种持久化方式，我们可以综合使用 AOF 和 RDB 两种持久化机制，用 AOF 来保证数据不丢失，作为数据恢复的第一选择; 用 RDB 来做不同程度的冷备，在 AOF 文件都丢失或损坏不可用的时候，还可以使用 RDB 来进行快速的数据恢复。</p><h2 id="14-3-混合持久化"><a href="#14-3-混合持久化" class="headerlink" title="14.3 混合持久化"></a>14.3 混合持久化</h2><p>重启 Redis 时，我们很少使用 rdb 来恢复内存状态，因为会丢失大量数据。</p><p>如果使用 AOF 日志重放，性能则相对 rdb 来说要慢很多，这样在 Redis 实例很大的情况下，启动的时候需要花费很长的时间。</p><p>Redis 4.0 为了解决这个问题，带来了一个新的持久化选项——混合持久化。</p><p>混合持久化同样也是通过<code>bgrewriteaof</code>完成的，不同的是当开启混合持久化时，fork出的子进程先将共享的内存副本全量的以RDB方式写入aof文件，然后在将aof_rewrite_buf重写缓冲区的增量命令以AOF方式写入到文件，写入完成后通知主进程更新统计信息，并将新的含有RDB格式和AOF格式的AOF文件替换旧的的AOF文件。</p><p>简单的说：<strong>新的AOF文件前半段是RDB格式的全量数据后半段是AOF格式的增量数据</strong>，如下图：</p><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/redis40.png" alt=""></p><p>在redis重启的时候，加载 aof 文件进行恢复数据：先加载 rdb 内容再加载剩余的 aof。</p><p>混合持久化配置：</p><pre><code class="ini">aof-use-rdb-preamble yes  # yes：开启，no：关闭</code></pre><h2 id="14-4-云厂商的改进"><a href="#14-4-云厂商的改进" class="headerlink" title="14.4 云厂商的改进"></a>14.4 云厂商的改进</h2><p>不同云厂商为了<code>赚钱</code>都对Redis做了不同的二次开发,阿里云做了一个Redis基于AOF日志的增量同步机制设计方案还不错,具体可以参考此篇文章:</p><p><a href="https://yq.aliyun.com/articles/68350" target="_blank" rel="noopener">Redis内核基于时间点的备份恢复和基于AOF日志的增量同步机制设计</a></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>13.Redis持久化——AOF</title>
      <link href="/2020/02/21/13-Redis%E6%8C%81%E4%B9%85%E5%8C%96-AOF/"/>
      <url>/2020/02/21/13-Redis%E6%8C%81%E4%B9%85%E5%8C%96-AOF/</url>
      
        <content type="html"><![CDATA[<h2 id="13-1-AOF机制"><a href="#13-1-AOF机制" class="headerlink" title="13.1 AOF机制"></a>13.1 AOF机制</h2><p>AOF 机制对每条写入命令作为日志，以 append-only 的模式写入一个日志文件中，在 redis 重启的时候，可以通过回放 AOF 日志中的写入指令来重新构建整个数据集。</p><p>类似于mysql的<code>redo log</code></p><h2 id="13-2-配置"><a href="#13-2-配置" class="headerlink" title="13.2 配置"></a>13.2 配置</h2><pre><code class="ini">############ APPEND ONLY MODE ###########......#如果 appendonly 配置为 no，则不启用 AOF 方式进行备份。如果 appendonly 配置为 yes，则以 AOF 方式备份 Redis 数据，那么此时 Redis 会按照配置，在特定的时候执行追加命令，用以备份数据。appendonly no......#这里定义追加的写入文件为 appendonly.aofappendfilename &quot;appendonly.aof&quot;......#appendfsync always#每次有新命令追加到 AOF 文件时就执行一次 fsync ：非常慢，也非常安全。appendfsync everysec#每秒 fsync 一次：足够快（和使用 RDB 持久化差不多），并且在故障时只会丢失 1 秒钟的数据。#appendfsync no#从不 fsync ：将数据交给操作系统来处理。更快，也更不安全的选择。......#它指定 Redis 重写 AOF 文件的条件，默认为 100，表示与上次 rewrite 的 AOF 文件大小相比，当前 AOF 文件增长量超过上次 AOF 文件大小的 100% 时，就会触发 background rewrite。若配置为 0，则会禁用自动 rewriteauto-aof-rewrite-percentage 100#它指定触发 rewrite 的AOF文件大小。若AOF文件小于该值，即使当前文件的增量比例达到 auto-aof-rewrite-percentage的配置值，也不会触发自动rewrite。即这两个配置项同时满足时，才会触发rewrite。auto-aof-rewrite-min-size 64mb......#Redis 在恢复时会忽略最后一条可能存在问题的指令，默认为 yes。即在 AOF 写入时，可能存在指令写错的问题（突然断电、写了一半），这种情况下 yes 会 log 并继续，而 no 会直接恢复失败。aof-load-truncated yes......</code></pre><h2 id="13-3-AOF持久化过程"><a href="#13-3-AOF持久化过程" class="headerlink" title="13.3 AOF持久化过程"></a>13.3 AOF持久化过程</h2><pre><code class="c">#file: src/aof.c/*  * 将 AOF 缓存写入到文件中。 * * 因为程序需要在回复客户端之前对 AOF 执行写操作。 * 而客户端能执行写操作的唯一机会就是在事件 loop 中， * 因此，程序将所有 AOF 写累积到缓存中， * 并在重新进入事件 loop 之前，将缓存写入到文件中。 * * 关于 force 参数： * * 当 fsync 策略为每秒钟保存一次时，如果后台线程仍然有 fsync 在执行， * 那么我们可能会延迟执行冲洗（flush）操作， * 因为 Linux 上的 write(2) 会被后台的 fsync 阻塞。 * * 当这种情况发生时，说明需要尽快冲洗 aof 缓存， * 程序会尝试在 serverCron() 函数中对缓存进行冲洗。 * * 不过，如果 force 为 1 的话，那么不管后台是否正在 fsync ， * 程序都直接进行写入。 */#define AOF_WRITE_LOG_ERROR_RATE 30 /* Seconds between errors logging. */void flushAppendOnlyFile(int force) {    ssize_t nwritten;    int sync_in_progress = 0;    // 缓冲区中没有任何内容，直接返回    if (sdslen(server.aof_buf) == 0) return;    // 策略为每秒 FSYNC     if (server.aof_fsync == AOF_FSYNC_EVERYSEC)        // 是否有 SYNC 正在后台进行？        sync_in_progress = bioPendingJobsOfType(REDIS_BIO_AOF_FSYNC) != 0;    // 每秒 fsync ，并且强制写入为假    if (server.aof_fsync == AOF_FSYNC_EVERYSEC &amp;&amp; !force) {        /*         * 当 fsync 策略为每秒钟一次时， fsync 在后台执行。         *         * 如果后台仍在执行 FSYNC ，那么我们可以延迟写操作一两秒         * （如果强制执行 write 的话，服务器主线程将阻塞在 write 上面）         */        if (sync_in_progress) {            // 有 fsync 正在后台进行 。。。            if (server.aof_flush_postponed_start == 0) {                /*                 * 前面没有推迟过 write 操作，这里将推迟写操作的时间记录下来                 * 然后就返回，不执行 write 或者 fsync                 */                server.aof_flush_postponed_start = server.unixtime;                return;            } else if (server.unixtime - server.aof_flush_postponed_start &lt; 2) {                /*                 * 如果之前已经因为 fsync 而推迟了 write 操作                 * 但是推迟的时间不超过 2 秒，那么直接返回                 * 不执行 write 或者 fsync                 */                return;            }            /*              * 如果后台还有 fsync 在执行，并且 write 已经推迟 &gt;= 2 秒             * 那么执行写操作（write 将被阻塞）             */            server.aof_delayed_fsync++;            redisLog(REDIS_NOTICE,&quot;Asynchronous AOF fsync is taking too long (disk is busy?). Writing the AOF buffer without waiting for fsync to complete, this may slow down Redis.&quot;);        }    }    /*      * 执行到这里，程序会对 AOF 文件进行写入。     *     * 清零延迟 write 的时间记录     */    server.aof_flush_postponed_start = 0;    /*      * 执行单个 write 操作，如果写入设备是物理的话，那么这个操作应该是原子的     *     * 当然，如果出现像电源中断这样的不可抗现象，那么 AOF 文件也是可能会出现问题的     * 这时就要用 redis-check-aof 程序来进行修复。     */    nwritten = write(server.aof_fd,server.aof_buf,sdslen(server.aof_buf));    if (nwritten != (signed)sdslen(server.aof_buf)) {        static time_t last_write_error_log = 0;        int can_log = 0;        // 将日志的记录频率限制在每行 AOF_WRITE_LOG_ERROR_RATE 秒        if ((server.unixtime - last_write_error_log) &gt; AOF_WRITE_LOG_ERROR_RATE) {            can_log = 1;            last_write_error_log = server.unixtime;        }        // 如果写入出错，那么尝试将该情况写入到日志里面        if (nwritten == -1) {            if (can_log) {                redisLog(REDIS_WARNING,&quot;Error writing to the AOF file: %s&quot;,                    strerror(errno));                server.aof_last_write_errno = errno;            }        } else {            if (can_log) {                redisLog(REDIS_WARNING,&quot;Short write while writing to &quot;                                       &quot;the AOF file: (nwritten=%lld, &quot;                                       &quot;expected=%lld)&quot;,                                       (long long)nwritten,                                       (long long)sdslen(server.aof_buf));            }            // 尝试移除新追加的不完整内容            if (ftruncate(server.aof_fd, server.aof_current_size) == -1) {                if (can_log) {                    redisLog(REDIS_WARNING, &quot;Could not remove short write &quot;                             &quot;from the append-only file.  Redis may refuse &quot;                             &quot;to load the AOF the next time it starts.  &quot;                             &quot;ftruncate: %s&quot;, strerror(errno));                }            } else {                nwritten = -1;            }            server.aof_last_write_errno = ENOSPC;        }        // 处理写入 AOF 文件时出现的错误        if (server.aof_fsync == AOF_FSYNC_ALWAYS) {            redisLog(REDIS_WARNING,&quot;Can&#39;t recover from AOF write error when the AOF fsync policy is &#39;always&#39;. Exiting...&quot;);            exit(1);        } else {            server.aof_last_write_status = REDIS_ERR;            if (nwritten &gt; 0) {                server.aof_current_size += nwritten;                sdsrange(server.aof_buf,nwritten,-1);            }            return;         }    } else {        /* Successful write(2). If AOF was in error state, restore the         * OK state and log the event. */        // 写入成功，更新最后写入状态        if (server.aof_last_write_status == REDIS_ERR) {            redisLog(REDIS_WARNING,                &quot;AOF write error looks solved, Redis can write again.&quot;);            server.aof_last_write_status = REDIS_OK;        }    }    // 更新写入后的 AOF 文件大小    server.aof_current_size += nwritten;    /*     * 如果 AOF 缓存的大小足够小的话，那么重用这个缓存，     * 否则的话，释放 AOF 缓存。     */    if ((sdslen(server.aof_buf)+sdsavail(server.aof_buf)) &lt; 4000) {        // 清空缓存中的内容，等待重用        sdsclear(server.aof_buf);    } else {        // 释放缓存        sdsfree(server.aof_buf);        server.aof_buf = sdsempty();    }    /*      * 如果 no-appendfsync-on-rewrite 选项为开启状态，     * 并且有 BGSAVE 或者 BGREWRITEAOF 正在进行的话，     * 那么不执行 fsync      */    if (server.aof_no_fsync_on_rewrite &amp;&amp;        (server.aof_child_pid != -1 || server.rdb_child_pid != -1))            return;    // 总是执行 fsnyc    if (server.aof_fsync == AOF_FSYNC_ALWAYS) {        aof_fsync(server.aof_fd);         // 更新最后一次执行 fsnyc 的时间        server.aof_last_fsync = server.unixtime;    // 策略为每秒 fsnyc ，并且距离上次 fsync 已经超过 1 秒    } else if ((server.aof_fsync == AOF_FSYNC_EVERYSEC &amp;&amp;                server.unixtime &gt; server.aof_last_fsync)) {        // 放到后台执行        if (!sync_in_progress) aof_background_fsync(server.aof_fd);        // 更新最后一次执行 fsync 的时间        server.aof_last_fsync = server.unixtime;    }}</code></pre><h2 id="13-4-AOF重写"><a href="#13-4-AOF重写" class="headerlink" title="13.4 AOF重写"></a>13.4 AOF重写</h2><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/aofDuring.png" alt=""></p><p>AOF文件重写过程与RDB快照bgsave工作过程有点相似，都是通过fork子进程，由子进程完成相应的操作，同样的在fork子进程简短的时间内，redis是阻塞的。</p><p>（1）开始bgrewriteaof，判断当前有没有bgsave命令(RDB持久化)/bgrewriteaof在执行，倘若有，则这些命令执行完成以后在执行。</p><p>（2）主进程fork出子进程，在这一个短暂的时间内，redis是阻塞的。</p><p>（3）主进程fork完子进程继续接受客户端请求。此时，客户端的写请求不仅仅写入aof_buf缓冲区，还写入aof_rewrite_buf重写缓冲区。一方面是写入aof_buf缓冲区并根据appendfsync策略同步到磁盘，保证原有AOF文件完整和正确。另一方面写入aof_rewrite_buf重写缓冲区，保存fork之后的客户端的写请求，防止新AOF文件生成期间丢失这部分数据。</p><p>（4.1）子进程写完新的AOF文件后，向主进程发信号，父进程更新统计信息。</p><p>（4.2）主进程把aof_rewrite_buf中的数据写入到新的AOF文件。</p><p>（5）使用新的AOF文件覆盖旧的AOF文件，标志AOF重写完成。</p><h2 id="13-5-文件类型"><a href="#13-5-文件类型" class="headerlink" title="13.5 文件类型"></a>13.5 文件类型</h2><p>可读文本文件,但大小比RDB文件大的多</p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>12.Redis持久化——RDB</title>
      <link href="/2020/02/21/12-Redis%E6%8C%81%E4%B9%85%E5%8C%96-RDB/"/>
      <url>/2020/02/21/12-Redis%E6%8C%81%E4%B9%85%E5%8C%96-RDB/</url>
      
        <content type="html"><![CDATA[<h2 id="12-1-RDB机制"><a href="#12-1-RDB机制" class="headerlink" title="12.1 RDB机制"></a>12.1 RDB机制</h2><p>RDB其实就是把数据以快照的形式保存在磁盘上。</p><p>RDB持久化是指在指定的时间间隔内将内存中的数据集快照写入磁盘。也是<code>默认的持久化方式</code>，这种方式是就是将内存中数据以快照的方式写入到二进制文件中,默认的文件名为dump.rdb。</p><h2 id="12-2-触发方式"><a href="#12-2-触发方式" class="headerlink" title="12.2 触发方式"></a>12.2 触发方式</h2><ul><li>手动触发：执行BGSAVE命令</li><li>自动触发：配置SAVE选项，在指定时间内发生指定次数的key修改，自动进行后台RDB SAVE</li></ul><pre><code class="c">#file: src/rdb.cvoid saveCommand(redisClient *c) {    // BGSAVE 已经在执行中，不能再执行 SAVE    // 否则将产生竞争条件    if (server.rdb_child_pid != -1) {        addReplyError(c,&quot;Background save already in progress&quot;);        return;    }    // 执行     if (rdbSave(server.rdb_filename) == REDIS_OK) {        addReply(c,shared.ok);    } else {        addReply(c,shared.err);    }}void bgsaveCommand(redisClient *c) {    // 不能重复执行 BGSAVE    if (server.rdb_child_pid != -1) {        addReplyError(c,&quot;Background save already in progress&quot;);    // 不能在 BGREWRITEAOF 正在运行时执行    } else if (server.aof_child_pid != -1) {        addReplyError(c,&quot;Can&#39;t BGSAVE while AOF log rewriting is in progress&quot;);    // 执行 BGSAVE    } else if (rdbSaveBackground(server.rdb_filename) == REDIS_OK) {        addReplyStatus(c,&quot;Background saving started&quot;);    } else {        addReply(c,shared.err);    }}int rdbSaveBackground(char *filename) {    pid_t childpid;    long long start;......    start = ustime();    if ((childpid = fork()) == 0) {        int retval;        /* Child */        // 关闭网络连接 fd        closeListeningSockets(0);        // 设置进程的标题，方便识别        redisSetProcTitle(&quot;redis-rdb-bgsave&quot;);        // 执行保存操作        retval = rdbSave(filename);......        // 向父进程发送信号        exitFromChild((retval == REDIS_OK) ? 0 : 1);    } else {......    }    return REDIS_OK; /* unreached */}/* Save the DB on disk. Return REDIS_ERR on error, REDIS_OK on success  * * 将数据库保存到磁盘上。 * * 保存成功返回 REDIS_OK ，出错/失败返回 REDIS_ERR 。 */int rdbSave(char *filename) {    dictIterator *di = NULL;    dictEntry *de;    char tmpfile[256];    char magic[10];    int j;    long long now = mstime();    FILE *fp;    rio rdb;    uint64_t cksum;    // 创建临时文件    snprintf(tmpfile,256,&quot;temp-%d.rdb&quot;, (int) getpid());    fp = fopen(tmpfile,&quot;w&quot;);    if (!fp) {        redisLog(REDIS_WARNING, &quot;Failed opening .rdb for saving: %s&quot;,            strerror(errno));        return REDIS_ERR;    }    // 初始化 I/O    rioInitWithFile(&amp;rdb,fp);    // 设置校验和函数    if (server.rdb_checksum)        rdb.update_cksum = rioGenericUpdateChecksum;    // 写入 RDB 版本号    snprintf(magic,sizeof(magic),&quot;REDIS%04d&quot;,REDIS_RDB_VERSION);    if (rdbWriteRaw(&amp;rdb,magic,9) == -1) goto werr;    // 遍历所有数据库    for (j = 0; j &lt; server.dbnum; j++) {        // 指向数据库        redisDb *db = server.db+j;        // 指向数据库键空间        dict *d = db-&gt;dict;        // 跳过空数据库        if (dictSize(d) == 0) continue;        // 创建键空间迭代器        di = dictGetSafeIterator(d);        if (!di) {            fclose(fp);            return REDIS_ERR;        }        /* Write the SELECT DB opcode          *         * 写入 DB 选择器         */        if (rdbSaveType(&amp;rdb,REDIS_RDB_OPCODE_SELECTDB) == -1) goto werr;        if (rdbSaveLen(&amp;rdb,j) == -1) goto werr;        /* Iterate this DB writing every entry          *         * 遍历数据库，并写入每个键值对的数据         */        while((de = dictNext(di)) != NULL) {            sds keystr = dictGetKey(de);            robj key, *o = dictGetVal(de);            long long expire;            // 根据 keystr ，在栈中创建一个 key 对象            initStaticStringObject(key,keystr);            // 获取键的过期时间            expire = getExpire(db,&amp;key);            // 保存键值对数据            if (rdbSaveKeyValuePair(&amp;rdb,&amp;key,o,expire,now) == -1) goto werr;        }        dictReleaseIterator(di);    }    di = NULL; /* So that we don&#39;t release it again on error. */    /* EOF opcode      *     * 写入 EOF 代码     */    if (rdbSaveType(&amp;rdb,REDIS_RDB_OPCODE_EOF) == -1) goto werr;    /*      * CRC64 校验和。     */    cksum = rdb.cksum;    memrev64ifbe(&amp;cksum);    rioWrite(&amp;rdb,&amp;cksum,8);    /* Make sure data will not remain on the OS&#39;s output buffers */    // 冲洗缓存，确保数据已写入磁盘    if (fflush(fp) == EOF) goto werr;    if (fsync(fileno(fp)) == -1) goto werr;    if (fclose(fp) == EOF) goto werr;    /*      * 使用 RENAME ，原子性地对临时文件进行改名，覆盖原来的 RDB 文件。     */    if (rename(tmpfile,filename) == -1) {        redisLog(REDIS_WARNING,&quot;Error moving temp DB file on the final destination: %s&quot;, strerror(errno));        unlink(tmpfile);        return REDIS_ERR;    }    // 写入完成，打印日志    redisLog(REDIS_NOTICE,&quot;DB saved on disk&quot;);    // 清零数据库脏状态    server.dirty = 0;    // 记录最后一次完成 SAVE 的时间    server.lastsave = time(NULL);    // 记录最后一次执行 SAVE 的状态    server.lastbgsave_status = REDIS_OK;    return REDIS_OK;werr:    // 关闭文件    fclose(fp);    // 删除文件    unlink(tmpfile);    redisLog(REDIS_WARNING,&quot;Write error saving DB on disk: %s&quot;, strerror(errno));    if (di) dictReleaseIterator(di);    return REDIS_ERR;}</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/rdbduring.png" alt=""></p><h2 id="12-3-配置"><a href="#12-3-配置" class="headerlink" title="12.3 配置"></a>12.3 配置</h2><pre><code class="ini">#file: redis.conf############SNAPSHOTTING#######......#当900秒执行1个写命令时，启用快照备份save 900 1#当300秒执行10个写命令时，启用快照备份save 300 10#当60秒内执行10000个写命令时，启用快照备份save 60 10000......#Redis 执行 save 命令的时候，将禁止写入命令#在默认情况下，如果 Redis 执行 bgsave 失败后，Redis 将停止接受写操作，这样以一种强硬的方式让用户知道数据不能正确的持久化到磁盘，否则就会没人注意到灾难的发生，如果后台保存进程重新启动工作了，Redis 也将自动允许写操作。然而如果安装了靠谱的监控，可能不希望 Redis 这样做，那么你可以将其修改为 no。stop-writes-on-bgsave-error yes......#这个命令意思是是否对 rbd 文件进行检验，如果是将对 rdb 文件检验。从 dbfilename 的配置可以知道，rdb 文件实际是 Redis 持久化的数据文件。rdbcompression yes......dbfilename dump.rdb</code></pre><h2 id="12-4-文件类型"><a href="#12-4-文件类型" class="headerlink" title="12.4 文件类型"></a>12.4 文件类型</h2><p>RDB保存的文件是一个二进制文件，可以通过redis自带的工具<code>redis-check-dump</code>来查看里面的内容</p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>11.Redis过期机制</title>
      <link href="/2020/02/20/11-Redis%E8%BF%87%E6%9C%9F%E6%9C%BA%E5%88%B6/"/>
      <url>/2020/02/20/11-Redis%E8%BF%87%E6%9C%9F%E6%9C%BA%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<h2 id="11-1-RedisDb结构"><a href="#11-1-RedisDb结构" class="headerlink" title="11.1 RedisDb结构"></a>11.1 RedisDb结构</h2><p>每个Redis服务都有多个Db库,每个库记录了不同应用的数据信息</p><p>RedisDb的结构如下:</p><pre><code class="c">#file : src/redis.htypedef struct redisDb {    // 数据库键空间，保存着数据库中的所有键值对    dict *dict;                 /* The keyspace for this DB */    // 键的过期时间，字典的键为键，字典的值为过期事件 UNIX 时间戳    dict *expires;              /* Timeout of keys with a timeout set */    // 正处于阻塞状态的键    dict *blocking_keys;        /* Keys with clients waiting for data (BLPOP) */    // 可以解除阻塞的键    dict *ready_keys;           /* Blocked keys that received a PUSH */    // 正在被 WATCH 命令监视的键    dict *watched_keys;         /* WATCHED keys for MULTI/EXEC CAS */    struct evictionPoolEntry *eviction_pool;    /* Eviction pool of keys */    // 数据库号码    int id;                     /* Database ID */    // 数据库的键的平均 TTL ，统计信息    long long avg_ttl;          /* Average TTL, just for stats */} redisDb;</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/redisdb.png" alt=""></p><p>redisDb结构的expires字典保存了数据库中所有键的过期时间:</p><ul><li>过期字典的键是一个指针,指向某个键对象</li><li>过期字典的值是一个long long 类型的整数,这个整数报错了键所指向数据库的过期时间,是一个毫秒精度的UNIX时间戳</li></ul><h2 id="11-2-设置过期时间"><a href="#11-2-设置过期时间" class="headerlink" title="11.2 设置过期时间"></a>11.2 设置过期时间</h2><pre><code class="c">#file : src/redis.cvoid expireCommand(redisClient *c) {    expireGenericCommand(c,mstime(),UNIT_SECONDS);}void expireatCommand(redisClient *c) {    expireGenericCommand(c,0,UNIT_SECONDS);}void pexpireCommand(redisClient *c) {    expireGenericCommand(c,mstime(),UNIT_MILLISECONDS);}void pexpireatCommand(redisClient *c) {    expireGenericCommand(c,0,UNIT_MILLISECONDS);}/*  * 这个函数是 EXPIRE 、 PEXPIRE 、 EXPIREAT 和 PEXPIREAT 命令的底层实现函数。 * * 命令的第二个参数可能是绝对值，也可能是相对值。 * 当执行 *AT 命令时， basetime 为 0 ，在其他情况下，它保存的就是当前的绝对时间。 * * unit 用于指定 argv[2] （传入过期时间）的格式， * 它可以是 UNIT_SECONDS 或 UNIT_MILLISECONDS ， * basetime 参数则总是毫秒格式的。 */void expireGenericCommand(redisClient *c, long long basetime, int unit) {    robj *key = c-&gt;argv[1], *param = c-&gt;argv[2];    long long when; /* unix time in milliseconds when the key will expire. */    // 取出 when 参数    if (getLongLongFromObjectOrReply(c, param, &amp;when, NULL) != REDIS_OK)        return;    // 如果传入的过期时间是以秒为单位的，那么将它转换为毫秒    if (unit == UNIT_SECONDS) when *= 1000;    when += basetime;    /* No key, return zero. */    // 取出键    if (lookupKeyRead(c-&gt;db,key) == NULL) {        addReply(c,shared.czero);        return;    }    /*      * 在载入数据时，或者服务器为附属节点时，     * 即使 EXPIRE 的 TTL 为负数，或者 EXPIREAT 提供的时间戳已经过期，     * 服务器也不会主动删除这个键，而是等待主节点发来显式的 DEL 命令。     *     * 程序会继续将（一个可能已经过期的 TTL）设置为键的过期时间，     * 并且等待主节点发来 DEL 命令。     */    if (when &lt;= mstime() &amp;&amp; !server.loading &amp;&amp; !server.masterhost) {        // when 提供的时间已经过期，服务器为主节点，并且没在载入数据        robj *aux;        redisAssertWithInfo(c,key,dbDelete(c-&gt;db,key));        server.dirty++;        // 传播 DEL 命令        aux = createStringObject(&quot;DEL&quot;,3);        rewriteClientCommandVector(c,2,aux,key);        decrRefCount(aux);        signalModifiedKey(c-&gt;db,key);        notifyKeyspaceEvent(REDIS_NOTIFY_GENERIC,&quot;del&quot;,key,c-&gt;db-&gt;id);        addReply(c, shared.cone);        return;    } else {        // 设置键的过期时间        // 如果服务器为附属节点，或者服务器正在载入，        // 那么这个 when 有可能已经过期的        setExpire(c-&gt;db,key,when);        addReply(c,shared.cone);        signalModifiedKey(c-&gt;db,key);        notifyKeyspaceEvent(REDIS_NOTIFY_GENERIC,&quot;expire&quot;,key,c-&gt;db-&gt;id);        server.dirty++;        return;    }}</code></pre><h2 id="11-3-过期键的删除策略"><a href="#11-3-过期键的删除策略" class="headerlink" title="11.3 过期键的删除策略"></a>11.3 过期键的删除策略</h2><ul><li>被动删除机制——惰性删除</li><li>主动删除机制——定期删除</li></ul><p>这两种删除机制下,如果内存满了需要释放,会走Redis的内存淘汰机制</p><h3 id="11-3-1-惰性删除"><a href="#11-3-1-惰性删除" class="headerlink" title="11.3.1 惰性删除"></a>11.3.1 惰性删除</h3><p>惰性删除: 放任过期键不管,但是每次从键空间获取建时,都检查取得的键是否过期,如果过期就删除该键,如果没过期就返回该键</p><p>优点:对CPU时间来说最友好</p><p>缺点:对内存最不友好,占用的内存一直不释放</p><p>实现代码：</p><pre><code class="c">#file: src/db.c/* * 检查 key 是否已经过期，如果是的话，将它从数据库中删除。 * 返回 0 表示键没有过期时间，或者键未过期。 * 返回 1 表示键已经因为过期而被删除了。 */int expireIfNeeded(redisDb *db, robj *key) {    // 取出键的过期时间    mstime_t when = getExpire(db,key);    mstime_t now;    // 没有过期时间    if (when &lt; 0) return 0; /* No expire for this key */    // 如果服务器正在进行载入，那么不进行任何过期检查    if (server.loading) return 0;    now = server.lua_caller ? server.lua_time_start : mstime();    // 当服务器运行在 replication 模式时    // 附属节点并不主动删除 key    // 它只返回一个逻辑上正确的返回值    // 真正的删除操作要等待主节点发来删除命令时才执行    // 从而保证数据的同步    if (server.masterhost != NULL) return now &gt; when;    // 运行到这里，表示键带有过期时间，并且服务器为主节点    // 如果未过期，返回 0    if (now &lt;= when) return 0;    /* Delete the key */    server.stat_expiredkeys++;    // 向 AOF 文件和附属节点传播过期信息    propagateExpire(db,key);    // 发送事件通知    notifyKeyspaceEvent(REDIS_NOTIFY_EXPIRED,        &quot;expired&quot;,key,db-&gt;id);    // 将过期键从数据库中删除    return dbDelete(db,key);}</code></pre><h3 id="11-3-2-定期删除"><a href="#11-3-2-定期删除" class="headerlink" title="11.3.2 定期删除"></a>11.3.2 定期删除</h3><p>定期删除:每隔一段时间,程序就会对数据库进行检查,删除里面的过期键，定期删除通过限制删除操作执行的时长和频率来减少删除操作对CPU的影响，通过定期删除可以有效的减少因为过期键而带来的内存浪费</p><p>定期删除策略是通过redis指定周期性函数<code>serverCron</code>时,调用对数据库执行的各种操作<code>databasesCron</code>,<code>databasesCron</code>调用<code>redis.c/activeExpireCycle</code>函数实现的,serverCron的调用频率是10HZ,所以定期删除`每100ms执行一次</p><blockquote><p>server.hz = 10 一秒钟执行10次</p><p>serverCron—-&gt;databasesCron—–&gt;activeExpireCycle</p></blockquote><pre><code class="c">#file: src/redis.c/*  * 函数尝试删除数据库中已经过期的键。 * 当带有过期时间的键比较少时，函数运行得比较保守， * 如果带有过期时间的键比较多，那么函数会以更积极的方式来删除过期键， * 从而可能地释放被过期键占用的内存。 * * 每次循环中被测试的数据库数目不会超过 REDIS_DBCRON_DBS_PER_CALL　默认16 。 * * * 如果 timelimit_exit 为真，那么说明还有更多删除工作要做， * 那么在 beforeSleep() 函数调用时，程序会再次执行这个函数。 * * * 过期循环的类型： * * 如果循环的类型为 ACTIVE_EXPIRE_CYCLE_FAST ， * 那么函数会以“快速过期”模式执行， * 执行的时间不会长过 EXPIRE_FAST_CYCLE_DURATION 毫秒， * 并且在 EXPIRE_FAST_CYCLE_DURATION 毫秒之内不会再重新执行。 * * 如果循环的类型为 ACTIVE_EXPIRE_CYCLE_SLOW ， * 那么函数会以“正常过期”模式执行， * 函数的执行时限为 REDIS_HS 常量的一个百分比， * 这个百分比由 REDIS_EXPIRELOOKUPS_TIME_PERC 定义。 */void activeExpireCycle(int type) {    // 静态变量，用来累积函数连续执行时的数据    static unsigned int current_db = 0; /* Last DB tested. */    static int timelimit_exit = 0;      /* Time limit hit in previous call? */    static long long last_fast_cycle = 0; /* When last fast cycle ran. */    unsigned int j, iteration = 0;    // 默认每次处理的数据库数量    unsigned int dbs_per_call = REDIS_DBCRON_DBS_PER_CALL;    // 函数开始的时间    long long start = ustime(), timelimit;    // 快速模式    if (type == ACTIVE_EXPIRE_CYCLE_FAST) {        // 如果上次函数没有触发 timelimit_exit ，那么不执行处理        if (!timelimit_exit) return;        // 如果距离上次执行未够一定时间，那么不执行处理        if (start &lt; last_fast_cycle + ACTIVE_EXPIRE_CYCLE_FAST_DURATION*2) return;        // 运行到这里，说明执行快速处理，记录当前时间        last_fast_cycle = start;    }    /*      * 一般情况下，函数只处理 REDIS_DBCRON_DBS_PER_CALL 个数据库，     * 除非：     *     * 1) 当前数据库的数量小于 REDIS_DBCRON_DBS_PER_CALL     * 2) 如果上次处理遇到了时间上限，那么这次需要对所有数据库进行扫描，     *     这可以避免过多的过期键占用空间     */    if (dbs_per_call &gt; server.dbnum || timelimit_exit)        dbs_per_call = server.dbnum;    // 函数处理的微秒时间上限    // ACTIVE_EXPIRE_CYCLE_SLOW_TIME_PERC 默认为 25 ，也即是 25 % 的 CPU 时间    timelimit = 1000000*ACTIVE_EXPIRE_CYCLE_SLOW_TIME_PERC/server.hz/100;    timelimit_exit = 0;    if (timelimit &lt;= 0) timelimit = 1;    // 如果是运行在快速模式之下    // 那么最多只能运行 FAST_DURATION 微秒     // 默认值为 1000 （微秒）    if (type == ACTIVE_EXPIRE_CYCLE_FAST)        timelimit = ACTIVE_EXPIRE_CYCLE_FAST_DURATION; /* in microseconds. */    // 遍历数据库    for (j = 0; j &lt; dbs_per_call; j++) {        int expired;        // 指向要处理的数据库        redisDb *db = server.db+(current_db % server.dbnum);        // 为 DB 计数器加一，如果进入 do 循环之后因为超时而跳出        // 那么下次会直接从下个 DB 开始处理        current_db++;        do {            unsigned long num, slots;            long long now, ttl_sum;            int ttl_samples;            // 获取数据库中带过期时间的键的数量            // 如果该数量为 0 ，直接跳过这个数据库            if ((num = dictSize(db-&gt;expires)) == 0) {                db-&gt;avg_ttl = 0;                break;            }            // 获取数据库中键值对的数量            slots = dictSlots(db-&gt;expires);            // 当前时间            now = mstime();            // 这个数据库的使用率低于 1% ，扫描起来太费力了（大部分都会 MISS）            // 跳过，等待字典收缩程序运行            if (num &amp;&amp; slots &gt; DICT_HT_INITIAL_SIZE &amp;&amp;                (num*100/slots &lt; 1)) break;            /*             * 样本计数器             */            // 已处理过期键计数器            expired = 0;            // 键的总 TTL 计数器            ttl_sum = 0;            // 总共处理的键计数器            ttl_samples = 0;            // 每次最多只能检查 LOOKUPS_PER_LOOP 个键            if (num &gt; ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP)                num = ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP;            // 开始遍历数据库            while (num--) {                dictEntry *de;                long long ttl;                // 从 expires 中随机取出一个带过期时间的键                if ((de = dictGetRandomKey(db-&gt;expires)) == NULL) break;                // 计算 TTL                ttl = dictGetSignedIntegerVal(de)-now;                // 如果键已经过期，那么删除它，并将 expired 计数器增一                if (activeExpireCycleTryExpire(db,de,now)) expired++;                if (ttl &lt; 0) ttl = 0;                // 累积键的 TTL                ttl_sum += ttl;                // 累积处理键的个数                ttl_samples++;            }            // 为这个数据库更新平均 TTL 统计数据            if (ttl_samples) {                // 计算当前平均值                long long avg_ttl = ttl_sum/ttl_samples;                // 如果这是第一次设置数据库平均 TTL ，那么进行初始化                if (db-&gt;avg_ttl == 0) db-&gt;avg_ttl = avg_ttl;                /* Smooth the value averaging with the previous one. */                // 取数据库的上次平均 TTL 和今次平均 TTL 的平均值                db-&gt;avg_ttl = (db-&gt;avg_ttl+avg_ttl)/2;            }            // 我们不能用太长时间处理过期键，            // 所以这个函数执行一定时间之后就要返回            // 更新遍历次数            iteration++;            // 每遍历 16 次执行一次            if ((iteration &amp; 0xf) == 0 &amp;&amp; /* check once every 16 iterations. */                (ustime()-start) &gt; timelimit)            {                // 如果遍历次数正好是 16 的倍数                // 并且遍历的时间超过了 timelimit                // 那么断开 timelimit_exit                timelimit_exit = 1;            }            // 已经超时了，返回            if (timelimit_exit) return;            // 如果已删除的过期键占当前总数据库带过期时间的键数量的 25 %            // 那么不再遍历        } while (expired &gt; ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP/4);    }}</code></pre><ol><li>设置每次遍历数据库数量的最大值:REDIS_DBCRON_DBS_PER_CALL(16)个</li><li>设置运行的最长时间:<ul><li>slow模式下最多运行25000微秒＝1000000*ACTIVE_EXPIRE_CYCLE_SLOW_TIME_PERC/server.hz/100</li><li>fast模式下最多运行1000微妙＝ACTIVE_EXPIRE_CYCLE_FAST_DURATION</li></ul></li><li>设置每遍历一个数据库最多取ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP(20)个键值</li><li>如果已删除的过期键占当前总数据库带过期时间的键数量的 25 %不再进行遍历</li></ol><h2 id="11-4-内存淘汰机制"><a href="#11-4-内存淘汰机制" class="headerlink" title="11.4 内存淘汰机制"></a>11.4 内存淘汰机制</h2><p>如果定期删除漏掉了很多键，惰性删除也没有进行,Redis会使用内存淘汰机制来释放内存</p><ul><li><p>noeviction：当内存不足以容纳新写入数据时，新写入操作会报错。<code>默认策略</code></p></li><li><p>allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key。</p></li><li><p>allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key。</p></li><li><p>volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key。</p></li><li><p>volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key。</p></li><li><p>volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除。</p></li><li><p>allkey-lfu: 获取所有key的访问频度删除访问最少的key</p></li><li><p>volatile-lfu:获取过期key的访问频度删除访问最少的key</p></li></ul><blockquote><p>如何选取合适的策略？</p><p>比较推荐的是两种lru策略。根据自己的业务需求。如果你使用Redis只是作为缓存，不作为DB持久化，那推荐选择allkeys-lru；如果你使用Redis同时用于缓存和数据持久化，那推荐选择volatile-lru。</p></blockquote><pre><code class="ini">#file : redis.conf# MAXMEMORY POLICY: how Redis will select what to remove when maxmemory# is reached. You can select among five behaviors:# # volatile-lru -&gt; remove the key with an expire set using an LRU algorithm# allkeys-lru -&gt; remove any key accordingly to the LRU algorithm# volatile-random -&gt; remove a random key with an expire set# allkeys-random -&gt; remove a random key, any key# volatile-ttl -&gt; remove the key with the nearest expire time (minor TTL)# noeviction -&gt; don&#39;t expire at all, just return an error on write operations## The default is:# maxmemory-policy noeviction</code></pre><h2 id="11-5-LRU算法"><a href="#11-5-LRU算法" class="headerlink" title="11.5 LRU算法"></a>11.5 LRU算法</h2><h3 id="11-5-1-什么是LRU"><a href="#11-5-1-什么是LRU" class="headerlink" title="11.5.1 什么是LRU"></a>11.5.1 什么是LRU</h3><p>就是一种缓存淘汰策略。</p><p>计算机的缓存容量有限，如果缓存满了就要删除一些内容，给新内容腾位置。但问题是，删除哪些内容呢？我们肯定希望删掉哪些没什么用的缓存，而把有用的数据继续留在缓存里，方便之后继续使用。那么，什么样的数据，我们判定为「有用的」的数据呢？</p><p>LRU 缓存淘汰算法就是一种常用策略。LRU 的全称是 Least Recently Used，也就是说我们认为最近使用过的数据应该是是「有用的」，很久都没用过的数据应该是无用的，内存满了就优先删那些很久没用过的数据。</p><h3 id="11-5-2-LRU的实现"><a href="#11-5-2-LRU的实现" class="headerlink" title="11.5.2 LRU的实现"></a>11.5.2 LRU的实现</h3><p>LRU 算法实际上是让你设计数据结构：首先要接收一个 capacity 参数作为缓存的最大容量，然后实现两个 API，一个是 put(key, val) 方法存入键值对，另一个是 get(key) 方法获取 key 对应的 val，如果 key 不存在则返回 -1。get 和 put 方法必须都是 O(1) 的时间复杂度</p><p>常用的方式是构造一个结构体包含一个HashMap和双链表</p><p>HashMap做取数据使用</p><p>双链表存访问的顺序</p><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/LRU.png" alt=""></p><p>我们看下go语言实现的LRU</p><pre><code class="go">type (    LRUCache struct {        Capacity int        HashMap  map[int]*Node        Head     *Node        Last     *Node    }    Node struct {        Val  int        Key  int        Pre  *Node        Next *Node    })func Constructor(capacity int) LRUCache {    cache := LRUCache{        Capacity: capacity,        HashMap:  make(map[int]*Node, capacity),        Head:     &amp;Node{},        Last:     &amp;Node{},    }    cache.Head.Next = cache.Last    cache.Last.Pre = cache.Head    return cache}func (this *LRUCache) Get(key int) int {    node, ok := this.HashMap[key]    if !ok {        return -1    }    this.remove(node)    this.setHead(node)    return node.Val}func (this *LRUCache) Put(key int, value int) {    node, ok := this.HashMap[key]    if ok {        node.Val = value        this.remove(node)    } else {        if len(this.HashMap) == this.Capacity {            delete(this.HashMap, this.Last.Pre.Key)            this.remove(this.Last.Pre)        }        node = &amp;Node{            Val:  value,            Key:  key,            Pre:  nil,            Next: nil,        }        this.HashMap[node.Key] = node    }    this.setHead(node)}func (this *LRUCache) setHead(node *Node) {    this.Head.Next.Pre = node    node.Next = this.Head.Next    this.Head.Next = node    node.Pre = this.Head}func (this *LRUCache) remove(node *Node) {    node.Pre.Next = node.Next    node.Next.Pre = node.Pre}/*============================*//*使用方法 * obj := Constructor(capacity); * param_1 := obj.Get(key); * obj.Put(key,value); */</code></pre><h3 id="11-5-3-Redis-LRU的实现"><a href="#11-5-3-Redis-LRU的实现" class="headerlink" title="11.5.3 Redis LRU的实现"></a>11.5.3 Redis LRU的实现</h3><pre><code class="c"># file: src/redis.cint freeMemoryIfNeeded(void) {....../* volatile-lru and allkeys-lru policy */            // 如果使用的是 LRU 策略，            // 那么从一集 sample 键中选出 IDLE 时间最长的那个键            else if (server.maxmemory_policy == REDIS_MAXMEMORY_ALLKEYS_LRU ||                server.maxmemory_policy == REDIS_MAXMEMORY_VOLATILE_LRU)            {                struct evictionPoolEntry *pool = db-&gt;eviction_pool;                while(bestkey == NULL) {                    evictionPoolPopulate(dict, db-&gt;dict, db-&gt;eviction_pool);                    /* Go backward from best to worst element to evict. */                    for (k = REDIS_EVICTION_POOL_SIZE-1; k &gt;= 0; k--) {                        if (pool[k].key == NULL) continue;                        de = dictFind(dict,pool[k].key);                        /* Remove the entry from the pool. */                        sdsfree(pool[k].key);                        /* Shift all elements on its right to left. */                        memmove(pool+k,pool+k+1,                            sizeof(pool[0])*(REDIS_EVICTION_POOL_SIZE-k-1));                        /* Clear the element on the right which is empty                         * since we shifted one position to the left.  */                        pool[REDIS_EVICTION_POOL_SIZE-1].key = NULL;                        pool[REDIS_EVICTION_POOL_SIZE-1].idle = 0;                        /* If the key exists, is our pick. Otherwise it is                         * a ghost and we need to try the next element. */                        if (de) {                            bestkey = dictGetKey(de);                            break;                        } else {                            /* Ghost... */                            continue;                        }                    }                }            }....../* This is an helper function for freeMemoryIfNeeded(), it is used in order * to populate the evictionPool with a few entries every time we want to * expire a key. Keys with idle time smaller than one of the current * keys are added. Keys are always added if there are free entries. * * We insert keys on place in ascending order, so keys with the smaller * idle time are on the left, and keys with the higher idle time on the * right. */#define EVICTION_SAMPLES_ARRAY_SIZE 16void evictionPoolPopulate(dict *sampledict, dict *keydict, struct evictionPoolEntry *pool) {    int j, k, count;    dictEntry *_samples[EVICTION_SAMPLES_ARRAY_SIZE];    dictEntry **samples;    /* Try to use a static buffer: this function is a big hit...     * Note: it was actually measured that this helps. */    if (server.maxmemory_samples &lt;= EVICTION_SAMPLES_ARRAY_SIZE) {        samples = _samples;    } else {        samples = zmalloc(sizeof(samples[0])*server.maxmemory_samples);    }#if 1 /* Use bulk get by default. */    count = dictGetRandomKeys(sampledict,samples,server.maxmemory_samples);#else    count = server.maxmemory_samples;    for (j = 0; j &lt; count; j++) samples[j] = dictGetRandomKey(sampledict);#endif    for (j = 0; j &lt; count; j++) {        unsigned long long idle;        sds key;        robj *o;        dictEntry *de;        de = samples[j];        key = dictGetKey(de);        /* If the dictionary we are sampling from is not the main         * dictionary (but the expires one) we need to lookup the key         * again in the key dictionary to obtain the value object. */        if (sampledict != keydict) de = dictFind(keydict, key);        o = dictGetVal(de);        idle = estimateObjectIdleTime(o);        /* Insert the element inside the pool.         * First, find the first empty bucket or the first populated         * bucket that has an idle time smaller than our idle time. */        k = 0;        while (k &lt; REDIS_EVICTION_POOL_SIZE &amp;&amp;               pool[k].key &amp;&amp;               pool[k].idle &lt; idle) k++;        if (k == 0 &amp;&amp; pool[REDIS_EVICTION_POOL_SIZE-1].key != NULL) {            /* Can&#39;t insert if the element is &lt; the worst element we have             * and there are no empty buckets. */            continue;        } else if (k &lt; REDIS_EVICTION_POOL_SIZE &amp;&amp; pool[k].key == NULL) {            /* Inserting into empty position. No setup needed before insert. */        } else {            /* Inserting in the middle. Now k points to the first element             * greater than the element to insert.  */            if (pool[REDIS_EVICTION_POOL_SIZE-1].key == NULL) {                /* Free space on the right? Insert at k shifting                 * all the elements from k to end to the right. */                memmove(pool+k+1,pool+k,                    sizeof(pool[0])*(REDIS_EVICTION_POOL_SIZE-k-1));            } else {                /* No free space on right? Insert at k-1 */                k--;                /* Shift all elements on the left of k (included) to the                 * left, so we discard the element with smaller idle time. */                sdsfree(pool[0].key);                memmove(pool,pool+1,sizeof(pool[0])*k);            }        }        pool[k].key = sdsdup(key);        pool[k].idle = idle;    }    if (samples != _samples) zfree(samples);}/* This is a version of dictGetRandomKey() that is modified in order to * return multiple entries by jumping at a random place of the hash table * and scanning linearly for entries. * * Returned pointers to hash table entries are stored into &#39;des&#39; that * points to an array of dictEntry pointers. The array must have room for * at least &#39;count&#39; elements, that is the argument we pass to the function * to tell how many random elements we need. * * The function returns the number of items stored into &#39;des&#39;, that may * be less than &#39;count&#39; if the hash table has less than &#39;count&#39; elements * inside. * * Note that this function is not suitable when you need a good distribution * of the returned items, but only when you need to &quot;sample&quot; a given number * of continuous elements to run some kind of algorithm or to produce * statistics. However the function is much faster than dictGetRandomKey() * at producing N elements, and the elements are guaranteed to be non * repeating. */int dictGetRandomKeys(dict *d, dictEntry **des, int count) {    int j; /* internal hash table id, 0 or 1. */    int stored = 0;    if (dictSize(d) &lt; count) count = dictSize(d);    while(stored &lt; count) {        for (j = 0; j &lt; 2; j++) {            /* Pick a random point inside the hash table 0 or 1. */            unsigned int i = random() &amp; d-&gt;ht[j].sizemask;            int size = d-&gt;ht[j].size;            /* Make sure to visit every bucket by iterating &#39;size&#39; times. */            while(size--) {                dictEntry *he = d-&gt;ht[j].table[i];                while (he) {                    /* Collect all the elements of the buckets found non                     * empty while iterating. */                    *des = he;                    des++;                    he = he-&gt;next;                    stored++;                    if (stored == count) return stored;                }                i = (i+1) &amp; d-&gt;ht[j].sizemask;            }            /* If there is only one table and we iterated it all, we should             * already have &#39;count&#39; elements. Assert this condition. */            assert(dictIsRehashing(d) != 0);        }    }    return stored; /* Never reached. */}typedef struct redisDb {......    struct evictionPoolEntry *eviction_pool;    /* Eviction pool of keys */......} redisDb;typedef struct redisObject {......    // 对象最后一次被访问的时间    unsigned lru:REDIS_LRU_BITS; /* lru time (relative to server.lruclock)......} robj;</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/LRUDuring.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>10.Redis数据结构——object</title>
      <link href="/2020/02/20/10-Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-object/"/>
      <url>/2020/02/20/10-Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-object/</url>
      
        <content type="html"><![CDATA[<h2 id="10-1-什么是object"><a href="#10-1-什么是object" class="headerlink" title="10.1 什么是object"></a>10.1 什么是object</h2><p>在前面的数个章节里， 我们陆续介绍了 Redis 用到的所有主要数据结构， 比如简单动态字符串（SDS）、双端链表、字典、压缩列表、整数集合， 等等。</p><p>Redis 并没有直接使用这些数据结构来实现键值对数据库， 而是基于这些数据结构创建了一个<code>对象系统</code>， 这个系统包含字符串对象、列表对象、哈希对象、集合对象和有序集合对象这五种类型的对象， 每种对象都用到了至少一种我们前面所介绍的数据结构。</p><p>通过这五种不同类型的对象， Redis 可以在执行命令之前， 根据对象的类型来判断一个对象是否可以执行给定的命令。 使用对象的另一个好处是， 我们可以针对不同的使用场景， 为对象设置多种不同的数据结构实现， 从而优化对象在不同场景下的使用效率</p><h2 id="10-2-数据结构"><a href="#10-2-数据结构" class="headerlink" title="10.2 数据结构"></a>10.2 数据结构</h2><pre><code class="c">#file : src/redis.ctypedef struct redisObject {    // 类型    unsigned type:4;    // 编码    unsigned encoding:4;    // 对象最后一次被访问的时间    unsigned lru:REDIS_LRU_BITS; /* lru time (relative to server.lruclock) */    // 引用计数    int refcount;    // 指向实际值的指针    void *ptr;} robj;</code></pre><p>Redis 使用对象来表示数据库中的键和值， 每次当我们在 Redis 的数据库中新创建一个键值对时， 我们至少会创建两个对象， 一个对象用作键值对的键（键对象）， 另一个对象用作键值对的值（值对象）。</p><h3 id="10-2-1-type"><a href="#10-2-1-type" class="headerlink" title="10.2.1 type"></a>10.2.1 type</h3><p>对象的 type 属性记录了对象的类型:</p><pre><code class="c">#file : src/redis.c// 对象类型#define REDIS_STRING 0  #字符串对象 &quot;string&quot;#define REDIS_LIST 1    #列表对象 &quot;list&quot;#define REDIS_SET 2     #哈希对象 &quot;hash&quot;#define REDIS_ZSET 3    #集合对象 &quot;set&quot;#define REDIS_HASH 4    #有序集合对象 &quot;zset&quot;</code></pre><h3 id="10-2-2-encoding"><a href="#10-2-2-encoding" class="headerlink" title="10.2.2 encoding"></a>10.2.2 encoding</h3><p>对象的 ptr 指针指向对象的底层实现数据结构， 而这些数据结构由对象的 encoding 属性决定。</p><p>encoding 属性记录了对象所使用的编码， 也即是说这个对象使用了什么数据结构作为对象的底层实现:</p><pre><code class="c">#file : src/redis.c// 对象编码#简单动态字符串#define REDIS_ENCODING_RAW 0     /* Raw representation */ #long 类型的整数#long 类型的整数#define REDIS_ENCODING_INT 1     /* Encoded as integer */#字典#define REDIS_ENCODING_HT 2      /* Encoded as hash table */#压缩字典#define REDIS_ENCODING_ZIPMAP 3  /* Encoded as zipmap */#双端链表#define REDIS_ENCODING_LINKEDLIST 4 /* Encoded as regular linked list */#压缩列表#define REDIS_ENCODING_ZIPLIST 5 /* Encoded as ziplist */#整数集合#define REDIS_ENCODING_INTSET 6  /* Encoded as intset */#跳表#define REDIS_ENCODING_SKIPLIST 7  /* Encoded as skiplist */#embstr编码的简单动态字符串#define REDIS_ENCODING_EMBSTR 8  /* Embedded sds string encoding */</code></pre><h2 id="10-3-Redis键的底层实现"><a href="#10-3-Redis键的底层实现" class="headerlink" title="10.3 Redis键的底层实现"></a>10.3 Redis键的底层实现</h2><p>对于 Redis 数据库保存的键值对来说， 键总是一个字符串对象， 而值则可以是字符串对象、列表对象、哈希对象、集合对象或者有序集合对象的其中一种</p><h2 id="10-4-Redis值的底层实现"><a href="#10-4-Redis值的底层实现" class="headerlink" title="10.4 Redis值的底层实现"></a>10.4 Redis值的底层实现</h2><h3 id="10-4-1-字符串对象"><a href="#10-4-1-字符串对象" class="headerlink" title="10.4.1 字符串对象"></a>10.4.1 字符串对象</h3><pre><code class="c">#file: src/t_string.c/* SET key value [NX] [XX] [EX &lt;seconds&gt;] [PX &lt;milliseconds&gt;] */void setCommand(redisClient *c) {    int j;    robj *expire = NULL;    int unit = UNIT_SECONDS;    int flags = REDIS_SET_NO_FLAGS;    // 设置选项参数    for (j = 3; j &lt; c-&gt;argc; j++) {        char *a = c-&gt;argv[j]-&gt;ptr;        robj *next = (j == c-&gt;argc-1) ? NULL : c-&gt;argv[j+1];        if ((a[0] == &#39;n&#39; || a[0] == &#39;N&#39;) &amp;&amp;            (a[1] == &#39;x&#39; || a[1] == &#39;X&#39;) &amp;&amp; a[2] == &#39;\0&#39;) {            flags |= REDIS_SET_NX;        } else if ((a[0] == &#39;x&#39; || a[0] == &#39;X&#39;) &amp;&amp;                   (a[1] == &#39;x&#39; || a[1] == &#39;X&#39;) &amp;&amp; a[2] == &#39;\0&#39;) {            flags |= REDIS_SET_XX;        } else if ((a[0] == &#39;e&#39; || a[0] == &#39;E&#39;) &amp;&amp;                   (a[1] == &#39;x&#39; || a[1] == &#39;X&#39;) &amp;&amp; a[2] == &#39;\0&#39; &amp;&amp; next) {            unit = UNIT_SECONDS;            expire = next;            j++;        } else if ((a[0] == &#39;p&#39; || a[0] == &#39;P&#39;) &amp;&amp;                   (a[1] == &#39;x&#39; || a[1] == &#39;X&#39;) &amp;&amp; a[2] == &#39;\0&#39; &amp;&amp; next) {            unit = UNIT_MILLISECONDS;            expire = next;            j++;        } else {            addReply(c,shared.syntaxerr);            return;        }    }    // 尝试对值对象进行编码    c-&gt;argv[2] = tryObjectEncoding(c-&gt;argv[2]);    setGenericCommand(c,flags,c-&gt;argv[1],c-&gt;argv[2],expire,unit,NULL,NULL);}void setnxCommand(redisClient *c) {    c-&gt;argv[2] = tryObjectEncoding(c-&gt;argv[2]);    setGenericCommand(c,REDIS_SET_NX,c-&gt;argv[1],c-&gt;argv[2],NULL,0,shared.cone,shared.czero);}void setexCommand(redisClient *c) {    c-&gt;argv[3] = tryObjectEncoding(c-&gt;argv[3]);    setGenericCommand(c,REDIS_SET_NO_FLAGS,c-&gt;argv[1],c-&gt;argv[3],c-&gt;argv[2],UNIT_SECONDS,NULL,NULL);}void psetexCommand(redisClient *c) {    c-&gt;argv[3] = tryObjectEncoding(c-&gt;argv[3]);    setGenericCommand(c,REDIS_SET_NO_FLAGS,c-&gt;argv[1],c-&gt;argv[3],c-&gt;argv[2],UNIT_MILLISECONDS,NULL,NULL);}void setGenericCommand(redisClient *c, int flags, robj *key, robj *val, robj *expire, int unit, robj *ok_reply, robj *abort_reply) {    long long milliseconds = 0; /* initialized to avoid any harmness warning */    // 取出过期时间    if (expire) {        // 取出 expire 参数的值        // T = O(N)        if (getLongLongFromObjectOrReply(c, expire, &amp;milliseconds, NULL) != REDIS_OK)            return;        // expire 参数的值不正确时报错        if (milliseconds &lt;= 0) {            addReplyError(c,&quot;invalid expire time in SETEX&quot;);            return;        }        // 不论输入的过期时间是秒还是毫秒        // Redis 实际都以毫秒的形式保存过期时间        // 如果输入的过期时间为秒，那么将它转换为毫秒        if (unit == UNIT_SECONDS) milliseconds *= 1000;    }    // 如果设置了 NX 或者 XX 参数，那么检查条件是否不符合这两个设置    // 在条件不符合时报错，报错的内容由 abort_reply 参数决定    if ((flags &amp; REDIS_SET_NX &amp;&amp; lookupKeyWrite(c-&gt;db,key) != NULL) ||        (flags &amp; REDIS_SET_XX &amp;&amp; lookupKeyWrite(c-&gt;db,key) == NULL))    {        addReply(c, abort_reply ? abort_reply : shared.nullbulk);        return;    }    // 将键值关联到数据库    setKey(c-&gt;db,key,val);    // 将数据库设为脏    server.dirty++;    // 为键设置过期时间    if (expire) setExpire(c-&gt;db,key,mstime()+milliseconds);    // 发送事件通知    notifyKeyspaceEvent(REDIS_NOTIFY_STRING,&quot;set&quot;,key,c-&gt;db-&gt;id);    // 发送事件通知    if (expire) notifyKeyspaceEvent(REDIS_NOTIFY_GENERIC,        &quot;expire&quot;,key,c-&gt;db-&gt;id);    // 设置成功，向客户端发送回复    // 回复的内容由 ok_reply 决定    addReply(c, ok_reply ? ok_reply : shared.ok);}#file:src/object// 尝试对字符串对象进行编码，以节约内存。robj *tryObjectEncoding(robj *o) {    long value;    sds s = o-&gt;ptr;    size_t len;    redisAssertWithInfo(NULL,o,o-&gt;type == REDIS_STRING);    // 只在字符串的编码为 RAW 或者 EMBSTR 时尝试进行编码    if (!sdsEncodedObject(o)) return o;     // 不对共享对象进行编码     if (o-&gt;refcount &gt; 1) return o;    // 对字符串进行检查    // 只对长度小于或等于 21 字节，并且可以被解释为整数的字符串进行编码    len = sdslen(s);    if (len &lt;= 21 &amp;&amp; string2l(s,len,&amp;value)) {        if (server.maxmemory == 0 &amp;&amp;            value &gt;= 0 &amp;&amp;            value &lt; REDIS_SHARED_INTEGERS)        {            decrRefCount(o);            incrRefCount(shared.integers[value]);            return shared.integers[value];        } else {            if (o-&gt;encoding == REDIS_ENCODING_RAW) sdsfree(o-&gt;ptr);            o-&gt;encoding = REDIS_ENCODING_INT;            o-&gt;ptr = (void*) value;            return o;        }    }    // 尝试将 RAW 编码的字符串编码为 EMBSTR 编码    if (len &lt;= REDIS_ENCODING_EMBSTR_SIZE_LIMIT) {        robj *emb;        if (o-&gt;encoding == REDIS_ENCODING_EMBSTR) return o;        emb = createEmbeddedStringObject(s,sdslen(s));        decrRefCount(o);        return emb;    }    // 这个对象没办法进行编码，尝试从 SDS 中移除所有空余空间    if (o-&gt;encoding == REDIS_ENCODING_RAW &amp;&amp;        sdsavail(s) &gt; len/10)    {        o-&gt;ptr = sdsRemoveFreeSpace(o-&gt;ptr);    }    /* Return the original object. */    return o;}</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/stringadd.png" alt=""></p><h3 id="10-4-2-列表对象"><a href="#10-4-2-列表对象" class="headerlink" title="10.4.2 列表对象"></a>10.4.2 列表对象</h3><pre><code class="c"># file : src/t_list.cvoid lpushxCommand(redisClient *c) {    c-&gt;argv[2] = tryObjectEncoding(c-&gt;argv[2]);    pushxGenericCommand(c,NULL,c-&gt;argv[2],REDIS_HEAD);}void rpushxCommand(redisClient *c) {    c-&gt;argv[2] = tryObjectEncoding(c-&gt;argv[2]);    pushxGenericCommand(c,NULL,c-&gt;argv[2],REDIS_TAIL);}void pushxGenericCommand(redisClient *c, robj *refval, robj *val, int where) {    robj *subject;    listTypeIterator *iter;    listTypeEntry entry;    int inserted = 0;    // 取出列表对象    if ((subject = lookupKeyReadOrReply(c,c-&gt;argv[1],shared.czero)) == NULL ||        checkType(c,subject,REDIS_LIST)) return;    // 执行的是 LINSERT 命令    if (refval != NULL) {        // 看保存值 value 是否需要将列表编码转换为双端链表        listTypeTryConversion(subject,val);        /* Seek refval from head to tail */        // 在列表中查找 refval 对象        iter = listTypeInitIterator(subject,0,REDIS_TAIL);        while (listTypeNext(iter,&amp;entry)) {            if (listTypeEqual(&amp;entry,refval)) {                // 找到了，将值插入到节点的前面或后面                listTypeInsert(&amp;entry,val,where);                inserted = 1;                break;            }        }        listTypeReleaseIterator(iter);        if (inserted) {            /* Check if the length exceeds the ziplist length threshold. */            // 查看插入之后是否需要将编码转换为双端链表            if (subject-&gt;encoding == REDIS_ENCODING_ZIPLIST &amp;&amp;                ziplistLen(subject-&gt;ptr) &gt; server.list_max_ziplist_entries)                    listTypeConvert(subject,REDIS_ENCODING_LINKEDLIST);            signalModifiedKey(c-&gt;db,c-&gt;argv[1]);            notifyKeyspaceEvent(REDIS_NOTIFY_LIST,&quot;linsert&quot;,                                c-&gt;argv[1],c-&gt;db-&gt;id);            server.dirty++;        } else {            /* Notify client of a failed insert */            // refval 不存在，插入失败            addReply(c,shared.cnegone);            return;        }    // 执行的是 LPUSHX 或 RPUSHX 命令    } else {        char *event = (where == REDIS_HEAD) ? &quot;lpush&quot; : &quot;rpush&quot;;        listTypePush(subject,val,where);        signalModifiedKey(c-&gt;db,c-&gt;argv[1]);        notifyKeyspaceEvent(REDIS_NOTIFY_LIST,event,c-&gt;argv[1],c-&gt;db-&gt;id);        server.dirty++;    }    addReplyLongLong(c,listTypeLength(subject));}/* * 将给定元素添加到列表的表头或表尾。 * * 参数 where 决定了新元素添加的位置： * *  - REDIS_HEAD 将新元素添加到表头 *  - REDIS_TAIL 将新元素添加到表尾 * * 调用者无须担心 value 的引用计数，因为这个函数会负责这方面的工作。 */void listTypePush(robj *subject, robj *value, int where) {    /* Check if we need to convert the ziplist */    // 是否需要转换编码？    listTypeTryConversion(subject,value);    if (subject-&gt;encoding == REDIS_ENCODING_ZIPLIST &amp;&amp;        ziplistLen(subject-&gt;ptr) &gt;= server.list_max_ziplist_entries)            listTypeConvert(subject,REDIS_ENCODING_LINKEDLIST);    // ZIPLIST    if (subject-&gt;encoding == REDIS_ENCODING_ZIPLIST) {        int pos = (where == REDIS_HEAD) ? ZIPLIST_HEAD : ZIPLIST_TAIL;        // 取出对象的值，因为 ZIPLIST 只能保存字符串或整数        value = getDecodedObject(value);        subject-&gt;ptr = ziplistPush(subject-&gt;ptr,value-&gt;ptr,sdslen(value-&gt;ptr),pos);        decrRefCount(value);    // 双端链表    } else if (subject-&gt;encoding == REDIS_ENCODING_LINKEDLIST) {        if (where == REDIS_HEAD) {            listAddNodeHead(subject-&gt;ptr,value);        } else {            listAddNodeTail(subject-&gt;ptr,value);        }        incrRefCount(value);    // 未知编码    } else {        redisPanic(&quot;Unknown list encoding&quot;);    }}/* * 对输入值 value 进行检查，看是否需要将 subject 从 ziplist 转换为双端链表， * 以便保存值 value 。 * * 函数只对 REDIS_ENCODING_RAW 编码的 value 进行检查， * 因为整数编码的值不可能超长。 */void listTypeTryConversion(robj *subject, robj *value) {    // 确保 subject 为 ZIPLIST 编码    if (subject-&gt;encoding != REDIS_ENCODING_ZIPLIST) return;    if (sdsEncodedObject(value) &amp;&amp;        // 看字符串是否过长        sdslen(value-&gt;ptr) &gt; server.list_max_ziplist_value)            // 将编码转换为双端链表            listTypeConvert(subject,REDIS_ENCODING_LINKEDLIST);}/* * 将列表的底层编码从 ziplist 转换成双端链表 */void listTypeConvert(robj *subject, int enc) {    listTypeIterator *li;    listTypeEntry entry;    redisAssertWithInfo(NULL,subject,subject-&gt;type == REDIS_LIST);    // 转换成双端链表    if (enc == REDIS_ENCODING_LINKEDLIST) {        list *l = listCreate();        listSetFreeMethod(l,decrRefCountVoid);        // 遍历 ziplist ，并将里面的值全部添加到双端链表中        li = listTypeInitIterator(subject,0,REDIS_TAIL);        while (listTypeNext(li,&amp;entry)) listAddNodeTail(l,listTypeGet(&amp;entry));        listTypeReleaseIterator(li);        // 更新编码        subject-&gt;encoding = REDIS_ENCODING_LINKEDLIST;        // 释放原来的 ziplist        zfree(subject-&gt;ptr);        // 更新对象值指针        subject-&gt;ptr = l;    } else {        redisPanic(&quot;Unsupported list conversion&quot;);    }}#file : src/object.c/* * 创建一个 ZIPLIST 编码的列表对象 */robj *createZiplistObject(void) {    unsigned char *zl = ziplistNew();    robj *o = createObject(REDIS_LIST,zl);    o-&gt;encoding = REDIS_ENCODING_ZIPLIST;    return o;}</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/listadd.png" alt=""></p><h3 id="10-4-3-哈希对象"><a href="#10-4-3-哈希对象" class="headerlink" title="10.4.3 哈希对象"></a>10.4.3 哈希对象</h3><pre><code class="c">#file src/t_hash.c/*----------------------------------------------------------------------------- * Hash type commands *----------------------------------------------------------------------------*/void hsetCommand(redisClient *c) {    int update;    robj *o;    // 取出或新创建哈希对象    if ((o = hashTypeLookupWriteOrCreate(c,c-&gt;argv[1])) == NULL) return;    // 如果需要的话，转换哈希对象的编码    hashTypeTryConversion(o,c-&gt;argv,2,3);    // 编码 field 和 value 对象以节约空间    hashTypeTryObjectEncoding(o,&amp;c-&gt;argv[2], &amp;c-&gt;argv[3]);    // 设置 field 和 value 到 hash    update = hashTypeSet(o,c-&gt;argv[2],c-&gt;argv[3]);    // 返回状态：显示 field-value 对是新添加还是更新    addReply(c, update ? shared.czero : shared.cone);    // 发送键修改信号    signalModifiedKey(c-&gt;db,c-&gt;argv[1]);    // 发送事件通知    notifyKeyspaceEvent(REDIS_NOTIFY_HASH,&quot;hset&quot;,c-&gt;argv[1],c-&gt;db-&gt;id);    // 将服务器设为脏    server.dirty++;}void hsetnxCommand(redisClient *c) {    robj *o;    // 取出或新创建哈希对象    if ((o = hashTypeLookupWriteOrCreate(c,c-&gt;argv[1])) == NULL) return;    // 如果需要的话，转换哈希对象的编码    hashTypeTryConversion(o,c-&gt;argv,2,3);    // 如果 field-value 对已经存在    // 那么回复 0     if (hashTypeExists(o, c-&gt;argv[2])) {        addReply(c, shared.czero);    // 否则，设置 field-value 对    } else {        // 对 field 和 value 对象编码，以节省空间        hashTypeTryObjectEncoding(o,&amp;c-&gt;argv[2], &amp;c-&gt;argv[3]);        // 设置        hashTypeSet(o,c-&gt;argv[2],c-&gt;argv[3]);        // 回复 1 ，表示设置成功        addReply(c, shared.cone);        // 发送键修改信号        signalModifiedKey(c-&gt;db,c-&gt;argv[1]);        // 发送事件通知        notifyKeyspaceEvent(REDIS_NOTIFY_HASH,&quot;hset&quot;,c-&gt;argv[1],c-&gt;db-&gt;id);       // 将数据库设为脏        server.dirty++;    }}void hmsetCommand(redisClient *c) {    int i;    robj *o;    // field-value 参数必须成对出现    if ((c-&gt;argc % 2) == 1) {        addReplyError(c,&quot;wrong number of arguments for HMSET&quot;);        return;    }    // 取出或新创建哈希对象    if ((o = hashTypeLookupWriteOrCreate(c,c-&gt;argv[1])) == NULL) return;    // 如果需要的话，转换哈希对象的编码    hashTypeTryConversion(o,c-&gt;argv,2,c-&gt;argc-1);    // 遍历并设置所有 field-value 对    for (i = 2; i &lt; c-&gt;argc; i += 2) {        // 编码 field-value 对，以节约空间        hashTypeTryObjectEncoding(o,&amp;c-&gt;argv[i], &amp;c-&gt;argv[i+1]);        // 设置        hashTypeSet(o,c-&gt;argv[i],c-&gt;argv[i+1]);    }    // 向客户端发送回复    addReply(c, shared.ok);    // 发送键修改信号    signalModifiedKey(c-&gt;db,c-&gt;argv[1]);    // 发送事件通知    notifyKeyspaceEvent(REDIS_NOTIFY_HASH,&quot;hset&quot;,c-&gt;argv[1],c-&gt;db-&gt;id);    // 将数据库设为脏    server.dirty++;}/* * 对 argv 数组中的多个对象进行检查， * 看是否需要将对象的编码从 REDIS_ENCODING_ZIPLIST 转换成 REDIS_ENCODING_HT * * 注意程序只检查字符串值，因为它们的长度可以在常数时间内取得。 */void hashTypeTryConversion(robj *o, robj **argv, int start, int end) {    int i;    // 如果对象不是 ziplist 编码，那么直接返回    if (o-&gt;encoding != REDIS_ENCODING_ZIPLIST) return;    // 检查所有输入对象，看它们的字符串值是否超过了指定长度    for (i = start; i &lt;= end; i++) {        if (sdsEncodedObject(argv[i]) &amp;&amp;            sdslen(argv[i]-&gt;ptr) &gt; server.hash_max_ziplist_value)        {            // 将对象的编码转换成 REDIS_ENCODING_HT            hashTypeConvert(o, REDIS_ENCODING_HT);            break;        }    }}/* * 对哈希对象 o 的编码方式进行转换 * * 目前只支持将 ZIPLIST 编码转换成 HT 编码 */void hashTypeConvert(robj *o, int enc) {    if (o-&gt;encoding == REDIS_ENCODING_ZIPLIST) {        hashTypeConvertZiplist(o, enc);    } else if (o-&gt;encoding == REDIS_ENCODING_HT) {        redisPanic(&quot;Not implemented&quot;);    } else {        redisPanic(&quot;Unknown hash encoding&quot;);    }}/*  * 将给定的 field-value 对添加到 hash 中， * 如果 field 已经存在，那么删除旧的值，并关联新值。 * 这个函数负责对 field 和 value 参数进行引用计数自增。 * * 返回 0 表示元素已经存在，这次函数调用执行的是更新操作。 * 返回 1 则表示函数执行的是新添加操作。 */int hashTypeSet(robj *o, robj *field, robj *value) {    int update = 0;    // 添加到 ziplist    if (o-&gt;encoding == REDIS_ENCODING_ZIPLIST) {        unsigned char *zl, *fptr, *vptr;        // 解码成字符串或者数字        field = getDecodedObject(field);        value = getDecodedObject(value);        // 遍历整个 ziplist ，尝试查找并更新 field （如果它已经存在的话）        zl = o-&gt;ptr;        fptr = ziplistIndex(zl, ZIPLIST_HEAD);        if (fptr != NULL) {            // 定位到域 field            fptr = ziplistFind(fptr, field-&gt;ptr, sdslen(field-&gt;ptr), 1);            if (fptr != NULL) {                /* Grab pointer to the value (fptr points to the field) */                // 定位到域的值                vptr = ziplistNext(zl, fptr);                redisAssert(vptr != NULL);                // 标识这次操作为更新操作                update = 1;                /* Delete value */                // 删除旧的键值对                zl = ziplistDelete(zl, &amp;vptr);                /* Insert new value */                // 添加新的键值对                zl = ziplistInsert(zl, vptr, value-&gt;ptr, sdslen(value-&gt;ptr));            }        }        // 如果这不是更新操作，那么这就是一个添加操作        if (!update) {            /* Push new field/value pair onto the tail of the ziplist */            // 将新的 field-value 对推入到 ziplist 的末尾            zl = ziplistPush(zl, field-&gt;ptr, sdslen(field-&gt;ptr), ZIPLIST_TAIL);            zl = ziplistPush(zl, value-&gt;ptr, sdslen(value-&gt;ptr), ZIPLIST_TAIL);        }        // 更新对象指针        o-&gt;ptr = zl;        // 释放临时对象        decrRefCount(field);        decrRefCount(value);        // 检查在添加操作完成之后，是否需要将 ZIPLIST 编码转换成 HT 编码        if (hashTypeLength(o) &gt; server.hash_max_ziplist_entries)            hashTypeConvert(o, REDIS_ENCODING_HT);    // 添加到字典    } else if (o-&gt;encoding == REDIS_ENCODING_HT) {        // 添加或替换键值对到字典        // 添加返回 1 ，替换返回 0        if (dictReplace(o-&gt;ptr, field, value)) { /* Insert */            incrRefCount(field);        } else { /* Update */            update = 1;        }        incrRefCount(value);    } else {        redisPanic(&quot;Unknown hash encoding&quot;);    }    // 更新/添加指示变量    return update;}#file: src/object.c/* * 创建一个 ZIPLIST 编码的哈希对象 */robj *createHashObject(void) {    unsigned char *zl = ziplistNew();    robj *o = createObject(REDIS_HASH, zl);    o-&gt;encoding = REDIS_ENCODING_ZIPLIST;    return o;}</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/hashadd.png" alt=""></p><h3 id="10-4-4-集合对象"><a href="#10-4-4-集合对象" class="headerlink" title="10.4.4 集合对象"></a>10.4.4 集合对象</h3><pre><code class="c">#file: src/t_set.cvoid saddCommand(redisClient *c) {    robj *set;    int j, added = 0;    // 取出集合对象    set = lookupKeyWrite(c-&gt;db,c-&gt;argv[1]);    // 对象不存在，创建一个新的，并将它关联到数据库    if (set == NULL) {        set = setTypeCreate(c-&gt;argv[2]);        dbAdd(c-&gt;db,c-&gt;argv[1],set);    // 对象存在，检查类型    } else {        if (set-&gt;type != REDIS_SET) {            addReply(c,shared.wrongtypeerr);            return;        }    }    // 将所有输入元素添加到集合中    for (j = 2; j &lt; c-&gt;argc; j++) {        c-&gt;argv[j] = tryObjectEncoding(c-&gt;argv[j]);        // 只有元素未存在于集合时，才算一次成功添加        if (setTypeAdd(set,c-&gt;argv[j])) added++;    }    // 如果有至少一个元素被成功添加，那么执行以下程序    if (added) {        // 发送键修改信号        signalModifiedKey(c-&gt;db,c-&gt;argv[1]);        // 发送事件通知        notifyKeyspaceEvent(REDIS_NOTIFY_SET,&quot;sadd&quot;,c-&gt;argv[1],c-&gt;db-&gt;id);    }    // 将数据库设为脏    server.dirty += added;    // 返回添加元素的数量    addReplyLongLong(c,added);}/*  * 返回一个可以保存值 value 的集合。 * 当对象的值可以被编码为整数时，返回 intset ， * 否则，返回普通的哈希表。 */robj *setTypeCreate(robj *value) {    if (isObjectRepresentableAsLongLong(value,NULL) == REDIS_OK)        return createIntsetObject();    return createSetObject();}/*  * 将集合对象 setobj 的编码转换为 REDIS_ENCODING_HT 。 * * 新创建的结果字典会被预先分配为和原来的集合一样大。 */void setTypeConvert(robj *setobj, int enc) {    setTypeIterator *si;    // 确认类型和编码正确    redisAssertWithInfo(NULL,setobj,setobj-&gt;type == REDIS_SET &amp;&amp;                             setobj-&gt;encoding == REDIS_ENCODING_INTSET);    if (enc == REDIS_ENCODING_HT) {        int64_t intele;        // 创建新字典        dict *d = dictCreate(&amp;setDictType,NULL);        robj *element;        /* Presize the dict to avoid rehashing */        // 预先扩展空间        dictExpand(d,intsetLen(setobj-&gt;ptr));        /* To add the elements we extract integers and create redis objects */        // 遍历集合，并将元素添加到字典中        si = setTypeInitIterator(setobj);        while (setTypeNext(si,NULL,&amp;intele) != -1) {            element = createStringObjectFromLongLong(intele);            redisAssertWithInfo(NULL,element,dictAdd(d,element,NULL) == DICT_OK);        }        setTypeReleaseIterator(si);        // 更新集合的编码        setobj-&gt;encoding = REDIS_ENCODING_HT;        zfree(setobj-&gt;ptr);        // 更新集合的值对象        setobj-&gt;ptr = d;    } else {        redisPanic(&quot;Unsupported set conversion&quot;);    }}/* * 多态 add 操作 * * 添加成功返回 1 ，如果元素已经存在，返回 0 。 */int setTypeAdd(robj *subject, robj *value) {    long long llval;    // 字典    if (subject-&gt;encoding == REDIS_ENCODING_HT) {        // 将 value 作为键， NULL 作为值，将元素添加到字典中        if (dictAdd(subject-&gt;ptr,value,NULL) == DICT_OK) {            incrRefCount(value);            return 1;        }    // intset    } else if (subject-&gt;encoding == REDIS_ENCODING_INTSET) {        // 如果对象的值可以编码为整数的话，那么将对象的值添加到 intset 中        if (isObjectRepresentableAsLongLong(value,&amp;llval) == REDIS_OK) {            uint8_t success = 0;            subject-&gt;ptr = intsetAdd(subject-&gt;ptr,llval,&amp;success);            if (success) {                /* Convert to regular set when the intset contains                 * too many entries. */                // 添加成功                // 检查集合在添加新元素之后是否需要转换为字典                if (intsetLen(subject-&gt;ptr) &gt; server.set_max_intset_entries)                    setTypeConvert(subject,REDIS_ENCODING_HT);                return 1;            }        // 如果对象的值不能编码为整数，那么将集合从 intset 编码转换为 HT 编码        // 然后再执行添加操作        } else {            /* Failed to get integer from object, convert to regular set. */            setTypeConvert(subject,REDIS_ENCODING_HT);            /* The set *was* an intset and this value is not integer             * encodable, so dictAdd should always work. */            redisAssertWithInfo(NULL,value,dictAdd(subject-&gt;ptr,value,NULL) == DICT_OK);            incrRefCount(value);            return 1;        }    // 未知编码    } else {        redisPanic(&quot;Unknown set encoding&quot;);    }    // 添加失败，元素已经存在    return 0;}#file: src/db.c/* * 为执行写入操作而取出键 key 在数据库 db 中的值。 * 和 lookupKeyRead 不同，这个函数不会更新服务器的命中/不命中信息。 * 找到时返回值对象，没找到返回 NULL 。 */robj *lookupKeyWrite(redisDb *db, robj *key) {    // 删除过期键    expireIfNeeded(db,key);    // 查找并返回 key 的值对象    return lookupKey(db,key);}</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/setadd.png" alt=""></p><h3 id="10-4-5-有序集合对象"><a href="#10-4-5-有序集合对象" class="headerlink" title="10.4.5 有序集合对象"></a>10.4.5 有序集合对象</h3><pre><code class="c">#file : src/t_zset.cvoid zaddCommand(redisClient *c) {    zaddGenericCommand(c,0);}void zincrbyCommand(redisClient *c) {    zaddGenericCommand(c,1);}/* This generic command implements both ZADD and ZINCRBY. */void zaddGenericCommand(redisClient *c, int incr) {    static char *nanerr = &quot;resulting score is not a number (NaN)&quot;;    robj *key = c-&gt;argv[1];    robj *ele;    robj *zobj;    robj *curobj;    double score = 0, *scores = NULL, curscore = 0.0;    int j, elements = (c-&gt;argc-2)/2;    int added = 0, updated = 0;    // 输入的 score - member 参数必须是成对出现的    if (c-&gt;argc % 2) {        addReply(c,shared.syntaxerr);        return;    }    // 取出所有输入的 score 分值    scores = zmalloc(sizeof(double)*elements);    for (j = 0; j &lt; elements; j++) {        if (getDoubleFromObjectOrReply(c,c-&gt;argv[2+j*2],&amp;scores[j],NULL)            != REDIS_OK) goto cleanup;    }    /* Lookup the key and create the sorted set if does not exist. */    // 取出有序集合对象    zobj = lookupKeyWrite(c-&gt;db,key);    if (zobj == NULL) {        // 有序集合不存在，创建新有序集合        if (server.zset_max_ziplist_entries == 0 ||            server.zset_max_ziplist_value &lt; sdslen(c-&gt;argv[3]-&gt;ptr))        {            zobj = createZsetObject();        } else {            zobj = createZsetZiplistObject();        }        // 关联对象到数据库        dbAdd(c-&gt;db,key,zobj);    } else {        // 对象存在，检查类型        if (zobj-&gt;type != REDIS_ZSET) {            addReply(c,shared.wrongtypeerr);            goto cleanup;        }    }    // 处理所有元素    for (j = 0; j &lt; elements; j++) {        score = scores[j];        // 有序集合为 ziplist 编码        if (zobj-&gt;encoding == REDIS_ENCODING_ZIPLIST) {            unsigned char *eptr;            /* Prefer non-encoded element when dealing with ziplists. */            // 查找成员            ele = c-&gt;argv[3+j*2];            if ((eptr = zzlFind(zobj-&gt;ptr,ele,&amp;curscore)) != NULL) {                // 成员已存在                // ZINCRYBY 命令时使用                if (incr) {                    score += curscore;                    if (isnan(score)) {                        addReplyError(c,nanerr);                        goto cleanup;                    }                }                // 执行 ZINCRYBY 命令时，                // 或者用户通过 ZADD 修改成员的分值时执行                if (score != curscore) {                    // 删除已有元素                    zobj-&gt;ptr = zzlDelete(zobj-&gt;ptr,eptr);                    // 重新插入元素                    zobj-&gt;ptr = zzlInsert(zobj-&gt;ptr,ele,score);                    // 计数器                    server.dirty++;                    updated++;                }            } else {                // 元素不存在，直接添加                zobj-&gt;ptr = zzlInsert(zobj-&gt;ptr,ele,score);                // 查看元素的数量，                // 看是否需要将 ZIPLIST 编码转换为有序集合                if (zzlLength(zobj-&gt;ptr) &gt; server.zset_max_ziplist_entries)                    zsetConvert(zobj,REDIS_ENCODING_SKIPLIST);                // 查看新添加元素的长度                // 看是否需要将 ZIPLIST 编码转换为有序集合                if (sdslen(ele-&gt;ptr) &gt; server.zset_max_ziplist_value)                    zsetConvert(zobj,REDIS_ENCODING_SKIPLIST);                server.dirty++;                added++;            }        // 有序集合为 SKIPLIST 编码        } else if (zobj-&gt;encoding == REDIS_ENCODING_SKIPLIST) {            zset *zs = zobj-&gt;ptr;            zskiplistNode *znode;            dictEntry *de;            // 编码对象            ele = c-&gt;argv[3+j*2] = tryObjectEncoding(c-&gt;argv[3+j*2]);            // 查看成员是否存在            de = dictFind(zs-&gt;dict,ele);            if (de != NULL) {                // 成员存在                // 取出成员                curobj = dictGetKey(de);                // 取出分值                curscore = *(double*)dictGetVal(de);                // ZINCRYBY 时执行                if (incr) {                    score += curscore;                    if (isnan(score)) {                        addReplyError(c,nanerr);                        /* Don&#39;t need to check if the sorted set is empty                         * because we know it has at least one element. */                        goto cleanup;                    }                }                // 执行 ZINCRYBY 命令时，                // 或者用户通过 ZADD 修改成员的分值时执行                if (score != curscore) {                    // 删除原有元素                    redisAssertWithInfo(c,curobj,zslDelete(zs-&gt;zsl,curscore,curobj));                    // 重新插入元素                    znode = zslInsert(zs-&gt;zsl,score,curobj);                    incrRefCount(curobj); /* Re-inserted in skiplist. */                    // 更新字典的分值指针                    dictGetVal(de) = &amp;znode-&gt;score; /* Update score ptr. */                    server.dirty++;                    updated++;                }            } else {                // 元素不存在，直接添加到跳跃表                znode = zslInsert(zs-&gt;zsl,score,ele);                incrRefCount(ele); /* Inserted in skiplist. */                // 将元素关联到字典                redisAssertWithInfo(c,NULL,dictAdd(zs-&gt;dict,ele,&amp;znode-&gt;score) == DICT_OK);                incrRefCount(ele); /* Added to dictionary. */                server.dirty++;                added++;            }        } else {            redisPanic(&quot;Unknown sorted set encoding&quot;);        }    }    if (incr) /* ZINCRBY */        addReplyDouble(c,score);    else /* ZADD */        addReplyLongLong(c,added);cleanup:    zfree(scores);    if (added || updated) {        signalModifiedKey(c-&gt;db,key);        notifyKeyspaceEvent(REDIS_NOTIFY_ZSET,            incr ? &quot;zincr&quot; : &quot;zadd&quot;, key, c-&gt;db-&gt;id);    }}/* * 将跳跃表对象 zobj 的底层编码转换为 encoding 。 */void zsetConvert(robj *zobj, int encoding) {    zset *zs;    zskiplistNode *node, *next;    robj *ele;    double score;    if (zobj-&gt;encoding == encoding) return;    // 从 ZIPLIST 编码转换为 SKIPLIST 编码    if (zobj-&gt;encoding == REDIS_ENCODING_ZIPLIST) {        unsigned char *zl = zobj-&gt;ptr;        unsigned char *eptr, *sptr;        unsigned char *vstr;        unsigned int vlen;        long long vlong;        if (encoding != REDIS_ENCODING_SKIPLIST)            redisPanic(&quot;Unknown target encoding&quot;);        // 创建有序集合结构        zs = zmalloc(sizeof(*zs));        // 字典        zs-&gt;dict = dictCreate(&amp;zsetDictType,NULL);        // 跳跃表        zs-&gt;zsl = zslCreate();        // 有序集合在 ziplist 中的排列：        //        // | member-1 | score-1 | member-2 | score-2 | ... |        //        // 指向 ziplist 中的首个节点（保存着元素成员）        eptr = ziplistIndex(zl,0);        redisAssertWithInfo(NULL,zobj,eptr != NULL);        // 指向 ziplist 中的第二个节点（保存着元素分值）        sptr = ziplistNext(zl,eptr);        redisAssertWithInfo(NULL,zobj,sptr != NULL);        // 遍历所有 ziplist 节点，并将元素的成员和分值添加到有序集合中        while (eptr != NULL) {            // 取出分值            score = zzlGetScore(sptr);            // 取出成员            redisAssertWithInfo(NULL,zobj,ziplistGet(eptr,&amp;vstr,&amp;vlen,&amp;vlong));            if (vstr == NULL)                ele = createStringObjectFromLongLong(vlong);            else                ele = createStringObject((char*)vstr,vlen);            /* Has incremented refcount since it was just created. */            // 将成员和分值分别关联到跳跃表和字典中            node = zslInsert(zs-&gt;zsl,score,ele);            redisAssertWithInfo(NULL,zobj,dictAdd(zs-&gt;dict,ele,&amp;node-&gt;score) == DICT_OK);            incrRefCount(ele); /* Added to dictionary. */            // 移动指针，指向下个元素            zzlNext(zl,&amp;eptr,&amp;sptr);        }        // 释放原来的 ziplist        zfree(zobj-&gt;ptr);        // 更新对象的值，以及编码方式        zobj-&gt;ptr = zs;        zobj-&gt;encoding = REDIS_ENCODING_SKIPLIST;    // 从 SKIPLIST 转换为 ZIPLIST 编码    } else if (zobj-&gt;encoding == REDIS_ENCODING_SKIPLIST) {        // 新的 ziplist        unsigned char *zl = ziplistNew();        if (encoding != REDIS_ENCODING_ZIPLIST)            redisPanic(&quot;Unknown target encoding&quot;);        /* Approach similar to zslFree(), since we want to free the skiplist at         * the same time as creating the ziplist. */        // 指向跳跃表        zs = zobj-&gt;ptr;        // 先释放字典，因为只需要跳跃表就可以遍历整个有序集合了        dictRelease(zs-&gt;dict);        // 指向跳跃表首个节点        node = zs-&gt;zsl-&gt;header-&gt;level[0].forward;        // 释放跳跃表表头        zfree(zs-&gt;zsl-&gt;header);        zfree(zs-&gt;zsl);        // 遍历跳跃表，取出里面的元素，并将它们添加到 ziplist        while (node) {            // 取出解码后的值对象            ele = getDecodedObject(node-&gt;obj);            // 添加元素到 ziplist            zl = zzlInsertAt(zl,NULL,ele,node-&gt;score);            decrRefCount(ele);            // 沿着跳跃表的第 0 层前进            next = node-&gt;level[0].forward;            zslFreeNode(node);            node = next;        }        // 释放跳跃表        zfree(zs);        // 更新对象的值，以及对象的编码方式        zobj-&gt;ptr = zl;        zobj-&gt;encoding = REDIS_ENCODING_ZIPLIST;    } else {        redisPanic(&quot;Unknown sorted set encoding&quot;);    }}</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/zsetadd.png" alt=""></p><h2 id="10-5-内存回收"><a href="#10-5-内存回收" class="headerlink" title="10.5 内存回收"></a>10.5 内存回收</h2><p>因为 C 语言并不具备自动的内存回收功能， 所以 Redis 在自己的对象系统中构建了一个引用计数（reference counting）技术实现的内存回收机制， 通过这一机制， 程序可以通过跟踪对象的引用计数信息， 在适当的时候自动释放对象并进行内存回收。</p><p>每个对象的引用计数信息由 redisObject 结构的 refcount 属性记录</p><p>对象的引用计数信息会随着对象的使用状态而不断变化：</p><ul><li>在创建一个新对象时， 引用计数的值会被初始化为 1 ；</li><li>当对象被一个新程序使用时， 它的引用计数值会被增一；</li><li>当对象不再被一个程序使用时， 它的引用计数值会被减一；</li><li>当对象的引用计数值变为 0 时， 对象所占用的内存会被释放。</li></ul><p>操作refcount的函数:</p><pre><code class="c">#file: src/object.c#incrRefCount 将对象的引用计数值增一。#decrRefCount 将对象的引用计数值减一，当对象的引用计数值等于0时，释放对象。#resetRefCount 将对象的引用计数值设置为0，但并不释放对象，这个函数通常在需要重新设置对象的引用计数值时使用/* * 为对象的引用计数增一 */void incrRefCount(robj *o) {    o-&gt;refcount++;}/* * 为对象的引用计数减一 * 当对象的引用计数降为 0 时，释放对象。 */void decrRefCount(robj *o) {    if (o-&gt;refcount &lt;= 0) redisPanic(&quot;decrRefCount against refcount &lt;= 0&quot;);    // 释放对象    if (o-&gt;refcount == 1) {        switch(o-&gt;type) {        case REDIS_STRING: freeStringObject(o); break;        case REDIS_LIST: freeListObject(o); break;        case REDIS_SET: freeSetObject(o); break;        case REDIS_ZSET: freeZsetObject(o); break;        case REDIS_HASH: freeHashObject(o); break;        default: redisPanic(&quot;Unknown object type&quot;); break;        }        zfree(o);    // 减少计数    } else {        o-&gt;refcount--;    }}robj *resetRefCount(robj *obj) {    obj-&gt;refcount = 0;    return obj;}</code></pre><h2 id="10-6-对象共享"><a href="#10-6-对象共享" class="headerlink" title="10.6 对象共享"></a>10.6 对象共享</h2><p>除了用于实现引用计数内存回收机制之外， 对象的引用计数属性还带有对象共享的作用。</p><p>在 Redis 中， 让多个键共享同一个值对象需要执行以下两个步骤：</p><ol><li>将数据库键的值指针指向一个现有的值对象；</li><li>将被共享的值对象的引用计数增一。</li></ol><p>目前来说， Redis 会在初始化服务器时， 创建一万个字符串对象， 这些对象包含了<code>从 0 到 9999 的所有整数值</code>， 当服务器需要用到值为 0 到 9999 的字符串对象时， 服务器就会使用这些共享对象， 而不是新创建对象。</p><p><code>【注意】redis只对包含整数值的字符串对象进行共享。</code></p><blockquote><p>尽管共享更复杂的对象可以节约更多的内存，但验证共享对象和目标对象是否相同所需的复杂度就会越高， 消耗的 CPU 时间也会越多</p></blockquote><h2 id="10-7-对象空转时长"><a href="#10-7-对象空转时长" class="headerlink" title="10.7 对象空转时长"></a>10.7 对象空转时长</h2><p>redisObject 结构包含一个属性为 lru 属性， 该属性记录了对象最后一次被命令程序访问的时间：</p><pre><code class="c">redis&gt; SET foo &quot;bar&quot;OKredis&gt; OBJECT IDLETIME foo(integer) 5redis&gt; OBJECT IDLETIME foo(integer) 15redis&gt; GET foo&quot;bar&quot;redis&gt; OBJECT IDLETIME foo(integer) 5</code></pre><p>如果服务器打开了 maxmemory 选项， 并且服务器用于回收内存的算法为 volatile-lru 或者 allkeys-lru ， 那么当服务器占用的内存数超过了 maxmemory 选项所设置的上限值时， 空转时长较高的那部分键会优先被服务器释放， 从而回收内存。</p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>9.Redis数据结构——zipmap</title>
      <link href="/2020/02/20/9-Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-zipmap/"/>
      <url>/2020/02/20/9-Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-zipmap/</url>
      
        <content type="html"><![CDATA[<p><code>【注意】注意，从 2.6 版本开始，Redis使用ziplist 来表示小Hash,而不再使用 zipmap</code></p><p>zipmap压缩字典为节约空间而实现的字符串到字符串映射结构<br>这个数据结构非常节约内存，并且支持复杂度为 O(N) 的查找操作。</p><p>Redis 使用这个数据结构来储存键值对数量不多的 Hash ，一旦键值对的数量超过某个给定值，Hash 的底层表示就会自动转换成哈希表。</p><p>因为很多时候，一个 Hash 都只保存少数几个 key-value 对，<br>所以使用 zipmap 比起直接使用真正的哈希表要节约不少内存。</p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>8.Redis数据结构——ziplist</title>
      <link href="/2020/02/20/8-Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-ziplist/"/>
      <url>/2020/02/20/8-Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-ziplist/</url>
      
        <content type="html"><![CDATA[<h2 id="8-1-什么是ziplist"><a href="#8-1-什么是ziplist" class="headerlink" title="8.1 什么是ziplist"></a>8.1 什么是ziplist</h2><p>压缩列表（ziplist）是列表键和哈希键的底层实现之一。</p><p>当一个列表键只包含少量列表项， 并且每个列表项要么就是小整数值， 要么就是长度比较短的字符串， 那么 Redis 就会使用压缩列表来做列表键的底层实现。</p><h2 id="8-2-数据结构"><a href="#8-2-数据结构" class="headerlink" title="8.2 数据结构"></a>8.2 数据结构</h2><p>在本质上就是一块连续的内存,逻辑上设计成了特殊编码的双端链表</p><pre><code class="c">#file: src/ziplist.c/*  * Ziplist 是为了尽可能地节约内存而设计的特殊编码双端链表。 * Ziplist 可以储存字符串值和整数值， * 其中，整数值被保存为实际的整数，而不是字符数组。 * Ziplist 允许在列表的两端进行 O(1) 复杂度的 push 和 pop 操作。 * 但是，因为这些操作都需要对整个 ziplist 进行内存重分配， * 所以实际的复杂度和 ziplist 占用的内存大小有关。 * ---------------------------------------------------------------------------- * * ZIPLIST OVERALL LAYOUT: * Ziplist 的整体布局： * * The general layout of the ziplist is as follows: * 以下是 ziplist 的一般布局： * * &lt;zlbytes&gt;&lt;zltail&gt;&lt;zllen&gt;&lt;entry&gt;&lt;entry&gt;&lt;zlend&gt; * * &lt;zlbytes&gt; 是一个无符号整数，保存着 ziplist 使用的内存数量。 * 通过这个值，程序可以直接对 ziplist 的内存大小进行调整， * 而无须为了计算 ziplist 的内存大小而遍历整个列表。 * * &lt;zltail&gt; 保存着到达列表中最后一个节点的偏移量。 * 这个偏移量使得对表尾的 pop 操作可以在无须遍历整个列表的情况下进行。 * * &lt;zllen&gt; 保存着列表中的节点数量。 *  * 当 zllen 保存的值大于 2**16-2 时， * 程序需要遍历整个列表才能知道列表实际包含了多少个节点。 * * &lt;zlend&gt; 的长度为 1 字节，值为 255 ，标识列表的末尾。 * * ZIPLIST 节点： * * 每个 ziplist 节点的前面都带有一个 header ，这个 header 包含两部分信息： * * 1)前置节点的长度，在程序从后向前遍历时使用。 * * 2)当前节点所保存的值的类型和长度。 * * 编码前置节点的长度的方法如下： * * 1) 如果前置节点的长度小于 254 字节，那么程序将使用 1 个字节来保存这个长度值。 * * 2) 如果前置节点的长度大于等于 254 字节，那么程序将使用 5 个字节来保存这个长度值： *    a) 第 1 个字节的值将被设为 254 ，用于标识这是一个 5 字节长的长度值。 *    b) 之后的 4 个字节则用于保存前置节点的实际长度。 * * * header 另一部分的内容和节点所保存的值有关。 * * 1) 如果节点保存的是字符串值， *    那么这部分 header 的头 2 个位将保存编码字符串长度所使用的类型， *    而之后跟着的内容则是字符串的实际长度。 * * |00pppppp| - 1 byte *      String value with length less than or equal to 63 bytes (6 bits). *      字符串的长度小于或等于 63 字节。 * |01pppppp|qqqqqqqq| - 2 bytes *      String value with length less than or equal to 16383 bytes (14 bits). *      字符串的长度小于或等于 16383 字节。 * |10______|qqqqqqqq|rrrrrrrr|ssssssss|tttttttt| - 5 bytes *      String value with length greater than or equal to 16384 bytes. *      字符串的长度大于或等于 16384 字节。 * * 2) 如果节点保存的是整数值， *    那么这部分 header 的头 2 位都将被设置为 1 ， *    而之后跟着的 2 位则用于标识节点所保存的整数的类型。 * * |11000000| - 1 byte *      Integer encoded as int16_t (2 bytes). *      节点的值为 int16_t 类型的整数，长度为 2 字节。 * |11010000| - 1 byte *      Integer encoded as int32_t (4 bytes). *      节点的值为 int32_t 类型的整数，长度为 4 字节。 * |11100000| - 1 byte *      Integer encoded as int64_t (8 bytes). *      节点的值为 int64_t 类型的整数，长度为 8 字节。 * |11110000| - 1 byte *      Integer encoded as 24 bit signed (3 bytes). *      节点的值为 24 位（3 字节）长的整数。 * |11111110| - 1 byte *      Integer encoded as 8 bit signed (1 byte). *      节点的值为 8 位（1 字节）长的整数。 * |1111xxxx| - (with xxxx between 0000 and 1101) immediate 4 bit integer. *      Unsigned integer from 0 to 12. The encoded value is actually from *      1 to 13 because 0000 and 1111 can not be used, so 1 should be *      subtracted from the encoded 4 bit value to obtain the right value. *      节点的值为介于 0 至 12 之间的无符号整数。 *      因为 0000 和 1111 都不能使用，所以位的实际值将是 1 至 13 。 *      程序在取得这 4 个位的值之后，还需要减去 1 ，才能计算出正确的值。 *      比如说，如果位的值为 0001 = 1 ，那么程序返回的值将是 1 - 1 = 0 。 * |11111111| - End of ziplist. *      ziplist 的结尾标识 * * All the integers are represented in little endian byte order. * * 所有整数都表示为小端字节序。 *</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/ziplist.png" alt=""></p><h2 id="8-3-数据插入"><a href="#8-3-数据插入" class="headerlink" title="8.3 数据插入"></a>8.3 数据插入</h2><pre><code class="c">#file: src/ziplist.c/* * 根据指针 p 所指定的位置，将长度为 slen 的字符串 s 插入到 zl 中。 * 函数的返回值为完成插入操作之后的 ziplist * T = O(N^2) */static unsigned char *__ziplistInsert(unsigned char *zl, unsigned char *p, unsigned char *s, unsigned int slen) {    // 记录当前 ziplist 的长度    size_t curlen = intrev32ifbe(ZIPLIST_BYTES(zl)), reqlen, prevlen = 0;    size_t offset;    int nextdiff = 0;    unsigned char encoding = 0;    long long value = 123456789; /* initialized to avoid warning. Using a value                                    that is easy to see if for some reason                                    we use it uninitialized. */    zlentry entry, tail;    /* Find out prevlen for the entry that is inserted. */    if (p[0] != ZIP_END) {        // 如果 p[0] 不指向列表末端，说明列表非空，并且 p 正指向列表的其中一个节点        // 那么取出 p 所指向节点的信息，并将它保存到 entry 结构中        // 然后用 prevlen 变量记录前置节点的长度        // （当插入新节点之后 p 所指向的节点就成了新节点的前置节点）        // T = O(1)        entry = zipEntry(p);        prevlen = entry.prevrawlen;    } else {        // 如果 p 指向表尾末端，那么程序需要检查列表是否为：        // 1)如果 ptail 也指向 ZIP_END ，那么列表为空；        // 2)如果列表不为空，那么 ptail 将指向列表的最后一个节点。        unsigned char *ptail = ZIPLIST_ENTRY_TAIL(zl);        if (ptail[0] != ZIP_END) {            // 表尾节点为新节点的前置节点            // 取出表尾节点的长度            // T = O(1)            prevlen = zipRawEntryLength(ptail);        }    }    // 尝试看能否将输入字符串转换为整数，如果成功的话：    // 1)value 将保存转换后的整数值    // 2)encoding 则保存适用于 value 的编码方式    // 无论使用什么编码， reqlen 都保存节点值的长度    // T = O(N)    if (zipTryEncoding(s,slen,&amp;value,&amp;encoding)) {        /* &#39;encoding&#39; is set to the appropriate integer encoding */        reqlen = zipIntSize(encoding);    } else {        /* &#39;encoding&#39; is untouched, however zipEncodeLength will use the         * string length to figure out how to encode it. */        reqlen = slen;    }    /* We need space for both the length of the previous entry and     * the length of the payload. */    // 计算编码前置节点的长度所需的大小    // T = O(1)    reqlen += zipPrevEncodeLength(NULL,prevlen);    // 计算编码当前节点值所需的大小    // T = O(1)    reqlen += zipEncodeLength(NULL,encoding,slen);    // 只要新节点不是被添加到列表末端，    // 那么程序就需要检查看 p 所指向的节点（的 header）能否编码新节点的长度。    // nextdiff 保存了新旧编码之间的字节大小差，如果这个值大于 0     // 那么说明需要对 p 所指向的节点（的 header ）进行扩展    // T = O(1)    nextdiff = (p[0] != ZIP_END) ? zipPrevLenByteDiff(p,reqlen) : 0;    // 因为重分配空间可能会改变 zl 的地址    // 所以在分配之前，需要记录 zl 到 p 的偏移量，然后在分配之后依靠偏移量还原 p     offset = p-zl;    // curlen 是 ziplist 原来的长度    // reqlen 是整个新节点的长度    // nextdiff 是新节点的后继节点扩展 header 的长度（要么 0 字节，要么 4 个字节）    // T = O(N)    zl = ziplistResize(zl,curlen+reqlen+nextdiff);    p = zl+offset;    /* Apply memory move when necessary and update tail offset. */    if (p[0] != ZIP_END) {        // 新元素之后还有节点，因为新元素的加入，需要对这些原有节点进行调整        /* Subtract one because of the ZIP_END bytes */        // 移动现有元素，为新元素的插入空间腾出位置        // T = O(N)        memmove(p+reqlen,p-nextdiff,curlen-offset-1+nextdiff);        /* Encode this entry&#39;s raw length in the next entry. */        // 将新节点的长度编码至后置节点        // p+reqlen 定位到后置节点        // reqlen 是新节点的长度        // T = O(1)        zipPrevEncodeLength(p+reqlen,reqlen);        /* Update offset for tail */        // 更新到达表尾的偏移量，将新节点的长度也算上        ZIPLIST_TAIL_OFFSET(zl) =            intrev32ifbe(intrev32ifbe(ZIPLIST_TAIL_OFFSET(zl))+reqlen);        // 如果新节点的后面有多于一个节点        // 那么程序需要将 nextdiff 记录的字节数也计算到表尾偏移量中        // 这样才能让表尾偏移量正确对齐表尾节点        // T = O(1)        tail = zipEntry(p+reqlen);        if (p[reqlen+tail.headersize+tail.len] != ZIP_END) {            ZIPLIST_TAIL_OFFSET(zl) =                intrev32ifbe(intrev32ifbe(ZIPLIST_TAIL_OFFSET(zl))+nextdiff);        }    } else {        // 新元素是新的表尾节点        ZIPLIST_TAIL_OFFSET(zl) = intrev32ifbe(p-zl);    }    // 当 nextdiff != 0 时，新节点的后继节点的（header 部分）长度已经被改变，    // 所以需要级联地更新后续的节点    if (nextdiff != 0) {        offset = p-zl;        // T  = O(N^2)        zl = __ziplistCascadeUpdate(zl,p+reqlen);        p = zl+offset;    }    // 一切搞定，将前置节点的长度写入新节点的 header    p += zipPrevEncodeLength(p,prevlen);    // 将节点值的长度写入新节点的 header    p += zipEncodeLength(p,encoding,slen);    // 写入节点值    if (ZIP_IS_STR(encoding)) {        // T = O(N)        memcpy(p,s,slen);    } else {        // T = O(1)        zipSaveInteger(p,value,encoding);    }    // 更新列表的节点数量计数器    // T = O(1)    ZIPLIST_INCR_LENGTH(zl,1);    return zl;}</code></pre><h2 id="8-4-数据删除"><a href="#8-4-数据删除" class="headerlink" title="8.4 数据删除"></a>8.4 数据删除</h2><pre><code class="c">#file: src/ziplist.c/*  * 从位置 p 开始，连续删除 num 个节点。 * 函数的返回值为处理删除操作之后的 ziplist 。 * * T = O(N^2) */static unsigned char *__ziplistDelete(unsigned char *zl, unsigned char *p, unsigned int num) {    unsigned int i, totlen, deleted = 0;    size_t offset;    int nextdiff = 0;    zlentry first, tail;    // 计算被删除节点总共占用的内存字节数    // 以及被删除节点的总个数    // T = O(N)    first = zipEntry(p);    for (i = 0; p[0] != ZIP_END &amp;&amp; i &lt; num; i++) {        p += zipRawEntryLength(p);        deleted++;    }    // totlen 是所有被删除节点总共占用的内存字节数    totlen = p-first.p;    if (totlen &gt; 0) {        if (p[0] != ZIP_END) {            // 执行这里，表示被删除节点之后仍然有节点存在            // 因为位于被删除范围之后的第一个节点的 header 部分的大小            // 可能容纳不了新的前置节点，所以需要计算新旧前置节点之间的字节数差            // T = O(1)            nextdiff = zipPrevLenByteDiff(p,first.prevrawlen);            // 如果有需要的话，将指针 p 后退 nextdiff 字节，为新 header 空出空间            p -= nextdiff;            // 将 first 的前置节点的长度编码至 p 中            // T = O(1)            zipPrevEncodeLength(p,first.prevrawlen);            // 更新到达表尾的偏移量            // T = O(1)            ZIPLIST_TAIL_OFFSET(zl) =                intrev32ifbe(intrev32ifbe(ZIPLIST_TAIL_OFFSET(zl))-totlen);            // 如果被删除节点之后，有多于一个节点            // 那么程序需要将 nextdiff 记录的字节数也计算到表尾偏移量中            // 这样才能让表尾偏移量正确对齐表尾节点            // T = O(1)            tail = zipEntry(p);            if (p[tail.headersize+tail.len] != ZIP_END) {                ZIPLIST_TAIL_OFFSET(zl) =                   intrev32ifbe(intrev32ifbe(ZIPLIST_TAIL_OFFSET(zl))+nextdiff);            }            // 从表尾向表头移动数据，覆盖被删除节点的数据            // T = O(N)            memmove(first.p,p,                intrev32ifbe(ZIPLIST_BYTES(zl))-(p-zl)-1);        } else {            // 执行这里，表示被删除节点之后已经没有其他节点了            // T = O(1)            ZIPLIST_TAIL_OFFSET(zl) =                intrev32ifbe((first.p-zl)-first.prevrawlen);        }        // 缩小并更新 ziplist 的长度        offset = first.p-zl;        zl = ziplistResize(zl, intrev32ifbe(ZIPLIST_BYTES(zl))-totlen+nextdiff);        ZIPLIST_INCR_LENGTH(zl,-deleted);        p = zl+offset;        // 如果 p 所指向的节点的大小已经变更，那么进行级联更新        // 检查 p 之后的所有节点是否符合 ziplist 的编码要求        // T = O(N^2)        if (nextdiff != 0)            zl = __ziplistCascadeUpdate(zl,p);    }    return zl;}</code></pre><h2 id="8-5-联级更新"><a href="#8-5-联级更新" class="headerlink" title="8.5 联级更新"></a>8.5 联级更新</h2><p>我们看到插入和删除的时候都调用了<code>__ziplistCascadeUpdate</code>函数来更新后面节点的大小</p><pre><code class="c">#file: src/ziplist.c/* * 当将一个新节点添加到某个节点之前的时候， * 如果原节点的 header 空间不足以保存新节点的长度， * 那么就需要对原节点的 header 空间进行扩展（从 1 字节扩展到 5 字节）。 * * 但是，当对原节点进行扩展之后，原节点的下一个节点的 prevlen 可能出现空间不足， * 这种情况在多个连续节点的长度都接近 ZIP_BIGLEN 时可能发生。 * * 这个函数就用于检查并修复后续节点的空间问题。 * * 反过来说， * 因为节点的长度变小而引起的连续缩小也是可能出现的， * 不过，为了避免扩展-缩小-扩展-缩小这样的情况反复出现（flapping，抖动）， * 我们不处理这种情况，而是任由 prevlen 比所需的长度更长。 * * 注意，程序的检查是针对 p 的后续节点，而不是 p 所指向的节点。 * 因为节点 p 在传入之前已经完成了所需的空间扩展工作。 * * T = O(N^2) */static unsigned char *__ziplistCascadeUpdate(unsigned char *zl, unsigned char *p) {    size_t curlen = intrev32ifbe(ZIPLIST_BYTES(zl)), rawlen, rawlensize;    size_t offset, noffset, extra;    unsigned char *np;    zlentry cur, next;    // T = O(N^2)    while (p[0] != ZIP_END) {        // 将 p 所指向的节点的信息保存到 cur 结构中        cur = zipEntry(p);        // 当前节点的长度        rawlen = cur.headersize + cur.len;        // 计算编码当前节点的长度所需的字节数        // T = O(1)        rawlensize = zipPrevEncodeLength(NULL,rawlen);        // 如果已经没有后续空间需要更新了，跳出        if (p[rawlen] == ZIP_END) break;        // 取出后续节点的信息，保存到 next 结构中        // T = O(1)        next = zipEntry(p+rawlen);        // 后续节点编码当前节点的空间已经足够，无须再进行任何处理，跳出        // 可以证明，只要遇到一个空间足够的节点，        // 那么这个节点之后的所有节点的空间都是足够的        if (next.prevrawlen == rawlen) break;        if (next.prevrawlensize &lt; rawlensize) {            // 执行到这里，表示 next 空间的大小不足以编码 cur 的长度            // 所以程序需要对 next 节点的（header 部分）空间进行扩展            // 记录 p 的偏移量            offset = p-zl;            // 计算需要增加的节点数量            extra = rawlensize-next.prevrawlensize;            // 扩展 zl 的大小            // T = O(N)            zl = ziplistResize(zl,curlen+extra);            // 还原指针 p            p = zl+offset;            // 记录下一节点的偏移量            np = p+rawlen;            noffset = np-zl;            // 当 next 节点不是表尾节点时，更新列表到表尾节点的偏移量            //             // 不用更新的情况（next 为表尾节点）：            //            // |     | next |      ==&gt;    |     | new next          |            //       ^                          ^            //       |                          |            //     tail                        tail            //            // 需要更新的情况（next 不是表尾节点）：            //            // | next |     |   ==&gt;     | new next          |     |            //        ^                        ^            //        |                        |            //    old tail                 old tail            //             // 更新之后：            //            // | new next          |     |            //                     ^            //                     |            //                  new tail            // T = O(1)            if ((zl+intrev32ifbe(ZIPLIST_TAIL_OFFSET(zl))) != np) {                ZIPLIST_TAIL_OFFSET(zl) =                    intrev32ifbe(intrev32ifbe(ZIPLIST_TAIL_OFFSET(zl))+extra);            }            /* Move the tail to the back. */            // 向后移动 cur 节点之后的数据，为 cur 的新 header 腾出空间            //            // 示例：            //            // | header | value |  ==&gt;  | header |    | value |  ==&gt;  | header      | value |            //                                   |&lt;--&gt;|            //                            为新 header 腾出的空间            // T = O(N)            memmove(np+rawlensize,                np+next.prevrawlensize,                curlen-noffset-next.prevrawlensize-1);            // 将新的前一节点长度值编码进新的 next 节点的 header            // T = O(1)            zipPrevEncodeLength(np,rawlen);            /* Advance the cursor */            // 移动指针，继续处理下个节点            p += rawlen;            curlen += extra;        } else {            if (next.prevrawlensize &gt; rawlensize) {                /* This would result in shrinking, which we want to avoid.                 * So, set &quot;rawlen&quot; in the available bytes. */                // 执行到这里，说明 next 节点编码前置节点的 header 空间有 5 字节                // 而编码 rawlen 只需要 1 字节                // 但是程序不会对 next 进行缩小，                // 所以这里只将 rawlen 写入 5 字节的 header 中就算了。                // T = O(1)                zipPrevEncodeLengthForceLarge(p+rawlen,rawlen);            } else {                // 运行到这里，                // 说明 cur 节点的长度正好可以编码到 next 节点的 header 中                // T = O(1)                zipPrevEncodeLength(p+rawlen,rawlen);            }            /* Stop here, as the raw length of &quot;next&quot; has not changed. */            break;        }    }    return zl;}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>7.Redis数据结构——iniset</title>
      <link href="/2020/02/19/7-Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-iniset/"/>
      <url>/2020/02/19/7-Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-iniset/</url>
      
        <content type="html"><![CDATA[<h2 id="7-1-什么是iniset"><a href="#7-1-什么是iniset" class="headerlink" title="7.1 什么是iniset"></a>7.1 什么是iniset</h2><p>整数集合（intset）是集合键的底层实现之一,当一个集合只包含整数值元素,并且这个集合的元素数量不多时,Redis就会使用整数集合作为集合键的底层实现</p><h2 id="7-1-数据结构"><a href="#7-1-数据结构" class="headerlink" title="7.1 数据结构"></a>7.1 数据结构</h2><pre><code class="c">#file: src/intset.htypedef struct intset {    // 编码方式    uint32_t encoding;    // 集合包含的元素数量    uint32_t length;    // 保存元素的数组    int8_t contents[];} intset;/* * encoding的取值　intset 的编码方式 */#define INTSET_ENC_INT16 (sizeof(int16_t))#define INTSET_ENC_INT32 (sizeof(int32_t))#define INTSET_ENC_INT64 (sizeof(int64_t))</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/intsetadd.png" alt=""></p><h2 id="7-2-centent类型"><a href="#7-2-centent类型" class="headerlink" title="7.2 centent类型"></a>7.2 centent类型</h2><p><code>struct iniset</code>里的<code>content</code>数据的真正类型取决于encoding的属性值</p><pre><code class="c">#file: src/intset.c/*  * 返回适用于传入值 v 的编码方式 * T = O(1) */static uint8_t _intsetValueEncoding(int64_t v) {    if (v &lt; INT32_MIN || v &gt; INT32_MAX)        return INTSET_ENC_INT64;    else if (v &lt; INT16_MIN || v &gt; INT16_MAX)        return INTSET_ENC_INT32;    else        return INTSET_ENC_INT16;}</code></pre><ul><li>如果 encoding 属性的值为 INTSET_ENC_INT16 ， 那么 contents 就是一个 int16_t 类型的数组， 数组里的每个项都是一个 int16_t 类型的整数值 （最小值为 -32,768 ，最大值为 32,767 ）。</li><li>如果 encoding 属性的值为 INTSET_ENC_INT32 ， 那么 contents 就是一个 int32_t 类型的数组， 数组里的每个项都是一个 int32_t 类型的整数值 （最小值为 -2,147,483,648 ，最大值为 2,147,483,647 ）。</li><li>如果 encoding 属性的值为 INTSET_ENC_INT64 ， 那么 contents 就是一个 int64_t 类型的数组， 数组里的每个项都是一个 int64_t 类型的整数值 （最小值为 -9,223,372,036,854,775,808 ，最大值为 9,223,372,036,854,775,807 ）。</li></ul><h2 id="7-3-类型升级"><a href="#7-3-类型升级" class="headerlink" title="7.3 类型升级"></a>7.3 类型升级</h2><p>每当我们要将一个新元素添加到整数集合里面， 并且新元素的类型比整数集合现有所有元素的类型都要长时， 整数集合需要先进行升级（upgrade）， 然后才能将新元素添加到整数集合里面。</p><p>升级整数集合并添加新元素共分为三步进行：</p><ul><li>根据新元素的类型， 扩展整数集合底层数组的空间大小， 并为新元素分配空间。</li><li>将底层数组现有的所有元素都转换成与新元素相同的类型， 并将类型转换后的元素放置到正确的位上， 而且在放置元素的过程中，需要继续维持底层数组的有序性质不变。</li><li>将新元素添加到底层数组里面。</li></ul><pre><code class="c">#file: src/intset.c/*  * 根据值 value 所使用的编码方式，对整数集合的编码进行升级， * 并将值 value 添加到升级后的整数集合中。 * 返回值：添加新元素之后的整数集合 * T = O(N) */static intset *intsetUpgradeAndAdd(intset *is, int64_t value) {    // 当前的编码方式    uint8_t curenc = intrev32ifbe(is-&gt;encoding);    // 新值所需的编码方式    uint8_t newenc = _intsetValueEncoding(value);    // 当前集合的元素数量    int length = intrev32ifbe(is-&gt;length);    // 根据 value 的值，决定是将它添加到底层数组的最前端还是最后端    // 注意，因为 value 的编码比集合原有的其他元素的编码都要大    // 所以 value 要么大于集合中的所有元素，要么小于集合中的所有元素    // 因此，value 只能添加到底层数组的最前端或最后端    int prepend = value &lt; 0 ? 1 : 0;    /* First set new encoding and resize */    // 更新集合的编码方式    is-&gt;encoding = intrev32ifbe(newenc);    // 根据新编码对集合（的底层数组）进行空间调整    // T = O(N)    is = intsetResize(is,intrev32ifbe(is-&gt;length)+1);    // 根据集合原来的编码方式，从底层数组中取出集合元素    // 然后再将元素以新编码的方式添加到集合中    // 当完成了这个步骤之后，集合中所有原有的元素就完成了从旧编码到新编码的转换    // 因为新分配的空间都放在数组的后端，所以程序先从后端向前端移动元素    // 举个例子，假设原来有 curenc 编码的三个元素，它们在数组中排列如下：    // | x | y | z |     // 当程序对数组进行重分配之后，数组就被扩容了（符号 ？ 表示未使用的内存）：    // | x | y | z | ? |   ?   |   ?   |    // 这时程序从数组后端开始，重新插入元素：    // | x | y | z | ? |   z   |   ?   |    // | x | y |   y   |   z   |   ?   |    // |   x   |   y   |   z   |   ?   |    // 最后，程序可以将新元素添加到最后 ？ 号标示的位置中：    // |   x   |   y   |   z   |  new  |    // 上面演示的是新元素比原来的所有元素都大的情况，也即是 prepend == 0    // 当新元素比原来的所有元素都小时（prepend == 1），调整的过程如下：    // | x | y | z | ? |   ?   |   ?   |    // | x | y | z | ? |   ?   |   z   |    // | x | y | z | ? |   y   |   z   |    // | x | y |   x   |   y   |   z   |    // 当添加新值时，原本的 | x | y | 的数据将被新值代替    // |  new  |   x   |   y   |   z   |    // T = O(N)    while(length--)        _intsetSet(is,length+prepend,_intsetGetEncoded(is,length,curenc));    /* Set the value at the beginning or the end. */    // 设置新值，根据 prepend 的值来决定是添加到数组头还是数组尾    if (prepend)        _intsetSet(is,0,value);    else        _intsetSet(is,intrev32ifbe(is-&gt;length),value);    // 更新整数集合的元素数量    is-&gt;length = intrev32ifbe(intrev32ifbe(is-&gt;length)+1);    return is;}</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/intsetupgrade.png" alt=""></p><h2 id="7-4-类型降级"><a href="#7-4-类型降级" class="headerlink" title="7.4 类型降级"></a>7.4 类型降级</h2><p>我们在起删除给定元素的代码中可以发现:<code>intset不支持降级操作!</code></p><pre><code class="c">/* * 从整数集合中删除值 value 。 * *success 的值指示删除是否成功： * - 因值不存在而造成删除失败时该值为 0 。 * - 删除成功时该值为 1 。 * T = O(N) */intset *intsetRemove(intset *is, int64_t value, int *success) {    // 计算 value 的编码方式    uint8_t valenc = _intsetValueEncoding(value);    uint32_t pos;    // 默认设置标识值为删除失败    if (success) *success = 0;    // 当 value 的编码大小小于或等于集合的当前编码方式（说明 value 有可能存在于集合）    // 并且 intsetSearch 的结果为真，那么执行删除    // T = O(log N)    if (valenc &lt;= intrev32ifbe(is-&gt;encoding) &amp;&amp; intsetSearch(is,value,&amp;pos)) {        // 取出集合当前的元素数量        uint32_t len = intrev32ifbe(is-&gt;length);        /* We know we can delete */        // 设置标识值为删除成功        if (success) *success = 1;        /* Overwrite value with tail and update length */        // 如果 value 不是位于数组的末尾        // 那么需要对原本位于 value 之后的元素进行移动        //        // 举个例子，如果数组表示如下，而 b 为删除的目标        // | a | b | c | d |        // 那么 intsetMoveTail 将 b 之后的所有数据向前移动一个元素的空间，        // 覆盖 b 原来的数据        // | a | c | d | d |        // 之后 intsetResize 缩小内存大小时，        // 数组末尾多出来的一个元素的空间将被移除        // | a | c | d |        if (pos &lt; (len-1)) intsetMoveTail(is,pos+1,pos);        // 缩小数组的大小，移除被删除元素占用的空间        // T = O(N)        is = intsetResize(is,len-1);        // 更新集合的元素数量        is-&gt;length = intrev32ifbe(len-1);    }    return is;}</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/intsetdel.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>6.Redis数据结构——跳表</title>
      <link href="/2020/02/19/6-Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E8%B7%B3%E8%A1%A8/"/>
      <url>/2020/02/19/6-Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E8%B7%B3%E8%A1%A8/</url>
      
        <content type="html"><![CDATA[<h2 id="6-1-什么是跳表"><a href="#6-1-什么是跳表" class="headerlink" title="6.1 什么是跳表"></a>6.1 什么是跳表</h2><p>跳表全称叫做跳跃表，简称跳表。是redis有序集合的底层实现</p><p>redis 的跳跃表实现由 zskiplist 和 zskiplistNode 两个结构组成， 其中 zskiplist 用于保存跳跃表信息（比如表头节点、表尾节点、长度）， 而 zskiplistNode 则用于表示跳跃表节点。<br>每个跳跃表节点的层高都是 1 至 32 之间的随机数。<br>在同一个跳跃表中， 多个节点可以包含相同的分值， 但每个节点的成员对象必须是唯一的。<br>跳跃表中的节点按照分值大小进行排序， 当分值相同时， 节点按照成员对象的大小进行排序。</p><h2 id="6-2-跳表的数据结构"><a href="#6-2-跳表的数据结构" class="headerlink" title="6.2 跳表的数据结构"></a>6.2 跳表的数据结构</h2><pre><code class="c">#file : reids.htypedef struct zskiplistNode {    // 成员对象    robj *obj;    // 分值   double score;    // 后退指针    struct zskiplistNode *backward;    // 层    struct zskiplistLevel {        // 前进指针        struct zskiplistNode *forward;        // 跨度        unsigned int span;    } level[];} zskiplistNode;/* * 跳跃表 */typedef struct zskiplist {    // 表头节点和表尾节点    struct zskiplistNode *header, *tail;    // 表中节点的数量    unsigned long length;    // 表中层数最大的节点的层数    int level;} zskiplist;</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/skipnode.png" alt=""></p><h2 id="6-3-跳表的初始化与插入"><a href="#6-3-跳表的初始化与插入" class="headerlink" title="6.3 跳表的初始化与插入"></a>6.3 跳表的初始化与插入</h2><pre><code class="c">#file : src/t_zset.c#define ZSKIPLIST_MAXLEVEL 32/* * 创建并返回一个新的跳跃表 * T = O(1) */zskiplist *zslCreate(void) {    int j;    zskiplist *zsl;    // 分配空间    zsl = zmalloc(sizeof(*zsl));    // 设置高度和起始层数    zsl-&gt;level = 1;    zsl-&gt;length = 0;    // 初始化表头节点    // T = O(1)    zsl-&gt;header = zslCreateNode(ZSKIPLIST_MAXLEVEL,0,NULL);    for (j = 0; j &lt; ZSKIPLIST_MAXLEVEL; j++) {        zsl-&gt;header-&gt;level[j].forward = NULL;        zsl-&gt;header-&gt;level[j].span = 0;    }    zsl-&gt;header-&gt;backward = NULL;    // 设置表尾    zsl-&gt;tail = NULL;    return zsl;}/* * 创建一个层数为 level 的跳跃表节点， * 并将节点的成员对象设置为 obj ，分值设置为 score 。 * 返回值为新创建的跳跃表节点 * T = O(1) */zskiplistNode *zslCreateNode(int level, double score, robj *obj) {    // 分配空间    zskiplistNode *zn = zmalloc(sizeof(*zn)+level*sizeof(struct zskiplistLevel));    // 设置属性    zn-&gt;score = score;    zn-&gt;obj = obj;    return zn;}/* * 创建一个成员为 obj ，分值为 score 的新节点， * 并将这个新节点插入到跳跃表 zsl 中。 * 函数的返回值为新节点。 * T_wrost = O(N^2), T_avg = O(NlogN) */zskiplistNode *zslInsert(zskiplist *zsl, double score, robj *obj) {    zskiplistNode *update[ZSKIPLIST_MAXLEVEL], *x;    unsigned int rank[ZSKIPLIST_MAXLEVEL];    int i, level;    //判断给的分值是够合理    redisAssert(!isnan(score));    // 在各个层查找节点的插入位置    // T_wrost = O(N^2), T_avg = O(N log N)    x = zsl-&gt;header;    for (i = zsl-&gt;level-1; i &gt;= 0; i--) {        // 如果 i 不是 zsl-&gt;level-1 层        // 那么 i 层的起始 rank 值为 i+1 层的 rank 值        // 各个层的 rank 值一层层累积        // 最终 rank[0] 的值加一就是新节点的前置节点的排位        // rank[0] 会在后面成为计算 span 值和 rank 值的基础        rank[i] = i == (zsl-&gt;level-1) ? 0 : rank[i+1];        // 沿着前进指针遍历跳跃表        // T_wrost = O(N^2), T_avg = O(N log N)        while (x-&gt;level[i].forward &amp;&amp;            (x-&gt;level[i].forward-&gt;score &lt; score ||                // 比对分值                (x-&gt;level[i].forward-&gt;score == score &amp;&amp;                // 比对成员， T = O(N)                compareStringObjects(x-&gt;level[i].forward-&gt;obj,obj) &lt; 0))) {            // 记录沿途跨越了多少个节点            rank[i] += x-&gt;level[i].span;            // 移动至下一指针            x = x-&gt;level[i].forward;        }        // 记录将要和新节点相连接的节点        update[i] = x;    }    /*      * zslInsert() 的调用者会确保同分值且同成员的元素不会出现，     * 所以这里不需要进一步进行检查，可以直接创建新元素。     */    // 获取一个随机值作为新节点的层数    // T = O(N)    level = zslRandomLevel();    // 如果新节点的层数比表中其他节点的层数都要大    // 那么初始化表头节点中未使用的层，并将它们记录到 update 数组中    // 将来也指向新节点    if (level &gt; zsl-&gt;level) {        // 初始化未使用层        // T = O(1)        for (i = zsl-&gt;level; i &lt; level; i++) {            rank[i] = 0;            update[i] = zsl-&gt;header;            update[i]-&gt;level[i].span = zsl-&gt;length;        }        // 更新表中节点最大层数        zsl-&gt;level = level;    }    // 创建新节点    x = zslCreateNode(level,score,obj);    // 将前面记录的指针指向新节点，并做相应的设置    // T = O(1)    for (i = 0; i &lt; level; i++) {        // 设置新节点的 forward 指针        x-&gt;level[i].forward = update[i]-&gt;level[i].forward;        // 将沿途记录的各个节点的 forward 指针指向新节点        update[i]-&gt;level[i].forward = x;        /* update span covered by update[i] as x is inserted here */        // 计算新节点跨越的节点数量        x-&gt;level[i].span = update[i]-&gt;level[i].span - (rank[0] - rank[i]);        // 更新新节点插入之后，沿途节点的 span 值        // 其中的 +1 计算的是新节点        update[i]-&gt;level[i].span = (rank[0] - rank[i]) + 1;    }    /* increment span for untouched levels */    // 未接触的节点的 span 值也需要增一，这些节点直接从表头指向新节点    // T = O(1)    for (i = level; i &lt; zsl-&gt;level; i++) {        update[i]-&gt;level[i].span++;    }    // 设置新节点的后退指针    x-&gt;backward = (update[0] == zsl-&gt;header) ? NULL : update[0];    if (x-&gt;level[0].forward)        x-&gt;level[0].forward-&gt;backward = x;    else        zsl-&gt;tail = x;    // 跳跃表的节点计数增一    zsl-&gt;length++;    return x;}</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/skiplist.png" alt=""></p><h2 id="6-4-跳表的层数确定"><a href="#6-4-跳表的层数确定" class="headerlink" title="6.4 跳表的层数确定"></a>6.4 跳表的层数确定</h2><p>理论上每层的比例为1:2,但是在实际使用中，我们的链表是通过多次插入/删除形成的，换句话说是“动态”的。这个比例就被被破坏了。因此跳表（skip list）表示，我们就不强制要求 1:2 了，一个节点要不要被索引，建几层的索引，都在节点插入时由<code>zslRandomLevel</code>决定:</p><pre><code class="c">#file : src/t_zset.c/*  * 返回一个随机值，用作新跳跃表节点的层数。 * 返回值介乎 1 和 ZSKIPLIST_MAXLEVEL 之间（包含 ZSKIPLIST_MAXLEVEL）， * 根据随机算法所使用的幂次定律，越大的值生成的几率越小。 * T = O(N) */int zslRandomLevel(void) {    int level = 1;    while ((random()&amp;0xFFFF) &lt; (ZSKIPLIST_P * 0xFFFF))        level += 1;    return (level&lt;ZSKIPLIST_MAXLEVEL) ? level : ZSKIPLIST_MAXLEVEL;}</code></pre><h2 id="6-5-删除跳表节点"><a href="#6-5-删除跳表节点" class="headerlink" title="6.5 删除跳表节点"></a>6.5 删除跳表节点</h2><pre><code class="c">#file : src/t_zset.c/*  * 内部删除函数， * 被 zslDelete 、 zslDeleteRangeByScore 和 zslDeleteByRank 等函数调用。 * T = O(1) */void zslDeleteNode(zskiplist *zsl, zskiplistNode *x, zskiplistNode **update) {    int i;    // 更新所有和被删除节点 x 有关的节点的指针，解除它们之间的关系    // T = O(1)    for (i = 0; i &lt; zsl-&gt;level; i++) {        if (update[i]-&gt;level[i].forward == x) {            update[i]-&gt;level[i].span += x-&gt;level[i].span - 1;            update[i]-&gt;level[i].forward = x-&gt;level[i].forward;        } else {            update[i]-&gt;level[i].span -= 1;        }    }    // 更新被删除节点 x 的前进和后退指针    if (x-&gt;level[0].forward) {        x-&gt;level[0].forward-&gt;backward = x-&gt;backward;    } else {        zsl-&gt;tail = x-&gt;backward;    }    // 更新跳跃表最大层数（只在被删除节点是跳跃表中最高的节点时才执行）    // T = O(1)    while(zsl-&gt;level &gt; 1 &amp;&amp; zsl-&gt;header-&gt;level[zsl-&gt;level-1].forward == NULL)        zsl-&gt;level--;    // 跳跃表节点计数器减一    zsl-&gt;length--;}</code></pre>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>5.Redis数据结构——字典</title>
      <link href="/2020/02/19/5-Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E5%AD%97%E5%85%B8/"/>
      <url>/2020/02/19/5-Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E5%AD%97%E5%85%B8/</url>
      
        <content type="html"><![CDATA[<h2 id="5-1-什么是字典"><a href="#5-1-什么是字典" class="headerlink" title="5.1 什么是字典"></a>5.1 什么是字典</h2><p>字典经常作为一种数据结构内置在很多高级编程语言里面， 但 Redis 所使用的 C 语言并没有内置这种数据结构， 因此 Redis 构建了自己的字典实现。</p><p>字典在 Redis 中的应用相当广泛， 比如 Redis 的数据库就是使用字典来作为底层实现的， 对数据库的增、删、查、改操作也是构建在对字典的操作之上的。</p><p>Redis 的字典使用哈希表作为底层实现， 一个哈希表里面可以有多个哈希表节点， 而每个哈希表节点就保存了字典中的一个键值对。</p><h2 id="5-2-dict-hash-dictEntry数据结构"><a href="#5-2-dict-hash-dictEntry数据结构" class="headerlink" title="5.2 dict hash dictEntry数据结构"></a>5.2 dict hash dictEntry数据结构</h2><pre><code class="c">#file: src/dict.h/* * 字典 */typedef struct dict {    // 类型特定函数    dictType *type;    // 私有数据    void *privdata;    // 哈希表    dictht ht[2];    // rehash 索引    // 当 rehash 不在进行时，值为 -1    int rehashidx; /* rehashing not in progress if rehashidx == -1 */    // 目前正在运行的安全迭代器的数量    int iterators; /* number of iterators currently running */} dict;/* * 哈希表 * 每个字典都使用两个哈希表，从而实现渐进式 rehash 。 */typedef struct dictht {       // 哈希表数组    dictEntry **table;    // 哈希表大小    // 哈希表的大小总是 2 的某个次方，并且哈希表使用链表来解决冲突    unsigned long size;    // 哈希表大小掩码，用于计算索引值    // 总是等于 size - 1    unsigned long sizemask;    // 该哈希表已有节点的数量    unsigned long used;} dictht;/* * 哈希表节点 */typedef struct dictEntry {    // 键    void *key;    // 值    union {        void *val;        uint64_t u64;        int64_t s64;    } v;    // 指向下个哈希表节点，形成链表    struct dictEntry *next;} dictEntry;</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/dict.png" alt=""></p><h2 id="5-3-添加字典"><a href="#5-3-添加字典" class="headerlink" title="5.3 添加字典"></a>5.3 添加字典</h2><pre><code class="c"># file:src/dict.c/* * 尝试将给定键值对添加到字典中 * 只有给定键key不存在于字典时,添加操作才会成功 * 添加成功返回DICT_OK ，失败返回 DICT_ERR * 最坏T=O(N),平均O(1)  */int dictAdd(dict *d, void *key, void *val){    // 尝试添加键到字典，并返回包含了这个键的新哈希节点    dictEntry *entry = dictAddRaw(d,key);    // 键已存在，添加失败    if (!entry) return DICT_ERR;    // 键不存在，设置节点的值    // T = O(1)    dictSetVal(d, entry, val);    // 添加成功    return DICT_OK;}/* * 尝试将键插入到字典中 * 如果键已经在字典存在，那么返回 NULL * 如果键不存在，那么程序创建新的哈希节点， * 将节点和键关联，并插入到字典，然后返回节点本身 */dictEntry *dictAddRaw(dict *d, void *key){    int index;    dictEntry *entry;    dictht *ht;    // 如果条件允许的话，进行单步 rehash    if (dictIsRehashing(d)) _dictRehashStep(d);    // 计算键在哈希表中的索引值 使用MurmurHash算法    // 如果值为 -1 ，那么表示键已经存在    // T = O(N)    if ((index = _dictKeyIndex(d, key)) == -1)        return NULL;    // T = O(1)    // 如果字典正在 rehash ，那么将新键添加到 1 号哈希表    // 否则，将新键添加到 0 号哈希表    ht = dictIsRehashing(d) ? &amp;d-&gt;ht[1] : &amp;d-&gt;ht[0];    // 为新节点分配空间    entry = zmalloc(sizeof(*entry));    // 将新节点插入到链表表头    entry-&gt;next = ht-&gt;table[index];    ht-&gt;table[index] = entry;    // 更新哈希表已使用节点数量    ht-&gt;used++;    // 设置新节点的键    // T = O(1)    dictSetKey(d, entry, key);    return entry;}</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/dictadd.png" alt=""></p><h2 id="5-3-Rehash"><a href="#5-3-Rehash" class="headerlink" title="5.3 Rehash"></a>5.3 Rehash</h2><pre><code class="c"># file:src/dict.c/*  * 执行 N 步渐进式 rehash 。 * 返回 1 表示仍有键需要从 0 号哈希表移动到 1 号哈希表， * 返回 0 则表示所有键都已经迁移完毕。 * * 注意，每步 rehash 都是以一个哈希表索引（桶）作为单位的， * 一个桶里可能会有多个节点， * 被 rehash 的桶里的所有节点都会被移动到新哈希表。 * T = O(N) */int dictRehash(dict *d, int n) {    // 只可以在 rehash 进行中时执行    if (!dictIsRehashing(d)) return 0;    // 进行 N 步迁移    // T = O(N)    while(n--) {        dictEntry *de, *nextde;        /* Check if we already rehashed the whole table... */        // 如果 0 号哈希表为空，那么表示 rehash 执行完毕        // T = O(1)        if (d-&gt;ht[0].used == 0) {            // 释放 0 号哈希表            zfree(d-&gt;ht[0].table);            // 将原来的 1 号哈希表设置为新的 0 号哈希表            d-&gt;ht[0] = d-&gt;ht[1];            // 重置旧的 1 号哈希表            _dictReset(&amp;d-&gt;ht[1]);            // 关闭 rehash 标识            d-&gt;1rehashidx = -1;            // 返回 0 ，向调用者表示 rehash 已经完成            return 0;        }        /* Note that rehashidx can&#39;t overflow as we are sure there are more         * elements because ht[0].used != 0 */        // 确保 rehashidx 没有越界        assert(d-&gt;ht[0].size &gt; (unsigned)d-&gt;rehashidx);        // 略过数组中为空的索引，找到下一个非空索引        while(d-&gt;ht[0].table[d-&gt;rehashidx] == NULL) d-&gt;rehashidx++;        // 指向该索引的链表表头节点        de = d-&gt;ht[0].table[d-&gt;rehashidx];        /* Move all the keys in this bucket from the old to the new hash HT */        // 将链表中的所有节点迁移到新哈希表        // T = O(1)        while(de) {            unsigned int h;            // 保存下个节点的指针            nextde = de-&gt;next;            /* Get the index in the new hash table */            // 计算新哈希表的哈希值，以及节点插入的索引位置            h = dictHashKey(d, de-&gt;key) &amp; d-&gt;ht[1].sizemask;            // 插入节点到新哈希表            de-&gt;next = d-&gt;ht[1].table[h];            d-&gt;ht[1].table[h] = de;            // 更新计数器            d-&gt;ht[0].used--;            d-&gt;ht[1].used++;            // 继续处理下个节点            de = nextde;        }        // 将刚迁移完的哈希表索引的指针设为空        d-&gt;ht[0].table[d-&gt;rehashidx] = NULL;        // 更新 rehash 索引        d-&gt;rehashidx++;    }    return 1;}/* * 在给定毫秒数内，以 100 步为单位，对字典进行 rehash 。 * * T = O(N) */int dictRehashMilliseconds(dict *d, int ms) {    // 记录开始时间    long long start = timeInMilliseconds();    int rehashes = 0;    while(dictRehash(d,100)) {        rehashes += 100;        // 如果时间已过，跳出        if (timeInMilliseconds()-start &gt; ms) break;    }    return rehashes;}/* * 创建一个新的哈希表，并根据字典的情况，选择以下其中一个动作来进行： * 1) 如果字典的 0 号哈希表为空，那么将新哈希表设置为 0 号哈希表 * 2) 如果字典的 0 号哈希表非空，那么将新哈希表设置为 1 号哈希表， *    并打开字典的 rehash 标识，使得程序可以开始对字典进行 rehash * size 参数不够大，或者 rehash 已经在进行时，返回 DICT_ERR 。 * 成功创建 0 号哈希表，或者 1 号哈希表时，返回 DICT_OK 。 */int dictExpand(dict *d, unsigned long size){    // 新哈希表    dictht n; /* the new hash table */    // 根据 size 参数，计算哈希表的大小    // T = O(1)    unsigned long realsize = _dictNextPower(size);    /* the size is invalid if it is smaller than the number of     * elements already inside the hash table */    // 不能在字典正在 rehash 时进行    // size 的值也不能小于 0 号哈希表的当前已使用节点    if (dictIsRehashing(d) || d-&gt;ht[0].used &gt; size)        return DICT_ERR;    /* Allocate the new hash table and initialize all pointers to NULL */    // 为哈希表分配空间，并将所有指针指向 NULL    n.size = realsize;    n.sizemask = realsize-1;    // T = O(N)    n.table = zcalloc(realsize*sizeof(dictEntry*));    n.used = 0;    /* Is this the first initialization? If so it&#39;s not really a rehashing     * we just set the first hash table so that it can accept keys. */    // 如果 0 号哈希表为空，那么这是一次初始化：    // 程序将新哈希表赋给 0 号哈希表的指针，然后字典就可以开始处理键值对了。    if (d-&gt;ht[0].table == NULL) {        d-&gt;ht[0] = n;        return DICT_OK;    }    /* Prepare a second hash table for incremental rehashing */    // 如果 0 号哈希表非空，那么这是一次 rehash ：    // 程序将新哈希表设置为 1 号哈希表，    // 并将字典的 rehash 标识打开，让程序可以开始对字典进行 rehash    d-&gt;ht[1] = n;    d-&gt;rehashidx = 0;    return DICT_OK;}/* * 计算第一个大于等于 size 的 2 的 N 次方，用作哈希表的值 * T = O(1) */static unsigned long _dictNextPower(unsigned long size){    unsigned long i = DICT_HT_INITIAL_SIZE;    if (size &gt;= LONG_MAX) return LONG_MAX;    while(1) {        if (i &gt;= size)            return i;        i *= 2;    }}</code></pre><p>随着操作的不断执行， 哈希表保存的键值对会逐渐地增多或者减少， 为了让哈希表的负载因子（load factor）维持在一个合理的范围之内， 当哈希表保存的键值对数量太多或者太少时， 程序需要对哈希表的大小进行相应的扩展或者收缩。</p><p>扩展和收缩哈希表的工作可以通过执行 rehash （重新散列）操作来完成， Redis 对字典的哈希表执行 rehash 的步骤如下：</p><ul><li><p>为字典的 ht[1] 哈希表分配空间(使用函数dictExpand)， 这个哈希表的空间大小(使用_dictNextPower计算大小)取决于要执行的操作， 以及 ht[0] 当前包含的键值对数量 （也即是 ht[0].used 属性的值）：</p><ul><li><p>如果执行的是扩展操作， 那么 ht[1] 的大小为第一个大于等于 ht[0].used * 2 的 2^n</p></li><li><p>如果执行的是收缩操作， 那么 ht[1] 的大小为第一个大于等于 ht[0].used 的 2^n </p></li></ul></li><li><p>将保存在 ht[0] 中的所有键值对 rehash 到 ht[1] 上面： rehash 指的是重新计算键的哈希值和索引值， 然后将键值对放置到 ht[1] 哈希表的指定位置上</p></li><li><p>当 ht[0] 包含的所有键值对都迁移到了 ht[1] 之后 （ht[0] 变为空表）, 释放 ht[0] ,将 ht[1] 设置为 ht[0] ， 并在 ht[1] 新创建一个空白哈希表，为下一次 rehash 做准备</p></li></ul><p>实际过程大多通过渐进式rehash来将数据做转移:</p><ul><li>为 ht[1] 分配空间， 让字典同时持有 ht[0] 和 ht[1] 两个哈希表。</li><li>在字典中维持一个索引计数器变量 rehashidx ， 并将它的值设置为 0 ， 表示 rehash 工作正式开始。</li><li>在 rehash 进行期间， 每次对字典执行添加、删除、查找或者更新操作时， 程序除了执行指定的操作以外， 还会顺带将 ht[0] 哈希表在 rehashidx 索引上的所有键值对 rehash 到 ht[1] ， 当 rehash 工作完成之后， 程序将 rehashidx 属性的值增一。</li><li>随着字典操作的不断执行， 最终在某个时间点上， ht[0] 的所有键值对都会被 rehash 至 ht[1] ， 这时程序将 rehashidx 属性的值设为 -1 ， 表示 rehash 操作已完成。</li></ul><p>另外， 在渐进式 rehash 执行期间， 新添加到字典的键值对一律会被保存到 ht[1] 里面， 而 ht[0] 则不再进行任何添加操作： 这一措施保证了 ht[0] 包含的键值对数量会只减不增， 并随着 rehash 操作的执行而最终变成空表。</p><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/rehash0.png" alt=""><br><img src="http://cache410.oss-cn-beijing.aliyuncs.com/rehash1.png" alt=""><br><img src="http://cache410.oss-cn-beijing.aliyuncs.com/rehash2.png" alt=""><br><img src="http://cache410.oss-cn-beijing.aliyuncs.com/rehash3.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>11.Mysql日志</title>
      <link href="/2020/02/18/11-Mysql%E6%97%A5%E5%BF%97/"/>
      <url>/2020/02/18/11-Mysql%E6%97%A5%E5%BF%97/</url>
      
        <content type="html"><![CDATA[<p>主要包括:</p><ol><li>错误日志 Error Log</li><li>慢查询日志 Slow Query Log</li><li>二进制日志 Bin Log</li><li>重做日志 Redo log</li><li>回滚日志 Undo Log</li><li>中继日志 Relay Log</li><li>一般查询日志 Gerneral Log</li></ol><h2 id="11-1-Error-Log"><a href="#11-1-Error-Log" class="headerlink" title="11.1 Error Log"></a>11.1 Error Log</h2><h3 id="11-1-1-作用"><a href="#11-1-1-作用" class="headerlink" title="11.1.1 作用"></a>11.1.1 作用</h3><p>用来记录从服务器启动和关闭过程中的信息（未必是错误信息，如mysql如何启动InnoDB的表空间文件的、如何初始化自己的存储引擎的等等）、服务器运行过程中的错误信息、事件调度器运行一个事件时产生的信息、在从服务器上启动服务器进程时产生的信息</p><p>在mysql数据库中，错误日志功能是默认开启的</p><p>默认情况下，错误日志存储在mysql数据库的数据文件中。</p><p>错误日志文件通常的名称为hostname.err。其中，hostname表示服务器主机名。</p><h3 id="11-1-2-相关参数"><a href="#11-1-2-相关参数" class="headerlink" title="11.1.2 相关参数"></a>11.1.2 相关参数</h3><pre><code class="mysql">#错误日志存储的位置以及名称mysql&gt; select @@log_error;+-----------------+| @@log_error     |+-----------------+| ./centos7-1.err |+-----------------+1 row in set (0.00 sec)#错误级别mysql&gt; select @@log_error_verbosity;+-----------------------+| @@log_error_verbosity |+-----------------------+|                     3 |+-----------------------+1 row in set (0.00 sec)#错误级别　已废弃不推荐使用的　等同于log_error_verbositymysql&gt; select @@log_warnings;+----------------+| @@log_warnings |+----------------+|              2 |+----------------+1 row in set, 1 warning (0.00 sec)</code></pre><h3 id="11-1-3-修改记录级别"><a href="#11-1-3-修改记录级别" class="headerlink" title="11.1.3 修改记录级别"></a>11.1.3 修改记录级别</h3><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/error_verbosity.png" alt=""></p><h3 id="11-1-4-清空归档日志"><a href="#11-1-4-清空归档日志" class="headerlink" title="11.1.4 清空归档日志"></a>11.1.4 清空归档日志</h3><pre><code class="shell">mv host_name.err host_name.err-oldmysqladmin flush-logsmv host_name.err-old backup-directory</code></pre><h2 id="11-2-Slow-Query-Log"><a href="#11-2-Slow-Query-Log" class="headerlink" title="11.2 Slow Query Log"></a>11.2 Slow Query Log</h2><h3 id="11-2-1-作用"><a href="#11-2-1-作用" class="headerlink" title="11.2.1 作用"></a>11.2.1 作用</h3><p>查询日志是用来记录执行时间超过指定时间的查询语句。通过慢查询日志，可以查找出哪些查询语句的执行效率很低，以便进行优化。一般建议开启，它对服务器性能的影响微乎其微，但是可以记录mysql服务器上执行了很长时间的查询语句。可以帮助我们定位性能问题</p><h3 id="11-2-2-相关参数"><a href="#11-2-2-相关参数" class="headerlink" title="11.2.2 相关参数"></a>11.2.2 相关参数</h3><pre><code class="mysql">#是否开启慢查询 1开启 0关闭mysql&gt; select @@slow_query_log;+------------------+| @@slow_query_log |+------------------+|                1 |+------------------+1 row in set (0.00 sec)# 慢查询文件位置mysql&gt; select @@slow_query_log_file;+----------------------------+| @@slow_query_log_file      |+----------------------------+| /log/3306/slowlog/slow.log |+----------------------------+1 row in set (0.00 sec)# 慢查询时间阀值　单位为秒mysql&gt; select @@long_query_time;+-------------------+| @@long_query_time |+-------------------+|          5.000000 |+-------------------+1 row in set (0.00 sec)# 1开启　０关闭# 运行的SQL语句没有使用索引，则MySQL数据库同样会将这条SQL语句记录到慢查询日志文件mysql&gt; select @@log_queries_not_using_indexes;+---------------------------------+| @@log_queries_not_using_indexes |+---------------------------------+|                               1 |+---------------------------------+1 row in set (0.00 sec)</code></pre><h3 id="11-2-3-查看slow-log"><a href="#11-2-3-查看slow-log" class="headerlink" title="11.2.3 查看slow.log"></a>11.2.3 查看slow.log</h3><p>slow.log属于文本日志,我们可以通过linux命令查看slow.log</p><pre><code class="shell">[root@centos7-1 slowlog]# tail -f slow.log # Time: 2019-07-09T02:00:48.300499Z# User@Host: root[root] @ localhost []  Id:     5# Query_time: 5.075423  Lock_time: 0.000123 Rows_sent: 174  Rows_examined: 4994309SET timestamp=1562637648;select * from t_scrm_pet_info where pet_name =&quot;Winter&quot;;</code></pre><p>含义如下:</p><ul><li>SQL 的执行时间：# Time: 2019-07-09T02:00:48.300499Z</li><li>SQL 的执行主机：# User@Host: root[root] @ localhost []  Id:     5</li><li>SQL 的执行信息：# Query_time: 5.075423  Lock_time: 0.000123 Rows_sent: 174  Rows_examined: 4994309</li><li>SQL 的执行时间：SET timestamp=1562637648;</li><li>SQL 的执行内容：select * from t_scrm_pet_info where pet_name =”Winter”;</li></ul><h3 id="11-2-4-mysqldumpslow"><a href="#11-2-4-mysqldumpslow" class="headerlink" title="11.2.4 mysqldumpslow"></a>11.2.4 mysqldumpslow</h3><p>mysqldumpslow 是一个针对于 MySQL 慢查询的命令行程序。可以通过 mysqldumpslow 查找出查询较慢的 SQL 语句。</p><pre><code class="shell">[root@centos7-1 slowlog]# mysqldumpslow --helpUsage: mysqldumpslow [ OPTS... ] [ LOGS... ]Parse and summarize the MySQL slow query log. Options are  --verbose    verbose  --debug      debug  --help       write this text to standard output  -v           verbose  -d           debug  -s ORDER     what to sort by (al, at, ar, c, l, r, t), &#39;at&#39; is default                al: average lock time                ar: average rows sent                at: average query time                 c: count                 l: lock time                 r: rows sent                 t: query time    -r           reverse the sort order (largest last instead of first)  -t NUM       just show the top n queries  -a           don&#39;t abstract all numbers to N and strings to &#39;S&#39;  -n NUM       abstract numbers with at least n digits within names  -g PATTERN   grep: only consider stmts that include this string  -h HOSTNAME  hostname of db server for *-slow.log filename (can be wildcard),               default is &#39;*&#39;, i.e. match all  -i NAME      name of server instance (if using mysql.server startup script)  -l           don&#39;t subtract lock time from total time</code></pre><p>通过mysqldumpslow  查看慢日志：</p><pre><code class="shell">[root@centos7-1 slowlog]# mysqldumpslow slow.log Reading mysql slow query log from slow.logCount: 3  Time=5.12s (15s)  Lock=0.00s (0s)  Rows=1661.3 (4984), root[root]@localhost  select * from t_scrm_pet_info where pet_name =&quot;S&quot;</code></pre><ul><li>Count：出现次数,</li><li>Time：执行最长时间和累计总耗费时间</li><li>Lock：等待锁的时间</li><li>Rows：返回客户端行总数和扫描行总数</li></ul><h2 id="11-3-Binlog"><a href="#11-3-Binlog" class="headerlink" title="11.3 Binlog"></a>11.3 Binlog</h2><h3 id="11-3-1-作用"><a href="#11-3-1-作用" class="headerlink" title="11.3.1 作用"></a>11.3.1 作用</h3><p>主要记录数据库变化(DDL,DCL,DML)性质的日志,是逻辑层性质日志</p><p>主要有以下作用:</p><ul><li>恢复(recovery)： 对于误删除的数据可以通过binlog恢复</li><li>复制(replication) :可以通过binlog做主从同步</li><li>审计(audit)：可以通过抓取binlog日志来满足审计需求</li></ul><h3 id="11-3-2-相关参数"><a href="#11-3-2-相关参数" class="headerlink" title="11.3.2 相关参数"></a>11.3.2 相关参数</h3><pre><code class="ini">cat /etc/my.cnf....#主机编号　主从同步的时候使用　开启binlog需要加此参数server_id=1            #日志存放的目录＋日志名前缀 :mysql-bin.000001 mysql-bin.000002 ...log_bin=/log/3306/binlog/mysql-bin#binlog日志刷盘策略【重要】sync_binlog=1#binlig的记录格式binlog_format=row#指定单个binlog文件的大小(默认1G)max_binlog_size=200M</code></pre><h4 id="11-3-2-1-binglog-format"><a href="#11-3-2-1-binglog-format" class="headerlink" title="11.3.2.1 binglog_format"></a>11.3.2.1 binglog_format</h4><p>二进制日志有以下几种格式可选:</p><ul><li><p>STATEMENT模式（SBR）</p><p>每一条会修改数据的sql语句会记录到binlog中。优点是并不需要记录每一条sql语句和每一行的数据变化，减少了binlog日志量，节约IO，提高性能。缺点是在某些情况下会导致master-slave中的数据不一致(如sleep()函数， last_insert_id()，以及user-defined functions(udf)等会出现问题</p></li><li><p>ROW模式（RBR）(<code>5.7版本默认</code>)</p><p>不记录每条sql语句的上下文信息，仅需记录哪条数据被修改了，修改成什么样了。而且不会出现某些特定情况下的存储过程、或function、或trigger的调用和触发无法被正确复制的问题。缺点是会产生大量的日志，尤其是alter table的时候会让日志暴涨。</p></li><li><p>MIXED模式（MBR）</p><p>以上两种模式的混合使用，一般的复制使用STATEMENT模式保存binlog，对于STATEMENT模式无法复制的操作使用ROW模式保存binlog，MySQL会根据执行的SQL语句选择日志保存方式。</p></li></ul><table><thead><tr><th align="center">模式</th><th align="left">优点</th><th align="center">缺点</th></tr></thead><tbody><tr><td align="center">SBR</td><td align="left">可读性高,日志量少,主从版本可以不一样</td><td align="center">不够严禁</td></tr><tr><td align="center">RBR</td><td align="left">可读性底,日志量大,主从版本需要统一</td><td align="center">足够严禁</td></tr></tbody></table><h2 id="11-4-Redo-Log"><a href="#11-4-Redo-Log" class="headerlink" title="11.4 Redo Log"></a>11.4 Redo Log</h2><h2 id="11-5-Undo-Log"><a href="#11-5-Undo-Log" class="headerlink" title="11.5 Undo Log"></a>11.5 Undo Log</h2>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> Mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>10.MysqlInnodb存储引擎</title>
      <link href="/2020/02/18/10-MysqlInnodb%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/"/>
      <url>/2020/02/18/10-MysqlInnodb%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/</url>
      
        <content type="html"><![CDATA[<h2 id="10-1-关键特性"><a href="#10-1-关键特性" class="headerlink" title="10.1 关键特性"></a>10.1 关键特性</h2><ul><li>B-tree索引+聚簇索引</li><li>数据缓存与加密</li><li>外键支持</li><li>行级锁</li><li>事务和MVCC</li><li>复制和备份恢复</li></ul><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/InnoDBStorageEngineFeatures.png" alt=""></p><h2 id="10-2-Innodb逻辑结构图"><a href="#10-2-Innodb逻辑结构图" class="headerlink" title="10.2 Innodb逻辑结构图"></a>10.2 Innodb逻辑结构图</h2><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/innodb-architecture5.7.png" alt=""></p><h2 id="10-3-Innodb内存结构"><a href="#10-3-Innodb内存结构" class="headerlink" title="10.3 Innodb内存结构"></a>10.3 Innodb内存结构</h2><p>主要包括以下几部分:</p><ul><li>Buffer Pool</li><li>Change Buffer</li><li>AHI</li><li>Log Buffer</li></ul><h3 id="10-3-1-Buffer-Pool"><a href="#10-3-1-Buffer-Pool" class="headerlink" title="10.3.1 Buffer Pool"></a>10.3.1 Buffer Pool</h3><h4 id="10-3-1-1-作用"><a href="#10-3-1-1-作用" class="headerlink" title="10.3.1.1 作用"></a>10.3.1.1 作用</h4><p>前面的文章Mysql索引介绍中,我们知道Innodb是以页为储存单位来保存数据的,<code>读取和处理数据的时候同样需要已页为单位将数据加载到内存中</code> </p><p>如果没有Buffer Pool会进行频繁的磁盘IO,这样会大大拉低Mysql的性能,因此Mysql使用Buffer Pool来做存储数据和索引的缓存,容许在内存中直接操作表数据,提高处理速度</p><blockquote><p>Buffer Pool 的功能就是 缓存“页” ，减少磁盘IO,提高读写效率。</p></blockquote><h4 id="10-3-1-2-Buffer-Pool结构"><a href="#10-3-1-2-Buffer-Pool结构" class="headerlink" title="10.3.1.2 Buffer Pool结构"></a>10.3.1.2 Buffer Pool结构</h4><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/buffer_pool1.png" alt=""></p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/bufferpoolself.png" alt=""></p><p>Buffer Poll是由一个个Instance组成,每个instance都有自己的锁，信号量，物理块(Buffer chunks)以及逻辑链表(下面的各种List)，即<code>各个instance之间没有竞争关系，可以并发读取与写入</code>。所有instance的物理块(Buffer chunks)在数据库启动的时候被分配，直到数据库关闭内存才予以释放</p><pre><code>innodb_buffer_pool_instances = innodb_buffer_pool_size/innodb_buffer_pool_instanceInstance实例数目=BufferPool总大小/每个Instance的大小【注意】当innodb_buffer_pool_size小于1GB时候，innodb_buffer_pool_instances被重置为1，主要是防止有太多小的instance从而导致性能问题</code></pre><p>每个Buffer Pool Instance有一个page hash链表，通过它，使用space_id和page_no就能快速找到已经被读入内存的数据页，而不用线性遍历LRU List去查找。</p><p>注意这个hash表不是InnoDB的自适应哈希(AHI)，自适应哈希是为了减少Btree的扫描，而page hash是为了避免扫描LRU List。</p><p><code>Buffer Pool会通过三种Page和链表来管理这些经常访问的数据，保证热数据不被置换出Buffer Pool</code></p><h4 id="10-3-1-3-Page的分类"><a href="#10-3-1-3-Page的分类" class="headerlink" title="10.3.1.3 Page的分类"></a>10.3.1.3 Page的分类</h4><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/pageclass.png" alt=""></p><h4 id="10-3-1-4-链表的分类"><a href="#10-3-1-4-链表的分类" class="headerlink" title="10.3.1.4 链表的分类"></a>10.3.1.4 链表的分类</h4><p>链表节点是数据页的控制体(控制体中有指针指向真正的数据页)，链表中的所有节点都有同一的属性，引入其的目的是方便管理</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/listclass.png" alt=""></p><ul><li><p>Free List</p><p>Free 链表 存放的是空闲页面，初始化的时候申请一定数量的页面</p><p>在执行SQL的过程中，每次成功load 页面到内存后，会判断Free 链表的页面是否够用。如果不够用的话，就flush LRU 链表和Flush 链表来释放空闲页。如果够用，就从Free 链表里面删除对应的页面，在LRU 链表增加页面，保持总数不变。</p></li><li><p>LRU List</p><p>默认情况下：</p><ol><li><p>Old 链表占整个LRU 链表的比例是3/8。该比例由<code>innodb_old_blocks_pct</code>控制，默认值是37（3/8*100）。该值取值范围为5~95，为全局动态变量。</p></li><li><p>当新的页被读取到Buffer Pool里面的时候，和<code>传统的LRU算法插入到LRU链表头部不同，Innodb LRU算法是将新的页面插入到Yong 链表的尾部和Old 链表的头部中间的位置，这个位置叫做Mid Point</code>，如下图所示</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/lrulist.png" alt=""></p></li></ol></li></ul><ol start="3"><li><p>频繁访问一个Buffer Pool的页面，会促使页面往Young链表的头部移动。如果一个Page在被读到Buffer Pool后很快就被访问(需要超过innodb_old_block_time)，那么该Page会往Young List的头部移动，但是如果一个页面是通过预读的方式读到Buffer Pool，且之后短时间内没有被访问，那么很可能在下次访问之前就被移动到Old List的尾部，而被驱逐了。</p></li><li><p>随着数据库的持续运行，新的页面被不断的插入到LRU链表的Mid Point，Old 链表里的页面会逐渐的被移动Old链表的尾部。同时，当经常被访问的页面移动到LRU链表头部的时候，那些没有被访问的页面会逐渐的被移动到链表的尾部。最终，位于Old 链表尾部的页面将被驱逐。</p></li><li><p>如果一个数据页已经处于Young 链表，当它再次被访问的时候，<code>只有当其处于Young 链表长度的1/4(大约值)之后，才会被移动到Young 链表的头部</code>。这样做的目的是减少对LRU 链表的修改，因为LRU 链表的目标是保证经常被访问的数据页不会被驱逐出去。</p></li><li><p>innodb_old_blocks_time 控制的Old 链表头部页面的转移策略。<code>该Page需要在Old 链表停留超过innodb_old_blocks_time 时间，之后再次被访问，才会移动到Young 链表</code>。这么操作是避免Young 链表被那些只在innodb_old_blocks_time时间间隔内频繁访问，之后就不被访问的页面塞满，从而有效的保护Young 链表。</p></li><li><p>在全表扫描或者全索引扫描的时候，Innodb会将大量的页面写入LRU 链表的Mid Point位置，并且只在短时间内访问几次之后就不再访问了。设置innodb_old_blocks_time的时间窗口可以有效的保护Young List，保证了真正的频繁访问的页面不被驱逐。<code>innodb_old_blocks_time 单位是毫秒，默认值是1000，即１秒。调大该值提高了从Old链表移动到Young链表的难度，会促使更多页面被移动到Old 链表，老化，从而被驱逐</code></p></li><li><p>当扫描的表很大，Buffer Pool都放不下时，可以将innodb_old_blocks_pct设置为较小的值，这样只读取一次的数据页就不会占据大部分的Buffer Pool。例如，设置innodb_old_blocks_pct = 5，会将仅读取一次的数据页在Buffer Pool的占用限制为5％。当经常扫描一些小表时，这些页面在Buffer Pool移动的开销较小，我们可以适当的调大innodb_old_blocks_pct，例如设置innodb_old_blocks_pct = 50</p></li></ol><p>  在SHOW ENGINE INNODB STATUS 里面提供了Buffer Pool一些监控指标，有几个我们需要关注一下：</p><pre><code class="mysql">  =====================================  mysql&gt; show engine innnodb status\G  ……  Pages made young 0, not young 0  0.00 youngs/s, 0.00 non-youngs/s  ======================================  数据页从冷到热，称为young；not young就是数据在没有成为热数据情况下就被刷走的量(累计值)。</code></pre><table><thead><tr><th align="left">指标</th><th align="left">场景</th><th align="left">处理方法</th><th>作用</th></tr></thead><tbody><tr><td align="left">youngs/s很小</td><td align="left">都是一些小事务，没有大表全扫描</td><td align="left">调大innodb_old_blocks_pct，减小innodb_old_blocks_time</td><td>使Old List 的长度更长，到Old List 的尾部消耗的时间会更久，提升下一次访问到Old List里面的页面的可能性</td></tr><tr><td align="left">youngs/s很大</td><td align="left"></td><td align="left">可以调小innodb_old_blocks_pct，同时调大innodb_old_blocks_time</td><td>保护热数据</td></tr><tr><td align="left">non-youngs/s很大</td><td align="left">大量的全表扫描</td><td align="left">可以调小innodb_old_blocks_pct，同时调大innodb_old_blocks_time</td><td>保护young list</td></tr><tr><td align="left">non-youngs/s不大</td><td align="left">存在大量全表扫描</td><td align="left">调大innodb_old_blocks_time</td><td>使得这些短时间频繁访问的页面保留在Old 链表里面</td></tr></tbody></table><p>  每隔1秒钟，Page Cleaner线程执行LRU List Flush的操作，来释放足够的Free Page。innodb_lru_scan_depth 变量控制每个Buffer Pool实例每次扫描LRU List的长度，来寻找对应的脏页，执行Flush操作。</p><ul><li><p>Flush List</p><ol><li>Flush 链表里面保存的都是脏页，也会存在于LRU 链表。</li><li>Flush 链表是按照oldest_modification排序，值大的在头部，值小的在尾部</li><li>当有页面访被修改的时候，使用mini-transaction，对应的page进入Flush 链表</li><li>如果当前页面已经是脏页，就不需要再次加入Flush list，否则是第一次修改，需要加入Flush 链表</li><li>当Page Cleaner线程执行flush操作的时候，从尾部开始scan，将一定的脏页写入磁盘，推进检查点，减少recover的时间</li></ol></li></ul><blockquote><p>LRU链表和FLUSH链表的区别 </p></blockquote><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/lru-flush-diff.png" alt=""></p><h3 id="10-3-2-Change-Buffer"><a href="#10-3-2-Change-Buffer" class="headerlink" title="10.3.2 Change Buffer"></a>10.3.2 Change Buffer</h3><h4 id="10-3-2-1-作用"><a href="#10-3-2-1-作用" class="headerlink" title="10.3.2.1 作用"></a>10.3.2.1 作用</h4><p>Change buffer的主要目的是将对<code>二级索引</code>的数据操作缓存下来，以此减少二级索引的随机IO，并达到操作合并的效果。</p><p>对表执行 INSERT，UPDATE和 DELETE操作时， 索引列的值（尤其是secondary keys的值）通常按未排序顺序排列，需要大量I / O才能使二级索引更新。Change Buffer会缓存这个更新当相关页面不在Buffer Pool中，从而磁盘上的相关页面不会立即被读避免了昂贵的I / O操作</p><h4 id="10-3-2-2-参数"><a href="#10-3-2-2-参数" class="headerlink" title="10.3.2.2 参数"></a>10.3.2.2 参数</h4><ul><li><p>参数：innodb_change_buffer_max_size</p><p>介绍：配置写缓冲的大小，占整个缓冲池的比例，默认值是25%，最大值是50%。</p><p><code>写多读少的业务，才需要调大这个值，读多写少的业务，25%其实也多了</code></p></li><li><p>参数：innodb_change_buffering<br>介绍：配置哪些写操作启用写缓冲，可以设置成all/none/inserts/deletes等</p></li></ul><pre><code class="mysql">mysql&gt; select @@innodb_change_buffer_max_size;+---------------------------------+| @@innodb_change_buffer_max_size |+---------------------------------+|                              25 |+---------------------------------+1 row in set (0.00 sec)mysql&gt; select @@innodb_change_buffering;+---------------------------+| @@innodb_change_buffering |+---------------------------+| all                       |+---------------------------+1 row in set (0.00 sec)</code></pre><h3 id="10-3-3-Adaptive-Hash-Index-AHI"><a href="#10-3-3-Adaptive-Hash-Index-AHI" class="headerlink" title="10.3.3 Adaptive Hash Index(AHI)"></a>10.3.3 Adaptive Hash Index(AHI)</h3><p>哈希(hash)是一种非常快的查找方法,在一般情况下这种查找的时间复杂度为O(1),即一般仅需要一次查找就能定位数据。而B+树的查找次数,取决于B+树的高度,在生产环境中,B+树的高度一般为3-4层,故需要3-4次的查询。</p><p>InnoDB存储引擎会监控对表上各索引页的查询。如果观察到建立哈希索引可以带来速度提升,则建立哈希索引,称之为<code>自适应哈希索引(Adaptive Hash Index,AHI)</code> AHI是通过缓冲池的B+树页构造而来,因此建立的速度很快,而且不需要对整张表构建哈希索引。 InnoDB存储引擎会自动根据访问的频率和模式来自动地为某些热点页建立哈希索引。</p><p>我们可以认为：<code>AHI是建立在B+Tree数索引上的索引</code>,是Innodb内部用来自身提高查询速度的自优化功能</p><h3 id="10-3-4-Log-Buffer"><a href="#10-3-4-Log-Buffer" class="headerlink" title="10.3.4 Log Buffer"></a>10.3.4 Log Buffer</h3><h4 id="10-3-4-1-功能"><a href="#10-3-4-1-功能" class="headerlink" title="10.3.4.1 功能"></a>10.3.4.1 功能</h4><p><code>负责redo日志的缓冲</code></p><p>redo log日志作用后面的文章将会介绍</p><h4 id="10-3-4-2-刷盘时机"><a href="#10-3-4-2-刷盘时机" class="headerlink" title="10.3.4.2 刷盘时机"></a>10.3.4.2 刷盘时机</h4><ul><li>redo log buffer 空间不足的时候</li><li>事务提交的时候</li><li>后台线程在不停的刷</li><li>服务正常关闭的时候</li><li>checkpoint的时候</li></ul><h4 id="10-3-4-3-关键参数"><a href="#10-3-4-3-关键参数" class="headerlink" title="10.3.4.3 关键参数"></a>10.3.4.3 关键参数</h4><ul><li>innodb_flush_log_at_trx_commit</li></ul><pre><code class="mysql">mysql&gt; select @@innodb_flush_log_at_trx_commit;+----------------------------------+| @@innodb_flush_log_at_trx_commit |+----------------------------------+|                                1 |+----------------------------------+1 row in set (0.00 sec)作用:主要控制了innodb将log buffer中的数据写入日志文件并flush磁盘的时间点取值分别为0、1、2三个参数说明:1.每次事物的提交都会引起日志文件写入、flush磁盘的操作，确保了事务的ACID；flush  到操作系统的文件系统缓存,fsync到物理磁盘.0.表示当事务提交时，不做日志写入操作，而是每秒钟将log buffer中的数据写入文件系统缓存并且秒fsync磁盘一次；2.每次事务提交引起写入文件系统缓存,但每秒钟完成一次fsync磁盘操作。</code></pre><ul><li>Innodb_flush_method</li></ul><pre><code class="mysql">mysql&gt; select @@Innodb_flush_method;+-----------------------+| @@Innodb_flush_method |+-----------------------+| NULL                  |+-----------------------+1 row in set (0.00 sec)</code></pre><p>可选模式:</p><ul><li><p>FSYNC(默认值):</p><ul><li>buffer pool的数据写磁盘时,要先经历os cache,然后再写到磁盘</li><li>log buffer的数据写磁盘时,要先经历os cache,然后再写到磁盘</li></ul></li><li><p>O_DSYNC:</p><ul><li>buffer pool的数据写磁盘时,要先经历os cache,然后再写到磁盘</li><li>log buffer 的数据写磁盘时,直接写到写到磁盘,跨过os cache</li></ul></li><li><p>O_DIRECT：</p><ul><li><p>buffer pool的数据写磁盘时,直接写到写到磁盘,跨过os cache</p></li><li><p>log buffer的数据写磁盘时,要先经历os cache,然后再写到磁盘</p></li></ul></li></ul><p>建议使用:O_DIRECT+固态硬盘</p><h2 id="10-4-Innodb物理存储结构"><a href="#10-4-Innodb物理存储结构" class="headerlink" title="10.4 Innodb物理存储结构"></a>10.4 Innodb物理存储结构</h2><p>​    主要包含以下几部分:</p><ul><li>系统表空间 System Tablespace</li><li>Undo日志</li><li>Redo日志</li><li>临时表空间</li><li>用户表空间</li><li>ib_buffer_pool</li></ul><h3 id="10-4-1-System-Tablespace"><a href="#10-4-1-System-Tablespace" class="headerlink" title="10.4.1 System Tablespace"></a>10.4.1 System Tablespace</h3><p>5.7版本的Mysql系统表空间用来存储以下信息:</p><ul><li>Innodb的数据字典</li><li>double buffer</li><li>change buffer</li><li>undo log</li></ul><p>5.6版本的Mysql系统表空间还存储是临时表数据</p><p>8.8版本的Mysql系统表空间取消存储数据字典信息并将undo log独立了出来</p><p>Mysql在慢慢瘦身系统表空间,把比较关键的数据独立出来了</p><h4 id="10-4-1-1-ibdata文件"><a href="#10-4-1-1-ibdata文件" class="headerlink" title="10.4.1.1 ibdata文件"></a>10.4.1.1 ibdata文件</h4><p>默认情况下,系统表空间在磁盘上的文件名为<code>ibdata1</code>,存在<code>/data</code>文件夹下</p><p>我们可以通过<code>innodb_data_file_path</code>参数修改系统表空间文件的数量</p><pre><code class="mysql">innodb_data_file_path=ibdata1:1G:ibdata2:1G:autoextend含义:有多个ibdata 第一个名称为ibdata1大小1G 第二个名称为ibdata2大小1Gautoextend意思是以此类推的生成ibdata</code></pre><p><code>innodb_data_file_path</code>参数通常要在初始化的时候加入到my.cnf文件下配置好</p><p>如果是在已运行的数据库上扩展多个ibdata文件,在设置<code>innodb_data_file_path</code>参数时,已有的ibdata1文件大小应该和磁盘上真正运行的ibdata1大小一致,而不是随便指定</p><h4 id="10-4-1-2-缩小系统表空间大小"><a href="#10-4-1-2-缩小系统表空间大小" class="headerlink" title="10.4.1.2 缩小系统表空间大小"></a>10.4.1.2 缩小系统表空间大小</h4><p>我们不能从系统表空间中删除数据,如果想减小系统表空间的大小我们只能做如下操作:</p><ol><li>mysqldump数据</li><li>关闭服务</li><li>删除所有 .ibd文件,ibdata文件ib_log文件</li><li>删除所有.frm文件</li><li>配置新系统表空间</li><li>重启服务</li><li>导入数据</li></ol><h3 id="10-4-2-Redo-log"><a href="#10-4-2-Redo-log" class="headerlink" title="10.4.2 Redo log"></a>10.4.2 Redo log</h3><p>Redo log　重做日志</p><h4 id="10-4-2-1-功能"><a href="#10-4-2-1-功能" class="headerlink" title="10.4.2.1 功能"></a>10.4.2.1 功能</h4><p>用户存储Mysql在做修改类操作时的数据页变化过程和版本号(LSN),属于物理日志</p><p>默认用两个文件存储redo log,是循环覆盖使用的</p><h4 id="10-4-2-2-文件位置"><a href="#10-4-2-2-文件位置" class="headerlink" title="10.4.2.2 文件位置"></a>10.4.2.2 文件位置</h4><p>一般也是存储在<code>/data</code>目录下,文件名为ib_logfile0 和 ib_logfile1</p><h4 id="10-4-2-3-控制参数"><a href="#10-4-2-3-控制参数" class="headerlink" title="10.4.2.3 控制参数"></a>10.4.2.3 控制参数</h4><pre><code class="ini">innodb_log_file_size=50331648    #设置文件大小innodb_log_files_in_group=2      #设置文件个数innodb_log_group_home_dir=./     #设置存储位置</code></pre><h3 id="10-4-3-Undo-log"><a href="#10-4-3-Undo-log" class="headerlink" title="10.4.3 Undo log"></a>10.4.3 Undo log</h3><p>Undo log　回滚日志</p><h4 id="10-4-3-1-功能"><a href="#10-4-3-1-功能" class="headerlink" title="10.4.3.1 功能"></a>10.4.3.1 功能</h4><p>用来存储回滚日志,记录每次操作的反操作,属于逻辑日志</p><ol><li>使用快照功能,提供Innodb多版本并发读写</li><li>通过记录的反操作,提供回滚功能</li></ol><h4 id="10-4-3-2-文件位置"><a href="#10-4-3-2-文件位置" class="headerlink" title="10.4.3.2 文件位置"></a>10.4.3.2 文件位置</h4><p>ibdataN里和ibtmp1里</p><h4 id="10-4-3-3-控制参数"><a href="#10-4-3-3-控制参数" class="headerlink" title="10.4.3.3 控制参数"></a>10.4.3.3 控制参数</h4><pre><code class="ini"> innodb_rollback_segments=128 #回滚段的个数</code></pre>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> Mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>4.Redis数据结构——listNode</title>
      <link href="/2020/02/18/4-Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-listNode/"/>
      <url>/2020/02/18/4-Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-listNode/</url>
      
        <content type="html"><![CDATA[<h2 id="4-1-什么是listNode"><a href="#4-1-什么是listNode" class="headerlink" title="4.1 什么是listNode"></a>4.1 什么是listNode</h2><p>listNode就是常规数据结构的一种——链表</p><p>Redis没有引用第三方的库来实现链表,而是自己手撸了一个</p><h2 id="4-2-list-amp-node数据结构"><a href="#4-2-list-amp-node数据结构" class="headerlink" title="4.2 list&amp;node数据结构"></a>4.2 list&amp;node数据结构</h2><pre><code class="c">#file:src/adlist.h/* * 双端链表节点 */typedef struct listNode {    // 前置节点    struct listNode *prev;    // 后置节点    struct listNode *next;    // 节点的值    void *value;} listNode;/* * 双端链表结构 */typedef struct list {   // 表头节点    listNode *head;    // 表尾节点    listNode *tail;    // 节点值复制函数    void *(*dup)(void *ptr);    // 节点值释放函数    void (*free)(void *ptr);    // 节点值对比函数    int (*match)(void *ptr, void *key);    // 链表所包含的节点数量    unsigned long len;} list;</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/listnode.png" alt=""></p><h2 id="4-3-新增结点"><a href="#4-3-新增结点" class="headerlink" title="4.3 新增结点"></a>4.3 新增结点</h2><p>没啥说的　就是双链表的新增</p><pre><code class="c">#file:src/adlist.c/* * 创建一个包含值 value 的新节点，并将它插入到 old_node 的之前或之后 * 如果 after 为 0 ，将新节点插入到 old_node 之前。 * 如果 after 为 1 ，将新节点插入到 old_node 之后。 * T = O(1) */list *listInsertNode(list *list, listNode *old_node, void *value, int after) {    listNode *node;    // 创建新节点    if ((node = zmalloc(sizeof(*node))) == NULL)        return NULL;    // 保存值    node-&gt;value = value;    // 将新节点添加到给定节点之后    if (after) {        node-&gt;prev = old_node;        node-&gt;next = old_node-&gt;next;        // 给定节点是原表尾节点        if (list-&gt;tail == old_node) {            list-&gt;tail = node;        }    // 将新节点添加到给定节点之前    } else {        node-&gt;next = old_node;        node-&gt;prev = old_node-&gt;prev;        // 给定节点是原表头节点        if (list-&gt;head == old_node) {            list-&gt;head = node;        }    }    // 更新新节点的前置指针    if (node-&gt;prev != NULL) {        node-&gt;prev-&gt;next = node;    }    // 更新新节点的后置指针    if (node-&gt;next != NULL) {        node-&gt;next-&gt;prev = node;    }    // 更新链表节点数    list-&gt;len++;    return list;}</code></pre><h2 id="4-4-删除结点"><a href="#4-4-删除结点" class="headerlink" title="4.4 删除结点"></a>4.4 删除结点</h2><p>也没啥说的,链表的删除操作</p><pre><code class="c">#file:src/adlist.c/* * 从链表 list 中删除给定节点 node  * T = O(1) */void listDelNode(list *list, listNode *node){    // 调整前置节点的指针    if (node-&gt;prev)        node-&gt;prev-&gt;next = node-&gt;next;    else        list-&gt;head = node-&gt;next;    // 调整后置节点的指针    if (node-&gt;next)        node-&gt;next-&gt;prev = node-&gt;prev;    else        list-&gt;tail = node-&gt;prev;    // 释放值    //对节点私有值的释放工作由list进行    if (list-&gt;free) list-&gt;free(node-&gt;value);    // 释放节点    zfree(node);    // 链表数减一    list-&gt;len--;}</code></pre><h2 id="4-5-查找结点"><a href="#4-5-查找结点" class="headerlink" title="4.5 查找结点"></a>4.5 查找结点</h2><pre><code class="c">#file:src/adlist.c/*  * 查找链表 list 中值和 key 匹配的节点。 * T = O(N) */listNode *listSearchKey(list *list, void *key){    listIter *iter;    listNode *node;    // 迭代整个链表    iter = listGetIterator(list, AL_START_HEAD);    while((node = listNext(iter)) != NULL) {        // 对比,对比操作由链表的 match 函数负责进行，        //如果没有设置 match 函数，那么直接通过对比值的指针来决定是否匹配        if (list-&gt;match) {            if (list-&gt;match(node-&gt;value, key)) {                listReleaseIterator(iter);                // 找到                return node;            }        } else {            if (key == node-&gt;value) {                listReleaseIterator(iter);                // 找到                return node;            }        }    }    listReleaseIterator(iter);    // 未找到    return NULL;}</code></pre><h2 id="4-6-修改结点"><a href="#4-6-修改结点" class="headerlink" title="4.6 修改结点"></a>4.6 修改结点</h2><p>在Redis实现的双链表里,<code>结点的值不能被修改只能被删除</code></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>3.Redis数据结构——SDS</title>
      <link href="/2020/02/18/3-Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-SDS/"/>
      <url>/2020/02/18/3-Redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-SDS/</url>
      
        <content type="html"><![CDATA[<h2 id="3-1-什么是SDS"><a href="#3-1-什么是SDS" class="headerlink" title="3.1 什么是SDS"></a>3.1 什么是SDS</h2><p>C语言中有定义好的String字符串,但是Redis并没有使用String字符串来作为默认的字符串存储格式,而是定义了一个结构体SDS(简单动态字符串)来实现</p><p>Redis中的每一个键都是一个SDS,String类型的每一个值也都是SDS</p><h2 id="3-2-SDS结构"><a href="#3-2-SDS结构" class="headerlink" title="3.2 SDS结构"></a>3.2 SDS结构</h2><pre><code class="c">#file: /src/sds.h/* * 保存SDS对象的结构 */struct sdshdr {    // buf 中已占用空间的长度    int len;    // buf 中剩余可用空间的长度    int free;    // 数据空间    char buf[];};</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/sdsstruct.png" alt=""></p><h2 id="3-3-新建SDS"><a href="#3-3-新建SDS" class="headerlink" title="3.3 新建SDS"></a>3.3 新建SDS</h2><pre><code class="c">#dep/hiredis/sds.c#创建SDS对象　根据字符串指针获取其长度　传给sdsnewlensds sdsnew(const char *init) {    size_t initlen = (init == NULL) ? 0 : strlen(init);    return sdsnewlen(init, initlen);}#被sdsnew调用sds sdsnewlen(const void *init, size_t initlen) {    struct sdshdr *sh;    if (init) {        sh = zmalloc(sizeof(struct sdshdr)+initlen+1);    } else {        sh = zcalloc(sizeof(struct sdshdr)+initlen+1);    }    if (sh == NULL) return NULL;    sh-&gt;len = initlen;  //sds-&gt;len = 字符串长度    sh-&gt;free = 0;　　　　//sds-&gt;free = 0    if (initlen &amp;&amp; init)        memcpy(sh-&gt;buf, init, initlen);    sh-&gt;buf[initlen] = &#39;\0&#39;;    return (char*)sh-&gt;buf;}</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/sdsnew.png" alt=""></p><h2 id="3-4-修改SDS"><a href="#3-4-修改SDS" class="headerlink" title="3.4 修改SDS"></a>3.4 修改SDS</h2><pre><code class="c">#dep/hiredis/sds.csds sdscpy(sds s, const char *t) {    return sdscpylen(s, t, strlen(t));}sds sdscpylen(sds s, const char *t, size_t len) {    struct sdshdr *sh = (void*) (s-(sizeof(struct sdshdr)));    size_t totlen = sh-&gt;free+sh-&gt;len;    if (totlen &lt; len) {        # 特别注意sdsMakeRoomFor函数　是对sds的扩容操作        s = sdsMakeRoomFor(s,len-sh-&gt;len);        if (s == NULL) return NULL;        sh = (void*) (s-(sizeof(struct sdshdr)));        totlen = sh-&gt;free+sh-&gt;len;    }    memcpy(s, t, len);    s[len] = &#39;\0&#39;;    sh-&gt;len = len;    sh-&gt;free = totlen-len;    return s;}</code></pre><p>整体代码写的很清晰,没什么过多解释的,我们特别注意下<code>sdsMakeRoomFor</code>这个函数,是对sds的扩容操作：</p><pre><code class="c">#dep/hiredis/sds.c#define SDS_MAX_PREALLOC (1024*1024)  #1MBsds sdsMakeRoomFor(sds s, size_t addlen) {    struct sdshdr *sh, *newsh;    size_t free = sdsavail(s);    size_t len, newlen;    if (free &gt;= addlen) return s;    len = sdslen(s);    sh = (void*) (s-(sizeof(struct sdshdr)));    newlen = (len+addlen);    if (newlen &lt; SDS_MAX_PREALLOC)        newlen *= 2;    else        newlen += SDS_MAX_PREALLOC;    newsh = zrealloc(sh, sizeof(struct sdshdr)+newlen+1);    if (newsh == NULL) return NULL;    newsh-&gt;free = newlen - len;    return newsh-&gt;buf;}</code></pre><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/sdsedit.png" alt=""></p><p>我们注意到:</p><ul><li>修改sds时redis会进行<code>空间预分配</code>,用以减少连续字符串增长操作所需的内存重新分配次数</li><li>如果将sds字符串缩短,sds的空间也不会立即释放,采用<code>惰性空间释放的方式</code>使用free属性将这些字节数量记录下来，将来使用<code>sdsRemoveFreeSpace</code>进行释放</li></ul><pre><code class="c">#dep/hiredis/sds.csds sdsRemoveFreeSpace(sds s) {    struct sdshdr *sh;    sh = (void*) (s-(sizeof(struct sdshdr)));    sh = zrealloc(sh, sizeof(struct sdshdr)+sh-&gt;len+1);    sh-&gt;free = 0;    return sh-&gt;buf;}</code></pre><h2 id="3-5-SDS与C字符串区别"><a href="#3-5-SDS与C字符串区别" class="headerlink" title="3.5 SDS与C字符串区别"></a>3.5 SDS与C字符串区别</h2><table><thead><tr><th align="center">序号</th><th>C 字符串</th><th>SDS</th></tr></thead><tbody><tr><td align="center">１</td><td>获取字符串长度的复杂度为 O(N)</td><td>获取字符串长度的复杂度为 O(1) 。</td></tr><tr><td align="center">２</td><td>API 是不安全的，可能会造成缓冲区溢出</td><td>API 是安全的，不会造成缓冲区溢出</td></tr><tr><td align="center">３</td><td>修改字符串长度 N 次必然需要执行 N 次内存重分配</td><td>修改字符串长度 N 次最多需要执行 N 次内存重分配</td></tr><tr><td align="center">４</td><td>只能保存文本数据</td><td>可以保存文本或者二进制数据</td></tr><tr><td align="center">５</td><td>可以使用所有 &lt;string.h&gt; 库中的函数</td><td>可以使用一部分 &lt;string.h&gt; 库中的函数</td></tr></tbody></table><p>区别①②④主要是因为sds结构的<code>len</code>属性,不依靠<code>\0</code>来判断结尾</p><p>区别③主要因为sds的空间预分配算法</p><p>区别⑤sds本质上还是一个封装了的string</p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2.Redis数据操作</title>
      <link href="/2020/02/18/2-Redis%E6%95%B0%E6%8D%AE%E6%93%8D%E4%BD%9C/"/>
      <url>/2020/02/18/2-Redis%E6%95%B0%E6%8D%AE%E6%93%8D%E4%BD%9C/</url>
      
        <content type="html"><![CDATA[<h2 id="2-1-String命令"><a href="#2-1-String命令" class="headerlink" title="2.1 String命令"></a>2.1 String命令</h2><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/string.png" alt=""></p><h2 id="2-2-List命令"><a href="#2-2-List命令" class="headerlink" title="2.2 List命令"></a>2.2 List命令</h2><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/list.png" alt=""></p><h2 id="2-3-Hash命令"><a href="#2-3-Hash命令" class="headerlink" title="2.3 Hash命令"></a>2.3 Hash命令</h2><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/hash.png" alt=""></p><h2 id="2-4-Set命令"><a href="#2-4-Set命令" class="headerlink" title="2.4 Set命令"></a>2.4 Set命令</h2><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/set.png" alt=""></p><h2 id="2-5-ZSet命令"><a href="#2-5-ZSet命令" class="headerlink" title="2.5 ZSet命令"></a>2.5 ZSet命令</h2><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/zset.png" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>1.Redis简介</title>
      <link href="/2020/02/18/1-Redis%E7%AE%80%E4%BB%8B/"/>
      <url>/2020/02/18/1-Redis%E7%AE%80%E4%BB%8B/</url>
      
        <content type="html"><![CDATA[<h2 id="1-1-Redis特点"><a href="#1-1-Redis特点" class="headerlink" title="1.1 Redis特点"></a>1.1 Redis特点</h2><ul><li>Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用。</li><li>Redis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。</li><li>Redis支持数据的备份，即master-slave模式的数据备份</li><li>Redis有原生的集群模式</li><li>Redis是单线程模式</li></ul><h2 id="1-2-与Memcache对比"><a href="#1-2-与Memcache对比" class="headerlink" title="1.2 与Memcache对比"></a>1.2 与Memcache对比</h2><table><thead><tr><th align="center">名称</th><th align="center">持久化</th><th align="center">数据类型</th><th>集群支持</th></tr></thead><tbody><tr><td align="center">Redis</td><td align="center">可持久化</td><td align="center">五种</td><td>原生支持cluster模式</td></tr><tr><td align="center">Memcached</td><td align="center">不可持久化</td><td align="center">一种</td><td>没有原生的集群模式,需要依靠客户端来实现往集群中分片写入数据</td></tr></tbody></table><h2 id="1-3-Redis线程模型"><a href="#1-3-Redis线程模型" class="headerlink" title="1.3 Redis线程模型"></a>1.3 Redis线程模型</h2><p>redis 基于 <code>reactor 模式</code>开发了网络事件处理器，这个处理器叫做文件事件处理器，file event handler，这个文件事件处理器是单线程的，所以redis 是单线程的模型，采用 io多路复用机制同时监听多个 socket,根据socket上的事件来选择对应的事件处理器来处理这个事件</p><p>文件事件处理器的结构包含 4 个部分：</p><ul><li>多个 Socket</li><li>IO 多路复用程序</li><li>文件事件分派器</li><li>事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）</li></ul><p>多个 Socket 可能会并发产生不同的操作，每个操作对应不同的文件事件，但是 IO 多路复用程序会监听多个 Socket，会将 Socket 产生的事件放入队列中排队，事件分派器每次从队列中取出一个事件，把该事件交给对应的事件处理器进行处理。</p><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/even.png" alt=""></p><h2 id="1-4-Redis为什么效率高"><a href="#1-4-Redis为什么效率高" class="headerlink" title="1.4 Redis为什么效率高"></a>1.4 Redis为什么效率高</h2><ul><li>纯内存操作</li><li>核心是基于非堵塞的IO多路复用机制</li><li>单线程反而避免了多线程的频繁上下文切换问题</li></ul><h2 id="1-5-Redis-数据结构"><a href="#1-5-Redis-数据结构" class="headerlink" title="1.5 Redis 数据结构"></a>1.5 Redis 数据结构</h2><p><img src="http://cache410.oss-cn-beijing.aliyuncs.com/datastruct.png" alt=""></p><p>​    </p>]]></content>
      
      
      <categories>
          
          <category> 中间件 </category>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>9.MysqlProfile介绍</title>
      <link href="/2020/02/16/9-MysqlProfile%E4%BB%8B%E7%BB%8D/"/>
      <url>/2020/02/16/9-MysqlProfile%E4%BB%8B%E7%BB%8D/</url>
      
        <content type="html"><![CDATA[<h2 id="9-1-相关参数"><a href="#9-1-相关参数" class="headerlink" title="9.1 相关参数"></a>9.1 相关参数</h2><pre><code class="mysql">mysql&gt; show variables like &#39;%profil%&#39;;+------------------------+-------+| Variable_name          | Value |+------------------------+-------+| have_profiling         | YES   || profiling              | OFF   || profiling_history_size | 15    |+------------------------+-------+3 rows in set (0.01 sec)have_profiling： 当前版本是否支持profiling功能profiling： 是否开启profiling功能profiling_history_size： 保留profiling的数目，默认是15，范围为0~100，为0时代表禁用profiling</code></pre><h2 id="9-2-开启profile"><a href="#9-2-开启profile" class="headerlink" title="9.2 开启profile"></a>9.2 开启profile</h2><pre><code class="mysql">session级别开启:mysql&gt; SET profiling = 1;全局开启echo &quot;profiling=1&quot; &gt;&gt; my.cnf</code></pre><h2 id="9-3-help-profile"><a href="#9-3-help-profile" class="headerlink" title="9.3 help profile"></a>9.3 help profile</h2><p>我们可以通过help profile查看profile的用法,官方的解释已经很好了</p><pre><code class="mysql">mysql&gt; help profile;Name: &#39;SHOW PROFILE&#39;Description:Syntax:SHOW PROFILE [type [, type] ... ]    [FOR QUERY n]    [LIMIT row_count [OFFSET offset]]type: {    ALL  | BLOCK IO  | CONTEXT SWITCHES  | CPU  | IPC  | MEMORY  | PAGE FAULTS  | SOURCE  | SWAPS}The SHOW PROFILE and SHOW PROFILES statements display profilinginformation that indicates resource usage for statements executedduring the course of the current session.*Note*:The SHOW PROFILE and SHOW PROFILES statements are deprecated and willbe removed in a future MySQL release. Use the Performance Schemainstead; seehttp://dev.mysql.com/doc/refman/5.7/en/performance-schema-query-profiling.html.To control profiling, use the profiling session variable, which has adefault value of 0 (OFF). Enable profiling by setting profiling to 1 orON:mysql&gt; SET profiling = 1;SHOW PROFILES displays a list of the most recent statements sent to theserver. The size of the list is controlled by theprofiling_history_size session variable, which has a default value of15. The maximum value is 100. Setting the value to 0 has the practicaleffect of disabling profiling.All statements are profiled except SHOW PROFILE and SHOW PROFILES, soyou will find neither of those statements in the profile list.Malformed statements are profiled. For example, SHOW PROFILING is anillegal statement, and a syntax error occurs if you try to execute it,but it will show up in the profiling list.SHOW PROFILE displays detailed information about a single statement.Without the FOR QUERY n clause, the output pertains to the mostrecently executed statement. If FOR QUERY n is included, SHOW PROFILEdisplays information for statement n. The values of n correspond to theQuery_ID values displayed by SHOW PROFILES.The LIMIT row_count clause may be given to limit the output torow_count rows. If LIMIT is given, OFFSET offset may be added to beginthe output offset rows into the full set of rows.By default, SHOW PROFILE displays Status and Duration columns. TheStatus values are like the State values displayed by SHOW PROCESSLIST,although there might be some minor differences in interpretion for thetwo statements for some status values (seehttp://dev.mysql.com/doc/refman/5.7/en/thread-information.html).Optional type values may be specified to display specific additionaltypes of information:o ALL displays all informationo BLOCK IO displays counts for block input and output operationso CONTEXT SWITCHES displays counts for voluntary and involuntary  context switcheso CPU displays user and system CPU usage timeso IPC displays counts for messages sent and receivedo MEMORY is not currently implementedo PAGE FAULTS displays counts for major and minor page faultso SOURCE displays the names of functions from the source code, together  with the name and line number of the file in which the function  occurso SWAPS displays swap countsProfiling is enabled per session. When a session ends, its profilinginformation is lost.URL: http://dev.mysql.com/doc/refman/5.7/en/show-profile.htmlExamples:mysql&gt; SELECT @@profiling;+-------------+| @@profiling |+-------------+|           0 |+-------------+1 row in set (0.00 sec)mysql&gt; SET profiling = 1;Query OK, 0 rows affected (0.00 sec)mysql&gt; DROP TABLE IF EXISTS t1;Query OK, 0 rows affected, 1 warning (0.00 sec)mysql&gt; CREATE TABLE T1 (id INT);Query OK, 0 rows affected (0.01 sec)mysql&gt; SHOW PROFILES;+----------+----------+--------------------------+| Query_ID | Duration | Query                    |+----------+----------+--------------------------+|        0 | 0.000088 | SET PROFILING = 1        ||        1 | 0.000136 | DROP TABLE IF EXISTS t1  ||        2 | 0.011947 | CREATE TABLE t1 (id INT) |+----------+----------+--------------------------+3 rows in set (0.00 sec)mysql&gt; SHOW PROFILE;+----------------------+----------+| Status               | Duration |+----------------------+----------+| checking permissions | 0.000040 || creating table       | 0.000056 || After create         | 0.011363 || query end            | 0.000375 || freeing items        | 0.000089 || logging slow query   | 0.000019 || cleaning up          | 0.000005 |+----------------------+----------+7 rows in set (0.00 sec)mysql&gt; SHOW PROFILE FOR QUERY 1;+--------------------+----------+| Status             | Duration |+--------------------+----------+| query end          | 0.000107 || freeing items      | 0.000008 || logging slow query | 0.000015 || cleaning up        | 0.000006 |+--------------------+----------+4 rows in set (0.00 sec)mysql&gt; SHOW PROFILE CPU FOR QUERY 2;+----------------------+----------+----------+------------+| Status               | Duration | CPU_user | CPU_system |+----------------------+----------+----------+------------+| checking permissions | 0.000040 | 0.000038 |   0.000002 || creating table       | 0.000056 | 0.000028 |   0.000028 || After create         | 0.011363 | 0.000217 |   0.001571 || query end            | 0.000375 | 0.000013 |   0.000028 || freeing items        | 0.000089 | 0.000010 |   0.000014 || logging slow query   | 0.000019 | 0.000009 |   0.000010 || cleaning up          | 0.000005 | 0.000003 |   0.000002 |+----------------------+----------+----------+------------+7 rows in set (0.00 sec)</code></pre><h2 id="9-4-type类型"><a href="#9-4-type类型" class="headerlink" title="9.4 type类型"></a>9.4 type类型</h2><p>这里我们主要关注两个指标　</p><ul><li><code>ALL</code>:显示所性能信息</li><li><code>BLOCK IO</code>:显示块(页)IO的数量<ul><li>BLOCK_OPS_IN:输入页数量</li><li>BLOCK_OPS_OUT:输出页数量</li></ul></li><li><code>CONTEXT SWITCHES</code>:上下文切换相关开销</li><li><code>CPU</code>:显示CPU相关开销信息<ul><li>CPU_user:用户所用时间,秒单位 </li><li>CPU_system:系统所用时间,秒单位 </li></ul></li><li><code>IPC</code>:显示发送和接收相关开销信息</li><li><code>MEMORY</code>:显示内存相关开销信息</li><li><code>PAGE FAULTS</code> :显示页面错误相关开销信息</li><li><code>SOURCE</code> :显示和Source_function，Source_file，Source_line相关的开销信息</li><li><code>SWAPS</code> :显示交换次数相关开销的信息</li></ul><h2 id="9-5-profile过程"><a href="#9-5-profile过程" class="headerlink" title="9.5 profile过程"></a>9.5 profile过程</h2><pre><code class="mysql">mysql&gt; show profile for query 4;+----------------------+-----------+| Status               | Duration  |+----------------------+-----------+| starting             |  0.000083 || checking permissions |  0.000013 || Opening tables       |  0.000019 || init                 |  0.000036 || System lock          |  0.000014 || optimizing           |  0.000012 || statistics           |  0.000021 || preparing            |  0.000018 || executing            |  0.000006 || Sending data         | 87.327560 || end                  |  0.000016 || query end            |  0.000013 || closing tables       |  0.000011 || freeing items        |  0.000027 || logging slow query   |  0.000057 || cleaning up          |  0.000017 |+----------------------+-----------+16 rows in set, 1 warning (0.00 sec)starting：开始checking permissions：检查权限Opening tables：打开表init ： 初始化System lock ：系统锁optimizing ： 优化statistics ： 统计preparing ：准备executing ：执行Sending data ：发送数据Sorting result ：排序end ：结束query end ：查询 结束closing tables ： 关闭表 ／去除TMP 表freeing items ： 释放事件cleaning up ：清理profile只能列出使用到的环节　没有使用的环节不显示</code></pre><h3 id="9-5-1-重点环节"><a href="#9-5-1-重点环节" class="headerlink" title="9.5.1 重点环节"></a>9.5.1 重点环节</h3><ul><li><code>preparing</code> ：准备</li><li><code>executing</code> ：执行</li><li><code>Sending data</code> ：发送数据  一般这个环节时间最长</li><li><code>Sorting result</code> ：排序</li></ul><h3 id="9-5-2-不应-减少出现的环节"><a href="#9-5-2-不应-减少出现的环节" class="headerlink" title="9.5.2 不应/减少出现的环节"></a>9.5.2 不应/减少出现的环节</h3><ul><li><code>converting HEAP to MyISAM</code>： 查询结果太大，内存都不够用了，往磁盘上搬了</li><li><code>creating tmp table</code> ：创建临时表，拷贝数据到临时表，然后再删除</li><li><code>copying to tmp table on disk</code> ：把内存中临时表复制到磁盘</li><li><code>locked</code>: 被锁喉了~</li></ul><h2 id="9-6-日常常用指令"><a href="#9-6-日常常用指令" class="headerlink" title="9.6 日常常用指令"></a>9.6 日常常用指令</h2><pre><code class="mysql">SHOW PROFILE block io,cpu FOR QUERY N;多注意CPU和IOmysql&gt; SHOW PROFILE block io,cpu FOR QUERY 4\G;*************************** 1. row ***************************       Status: starting     Duration: 0.000083     CPU_user: 0.000049   CPU_system: 0.000025 Block_ops_in: 0Block_ops_out: 0*************************** 2. row ***************************       Status: checking permissions     Duration: 0.000013     CPU_user: 0.000006   CPU_system: 0.000003 Block_ops_in: 0Block_ops_out: 0*************************** 3. row ***************************       Status: Opening tables     Duration: 0.000019     CPU_user: 0.000012   CPU_system: 0.000006 Block_ops_in: 0Block_ops_out: 0*************************** 4. row ***************************       Status: init     Duration: 0.000036     CPU_user: 0.000022   CPU_system: 0.000012 Block_ops_in: 0Block_ops_out: 0*************************** 5. row ***************************       Status: System lock     Duration: 0.000014     CPU_user: 0.000008   CPU_system: 0.000004 Block_ops_in: 0Block_ops_out: 0*************************** 6. row ***************************       Status: optimizing     Duration: 0.000012     CPU_user: 0.000007   CPU_system: 0.000003 Block_ops_in: 0Block_ops_out: 0*************************** 7. row ***************************       Status: statistics     Duration: 0.000021     CPU_user: 0.000013   CPU_system: 0.000007 Block_ops_in: 0Block_ops_out: 0*************************** 8. row ***************************       Status: preparing     Duration: 0.000018     CPU_user: 0.000011   CPU_system: 0.000006 Block_ops_in: 0Block_ops_out: 0*************************** 9. row ***************************       Status: executing     Duration: 0.000006     CPU_user: 0.000003   CPU_system: 0.000002 Block_ops_in: 0Block_ops_out: 0*************************** 10. row ***************************       Status: Sending data     Duration: 87.327560     CPU_user: 37.617680   CPU_system: 32.943640 Block_ops_in: 2591264Block_ops_out: 0*************************** 11. row ***************************       Status: end     Duration: 0.000016     CPU_user: 0.000006   CPU_system: 0.000004 Block_ops_in: 0Block_ops_out: 0*************************** 12. row ***************************       Status: query end     Duration: 0.000013     CPU_user: 0.000007   CPU_system: 0.000005 Block_ops_in: 0Block_ops_out: 0*************************** 13. row ***************************       Status: closing tables     Duration: 0.000011     CPU_user: 0.000006   CPU_system: 0.000004 Block_ops_in: 0Block_ops_out: 0*************************** 14. row ***************************       Status: freeing items     Duration: 0.000027     CPU_user: 0.000015   CPU_system: 0.000010 Block_ops_in: 0Block_ops_out: 0*************************** 15. row ***************************       Status: logging slow query     Duration: 0.000057     CPU_user: 0.000032   CPU_system: 0.000021 Block_ops_in: 0Block_ops_out: 8*************************** 16. row ***************************       Status: cleaning up     Duration: 0.000017     CPU_user: 0.000009   CPU_system: 0.000006 Block_ops_in: 0Block_ops_out: 016 rows in set, 1 warning (0.00 sec)ERROR: No query specified</code></pre><h2 id="9-7-使用Performance查看profi"><a href="#9-7-使用Performance查看profi" class="headerlink" title="9.7  使用Performance查看profi"></a>9.7  使用Performance查看profi</h2><p>通过help profile我们知道show proflie相关指令即将废弃,可以使用如下指令进行查询</p><p>在使用以下两个命令前需要做一些设置角色的操作:具体请参考官方文档:</p><p><a href="https://dev.mysql.com/doc/refman/5.7/en/performance-schema-query-profiling.html" target="_blank" rel="noopener">25.19.1 Query Profiling Using Performance Schema</a></p><h3 id="9-7-1-查看所有语句"><a href="#9-7-1-查看所有语句" class="headerlink" title="9.7.1 查看所有语句"></a>9.7.1 查看所有语句</h3><pre><code class="mysql">mysql&gt; SELECT EVENT_ID, TRUNCATE(TIMER_WAIT/1000000000000,6) as Duration, SQL_TEXT        FROM performance_schema.events_statements_history_long\G;*************************** 1. row ***************************EVENT_ID: 146Duration: 0.000842SQL_TEXT: UPDATE performance_schema.setup_consumers       SET ENABLED = &#39;YES&#39;       WHERE NAME LIKE &#39;%events_statements_%&#39;*************************** 2. row ***************************EVENT_ID: 147Duration: 0.000376SQL_TEXT: UPDATE performance_schema.setup_consumers       SET ENABLED = &#39;YES&#39;       WHERE NAME LIKE &#39;%events_stages_%&#39;*************************** 3. row ***************************EVENT_ID: 154Duration: 2.089741SQL_TEXT: select count(*) from t_scrm_pet_info where pet_birthday &gt; &#39;2019-01-01 00:00:01&#39; and pet_birthday &lt; &#39;2019-03-01 00:00:01&#39;*************************** 4. row ***************************EVENT_ID: 171Duration: 0.003488SQL_TEXT: SELECT EVENT_ID, TRUNCATE(TIMER_WAIT/1000000000000,6) as Duration, SQL_TEXT       FROM performance_schema.events_statements_history_long*************************** 5. row ***************************EVENT_ID: 188Duration: 0.000899SQL_TEXT: SELECT event_name AS Stage, TRUNCATE(TIMER_WAIT/1000000000000,6) AS Duration       FROM performance_schema.events_stages_history_long WHERE NESTING_EVENT_ID=154*************************** 6. row ***************************EVENT_ID: 205Duration: 0.000480SQL_TEXT: SELECT event_name AS Stage, TRUNCATE(TIMER_WAIT/1000000000000,6) AS Duration        FROM performance_schema.events_stages_history_long WHERE NESTING_EVENT_ID=154*************************** 7. row ***************************EVENT_ID: 222Duration: 0.000669SQL_TEXT: SELECT EVENT_ID, TRUNCATE(TIMER_WAIT/1000000000000,6) as Duration, SQL_TEXT        FROM performance_schema.events_statements_history_long7 rows in set (0.00 sec)ERROR: No query specified</code></pre><h3 id="9-7-2-查看指定语句"><a href="#9-7-2-查看指定语句" class="headerlink" title="9.7.2 查看指定语句"></a>9.7.2 查看指定语句</h3><pre><code class="mysql">mysql&gt; SELECT event_name AS Stage, TRUNCATE(TIMER_WAIT/1000000000000,6) AS Duration        FROM performance_schema.events_stages_history_long WHERE NESTING_EVENT_ID=154\G;*************************** 1. row ***************************   Stage: stage/sql/startingDuration: 0.000105*************************** 2. row ***************************   Stage: stage/sql/checking permissionsDuration: 0.000008*************************** 3. row ***************************   Stage: stage/sql/Opening tablesDuration: 0.000021*************************** 4. row ***************************   Stage: stage/sql/initDuration: 0.000059*************************** 5. row ***************************   Stage: stage/sql/System lockDuration: 0.000016*************************** 6. row ***************************   Stage: stage/sql/optimizingDuration: 0.000014*************************** 7. row ***************************   Stage: stage/sql/statisticsDuration: 0.000023*************************** 8. row ***************************   Stage: stage/sql/preparingDuration: 0.000017*************************** 9. row ***************************   Stage: stage/sql/executingDuration: 0.000002*************************** 10. row ***************************   Stage: stage/sql/Sending dataDuration: 2.089357*************************** 11. row ***************************   Stage: stage/sql/endDuration: 0.000005*************************** 12. row ***************************   Stage: stage/sql/query endDuration: 0.000012*************************** 13. row ***************************   Stage: stage/sql/closing tablesDuration: 0.000009*************************** 14. row ***************************   Stage: stage/sql/freeing itemsDuration: 0.000027*************************** 15. row ***************************   Stage: stage/sql/logging slow queryDuration: 0.000055*************************** 16. row ***************************   Stage: stage/sql/cleaning upDuration: 0.00000116 rows in set (0.00 sec)ERROR: No query specified</code></pre>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> Mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>8.MysqlExplain介绍</title>
      <link href="/2020/02/16/8-MysqlExplain%E4%BB%8B%E7%BB%8D/"/>
      <url>/2020/02/16/8-MysqlExplain%E4%BB%8B%E7%BB%8D/</url>
      
        <content type="html"><![CDATA[<h2 id="8-1-Explain各列意义"><a href="#8-1-Explain各列意义" class="headerlink" title="8.1 Explain各列意义"></a>8.1 Explain各列意义</h2><p>EXPLAIN 命令的输出内容大致如下:</p><pre><code class="mysql">mysql&gt; explain select *  from t_scrm_user_info where bigdata_user_id &gt; &#39;A1001036&#39; and bigdata_user_id &lt; &#39;A2100000&#39;\G;*************************** 1. row ***************************           id: 1  select_type: SIMPLE        table: t_scrm_user_info   partitions: NULL         type: rangepossible_keys: UQ_CUSTOMER_ID          key: UQ_CUSTOMER_ID      key_len: 130          ref: NULL         rows: 168902     filtered: 100.00        Extra: Using index condition1 row in set, 1 warning (0.00 sec)</code></pre><table><thead><tr><th align="center">列名称</th><th align="center">含义</th></tr></thead><tbody><tr><td align="center">id</td><td align="center">SELECT 查询的标识符. 每个 SELECT 都会自动分配一个唯一的标识符.</td></tr><tr><td align="center">select_type</td><td align="center">SELECT 查询的类型.</td></tr><tr><td align="center">table</td><td align="center">查询的是哪个表</td></tr><tr><td align="center">partitions</td><td align="center">匹配的分区</td></tr><tr><td align="center">type</td><td align="center">join 类型</td></tr><tr><td align="center">possible_keys</td><td align="center">此次查询中可能选用的索引</td></tr><tr><td align="center">key</td><td align="center">此次查询中确切使用到的索引.</td></tr><tr><td align="center">ref</td><td align="center">哪个字段或常数与 key 一起被使用</td></tr><tr><td align="center">rows</td><td align="center">显示此查询一共扫描了多少行. 这个是一个估计值.</td></tr><tr><td align="center">filtered</td><td align="center">表示此查询条件所过滤的数据的百分比</td></tr><tr><td align="center">extra</td><td align="center">额外的信息</td></tr></tbody></table><h2 id="8-2-id"><a href="#8-2-id" class="headerlink" title="8.2 id"></a>8.2 id</h2><p>表示select标识符，同时表明执行顺序，也就是说id是一个查询的序列号，查询序号即为sql语句执行的顺序。</p><ol><li>当id值相同时，按从上到下的顺序执行</li><li>当id全部不同时，按id从大到小执行</li><li>当id部分不同时，先执行id大的，id相同的，按从上到下的顺序执行</li></ol><h2 id="8-3-select-type"><a href="#8-3-select-type" class="headerlink" title="8.3 select_type"></a>8.3 select_type</h2><ol><li>SIMPLE 简单的select查询，查询中不包含子查询或者UNION</li><li>PRIMARY 查询中若包含任何复杂的子部分，最外层查询则被标记为PRIMARY</li><li>SUBQUERY 在SELECT或WHERE列表中包含了子查询</li><li>DERIVED 在FROM列表中包含的子查询被标记为DERIVED（衍生），MySQL会递归执行这些子查询，把结果放在临时表中</li><li>UNION 若第二个SELECT出现在UNION之后，则被标记为UNION：若UNION包含在FROM子句的子查询中，外层SELECT将被标记为：DERIVED</li><li>UNION RESULT 从UNION表获取结果的SELECT</li></ol><pre><code class="mysql">mysql&gt; explain select * from t_scrm_user_info where  id = 1\G;*************************** 1. row ***************************           id: 1  select_type: SIMPLE        table: t_scrm_user_info   partitions: NULL         type: constpossible_keys: PRIMARY,IX_ID_CREATE_TIME          key: PRIMARY      key_len: 4          ref: const         rows: 1     filtered: 100.00        Extra: NULL1 row in set, 1 warning (0.00 sec)ERROR: No query specified==================================================================================mysql&gt; explain select * from (select * from t_scrm_pet_info limit 20) t where  t.id = (select id from t_scrm_map limit 1)\G;*************************** 1. row ***************************           id: 1  select_type: PRIMARY        table: &lt;derived2&gt;   partitions: NULL         type: refpossible_keys: &lt;auto_key0&gt;          key: &lt;auto_key0&gt;      key_len: 4          ref: const         rows: 2     filtered: 100.00        Extra: Using where*************************** 2. row ***************************           id: 3  select_type: SUBQUERY        table: t_scrm_map   partitions: NULL         type: indexpossible_keys: NULL          key: IX_CREATE_TIME      key_len: 5          ref: NULL         rows: 11271619     filtered: 100.00        Extra: Using index*************************** 3. row ***************************           id: 2  select_type: DERIVED        table: t_scrm_pet_info   partitions: NULL         type: ALLpossible_keys: NULL          key: NULL      key_len: NULL          ref: NULL         rows: 4578062     filtered: 100.00        Extra: NULL3 rows in set, 1 warning (0.00 sec)ERROR: No query specified==================================================================================mysql&gt; explain select * from t_scrm_map where id =10 union select * from t_scrm_map where id = 20\G;*************************** 1. row ***************************           id: 1  select_type: PRIMARY        table: t_scrm_map   partitions: NULL         type: constpossible_keys: PRIMARY          key: PRIMARY      key_len: 4          ref: const         rows: 1     filtered: 100.00        Extra: NULL*************************** 2. row ***************************           id: 2  select_type: UNION        table: t_scrm_map   partitions: NULL         type: constpossible_keys: PRIMARY          key: PRIMARY      key_len: 4          ref: const         rows: 1     filtered: 100.00        Extra: NULL*************************** 3. row ***************************           id: NULL  select_type: UNION RESULT        table: &lt;union1,2&gt;   partitions: NULL         type: ALLpossible_keys: NULL          key: NULL      key_len: NULL          ref: NULL         rows: NULL     filtered: NULL        Extra: Using temporary3 rows in set, 1 warning (0.00 sec)</code></pre><h2 id="8-4-table"><a href="#8-4-table" class="headerlink" title="8.4 table"></a>8.4 table</h2><p>这一列表示 explain 的一行正在访问哪个表。</p><p>当 from 子句中有子查询时，table列是 <derivenN> 格式，表示当前查询依赖 id=N 的查询，于是先执行 id=N 的查询。当有 union 时，UNION RESULT 的 table 列的值为 &lt;union1,2&gt;，1和2表示参与 union 的 select 行id。</p><h2 id="8-5-partitions"><a href="#8-5-partitions" class="headerlink" title="8.5 partitions"></a>8.5 partitions</h2><p>使用的哪些分区（对于非分区表值为null）</p><h2 id="8-6-type"><a href="#8-6-type" class="headerlink" title="8.6 type"></a>8.6 type</h2><p>type所显示的是查询使用了哪种类型，type包含的类型包括如下图所示的几种：</p><p>从最好到最差依次是：</p><pre><code>system &gt; const &gt; eq_ref &gt; ref &gt; range &gt; index &gt; all</code></pre><p>一般来说，得保证查询至少达到range级别，最好能达到ref。</p><ul><li><code>const, system</code>：mysql能对查询的某部分进行优化并将其转化成一个常量。用于 primary key 或 unique key 的所有列与常数比较时，所以表最多有一个匹配行，读取1次，速度比较快。</li></ul><pre><code class="mysql">mysql&gt; explain select * from t_scrm_user_info where bigdata_user_id = &#39;B13470427&#39;\G;*************************** 1. row ***************************           id: 1  select_type: SIMPLE        table: t_scrm_user_info   partitions: NULL         type: constpossible_keys: UQ_CUSTOMER_ID          key: UQ_CUSTOMER_ID      key_len: 130          ref: const         rows: 1     filtered: 100.00        Extra: NULL1 row in set, 1 warning (0.00 sec)</code></pre><ul><li><code>eq_ref</code>：primary key 或 unique key 索引的所有部分被连接使用 ，最多只会返回一条符合条件的记录。这可能是在 const 之外最好的<code>联接类型</code>了，简单的 select 查询不会出现这种 type。</li></ul><pre><code class="mysql">mysql&gt; explain select * from t_scrm_user_info u left join t_scrm_map m on u.bigdata_user_id = m.bigdata_id where u.bigdata_user_id = &#39;B13470427&#39;\G;*************************** 1. row ***************************           id: 1  select_type: SIMPLE        table: u   partitions: NULL         type: constpossible_keys: UQ_CUSTOMER_ID          key: UQ_CUSTOMER_ID      key_len: 130          ref: const         rows: 1     filtered: 100.00        Extra: NULL*************************** 2. row ***************************           id: 1  select_type: SIMPLE        table: m   partitions: NULL         type: refpossible_keys: UQ_ID          key: UQ_ID      key_len: 258          ref: const         rows: 1     filtered: 100.00        Extra: Using where2 rows in set, 1 warning (0.00 sec)</code></pre><ul><li>ref：相比 eq_ref，不使用唯一索引，而是使用普通索引或者唯一性索引的部分前缀，索引要和某个值相比较，可能会找到多个符合条件的行。</li></ul><pre><code class="mysql">mysql&gt; explain select * from t_scrm_map where target_id = &#39;11255964&#39;\G;*************************** 1. row ***************************           id: 1  select_type: SIMPLE        table: t_scrm_map   partitions: NULL         type: refpossible_keys: IX_TRAGET_ID          key: IX_TRAGET_ID      key_len: 130          ref: const         rows: 1     filtered: 100.00        Extra: NULL1 row in set, 1 warning (0.00 sec)</code></pre><ul><li><code>ref_or_null</code>：类似ref，但是可以搜索值为NULL的行。</li><li><code>range</code>：范围扫描通常出现在 in(), between ,&gt; ,&lt;, &gt;= 等操作中。使用一个索引来检索给定范围的行。</li></ul><pre><code class="mysql">mysql&gt; explain select * from t_scrm_map where id &gt; 10 and id  &lt;20\G;*************************** 1. row ***************************           id: 1  select_type: SIMPLE        table: t_scrm_map   partitions: NULL         type: rangepossible_keys: PRIMARY          key: PRIMARY      key_len: 4          ref: NULL         rows: 9     filtered: 100.00        Extra: Using where1 row in set, 1 warning (0.00 sec)ERROR: No query specified</code></pre><ul><li><code>index</code>：和ALL一样，不同就是mysql只需扫描索引树，这通常比ALL快一些。</li></ul><pre><code class="mysql">mysql&gt; explain select count(*) from t_scrm_map\G;*************************** 1. row ***************************           id: 1  select_type: SIMPLE        table: t_scrm_map   partitions: NULL         type: indexpossible_keys: NULL          key: IX_CREATE_TIME      key_len: 5          ref: NULL         rows: 11271619     filtered: 100.00        Extra: Using index1 row in set, 1 warning (0.00 sec)ERROR: No query specified</code></pre><ul><li><code>ALL</code>：即全表扫描，意味着mysql需要从头到尾去查找所需要的行。通常情况下这需要增加索引来进行优化了</li></ul><pre><code class="mysql">mysql&gt; explain select * from t_scrm_map\G;*************************** 1. row ***************************           id: 1  select_type: SIMPLE        table: t_scrm_map   partitions: NULL         type: ALLpossible_keys: NULL          key: NULL      key_len: NULL          ref: NULL         rows: 11271619     filtered: 100.00        Extra: NULL1 row in set, 1 warning (0.00 sec)ERROR: No query specified</code></pre><h2 id="8-7-possible-keys"><a href="#8-7-possible-keys" class="headerlink" title="8.7  possible_keys"></a>8.7  possible_keys</h2><p>这一列显示查询可能使用哪些索引来查找。 </p><p>explain 时可能出现 possible_keys 有列，而 key 显示 NULL 的情况，这种情况是因为表中数据不多，mysql认为索引对此查询帮助不大，选择了全表查询。 </p><p>如果该列是NULL，则没有相关的索引。在这种情况下，可以通过检查 where 子句看是否可以创造一个适当的索引来提高查询性能，然后用 explain 查看效果。</p><h2 id="8-8-key"><a href="#8-8-key" class="headerlink" title="8.8 key"></a>8.8 key</h2><p>这一列显示mysql实际采用哪个索引来优化对该表的访问。</p><p>如果没有使用索引，则该列是 NULL。如果想强制mysql使用或忽视possible_keys列中的索引，在查询中使用 force index、ignore index。</p><h2 id="8-9-key-len列"><a href="#8-9-key-len列" class="headerlink" title="8.9 key_len列"></a>8.9 key_len列</h2><p>这一列显示了mysql在索引里使用的字节数，通过这个值可以算出具体使用了索引中的哪些列。 </p><pre><code class="mysql">key_len 的计算规则如下:字符串char(n): n 字节长度varchar(n): 如果是 utf8 编码, 则是 3 n + 2字节; 如果是 utf8mb4 编码, 则是 4n +2 字节.数值类型:TINYINT: 1字节SMALLINT: 2字节MEDIUMINT: 3字节INT: 4字节BIGINT: 8字节时间类型DATE: 3字节TIMESTAMP: 4字节DATETIME: 8字节字段属性: NULL 属性 占用一个字节. 如果一个字段是 NOT NULL 的, 则没有此属性.</code></pre><pre><code class="mysql">mysql&gt; explain select count(*) from t_scrm_map where target_id  = &#39;11255964&#39;\G;*************************** 1. row ***************************           id: 1  select_type: SIMPLE        table: t_scrm_map   partitions: NULL         type: refpossible_keys: IX_TRAGET_ID          key: IX_TRAGET_ID      key_len: 130          ref: const         rows: 1     filtered: 100.00        Extra: Using index1 row in set, 1 warning (0.00 sec)/**| t_scrm_map | CREATE TABLE `t_scrm_map` (  `id` int(10) unsigned NOT NULL AUTO_INCREMENT,  `bigdata_id` varchar(64) NOT NULL COMMENT &#39;唯一ID&#39;,  `type` tinyint(3) NOT NULL COMMENT &#39;关联类型&#39;,  PRIMARY KEY (`id`),  UNIQUE KEY `UQ_ID` (`bigdata_id`,`type`),  KEY `IX_MAP_ID` (`scrm_id`),) ENGINE=InnoDB AUTO_INCREMENT=11962156 DEFAULT CHARSET=utf8mb4 ROW_FORMAT=DYNAMIC COMMENT=&#39;关系表&#39; |*/mysql&gt; explain select count(*) from t_scrm_map where bigdata_id  = &#39;11255964&#39;\G;*************************** 1. row ***************************           id: 1  select_type: SIMPLE        table: t_scrm_map   partitions: NULL         type: refpossible_keys: UQ_ID          key: UQ_ID      key_len: 258          ref: const         rows: 1     filtered: 100.00        Extra: Using index1 row in set, 1 warning (0.04 sec)可以看到key_len = 258---&gt; 64*4+2;即只使用了索引UQ_ID的bigdata_id部分mysql&gt; explain select * from t_scrm_map where bigdata_id  = &#39;B11255964&#39; and type = 1\G;*************************** 1. row ***************************           id: 1  select_type: SIMPLE        table: t_scrm_map   partitions: NULL         type: constpossible_keys: UQ_ID          key: UQ_ID      key_len: 259          ref: const,const         rows: 1     filtered: 100.00        Extra: NULL1 row in set, 1 warning (0.04 sec)可以看到key_len = 258---&gt; 64*4+2+1;即使用了索引UQ_ID的bigdata_id和type部分</code></pre><h2 id="8-10-ref列"><a href="#8-10-ref列" class="headerlink" title="8.10 ref列"></a>8.10 ref列</h2><p>这一列显示了在key列记录的索引中，表查找值所用到的列或常量，常见的有：</p><ul><li><p>const（常量）</p></li><li><p>func</p></li><li><p>NULL</p></li><li><p>字段名</p></li></ul><h2 id="8-11-rows列rows"><a href="#8-11-rows列rows" class="headerlink" title="8.11 rows列rows"></a>8.11 rows列rows</h2><p>rows 也是一个重要的字段. MySQL 查询优化器根据统计信息, 估算 SQL 要查找到结果集需要扫描读取的数据行数. 这个值非常直观显示 SQL 的效率好坏, 原则上 rows 越少越好.</p><h2 id="8-12-Extra列"><a href="#8-12-Extra列" class="headerlink" title="8.12 Extra列"></a>8.12 Extra列</h2><p>这一列展示的是额外信息。常见的重要值如下： </p><h3 id="8-12-1-Using-filesort"><a href="#8-12-1-Using-filesort" class="headerlink" title="8.12.1 Using filesort"></a>8.12.1 Using filesort</h3><p>mysql 会对结果使用一个外部索引排序，而不是按索引次序从表里读取行。此时mysql会根据联接类型浏览所有符合条件的记录，并保存排序关键字和行指针，然后排序关键字并按顺序检索行信息。</p><p><code>这种情况是要考虑使用索引来优化的</code></p><pre><code class="mysql">mysql&gt; explain select * from t_scrm_map order by type asc\G;*************************** 1. row ***************************           id: 1  select_type: SIMPLE        table: t_scrm_map   partitions: NULL         type: ALLpossible_keys: NULL          key: NULL      key_len: NULL          ref: NULL         rows: 11271619     filtered: 100.00        Extra: Using filesort1 row in set, 1 warning (0.00 sec)</code></pre><h3 id="8-12-2-Using-temporary"><a href="#8-12-2-Using-temporary" class="headerlink" title="8.12.2 Using temporary"></a>8.12.2 Using temporary</h3><p>使用临时表保存中间结果，常用于GROUP BY 和 ORDER BY,DISTINCT操作中。</p><p>出现这种情况一般是要进行优化的，首先是想到用索引来优化。</p><pre><code class="mysql">mysql&gt; explain select distinct(type) from t_scrm_map order by type asc\G;*************************** 1. row ***************************           id: 1  select_type: SIMPLE        table: t_scrm_map   partitions: NULL         type: indexpossible_keys: UQ_ID          key: UQ_ID      key_len: 259          ref: NULL         rows: 11271619     filtered: 100.00        Extra: Using index; Using temporary; Using filesort1 row in set, 1 warning (0.00 sec)</code></pre><h3 id="8-12-3-Using-where"><a href="#8-12-3-Using-where" class="headerlink" title="8.12.3 Using where"></a>8.12.3 Using where</h3><p>在查找使用索引的情况下，需要回表去查询所需的数据</p><pre><code class="mysql">mysql&gt; explain select * from t_scrm_map where target_id  = &#39;11255964&#39; and type =2\G;*************************** 1. row ***************************           id: 1  select_type: SIMPLE        table: t_scrm_map   partitions: NULL         type: refpossible_keys: IX_TRAGET_ID          key: IX_TRAGET_ID      key_len: 130          ref: const         rows: 1     filtered: 10.00        Extra: Using where1 row in set, 1 warning (0.00 sec)</code></pre><h3 id="8-12-4-Using-index"><a href="#8-12-4-Using-index" class="headerlink" title="8.12.4 Using index"></a>8.12.4 Using index</h3><p>这发生在对表的请求列都是同一索引的部分的时候，返回的列数据只使用了索引中的信息，而没有再去访问表中的行记录。是性能高的表现。</p><pre><code class="mysql">mysql&gt; explain select count(*) from t_scrm_map\G;*************************** 1. row ***************************           id: 1  select_type: SIMPLE        table: t_scrm_map   partitions: NULL         type: indexpossible_keys: NULL          key: IX_CREATE_TIME      key_len: 5          ref: NULL         rows: 11271619     filtered: 100.00        Extra: Using index1 row in set, 1 warning (0.00 sec)</code></pre><h3 id="8-12-5-Using-index-condition"><a href="#8-12-5-Using-index-condition" class="headerlink" title="8.12.5 Using index condition"></a>8.12.5 Using index condition</h3><p>这是MySQL 5.6出来的新特性，叫做“索引条件推送”。</p><p>简单说一点就是MySQL原来在索引上是不能执行如like这样的操作的，但是现在可以了，这样减少了不必要的IO操作，但是只能用在二级索引上。</p><pre><code class="mysql">mysql&gt; explain select * from t_scrm_map where bigdata_id  = &#39;B11255964&#39; or bigdata_id like &#39;B125294%&#39;\G;*************************** 1. row ***************************           id: 1  select_type: SIMPLE        table: t_scrm_map   partitions: NULL         type: rangepossible_keys: UQ_ID          key: UQ_ID      key_len: 258          ref: NULL         rows: 8     filtered: 100.00        Extra: Using index condition1 row in set, 1 warning (0.00 sec)</code></pre><h3 id="8-12-6-Using-join-buffer"><a href="#8-12-6-Using-join-buffer" class="headerlink" title="8.12.6 Using join buffer"></a>8.12.6 Using join buffer</h3><p>使用了连接缓存：</p><ul><li>Block Nested Loop，连接算法是块嵌套循环连接;</li><li>Batched Key Access，连接算法是批量索引连接</li></ul><h3 id="8-12-7-Using-MRR"><a href="#8-12-7-Using-MRR" class="headerlink" title="8.12.7 Using MRR"></a>8.12.7 Using MRR</h3><p>使用了MRR优化算法</p><pre><code class="mysql">mysql&gt; explain select *  from t_scrm_user_info where bigdata_user_id &gt; &#39;A1001036&#39; and bigdata_user_id &lt; &#39;A2100000&#39;\G;*************************** 1. row ***************************           id: 1  select_type: SIMPLE        table: t_scrm_user_info   partitions: NULL         type: rangepossible_keys: UQ_CUSTOMER_ID          key: UQ_CUSTOMER_ID      key_len: 130          ref: NULL         rows: 168902     filtered: 100.00        Extra: Using index condition; Using MRR1 row in set, 1 warning (0.00 sec)</code></pre>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> Mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>7.Mysql优化器算法</title>
      <link href="/2020/02/16/7-Mysql%E4%BC%98%E5%8C%96%E5%99%A8%E7%AE%97%E6%B3%95/"/>
      <url>/2020/02/16/7-Mysql%E4%BC%98%E5%8C%96%E5%99%A8%E7%AE%97%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<p>除了我们自己手动进行优化外,根据之前的章节,我们可以知道,Mysql内部自己有优化器,对SQL语句进行一些内部的优化,本章介绍几个常用的优化算法:</p><ul><li>MRR</li><li>ICP</li><li>BKA</li></ul><h2 id="7-1-MRR"><a href="#7-1-MRR" class="headerlink" title="7.1 MRR"></a>7.1 MRR</h2><p>MRR——Multi Range Read</p><h3 id="7-1-1作用"><a href="#7-1-1作用" class="headerlink" title="7.1.1作用"></a>7.1.1作用</h3><p>减少磁盘的随机访问，并将随机访问转化为顺序的数据访问</p><h3 id="7-1-2-原理"><a href="#7-1-2-原理" class="headerlink" title="7.1.2 原理"></a>7.1.2 原理</h3><p>在不使用 MRR 时，优化器需要根据二级索引返回的记录来进行“回表”，这个过程一般会有较多的随机 IO, 使用 MRR 时，SQL 语句的执行过程是这样的：</p><ol><li>优化器将二级索引查询到的记录放到一块缓冲区中；</li><li>如果二级索引扫描到文件的末尾或者缓冲区已满，则使用<code>快速排序对缓冲区中的内容按照主键进行排序</code>；</li><li>用户线程调用 MRR 接口取 cluster index，然后根据cluster index 取行数据；</li><li>当根据缓冲区中的 cluster index 取完数据，则继续调用过程 2) 3)，直至扫描结束；</li></ol><p>通过上述过程，优化器将二级索引随机的 IO 进行排序，转化为主键的有序排列，从而实现了随机 IO 到顺序 IO 的转化，提升性能</p><p>在未开启MRR时,查询方式如图所示:</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/no-mrr-access-pattern.png" alt=""></p><p>开启MRR后,查询方式如下图所示:</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/mrr-access-pattern.png" alt=""></p><h3 id="7-1-3-开关MRR"><a href="#7-1-3-开关MRR" class="headerlink" title="7.1.3 开关MRR"></a>7.1.3 开关MRR</h3><p>我们可以通过 以下命令查看和开启MRR,5.6以后默认是开启的</p><pre><code class="mysql">查看MRR是否开启mysql&gt; select @@optimizer_switch\G*************************** 1. row ***************************@@optimizer_switch: index_merge=on,index_merge_union=on,index_merge_sort_union=on,index_merge_intersection=on,engine_condition_pushdown=on,index_condition_pushdown=on,mrr=on,mrr_cost_based=on,block_nested_loop=on,batched_key_access=off,materialization=on,semijoin=on,loosescan=on,firstmatch=on,duplicateweedout=on,subquery_materialization_cost_based=on,use_index_extensions=on,condition_fanout_filter=on,derived_merge=on1 row in set (0.00 sec)注意上面的mrr=on关闭MRRmysql&gt; set optimizer_switch=&#39;mrr=off&#39;;开启MRRmysql&gt; set optimizer_switch=&#39;mrr=on&#39;;相关参数当mrr=on,mrr_cost_based=on，则表示cost base的方式还选择启用MRR优化,当发现优化后的代价过高时就会不使用该项优化当mrr=on,mrr_cost_based=off，则表示总是开启MRR优化尽量设置 mrr_cost_based=ON，毕竟大多数情况下优化器是对的</code></pre><h3 id="7-1-4-开关对比"><a href="#7-1-4-开关对比" class="headerlink" title="7.1.4 开关对比"></a>7.1.4 开关对比</h3><pre><code class="mysql">mysql&gt; explain select *  from t_scrm_user_info where bigdata_user_id &gt; &#39;A1001036&#39; and bigdata_user_id &lt; &#39;A2100000&#39;;</code></pre><p>当<code>mrr=off</code>时</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/mrroffexplain.png" alt=""></p><p>当<code>mrr=on</code>时</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/mrrontime.png" alt=""></p><p>可以看到当mrr开启时, extra 的输出中多了 “Using MRR” 信息，即使用了 MRR Optimization IO 层面进行了优化，减少 IO 方面的开销</p><p>在时间上理论上可以查一个数量级,但是要在缓存池中没有预热以及查询的数据不在缓冲池中才可以</p><p>我测试的时候时间都差不多 (⊙﹏⊙)b</p><h2 id="7-2-ICP"><a href="#7-2-ICP" class="headerlink" title="7.2 ICP"></a>7.2 ICP</h2><p>ICP——Index Condition Pushdown</p><h3 id="7-2-1作用"><a href="#7-2-1作用" class="headerlink" title="7.2.1作用"></a>7.2.1作用</h3><p>在mysql数据库取出索引的同时,判断是否可以进行WHERE条件的过滤,也就是讲WHERE条件的过滤放到了存储引擎层,大大减少了上层SQL层对记录的fetch索取,以提高性能</p><h3 id="7-2-2-原理"><a href="#7-2-2-原理" class="headerlink" title="7.2.2 原理"></a>7.2.2 原理</h3><p>5.6 之前，在 SQL 语句的执行过程中，server 层通过 engine 的 api 获取数据，然后再进行 where_cond 的判断（具体判断逻辑在: evaluate_join_record），每一条数据都需要从engine层返回server层做判断。我们回顾一下上面把 ICP 关掉的测试，可以看到 Handler_read_next 的值陡增，其原因是第 1 个字段区分度不高，且 memo 字段无法使用索引，造成了类似 index 扫描的的情况，性能较低。</p><p>5.6 之后，在利用索引扫描的过程中，如果发现 where_cond 中含有这个 index 相关的条件，则将此条件记录在 handler 接口中，在索引扫描的过程中，只有满足索引与handler接口的条件时，才会返回到 server 层做进一步的处理，在前缀索引区分度不够，其它字段区分度高的情况下可以有效的减少 server &amp; engine之间的开销，提升查询性能。</p><p>开启ICP前查询方式如图所示:</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/index-access-2phases.png" alt=""></p><p>开启ICP后查询方式如图所示:</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/index-access-with-icp.png" alt=""></p><h3 id="7-2-3-开关ICP"><a href="#7-2-3-开关ICP" class="headerlink" title="7.2.3 开关ICP"></a>7.2.3 开关ICP</h3><pre><code class="mysql">默认是开启的查看MRR是否开启mysql&gt; select @@optimizer_switch\G*************************** 1. row ***************************@@optimizer_switch: index_merge=on,index_merge_union=on,index_merge_sort_union=on,index_merge_intersection=on,engine_condition_pushdown=on,index_condition_pushdown=on,mrr=on,mrr_cost_based=on,block_nested_loop=on,batched_key_access=off,materialization=on,semijoin=on,loosescan=on,firstmatch=on,duplicateweedout=on,subquery_materialization_cost_based=on,use_index_extensions=on,condition_fanout_filter=on,derived_merge=on1 row in set (0.00 sec)注意上面的index_condition_pushdown=onSET optimizer_switch=&#39;index_condition_pushdown=on&#39;SET optimizer_switch=&#39;index_condition_pushdown=off&#39;</code></pre><h3 id="7-2-4-开关对比"><a href="#7-2-4-开关对比" class="headerlink" title="7.2.4 开关对比"></a>7.2.4 开关对比</h3><p>开启ICP时,使用explain语句时extra字段有<code>Using index condition</code>关键字</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/mrroffexplain.png" alt=""></p><h3 id="7-2-5-使用场景"><a href="#7-2-5-使用场景" class="headerlink" title="7.2.5 使用场景"></a>7.2.5 使用场景</h3><ul><li><p>只支持 select 语句；</p></li><li><p>MyISAM 与 InnoDB 引擎都起作用;</p></li><li><p>ICP的优化策略可用于range、ref、eq_ref、ref_or_null 类型的访问数据方法；</p></li><li><p>不支持主建索引，只支持辅助索引；</p></li><li><p>涉及子查询的不能起作用</p></li><li><p>作用于多列索引的情况最为明显</p><pre><code class="mysql">SELECT * FROM people  WHERE zipcode=&#39;95054&#39;  AND lastname LIKE &#39;%etrunia%&#39;  AND address LIKE &#39;%Main Street%&#39;;</code></pre></li></ul><h2 id="7-3-BKA"><a href="#7-3-BKA" class="headerlink" title="7.3 BKA"></a>7.3 BKA</h2><p>BKA——Batched Key Access</p><p>BKA的前辈是BNL:</p><h3 id="7-3-1-Block-Nested-Loop-Join算法"><a href="#7-3-1-Block-Nested-Loop-Join算法" class="headerlink" title="7.3.1 Block Nested-Loop Join算法"></a>7.3.1 Block Nested-Loop Join算法</h3><p>将外层循环的行/结果集存入join buffer, 内层循环的每一行与整个buffer中的记录做比较，从而减少内层循环的次数。主要用于当被join的表上无索引。</p><h3 id="7-3-2-Batched-Key-Access算法"><a href="#7-3-2-Batched-Key-Access算法" class="headerlink" title="7.3.2 Batched Key Access算法"></a>7.3.2 Batched Key Access算法</h3><p>当被join的表能够使用索引时，就先好顺序，然后再去检索被join的表。对这些行按照索引字段进行排序，因此减少了随机IO。如果被Join的表上没有索引，则使用老版本的BNL策略(BLOCK Nested-loop)。</p><h3 id="7-3-3-BKA和BNL标识"><a href="#7-3-3-BKA和BNL标识" class="headerlink" title="7.3.3 BKA和BNL标识"></a>7.3.3 BKA和BNL标识</h3><p>Explain下的Extra显示不同：</p><ul><li><p>Using join buffer (Batched Key Access)</p></li><li><p>Using join buffer (Block Nested Loop)</p></li></ul><pre><code class="mysql">相关参数BAK使用了MRR，要想使用BAK必须打开MRR功能，而MRR基于mrr_cost_based的成本估算并不能保证总是使用MRR，官方推荐设置mrr_cost_based=off来总是开启MRR功能。打开BAK功能(BAK默认OFF)：SET optimizer_switch=&#39;mrr=on,mrr_cost_based=off,batched_key_access=on&#39;;BKA使用join buffer size来确定buffer的大小，buffer越大，访问被join的表/内部表就越顺序。BNL默认是开启的，设置BNL相关参数：SET optimizer_switch=’block_nested_loop’支持inner join, outer join, semi-join operations,including nested outer joins</code></pre><p><code>BKA主要适用于join的表上有索引可利用，无索引只能使用BNL</code></p><h3 id="7-3-4-BKA-BNL-MRR的关系"><a href="#7-3-4-BKA-BNL-MRR的关系" class="headerlink" title="7.3.4 BKA BNL MRR的关系"></a>7.3.4 BKA BNL MRR的关系</h3><p>BKA = BNL + MRR</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/bka.jpg" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> Mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>6.Mysql索引介绍</title>
      <link href="/2020/02/16/6-Mysql%E7%B4%A2%E5%BC%95%E4%BB%8B%E7%BB%8D/"/>
      <url>/2020/02/16/6-Mysql%E7%B4%A2%E5%BC%95%E4%BB%8B%E7%BB%8D/</url>
      
        <content type="html"><![CDATA[<p>【注意】主要介绍Innodb的索引结构</p><h2 id="6-1-Innodb索引组织表"><a href="#6-1-Innodb索引组织表" class="headerlink" title="6.1 Innodb索引组织表"></a>6.1 Innodb索引组织表</h2><p>和MyISAM的一个大区别,在Innodb的存储引擎中,表都是根据<code>主键</code>顺序组织存放的.我们把这种存储方式的表成为<code>索引组织表(index origanized table)</code>即大家常说的<code>IOT</code>方式</p><p>Innodb规定每一个表必须需要有主键(PK),主键的选择方式按照如下顺序选择:</p><ol><li>如有有定义主键 则选择此主键</li><li>如果为定义主键 选择<code>第一个定义的非空唯一索引</code>做主键:这里注意有三个条件:<code>非空</code>,<code>唯一</code>,<code>第一个满足以上两个条件的索引</code></li><li>如果以上两个都没有,Innodb会自动创建一个6字节大小的指针:隐式的创建,平时查询不能看到</li></ol><pre><code class="mysql">我们可以通过以下语句查看每一行的主键id,select *,_rowid form table;_rowid表示表的主键 需要注意的是 _rowid只能用于查看单个列为主键的情况 对于多列组成的主键就不好使了</code></pre><h2 id="6-1-Innodb逻辑存储结构"><a href="#6-1-Innodb逻辑存储结构" class="headerlink" title="6.1 Innodb逻辑存储结构"></a>6.1 Innodb逻辑存储结构</h2><p>之间介绍过Innodb库表的文件结构为两个:</p><pre><code>${tablename}.frm   #表结构文件${tablename}.idb   #表索引及数据文件</code></pre><p>所有的数据都被逻辑的存放在一个空间中(.idb文件中),我们称这个空间为<code>表空间(tablespace)</code></p><p>表空间的组成结构如下图所示:</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/innodb_engine_struct.png" alt=""></p><p>这样看可能不明显 再看一个:</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/tablespace.png" alt=""></p><pre><code>可以看到:表空间  ↓段segment  ↓区extent  ↓页page/块block   &lt;---最小储存单元而页里面包含了一个一个的行数据</code></pre><h3 id="6-2-1-表空间"><a href="#6-2-1-表空间" class="headerlink" title="6.2.1 表空间"></a>6.2.1 表空间</h3><p>在5.6以前所有的数据都存在共享表空间ibdata1中，在5.6以后加入了<code>innodb_file_per_table</code>参数默认是开启的,建议也是开启的,开启了这个参数后,每张表内的数据会单独放到一个表空间内</p><p>需要注意的是:每张表空间内存放的只有:</p><ul><li>数据</li><li>索引</li><li>插入缓存Bitmap</li></ul><p>其他的一些信息如:undo操作,插入缓存索引页,失误信息,double write buffer还是存在ibdata里</p><p>ibdata的具体介绍会在innodb索引章节进行介绍说明</p><h3 id="6-2-2-段"><a href="#6-2-2-段" class="headerlink" title="6.2.2 段"></a>6.2.2 段</h3><p>常见的段分类如下:</p><ul><li>数据段</li><li>索引段</li><li>回滚段</li></ul><h3 id="6-2-3-区"><a href="#6-2-3-区" class="headerlink" title="6.2.3 区"></a>6.2.3 区</h3><p>区是由<code>连续的页</code>组成的空间,<code>在任何情况下每个区的大小都为1MB</code></p><p>为了保证区的连续性,每次存储引擎都会从磁盘申请四五个区</p><p>默认情况下,Innodb页的大小为16KB,即一个区共有64个页  =&gt; (2^10) / (2^4)</p><p>页的大小可以在初始化的时候进行调整,但是区的大小总为1MB</p><h3 id="6-2-4-页"><a href="#6-2-4-页" class="headerlink" title="6.2.4 页"></a>6.2.4 页</h3><p>页是InnoDB存储引擎磁盘管理的最小单位，每个页默认16KB</p><p>可以通过参数<code>innodb_page_size</code>将页的大小设置为4K、8K、16K</p><p>若设置完成，则所有表中页的大小都为innodb_page_size，不可以再次对其进行修改</p><p>除非通过mysqldump导入和导出操作来产生新的库</p><p>innodb的所有数据文件（后缀为ibd的文件），他的大小始终都是<code>innodb_page_size</code> (16384(16k))的整数倍</p><pre><code>[root@centos7-1 baseinfo]# ll|grep &#39;ibd&#39; -rw-r-----. 1 mysql mysql 2663383040 xxx.ibd  =&gt; 2663383040 = 16384*162560-rw-r-----. 1 mysql mysql  868220928 ccc.ibd  =&gt; 868220928 = 16384*52992</code></pre><p><code>innodb_page_size</code>的大小限制了tablespace表空间的大小:</p><p>Table 14.25 InnoDB Maximum Tablespace Size</p><table><thead><tr><th>InnoDB Page Size</th><th>Maximum Tablespace Size</th></tr></thead><tbody><tr><td>4KB</td><td>16TB</td></tr><tr><td>8KB</td><td>32TB</td></tr><tr><td>16KB</td><td>64TB</td></tr><tr><td>32KB</td><td>128TB</td></tr><tr><td>64KB</td><td>256TB</td></tr></tbody></table><h3 id="6-2-5-行"><a href="#6-2-5-行" class="headerlink" title="6.2.5 行"></a>6.2.5 行</h3><p>Innodb存储引擎是面向列的,也就是数据是按行存放的,每个页存放行的记录也是有硬性规定的</p><p>最多允许存放16KB/2-200行记录,即7992行</p><p>但实际上互联网公司一行的数据大概为1KB,即一个page可以存放16行数据</p><h2 id="6-3-B-树结构"><a href="#6-3-B-树结构" class="headerlink" title="6.3 B+树结构"></a>6.3 B+树结构</h2><p>无论是MyISAM还是Innodb 他们在存储数据时,都用到了B+树结构</p><h3 id="6-3-1-B-树结构"><a href="#6-3-1-B-树结构" class="headerlink" title="6.3.1 B+树结构"></a>6.3.1 B+树结构</h3><p>(1) 原理图:</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/BTree.png" alt=""></p><p>(2)特点：</p><ul><li>非叶子节点只存储键值信息</li><li>所有叶子节点之间都有一个链指针</li><li>叶子节点也多存储了指向下一个叶子节点的指针，更方便叶子节点的范围遍历</li><li>数据记录都存放在叶子节点中</li><li>所有的叶子节点组成一个循环双向链表</li></ul><h3 id="6-3-2-MyISAM实现B-Tree"><a href="#6-3-2-MyISAM实现B-Tree" class="headerlink" title="6.3.2 MyISAM实现B+Tree"></a>6.3.2 MyISAM实现B+Tree</h3><p>(1)原理图：</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/MtISAMBTree.png" alt=""></p><p>(2)特点：</p><ul><li>索引文件和数据文件是分离的</li><li>索引文件仅保存数据行记录的地址（行指针）</li><li>主索引与二级索引无区别</li><li>二级索引也存储的是行指针</li></ul><h3 id="6-3-3-Innodb实现B-Tree"><a href="#6-3-3-Innodb实现B-Tree" class="headerlink" title="6.3.3 Innodb实现B+Tree"></a>6.3.3 Innodb实现B+Tree</h3><p>(1)原理图：</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/InnodbBtree.png" alt=""></p><p>(2)特点：</p><ul><li>主键索引既存储索引值，又在叶子节点中存储整行的数据</li><li>二级索引存储索引列值+主键信息</li><li>必须有主键 主键的选择如前文所释</li></ul><h2 id="6-4-索引分类"><a href="#6-4-索引分类" class="headerlink" title="6.4 索引分类"></a>6.4 索引分类</h2><p>我们根据索引文件是否和数据文件共同存储,可讲索引分为:</p><ul><li>聚簇索引(聚集索引)</li><li>非聚簇索引(辅助索引)</li></ul><p>不管是聚簇索引还是非聚簇索引我们看到他们内部都是B+树的,即高度平衡的,他们之间的区别是叶子节点是否存放的是一整行数据信息</p><h3 id="6-4-1-聚簇索引"><a href="#6-4-1-聚簇索引" class="headerlink" title="6.4.1 聚簇索引"></a>6.4.1 聚簇索引</h3><p>Innodb的数据页同B+树数据结构一样,每个页都通过一个双向链表来进行链接。</p><p>由于实际的数据页只能按照一颗B+树进行排序,因此每张表只能拥有一个<code>聚簇索引</code></p><p>在多数情况下,查询优化器倾向与采用聚簇索引:</p><ul><li>聚簇索引能够在叶子节点上直接找到数据</li><li>由于定义了数据的逻辑顺序,聚簇索引能够特别快的访问针对范围值的查询</li></ul><p>【注意】聚簇索引的存储并不是物理上连续的,而是逻辑上连续的:</p><ul><li>页通过双向链表链接,页按照主键的顺序排序</li><li>每个页的记录也是通过双向链表进行维护的,物理储存上可以同样不按照主键存储</li></ul><h3 id="6-4-1-非聚集索引"><a href="#6-4-1-非聚集索引" class="headerlink" title="6.4.1 非聚集索引"></a>6.4.1 非聚集索引</h3><p>对于非聚集索引,叶子节点不包含行记录的全部数据。叶子节点除了包含主键值以外,每个叶子节点的索引行还包含了一个书签(bookmark),在Innodb数据引擎中,这个bookmark就代表相应行数据的聚集索引键</p><p>他们之间的关系如下:</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/IndexRelat.jpg" alt=""></p><p>辅助索引的存在并不影响数据在聚集索引中的组织，因此<code>每张表上可以有多个辅助索引，但只能有一个聚集索引</code>。当通过辅助索引来寻找数据时，InnoDB存储引擎会遍历辅助索引并通过叶子级别的指针获得只想主键索引的主键，然后再通过主键索引来找到一个完整的行记录。</p><p>举例来说，如果在一棵高度为3的辅助索引树种查找数据，那需要对这个辅助索引树遍历3次找到指定主键，如果聚集索引树的高度同样为3，那么还需要对聚集索引树进行3次查找，最终找到一个完整的行数据所在的页，因此一共需要6次逻辑IO访问才能得到最终的一个数据页。</p><p>当然后面优化器部分会有相应的优化算法来优化IO次数</p><h2 id="6-4-索引作用"><a href="#6-4-索引作用" class="headerlink" title="6.4 索引作用"></a>6.4 索引作用</h2><blockquote><p>索引是存储引擎用于快速找到记录的一种数据结构,这是索引的基本功能</p></blockquote><h3 id="6-4-1-索引的优点"><a href="#6-4-1-索引的优点" class="headerlink" title="6.4.1 索引的优点"></a>6.4.1 索引的优点</h3><ul><li>索引大大检索了服务器需要扫描的数据量</li><li>索引可以帮助服务器避免排序和临时表</li><li>索引可以将随机IO变为顺序IO</li></ul><h3 id="6-4-2-索引平衡"><a href="#6-4-2-索引平衡" class="headerlink" title="6.4.2 索引平衡"></a>6.4.2 索引平衡</h3><p>索引太多,应用程序的性能可能受到影响,索引太少,对查询性能又会产生影响,要找到一个平衡点至关重要。</p><p>不要总是在事后才想起添加索引,设计表时要知道数据的使用,从一开始就应该在需要处添加索引</p><p>当然索引并不一定是最好的解决方案:</p><ul><li><p>在创建索引，更新数据表的时候，会给数据库带来额外的消耗。总的来说，只有当索引帮助存储引擎快速查找到记录带来的好处大于其带来的额外工作时，索引才是有效的。</p></li><li><p>对于非常小的表，大部分情况下全表扫描更高效。</p></li><li><p>对于中到大型的表，索引特别有效</p></li><li><p>但是对于特大型的表，建立和使用索引带来的代价将随之增长，这种情况下，需要使用一种技术可以直接区分出查询需要的一组数据，而不是一条记录一条记录的匹配。例如分区表技术;</p></li></ul><h2 id="6-5-索引种类"><a href="#6-5-索引种类" class="headerlink" title="6.5 索引种类"></a>6.5 索引种类</h2><ul><li>聚簇索引<ul><li>主键索引</li></ul></li><li>非聚簇索引<ul><li>普通单列索引</li><li>唯一索引</li><li>前缀索引</li><li>多列索引</li></ul></li></ul><h3 id="6-5-1-主键索引"><a href="#6-5-1-主键索引" class="headerlink" title="6.5.1 主键索引"></a>6.5.1 主键索引</h3><p>必须要有的索引，用于构建聚簇索引的基本条件</p><p>一个表只能有一个主键，不允许有空值。一般是在建表的时候同时创建主键索引。</p><p>关键字及创建方式:</p><pre><code class="mysql">  PRIMARY KEY (`id`)</code></pre><h3 id="6-5-2-普通单列索引"><a href="#6-5-2-普通单列索引" class="headerlink" title="6.5.2 普通单列索引"></a>6.5.2 普通单列索引</h3><p>普通索引是最基本的索引类型，唯一的任务是加快对数据的访问速度，没有任何限制。</p><p>关键字及创建方式:</p><pre><code class="mysql">CREATE INDEX index_name ON TABLE(column_name);ALTER TABLE table_name ADD INDEX index_name(column_name);INDEX index_name (name(length))</code></pre><h3 id="6-5-3-唯一索引"><a href="#6-5-3-唯一索引" class="headerlink" title="6.5.3 唯一索引"></a>6.5.3 唯一索引</h3><p>索引列的值必须唯一，但允许有空值。如果是组合索引，则列值的组合必须唯一。</p><p>关键字及创建方式:</p><pre><code class="mysql">UNIQUE INDEX index_name (column_name)CREATE UNIQUE INDEX index_name ON mytable(column_name)ALTER TABLE table_name ADD UNIQUE indexName(column_name)</code></pre><h3 id="6-5-4-前缀索引"><a href="#6-5-4-前缀索引" class="headerlink" title="6.5.4 前缀索引"></a>6.5.4 前缀索引</h3><p>有时候需要索引很长的字符列，这会让索引变得大且慢。</p><p>通常可以索引开始的部分字符，这样可以大大节约索引空间，从而提高索引效率。但这样也会降低索引的选择性。索引的选择性是指不重复的索引值（也称为基数，cardinality)和数据表的记录总数的比值，范围从1/#T到1之间。索引的选择性越高则查询效率越高，因为选择性高的索引可以让MySQL在查找时过滤掉更多的行。唯一索引的选择性是1，这是最好的索引选择性，性能也是最好的。</p><p>一般情况下某个前缀的选择性也是足够高的，足以满足查询性能。对于BLOB，TEXT，或者很长的VARCHAR类型的列，必须使用前缀索引，因为MySQL不允许索引这些列的完整长度。</p><p>诀窍在于要选择足够长的前缀以保证较高的选择性，同时又不能太长（以便节约空间）。前缀应该足够长，以使得前缀索引的选择性接近于索引的整个列。</p><p>换句话说，<code>前缀的”基数“应该接近于完整的列的”基数“</code>。</p><p>【注意】前缀索引只能作用在普通索引上 不能作用在唯一索引上</p><p>那就是计算完整列的选择性，并使其前缀的选择性接近于完整列的选择性。下面显示如何计算完整列的选择性：</p><pre><code class="mysql">mysql&gt; select count(distinct city) / count(*) from city_demo;+---------------------------------+| count(distinct city) / count(*) |+---------------------------------+|                          0.4283 |+---------------------------------+1 row in set (0.05 sec)</code></pre><p>可以在一个查询中针对不同前缀长度的选择性进行计算，这对于大表非常有用，下面给出如何在同一个查询中计算不同前缀长度的选择性：</p><pre><code class="mysql">mysql&gt; select count(distinct left(city,3))/count(*) as sel3,    -&gt; count(distinct left(city,4))/count(*) as sel4,    -&gt; count(distinct left(city,5))/count(*) as sel5,     -&gt; count(distinct left(city,6))/count(*) as sel6     -&gt; from city_demo;+--------+--------+--------+--------+| sel3   | sel4   | sel5   | sel6   |+--------+--------+--------+--------+| 0.3367 | 0.4075 | 0.4208 | 0.4267 |+--------+--------+--------+--------+1 row in set (0.01 sec)</code></pre><p>可以看见当索引前缀为6时的基数是0.4267，已经接近完整列选择性0.4283。</p><p>在上面的示例中，已经找到了合适的前缀长度，下面创建前缀索引：</p><pre><code class="mysql">mysql&gt; alter table city_demo add key (city(6));Query OK, 0 rows affected (0.19 sec)Records: 0  Duplicates: 0  Warnings: 0</code></pre><p>前缀索引是一种能使索引更小，更快的有效办法，但另一方面也有其<code>缺点</code>：</p><ul><li>mysql无法使用其前缀索引做ORDER BY和GROUP BY</li><li>无法使用前缀索引做覆盖扫描。</li></ul><h3 id="6-5-5-多列索引"><a href="#6-5-5-多列索引" class="headerlink" title="6.5.5 多列索引"></a>6.5.5 多列索引</h3><p>指多个字段上创建的索引，只有在查询条件中使用了创建索引时的第一个字段，索引才会被使用。使用组合索引时遵循最左前缀集合。</p><p>关键字及创建方式:</p><pre><code class="mysql">ALTER TABLE table ADD INDEX name_city_age (name,city,age);</code></pre><p>联合索引在内部的结构图如下图所示:</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/unionindex.png" alt=""></p><p>对于联合索引（a,b），where a =xxx and b =xxx，和where a=xxx 可以使用此联合索引，但是对于where b = xxx不能使用，因为b列数据在此联合索引上不是有序的。具体的索引是否生效会在以后章节介绍。</p><h2 id="6-6-覆盖索引"><a href="#6-6-覆盖索引" class="headerlink" title="6.6 覆盖索引"></a>6.6 覆盖索引</h2><h3 id="6-6-1-定义"><a href="#6-6-1-定义" class="headerlink" title="6.6.1 定义"></a>6.6.1 定义</h3><p>SQL只需要通过索引就可以返回查询所需要的数据，而不必通过二级索引查到主键之后再去查询数据。</p><p>这样可以减少大量的IO操作,无需进行回表操作。</p><h3 id="6-6-2-判断标准"><a href="#6-6-2-判断标准" class="headerlink" title="6.6.2 判断标准"></a>6.6.2 判断标准</h3><p>使用explain，可以通过输出的extra列来判断，对于一个索引覆盖查询，显示为<code>using index</code>,MySQL查询优化器在执行查询前会决定是否有索引覆盖查询</p><h3 id="6-6-3-优点"><a href="#6-6-3-优点" class="headerlink" title="6.6.3 优点"></a>6.6.3 优点</h3><p>覆盖索引是一种非常强大的工具，能大大提高查询性能，只需要读取索引而不用读取数据有以下一些优点<br>1、索引项通常比记录要小，所以MySQL访问更少的数据<br>2、索引都按值的大小顺序存储，相对于随机访问记录，需要更少的I/O<br>3、大多数据引擎能更好的缓存索引，比如MyISAM只缓存索引<br>4、覆盖索引对于InnoDB表尤其有用，因为InnoDB使用聚集索引组织数据，如果二级索引中包含查询所需的数据，就不再需要在聚集索引中查找了</p><h2 id="6-7-索引管理"><a href="#6-7-索引管理" class="headerlink" title="6.7 索引管理"></a>6.7 索引管理</h2><p>我们可以通过<code>SHOW INDEX FROM table</code>查看表的索引情况</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/showindex.png" alt=""></p><p>具体每个字段的含义如下:</p><p>下面我们一起了解下返回的这张表的含义：</p><ol><li>Table: 表名</li><li>Non_unique: 如果索引不能包括重复值则为0，如果可以则为1。也就是平时所说的唯一索引。</li><li>Key_name 索引名称，如果名字相同则表明是同一个索引，而并不是重复，比如上图中的而三条数据，其实是一个联合索引。</li><li>Seq_in_index 索引中的列序列号，从1开始。上图中的二、三数据，Seq_in_index一个是1一个是2，就是表明在联合索引中的顺序，我们就能推断出联合索引中索引的前后顺序。</li><li>Column_name 索引的列名。</li><li>Collation指的是列以什么方式存储在索引中，可是A或NULL,Btree总是A,即排序的。</li><li>Cardinality 是基数的意思，表示索引中唯一值的数目的估计值。我们知道某个字段的重复值越少越适合建索引，所以我们一般都是根据Cardinality来判断索引是否具有高选择性，如果这个值非常小，那就需要重新评估这个字段是否适合建立索引。</li><li>Sub_part 前置索引的意思，如果列只是被部分地编入索引，则为被编入索引的字符的数目。如果整列被编入索引，则为NULL。</li><li>Packed 指示关键字如何被压缩。如果没有被压缩，则为NULL。压缩一般包括压缩传输协议、压缩列解决方案和压缩表解决方案。</li><li>.Null 如果列含有NULL，则含有YES。</li><li>.Index_type表示索引类型，Mysql目前主要有以下几种索引类型：FULLTEXT，HASH，BTREE，RTREE。</li><li>.Comment Index_comment 注释的意思。</li></ol><h3 id="6-7-1-什么是Cardinality"><a href="#6-7-1-什么是Cardinality" class="headerlink" title="6.7.1 什么是Cardinality"></a>6.7.1 什么是Cardinality</h3><p>不是所有的查询条件出现的列都需要添加索引。对于什么时候添加B+树索引。一般的经验是，在访问表中很少一部分时使用B+树索引才有意义。对于性别字段、地区字段、类型字段，他们可取值范围很小，称为低选择性。如</p><pre><code class="mysql">SELECT * FROM student WHERE sex=&#39;M&#39;</code></pre><p>按性别进行查询时，可取值一般只有M、F。</p><p>因此SQL语句得到的结果可能是该表50%的数据(加入男女比例1:1)这时添加B+树索引是完全没有必要的。</p><p>相反，如果某个字段的取值范围很广，几乎没有重复，属于高选择性。则此时使用B+树的索引是最合适的。</p><p>例如对于姓名字段，基本上在一个应用中不允许重名的出现</p><h3 id="6-7-2-查看高选择性"><a href="#6-7-2-查看高选择性" class="headerlink" title="6.7.2 查看高选择性"></a>6.7.2 查看高选择性</h3><p>怎样查看索引是否有高选择性？通过SHOW INDEX结果中的列Cardinality来观察。非常关键，表示所以中不重复记录的预估值，需要注意的是Cardinality是一个预估值，而不是一个准确值基本上用户也不可能得到一个准确的值</p><p>在实际应用中，<code>Cardinality/n_row_in_table应尽可能的接近1</code>，如果非常小,那用户需要考虑是否还有必要创建这个索引。故在访问高选择性属性的字段并从表中取出很少一部分数据时，对于字段添加B+树索引是非常有必要的。如</p><pre><code class="mysql">SELECT * FROM member WHERE usernick=&#39;David&#39;;</code></pre><p>表member大约有500W行数据,usernick字段上有一个唯一索引。这也符号提到的高选择性</p><h3 id="6-7-3-Cardinality统计"><a href="#6-7-3-Cardinality统计" class="headerlink" title="6.7.3 Cardinality统计"></a>6.7.3 Cardinality统计</h3><p>Cardinality统计时放在存储引擎层进行的</p><p>在生成环境中，索引的更新操作可能非常频繁。如果每次索引在发生操作时就对其进行Cardinality统计，那么将会对数据库带来很大的负担。另外需要考虑的是，如果一张表的数据非常大，如一张表有50G的数据，那么统计一次Cardinality信息所需要的时间可能非常长。这样的环境下，是不能接受的。因此，数据库对于Cardinality信息的统计都是通过采样的方法完成</p><p>在InnoDB存储引擎中，Cardinality统计信息的更新发生在两个操作中：insert和update。InnoDB存储引擎内部对更新Cardinality信息的策略为:</p><ul><li>表中1/16的数据已发生了改变</li><li>stat_modified_counter&gt;2000 000 000</li></ul><p>接着考虑InnoDB存储引擎内部是怎样进行Cardinality信息统计和更新操作呢？同样是通过采样的方法。默认的InnoDB存储引擎对8个叶子节点Leaf Page进行采用。采用过程如下</p><ol><li>取得B+树索引中叶子节点的数量，记为A</li><li>随机取得B+树索引中的8个叶子节点，统计每个页不同记录的个数，即为P1，P2….P8</li><li>通过采样信息给出Cardinality的预估值:Cardinality=(P1+P2+…+P8)*A/8</li></ol><p>根据上述的说明可以发现，在InnoDB存储引擎中，Cardinality值通过对8个叶子节点预估而得的。而<code>不是一个实际精确的值</code>。再者，每次对Cardinality值的统计，都是通过随机取8个叶子节点得到的，这同时有暗示了另外一个Cardinality现象，即每次得到的Cardinality值可能不同的;</p><p>当然，有一种情况可以使得用户每次观察到的索引Cardinality值是一样的。那就是表足够小，表的叶子节点树小于或者等于8个</p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> Mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>4.MySQL体系结构</title>
      <link href="/2020/02/15/4-Mysql%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/"/>
      <url>/2020/02/15/4-Mysql%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/</url>
      
        <content type="html"><![CDATA[<h2 id="4-1-Mysql整体结构图"><a href="#4-1-Mysql整体结构图" class="headerlink" title="4. 1 Mysql整体结构图"></a>4. 1 Mysql整体结构图</h2><p>下图是Mysql官方给出的结构图:</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/Mysql%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84.png" alt="Mysql体系结构"></p><p>从上图可以发现Mysql由以下几部分组成</p><ul><li>客户端</li><li>连接层</li><li>SQL层</li><li>存储引擎层</li><li>文件系统</li><li>服务管理(非必须)</li></ul><h3 id="4-1-1-客户端"><a href="#4-1-1-客户端" class="headerlink" title="4.1.1 客户端"></a>4.1.1 客户端</h3><p>即Mysql提供给不同语言的API链接方式,支持的语言有很过Go,PHP,Java等等 没啥好说的哈</p><h3 id="4-1-2-连接层"><a href="#4-1-2-连接层" class="headerlink" title="4.1.2 连接层"></a>4.1.2 连接层</h3><p>主要负责以下功能:</p><ul><li>提供链接协议,两种: <code>socket连接&amp;TCP/IP连接</code></li><li>授权认证</li><li>提供专用的连接线程</li><li>最大连接数限制</li></ul><h3 id="4-1-3-SQL层"><a href="#4-1-3-SQL层" class="headerlink" title="4.1.3  SQL层"></a>4.1.3  SQL层</h3><p>主要负责以下功能:</p><ul><li>SQL语法检查</li><li>语义检查(DML,DCL,DQL,DTL)</li><li>权限判断</li><li>解析器:解析预处理,执行计划(是全表扫描还是走哪个索引)</li><li>优化分析器:帮我们选择最优的方案</li><li>执行器:执行SQL语句</li><li>查询缓存(QC)<ul><li>【注】这个不要开启,在许多情况下它会失效并且会拉低数据库性能</li><li>可以使用Redis来替代</li></ul></li></ul><h3 id="4-1-4-存储引擎层"><a href="#4-1-4-存储引擎层" class="headerlink" title="4.1.4 存储引擎层"></a>4.1.4 存储引擎层</h3><p>提供不同的存储引擎以供选择,类似于Linux的文件系统,和磁盘模块进行数据交互</p><p>我们可以通过show engine指令查看目前数据库支持的存储引擎</p><pre><code>[root@centos7-1 3306]# mysql -e&#39;show engines&#39;|awk &#39;{print $1}&#39;EngineCSVMRG_MYISAMMyISAM        ***BLACKHOLEPERFORMANCE_SCHEMAMEMORY          ARCHIVEInnoDB          *****FEDERATED</code></pre><p>经常提到的存储引擎有两个:</p><ul><li>InnoDB</li><li>MyISAM</li></ul><p>在早期使用的默认存储引擎为MyISAM,目前默认都是用InnoDB,他们之间的区别稍后会在存储引擎一篇中详细介绍</p><h3 id="4-1-5-文件系统"><a href="#4-1-5-文件系统" class="headerlink" title="4.1.5 文件系统"></a>4.1.5 文件系统</h3><p>用于存储数据文件和不同类型的日志</p><h2 id="4-2-MySQL文件结构"><a href="#4-2-MySQL文件结构" class="headerlink" title="4.2 MySQL文件结构"></a>4.2 MySQL文件结构</h2><p>目前我们的Mysql数据库下有以下几个库:</p><pre><code>mysql&gt; show databases;+--------------------+| Database           |+--------------------+| information_schema || baseinfo           || mysql              || performance_schema || sys                || test               |+--------------------+6 rows in set (0.00 sec)</code></pre><p>我们查看MySQL的数据存储文件夹下会看到如下文件:</p><pre><code>[root@centos7-1 3306]# tree -L 1.├── auto.cnf├── baseinfo├── centos7-1.err├── centos7-1.pid├── ib_buffer_pool├── ibdata1├── ib_logfile0├── ib_logfile1├── ibtmp1├── mysql├── performance_schema├── sys└── test</code></pre><p>意义如下:</p><pre><code>[root@centos7-1 3306]# tree -L 1.├── auto.cnf               #Mysql自动生成的一些配置文件├── baseinfo            #baseinfo库里的文件【自建库】├── centos7-1.err       #数据库错误日志 命名方式为 主机名+“.err”├── centos7-1.pid       #数据里的进程id文件├── ib_buffer_pool      #一些持久化了的buffer pool文件├── ibdata1             #ibddata文件存储临时表数据+用户数据├── ib_logfile0         #ib_logfile0～N为 redo log日志├── ib_logfile1├── ibtmp1              #临时表空间文件├── mysql               #Mysql库文件├── performance_schema  #performance_schema库文件夹【系统库】├── sys                    #sys库文件夹【系统库】└── test                #自建test库文件夹【自建库】</code></pre><p>我们看到baseinfo库为Innodb存储引擎库,而test为MyISAM存储引擎库, 他们在文件存储上又有不同之处:</p><pre><code>[root@centos7-1 3306]# tree testtest├── db.opt├── t1.frm├── t1.MYD└── t1.MYI0 directories, 4 files[root@centos7-1 3306]# tree baseinfo/baseinfo/├── db.opt├── t_scrm_map.frm├── t_scrm_map.ibd├── t_scrm_pet_info.frm├── t_scrm_pet_info.ibd├── t_scrm_user_info.frm└── t_scrm_user_info.ibd[root@centos7-1 test]# cat db.opt default-character-set=utf8mb4default-collation=utf8mb4_general_ci#db.opt的作用1、create database时会自动生成一个文件db.opt，存放的数据库的默认字符集，show create database时显示数据库默认字符集即db.opt中字符集2、这个文件丢失不影响数据库运行，该文件丢失之后新建表时，找不到数据库的默认字符集，就把character_set_server当成数据库的默认字符集，show create database时显示character_set_server字符集</code></pre><p>可以看到MyISAM库表的文件结构为三个:</p><pre><code>${tablename}.frm   #表结构文件${tablename}.MYI   #表索引文件 MyISAM Index${tablename}.MYD   #表数据文件 MyISAM Data</code></pre><p>而Innodb库表的文件结构为两个:</p><pre><code>${tablename}.frm   #表结构文件${tablename}.idb   #表索引及数据文件</code></pre><p>可以看到在文件存储上 MyISAM和Innodb就有截然不同的结构 从而造成了数据引擎上的巨大差异</p><h2 id="4-3-MySQL运行模式"><a href="#4-3-MySQL运行模式" class="headerlink" title="4.3  MySQL运行模式"></a>4.3  MySQL运行模式</h2><p>MySQL被设计成一个单进程多线程架构的数据库,这一点与SQL Server比较类似,但与Oracle多进程的架构不同</p><p><code>MySQL数据库实例在系统上表现就是一个进程</code></p><p>已Innodb存储引擎为例,包含的后台线程主要有四种（具体含义会在存储引擎章节做解释）:</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/Mysqld%E8%BF%9B%E7%A8%8B.png" alt=""></p><p>我们可以在mysql中执行以下语句看查看所有mysql的进程数,具体含义在innodb章节解释吧:</p><pre><code class="mysql">mysql&gt; select thread_id,name,type FROM performance_schema.threads;+-----------+----------------------------------------+------------+| thread_id | name                                   | type       |+-----------+----------------------------------------+------------+|         1 | thread/sql/main                        | BACKGROUND ||         2 | thread/sql/thread_timer_notifier       | BACKGROUND ||         3 | thread/innodb/io_ibuf_thread           | BACKGROUND ||         4 | thread/innodb/io_log_thread            | BACKGROUND ||         5 | thread/innodb/io_read_thread           | BACKGROUND ||         6 | thread/innodb/io_read_thread           | BACKGROUND ||         7 | thread/innodb/io_read_thread           | BACKGROUND ||         8 | thread/innodb/io_read_thread           | BACKGROUND ||         9 | thread/innodb/io_write_thread          | BACKGROUND ||        10 | thread/innodb/io_write_thread          | BACKGROUND ||        11 | thread/innodb/io_write_thread          | BACKGROUND ||        12 | thread/innodb/io_write_thread          | BACKGROUND ||        13 | thread/innodb/page_cleaner_thread      | BACKGROUND ||        16 | thread/innodb/srv_lock_timeout_thread  | BACKGROUND ||        17 | thread/innodb/srv_error_monitor_thread | BACKGROUND ||        18 | thread/innodb/srv_monitor_thread       | BACKGROUND ||        19 | thread/innodb/srv_master_thread        | BACKGROUND ||        20 | thread/innodb/srv_worker_thread        | BACKGROUND ||        21 | thread/innodb/srv_purge_thread         | BACKGROUND ||        22 | thread/innodb/srv_worker_thread        | BACKGROUND ||        23 | thread/innodb/srv_worker_thread        | BACKGROUND ||        24 | thread/innodb/buf_dump_thread          | BACKGROUND ||        25 | thread/innodb/dict_stats_thread        | BACKGROUND ||        26 | thread/sql/signal_handler              | BACKGROUND ||        27 | thread/sql/compress_gtid_table         | FOREGROUND ||        36 | thread/sql/one_connection              | FOREGROUND |+-----------+----------------------------------------+------------+26 rows in set (0.00 sec)</code></pre>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> Mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>5.MysqlSQL基础</title>
      <link href="/2020/02/15/5-MysqlSQL%E5%9F%BA%E7%A1%80/"/>
      <url>/2020/02/15/5-MysqlSQL%E5%9F%BA%E7%A1%80/</url>
      
        <content type="html"><![CDATA[<h2 id="5-1-常用数据类型"><a href="#5-1-常用数据类型" class="headerlink" title="5.1 常用数据类型"></a>5.1 常用数据类型</h2><h3 id="5-1-1-整型"><a href="#5-1-1-整型" class="headerlink" title="5.1.1 整型"></a>5.1.1 整型</h3><table><thead><tr><th align="center">类型</th><th align="center">字节</th><th align="center">范围(有符号位)</th></tr></thead><tbody><tr><td align="center">TINYINT</td><td align="center">1Byte</td><td align="center">0~2^8 OR  -2^7 ~ 2^7-1</td></tr><tr><td align="center">INT</td><td align="center">4Byte</td><td align="center">0~2^32 OR  -2^31 ~ 2^31-1</td></tr><tr><td align="center">BIGINT</td><td align="center">8Byte</td><td align="center">0~2^64 OR -2^63 ~ 2^63-1</td></tr></tbody></table><ul><li>int(M)  M表示总位数<ul><li>如果某个数不够定义字段时设置的位数，则前面以0补填，zerofill 属性修改</li><li>例：int(5)   插入一个数’123’，补填后为’00123’</li></ul></li><li>默认存在符号位，unsigned 属性修改</li><li>在满足要求的情况下，越小越好</li><li>1表示bool值真，0表示bool值假。MySQL没有布尔类型，通过整型0和1表示。常用tinyint(1)表示布尔型</li></ul><h3 id="5-1-2-小数"><a href="#5-1-2-小数" class="headerlink" title="5.1.2 小数"></a>5.1.2 小数</h3><table><thead><tr><th align="center">类型</th><th align="center">字节</th><th align="center">范围(有符号位)</th></tr></thead><tbody><tr><td align="center">float(单精度)</td><td align="center">4Byte</td><td align="center">自定义，表示近似值</td></tr><tr><td align="center">double(双精度)</td><td align="center">8Byte</td><td align="center">自定义，表示近似值</td></tr><tr><td align="center">decimal</td><td align="center">自定义</td><td align="center">自定义,表示精确数值</td></tr></tbody></table><ul><li><p>浮点型既支持符号位 unsigned 属性，也支持显示宽度 zerofill 属性，不同于整型，前后均会补填0</p></li><li><p>支持科学计数法表示。</p></li><li><p>定义浮点型时，需指定总位数和小数位数。</p><blockquote><p>float(M, D)     double(M, D)</p><p>M表示总位数，D表示小数位数</p><p>M和D的大小会决定浮点数的范围 不同于整型的固定范围</p><p>M既表示总位数（不包括小数点和正负号），也表示显示宽度（所有显示符号均包括）</p><p>decimal(M, D)   M也表示总位数，D表示小数位数</p><p>保存一个精确的数值，不会发生数据的改变，不同于浮点数的四舍五入<br>将浮点数转换为字符串来保存，每9位数字保存为4个字节</p></blockquote></li></ul><h3 id="5-1-3-字符"><a href="#5-1-3-字符" class="headerlink" title="5.1.3 字符"></a>5.1.3 字符</h3><table><thead><tr><th align="center">类型</th><th align="left">说明</th></tr></thead><tbody><tr><td align="center">CHAR</td><td align="left">定长字符串最多255个字符</td></tr><tr><td align="center">VARCHAR</td><td align="left">变长字符串最多65535个字符</td></tr><tr><td align="center">TEXT</td><td align="left">变长字符串最多65535个字符类型，在定义时,不需要定义长度<br/>也不会计算总长度不可给default值</td></tr><tr><td align="center">BLOB</td><td align="left">二进制字符串（字节字符串）</td></tr><tr><td align="center">ENUM</td><td align="left">枚举类型 smallint 存储</td></tr><tr><td align="center">SET</td><td align="left">集合类型 bigint存储</td></tr></tbody></table><pre><code>char(11) ：定长字符串类型,在存储字符串时，最大字符长度11个，立即分配11个字符长度的存储空间，如果存不满，空格填充varchar(11):变长的字符串类型看，最大字符长度11个。在存储字符串时，自动判断字符长度，按需分配存储空间。M表示能存储的最大长度，此长度是字符数，非字节数。不同的编码，所占用的空间不同。char,最多255个字符，与编码无关。varchar,最多65535字符，与编码有关。一条有效记录最大不能超过65535个字节。utf8 最大为21844个字符，gbk 最大为32766个字符，latin1 最大为65532个字符【注】varchar 是变长的，需要利用存储空间保存 varchar 的长度，如果数据小于255个字节，则采用一个字节来保存长度，反之需要两个字节来保存。varchar 的最大有效长度由最大行大小和使用的字符集确定。最大有效长度是65532字节，因为在varchar存字符串时，第一个字节是空的，不存在任何数据，然后还需两个字节来存放字符串的长度，所以有效长度是64432-1-2=65532字节。例：若一个表定义为 CREATE TABLE tb(c1 int, c2 char(30), c3 varchar(N)) charset=utf8; 问N的最大值是多少？答：(65535-1-2-4-30*3)/3</code></pre><pre><code>枚举类型说明enum(val1, val2, val3...)在已知的值中进行单选。最大数量为65535.枚举值在保存时，以2个字节的整型(smallint)保存。每个枚举值，按保存的位置顺序，从1开始逐一递增。表现为字符串类型，存储却是整型。NULL值的索引是NULL。空字符串错误值的索引值是0枚举类型，比较适合于将来此列的值是固定范围内的特点，可以使用enum,可以很大程度的优化我们的索引结构</code></pre><pre><code class="mysql">集合类型说明set(val1, val2, val3...)create table tab ( gender set(&#39;男&#39;, &#39;女&#39;, &#39;无&#39;) );insert into tab values (&#39;男, 女&#39;);最多可以有64个不同的成员。以bigint存储，共8个字节。采取位运算的形式当创建表时，SET成员值的尾部空格将自动被删除</code></pre><h3 id="5-1-4-时间"><a href="#5-1-4-时间" class="headerlink" title="5.1.4 时间"></a>5.1.4 时间</h3><table><thead><tr><th align="center">类型</th><th align="center">字节</th><th align="center">说明</th><th align="center">范围</th></tr></thead><tbody><tr><td align="center">datetime</td><td align="center">8Byte</td><td align="center">日期及时间</td><td align="center">1000-01-01 00:00:00 到 9999-12-31 23:59:59</td></tr><tr><td align="center">date</td><td align="center">3Byte</td><td align="center">日期</td><td align="center">1000-01-01 到 9999-12-31</td></tr><tr><td align="center">timestamp</td><td align="center">4Byte</td><td align="center">时间戳</td><td align="center">19700101000000 到 2038-01-19 03:14:07</td></tr><tr><td align="center">time</td><td align="center">3Byte</td><td align="center">时间</td><td align="center">-838:59:59 到 838:59:59</td></tr><tr><td align="center">year</td><td align="center">1Byte</td><td align="center">年份</td><td align="center">1901 - 2155</td></tr></tbody></table><h2 id="5-2-列属性"><a href="#5-2-列属性" class="headerlink" title="5.2 列属性"></a>5.2 列属性</h2><h3 id="5-2-1-PRIMARY"><a href="#5-2-1-PRIMARY" class="headerlink" title="5.2.1 PRIMARY"></a>5.2.1 PRIMARY</h3><ul><li>能唯一标识记录的字段，可以作为主键。</li><li>一个表只能有一个主键。</li><li>主键具有唯一性。</li><li>声明字段时，用 primary key 标识。</li><li>也可以在字段列表之后声明：create table tab ( id int, stu varchar(10), primary key (id));</li><li>主键字段的值不能为null。</li><li>主键可以由多个字段共同组成。此时需要在字段列表后声明的方法。<br>  例：create table tab ( id int, stu varchar(10), age int, primary key (stu, age));</li></ul><h3 id="5-2-2-UNIQUE"><a href="#5-2-2-UNIQUE" class="headerlink" title="5.2.2 UNIQUE"></a>5.2.2 UNIQUE</h3><p>唯一索引,使得某字段的值也不能重复。</p><h3 id="5-2-3-NULL"><a href="#5-2-3-NULL" class="headerlink" title="5.2.3 NULL"></a>5.2.3 NULL</h3><ul><li>null不是数据类型，是列的一个属性。</li><li>表示当前列是否可以为null，表示什么都没有。</li><li>null, 允许为空。默认；not null, 不允许为空。</li><li>insert into tab values (null, ‘val’); – 此时表示将第一个字段的值设为null, 取决于该字段是否允许为null</li></ul><h3 id="5-2-4-DEFAULT"><a href="#5-2-4-DEFAULT" class="headerlink" title="5.2.4 DEFAULT"></a>5.2.4 DEFAULT</h3><ul><li>当前字段的默认值。<pre><code class="mysql">#表示强制使用默认值insert into tab values (default, &#39;val&#39;);#表示将当前时间的时间戳 设为默认值create table tab ( add_time timestamp default current_timestamp )</code></pre></li></ul><h3 id="5-2-5-AUTO-INCREMENT"><a href="#5-2-5-AUTO-INCREMENT" class="headerlink" title="5.2.5 AUTO_INCREMENT"></a>5.2.5 AUTO_INCREMENT</h3><ul><li>自动增长约束</li><li>自动增长必须为索引（主键或unique）</li><li>只能存在一个字段为自动增长。</li><li>默认为1开始自动增长。可以通过表属性 auto_increment = x进行设置，或 alter table tbl auto_increment = x;</li></ul><h3 id="5-2-6-COMMENT"><a href="#5-2-6-COMMENT" class="headerlink" title="5.2.6 COMMENT"></a>5.2.6 COMMENT</h3><p>注释<br>例：create table tab ( id int ) comment ‘注释内容’;</p><h3 id="5-2-7-FOREIGN-KEY"><a href="#5-2-7-FOREIGN-KEY" class="headerlink" title="5.2.7 FOREIGN KEY"></a>5.2.7 FOREIGN KEY</h3><p>外键约束 高并发下不建议使用 ERP中常用</p><h2 id="5-3-表属性"><a href="#5-3-表属性" class="headerlink" title="5.3 表属性"></a>5.3 表属性</h2><h3 id="5-3-1-engine"><a href="#5-3-1-engine" class="headerlink" title="5.3.1 engine"></a>5.3.1 engine</h3><p>使用的存储引擎 建议都是用Innodb</p><h3 id="5-3-2-charset"><a href="#5-3-2-charset" class="headerlink" title="5.3.2 charset"></a>5.3.2 charset</h3><p>使用的字符集 这个参数也可以在列属性里设置,但是不建议这样做,整表设置相同字符集即可</p><p>常用的有:</p><ul><li>utf8 推荐使用** </li><li>utf8mb4 推荐使用***</li><li>gbk</li></ul><p>建议默认使用utf8mb4格式:</p><blockquote><p>MySQL在5.5.3之后增加了utf8mb4的编码，mb4即4-Byte UTF-8 Unicode Encoding，专门用来兼容四字节的unicode。utf8mb4为utf8的超集并兼容utf8，比utf8能表示更多的字符。</p><p>低版本的MySQL支持的utf8编码，最大字符长度为 3 字节，如果遇到 4 字节的字符就会出现错误了。</p><p>常见的四字节就是Emoji 表情（Emoji 是一种特殊的 Unicode 编码，常见于 ios 和 android 手机上），和一些不常用的汉字，以及任何新增的 Unicode 字符等等。</p></blockquote><h2 id="5-4-常用SQL分类"><a href="#5-4-常用SQL分类" class="headerlink" title="5.4 常用SQL分类"></a>5.4 常用SQL分类</h2><ul><li>DDL：数据定义语言</li><li>DML：数据操作语言</li><li>DCL：数据控制语言</li><li>DQL：数据的查询语言</li></ul><h2 id="5-5-DDL语句"><a href="#5-5-DDL语句" class="headerlink" title="5.5 DDL语句"></a>5.5 DDL语句</h2><h3 id="5-5-1-数据库操作"><a href="#5-5-1-数据库操作" class="headerlink" title="5.5.1 数据库操作"></a>5.5.1 数据库操作</h3><pre><code class="mysql"># 创建demo数据库mysql&gt; create database demo charset utf8mb4mysql&gt; create database if not exists demo charset utf8mb4;# 删除demo数据库mysql&gt; drop database demo;mysql&gt; drop database if exists demo;# 修改database字符集mysql&gt; alter database demo charset=utf8;</code></pre><h3 id="5-5-2-表操作"><a href="#5-5-2-表操作" class="headerlink" title="5.5.2 表操作"></a>5.5.2 表操作</h3><pre><code class="mysql"># 创建表CREATE TABLE `t_scrm_user_info`(  `id`          INT(10) UNSIGNED NOT NULL AUTO_INCREMENT,  `user_id`     VARCHAR(32)      NOT NULL COMMENT &#39;用户ID作为唯一标示&#39;,  `user_name`   VARCHAR(32)      NOT NULL DEFAULT &#39;&#39; COMMENT &#39;用户姓名&#39;,  `user_sex`    TINYINT(3)       NOT NULL DEFAULT 0 COMMENT &#39;用户性别 0未知 1男 2女&#39;,  `user_mobile` VARCHAR(16)      NOT NULL DEFAULT &#39;&#39; COMMENT &#39;用户手机号&#39;,  `user_status` TINYINT(3)       NOT NULL DEFAULT 0 COMMENT &#39;用户状态 0正常 1锁定 -1删除&#39;,  `user_avatar` varchar(256)     NOT NULL DEFAULT &#39;&#39; COMMENT &#39;用户头像&#39;,  `create_time` DATETIME         NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#39;创建时间&#39;,  PRIMARY KEY (`id`),  UNIQUE KEY `UQ_USER_ID` (`user_id`)) ENGINE = InnoDB  DEFAULT CHARSET = utf8mb4 COMMENT =&#39;用户信息表&#39;;# 删除表mysql&gt; drop table t_scrm_user_info;# 重命名表mysql&gt; RENAME TABLE t_scrm_user_info to demo;# 复制表mysql&gt; CREATE table t_scrm_user_info like demo;# 清空表mysql&gt; truncate table t_scrm_user_info;# 添加列——添加update_time列ALTER TABLE t_scrm_user_info ADD update_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT &#39;更新时间&#39;;# 添加列——在user_avatar列后添加user_remark列ALTER TABLE t_scrm_user_info ADD `user_remark` VARCHAR(128) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;用户备注&#39; AFTER user_avatar;# 更新列mysql&gt; ALTER TABLE t_scrm_user_info MODIFY user_name VARCHAR(64);注意上面语句更新的时候 会把user_name列上的其他属性更新没 如not null属性和comment属性所以建议写成如下：mysql&gt; ALTER TABLE t_scrm_user_info MODIFY user_name VARCHAR(32)      NOT NULL DEFAULT &#39;&#39; COMMENT &#39;用户姓名&#39;;# 更新列名mysql&gt; ALTER TABLE t_scrm_user_info CHANGE user_name u_name VARCHAR(32)      NOT NULL DEFAULT &#39;&#39; COMMENT &#39;用户姓名&#39;;# 删除列ALTER TABLE t_scrm_user_info DROP user_avatar;#添加索引ALTER TABLE tbl_name ADD INDEX index_name (column_list): 添加普通索引，索引值可出现多次。#删除索引DROP INDEX [indexName] ON mytable;</code></pre><h2 id="5-6-DML语句"><a href="#5-6-DML语句" class="headerlink" title="5.6 DML语句"></a>5.6 DML语句</h2><pre><code class="mysql"># 插入INSERT INTO t_scrm_user_info(user_id,user_name,user_sex,user_mobile,user_status) VALUES(&quot;123&quot;,&#39;nihao&#39;,1,&#39;18611111111&#39;,&#39;0&#39;),(&quot;345&quot;,&#39;hahah&#39;,1,&#39;18611111111&#39;,&#39;0&#39;);# 更新UPDATE t_scrm_user_info set user_id=&quot;444&quot; WHERE user_id=&quot;123&quot;;# 删除mysql&gt; DELETE FROM t_scrm_user_info where user_id =&quot;444&quot;;# 全表删除mysql&gt; DELETE FROM t_scrm_user_info;与truncate区别delete:         DML操作, 是逻辑性质删除,逐行进行删除,速度慢. 还在文件里 文件大小不会改变        主键继续原来的增长计数truncate:         DDL操作,对与表段中的数据页进行清空,速度快. 从文件里删除 文件大小改变        主键从1开始计数</code></pre><h2 id="5-7-DCL语句"><a href="#5-7-DCL语句" class="headerlink" title="5.7 DCL语句"></a>5.7 DCL语句</h2><pre><code class="mysql"># 管理用户通配符：%表示可以在任意主机使用用户登录数据库【注意】在mysql里面用户的定义为:用户名+主机名【注意】在mysql8.0中添加用户和授权必须是两步进行 不能用一条语句# 添加用户mysql&gt; CREATE USER &#39;read&#39;@&#39;10.15.2.%&#39; identified by &#39;123&#39;;# 删除用户mysql&gt; DROP USER &#39;read&#39;@&#39;10.15.2.%&#39;;#修改用户密码mysql&gt; set password for &#39;read&#39;@&#39;10.15.2.%&#39; = password(&#39;456&#39;);# 授权# 查看授权mysql&gt; show grants for &#39;read&#39;@&#39;10.15.2.%&#39;;+------------------------------------------+| Grants for read@10.15.2.%                |+------------------------------------------+| GRANT USAGE ON *.* TO &#39;read&#39;@&#39;10.15.2.%&#39; |+------------------------------------------+1 row in set (0.00 sec)# 添加授权grant 权限列表 on 数据库.表名  to  &#39;用户名&#39;@&#39;主机名&#39;;mysql&gt; GRANT CREATE,ALTER,DROP,INSERT,UPDATE,DELETE,SELECT ON demo.* TO &#39;read&#39;@&#39;10.15.2.%&#39;;# 授权所有权限mysql&gt; grant all privileges on demo.* to &#39;read&#39;@&#39;10.15.2.%&#39;;# 删除授权revoke 权限列表  on  数据库.表名  from  &#39;用户名&#39;@&#39;主机名&#39;;mysql&gt; revoke DROP,DELETE  on  demo.* from &#39;read&#39;@&#39;10.15.2.%&#39;;# 让授权生效FLUSH PRIVILEGES;</code></pre><h2 id="5-8-DQL语句"><a href="#5-8-DQL语句" class="headerlink" title="5.8 DQL语句"></a>5.8 DQL语句</h2><h3 id="5-8-1-SELECT"><a href="#5-8-1-SELECT" class="headerlink" title="5.8.1 SELECT"></a>5.8.1 SELECT</h3><pre><code class="mysql">SELECT [ALL|DISTINCT] select_expr FROM -&gt; WHERE -&gt; GROUP BY [合计函数] -&gt; HAVING -&gt; ORDER BY -&gt; LIMITa. select_expr    -- 可以用 * 表示所有字段。        select * from tb;    -- 可以使用表达式（计算公式、函数调用、字段也是个表达式）        select stu, 29+25, now() from tb;    -- 可以为每个列使用别名。适用于简化列标识，避免多个列标识符重复。        - 使用 as 关键字，也可省略 as.        select stu+10 as add10 from tb;b. FROM 子句    用于标识查询来源。    -- 可以为表起别名。使用as关键字。        SELECT * FROM tb1 AS tt, tb2 AS bb;    -- from子句后，可以同时出现多个表。        -- 多个表会横向叠加到一起，而数据会形成一个笛卡尔积。        SELECT * FROM tb1, tb2;    -- 向优化符提示如何选择索引        USE INDEX、IGNORE INDEX、FORCE INDEX        SELECT * FROM table1 USE INDEX (key1,key2) WHERE key1=1 AND key2=2 AND key3=3;        SELECT * FROM table1 IGNORE INDEX (key3) WHERE key1=1 AND key2=2 AND key3=3;c. WHERE 子句    -- 从from获得的数据源中进行筛选。    -- 整型1表示真，0表示假。    -- 表达式由运算符和运算数组成。        -- 运算数：变量（字段）、值、函数返回值        -- 运算符：            =, &lt;=&gt;, &lt;&gt;, !=, &lt;=, &lt;, &gt;=, &gt;, !, &amp;&amp;, ||,            in (not) null, (not) like, (not) in, (not) between and, is (not), and, or, not, xor            is/is not 加上ture/false/unknown，检验某个值的真假            &lt;=&gt;与&lt;&gt;功能相同，&lt;=&gt;可用于null比较d. GROUP BY 子句, 分组子句    GROUP BY 字段/别名 [排序方式]    分组后会进行排序。升序：ASC，降序：DESC    以下[合计函数]需配合 GROUP BY 使用：    count 返回不同的非NULL值数目  count(*)、count(字段)    sum 求和    max 求最大值    min 求最小值    avg 求平均值    group_concat 返回带有来自一个组的连接的非NULL值的字符串结果。组内字符串连接。e. HAVING 子句，条件子句    与 where 功能、用法相同，执行时机不同。    where 在开始时执行检测数据，对原数据进行过滤。    having 对筛选出的结果再次进行过滤。    having 字段必须是查询出来的，where 字段必须是数据表存在的。    where 不可以使用字段的别名，having 可以。因为执行WHERE代码时，可能尚未确定列值。    where 不可以使用合计函数。一般需用合计函数才会用 having    SQL标准要求HAVING必须引用GROUP BY子句中的列或用于合计函数中的列。f. ORDER BY 子句，排序子句    order by 排序字段/别名 排序方式 [,排序字段/别名 排序方式]...    升序：ASC，降序：DESC    支持多个字段的排序。g. LIMIT 子句，限制结果数量子句    仅对处理好的结果进行数量限制。将处理好的结果的看作是一个集合，按照记录出现的顺序，索引从0开始。    limit 起始位置, 获取条数    省略第一个参数，表示从索引0开始。limit 获取条数h. DISTINCT, ALL 选项    distinct 去除重复记录    默认为 all, 全部记录</code></pre><h3 id="5-8-2-多表查询"><a href="#5-8-2-多表查询" class="headerlink" title="5.8.2 多表查询"></a>5.8.2 多表查询</h3><p>多表查询使用join关键字进行连接</p><p>连接方式分为四种:</p><ul><li>INNER JOIN：如果表中有至少一个匹配，则返回行</li><li>LEFT JOIN：即使右表中没有匹配，也从左表返回所有的行</li><li>RIGHT JOIN：即使左表中没有匹配，也从右表返回所有的行</li><li>FULL JOIN：只要其中一个表中存在匹配，则返回行</li></ul><p>这里不详细介绍 看图理解</p><p><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/sql-join.png" alt=""></p><p>也可参考此篇<a href="https://www.runoob.com/sql/sql-join.html" target="_blank" rel="noopener">文档</a></p><h3 id="5-8-3-SHOW"><a href="#5-8-3-SHOW" class="headerlink" title="5.8.3 SHOW"></a>5.8.3 SHOW</h3><pre><code class="mysql">show  databases;                          #查看所有数据库show tables;                              #查看当前库的所有表SHOW TABLES FROM                          #查看某个指定库下的表show create database world                #查看建库语句show create table world.city              #查看建表语句show  grants for  root@&#39;localhost&#39;        #查看用户的权限信息show  charset；                            #查看字符集show collation                             #查看校对规则show processlist;                          #查看数据库连接情况show index from                            #表的索引情况show status                                 #数据库状态查看SHOW STATUS LIKE &#39;%lock%&#39;;                 #模糊查询数据库某些状态SHOW VARIABLES                             #查看所有配置信息SHOW variables LIKE &#39;%lock%&#39;;              #查看部分配置信息show engines                                #查看支持的所有的存储引擎show engine innodb status                  #查看InnoDB引擎相关的状态信息show binary logs                            #列举所有的二进制日志show master status                           #查看数据库的日志位置信息show binlog events;                          #查看二进制日志事件show slave status                           #查看从库状态SHOW RELAYLOG EVENTS                        #查看从库relaylog事件信息desc  (show colums from city)               #查看表的列定义信息</code></pre><h3 id="5-8-4其它关键字"><a href="#5-8-4其它关键字" class="headerlink" title="5.8.4其它关键字"></a>5.8.4其它关键字</h3><pre><code class="mysql"># distinct：去重复SELECT countrycode FROM city ;SELECT DISTINCT(countrycode) FROM city  ;# 联合查询- union allSELECT * FROM city WHERE countrycode IN (&#39;CHN&#39; ,&#39;USA&#39;);SELECT * FROM city WHERE countrycode=&#39;CHN&#39;UNION ALLSELECT * FROM city WHERE countrycode=&#39;USA&#39;# 联合查询- union SELECT * FROM city WHERE countrycode=&#39;CHN&#39;UNION SELECT * FROM city WHERE countrycode=&#39;USA&#39;说明:一般情况下,我们会将 IN 或者 OR 语句 改写成 UNION (ALL),来提高性能UNION     去重复UNION ALL 不去重复</code></pre>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> Mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>3.Mysql安装及初始化</title>
      <link href="/2020/02/14/3-Mysql%E5%AE%89%E8%A3%85%E5%8F%8A%E5%88%9D%E5%A7%8B%E5%8C%96/"/>
      <url>/2020/02/14/3-Mysql%E5%AE%89%E8%A3%85%E5%8F%8A%E5%88%9D%E5%A7%8B%E5%8C%96/</url>
      
        <content type="html"><![CDATA[<p>环境:Centos8 64位<br>版本:5.7.26 通用二级制版本<br>下载地址:   <a href="https://downloads.mysql.com/archives/get/p/23/file/mysql-5.7.26-linux-glibc2.12-x86_64.tar.gz" target="_blank" rel="noopener">https://downloads.mysql.com/archives/get/p/23/file/mysql-5.7.26-linux-glibc2.12-x86_64.tar.gz</a></p><h2 id="3-1-下载通用二进制包"><a href="#3-1-下载通用二进制包" class="headerlink" title="3.1 下载通用二进制包"></a>3.1 下载通用二进制包</h2><pre><code class="shell">[root@localhost Downloads]# wget  https://downloads.mysql.com/archives/get/p/23/file/mysql-5.7.26-linux-glibc2.12-x86_64.tar.gz</code></pre><h2 id="3-2-创建用户用户"><a href="#3-2-创建用户用户" class="headerlink" title="3.2 创建用户用户"></a>3.2 创建用户用户</h2><pre><code>[root@localhost ken]# useradd mysql</code></pre><h2 id="3-3-创建相应文件夹"><a href="#3-3-创建相应文件夹" class="headerlink" title="3.3 创建相应文件夹"></a>3.3 创建相应文件夹</h2><pre><code>#创建数据存放目录[root@localhost ken]# mkdir -p /data/3306#创建mysql程序存放的目录[root@localhost ken]# mkdir -p /app/database#创建日志存放的目录[root@localhost ken]# mkdir -p /log/3306</code></pre><h2 id="3-4-更改所属目录"><a href="#3-4-更改所属目录" class="headerlink" title="3.4 更改所属目录"></a>3.4 更改所属目录</h2><pre><code>[root@localhost ken]# chown -R mysql.mysql /data/3306  /app/database/ /log/3306/</code></pre><h2 id="3-5-解压mysql并放到指定目录"><a href="#3-5-解压mysql并放到指定目录" class="headerlink" title="3.5 解压mysql并放到指定目录"></a>3.5 解压mysql并放到指定目录</h2><pre><code>[ken@localhost Downloads]$ tar -zxvf mysql-5.7.26-linux-glibc2.12-i686.tar.gz [ken@localhost Downloads]$ lsmysql-5.7.26-linux-glibc2.12-i686  mysql-5.7.26-linux-glibc2.12-i686.tar.gz[ken@localhost Downloads]$ sudo mv mysql-5.7.26-linux-glibc2.12-i686 /app/database/mysql[ken@localhost Downloads]$ sudo chown -R mysql.mysql /app/database/mysql</code></pre><h2 id="3-6设置环境变量"><a href="#3-6设置环境变量" class="headerlink" title="3.6设置环境变量"></a>3.6设置环境变量</h2><pre><code>[ken@localhost ~]$ suPassword: [root@localhost ken]# echo &quot;export PATH=/app/database/mysql/bin:$PATH&quot; &gt;&gt; /etc/profile[root@localhost ken]# exitexit[ken@localhost ~]$ source /etc/profile#显示以下内容即可完成此安装步骤[ken@localhost bin]$ mysql -Vmysql  Ver 14.14 Distrib 5.7.26, for linux-glibc2.12 (x86_64) using  EditLine wrapper【注意】在centos8中 经常会报libncurses.so.5这个文件不存在 但是已经安装了libncurses库还是有报错的话主要是再ceontos中有它的升级版文件/lib64/libncurses.so.6.1 我们做一个软连接即可ln -s /lib64/libncurses.so.6.1 /lib64/libncurses.so.5</code></pre><h2 id="3-7-初始化Mysql"><a href="#3-7-初始化Mysql" class="headerlink" title="3.7 初始化Mysql"></a>3.7 初始化Mysql</h2><pre><code>[root@localhost ken]# mysqld --initialize-insecure --user=mysql --basedir=/app/database/mysql --datadir=/data/3306</code></pre><h2 id="3-8-配置文件设置"><a href="#3-8-配置文件设置" class="headerlink" title="3.8 配置文件设置"></a>3.8 配置文件设置</h2><pre><code>cat &gt; /etc/my.cnf &lt;&lt;EOF[mysqld]user=mysqlbasedir=/app/database/mysqldatadir=/data/3306socket=/tmp/mysql3306.sock[mysql]socket=/tmp/mysql3306.sockEOF</code></pre><h2 id="3-9-准备Mysql启动脚本"><a href="#3-9-准备Mysql启动脚本" class="headerlink" title="3.9 准备Mysql启动脚本"></a>3.9 准备Mysql启动脚本</h2><pre><code>root@localhost support-files]# pwd/app/database/mysql/support-files[root@localhost support-files]# cp mysql.server /etc/init.d/mysqld[root@localhost support-files]# service mysqld startStarting MySQL. SUCCESS! </code></pre><h2 id="3-10-验证是否可以连接成功"><a href="#3-10-验证是否可以连接成功" class="headerlink" title="3.10 验证是否可以连接成功"></a>3.10 验证是否可以连接成功</h2><pre><code>[root@localhost support-files]# mysqlWelcome to the MySQL monitor.  Commands end with ; or \g.Your MySQL connection id is 2Server version: 5.7.26 MySQL Community Server (GPL)Copyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type &#39;help;&#39; or &#39;\h&#39; for help. Type &#39;\c&#39; to clear the current input statement.mysql&gt; </code></pre>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> Mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2.Mysql产品线</title>
      <link href="/2020/02/13/2-Mysql%E4%BA%A7%E5%93%81%E7%BA%BF/"/>
      <url>/2020/02/13/2-Mysql%E4%BA%A7%E5%93%81%E7%BA%BF/</url>
      
        <content type="html"><![CDATA[<h2 id="2-1-Mysql主流厂家"><a href="#2-1-Mysql主流厂家" class="headerlink" title="2.1 Mysql主流厂家"></a>2.1 Mysql主流厂家</h2><ul><li>Oracle:MySQL官方版</li><li>红帽 :MariaDB</li><li>Percona: PerconaDB</li><li>阿里云做的也很好</li></ul><h2 id="2-2-Mysql主流版本"><a href="#2-2-Mysql主流版本" class="headerlink" title="2.2 Mysql主流版本"></a>2.2 Mysql主流版本</h2><ul><li>5.6—–5.6.36 5.6.38 5.6.40 5.6.46</li><li>5.7—–5.7.20 5.7.22 5.7.24 5.7.28</li><li>8.0—–8.0.11</li></ul><p><code>建议选择GA稳定版下半年发布的产品</code></p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> Mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>1.数据库分类</title>
      <link href="/2020/02/12/1-%E6%95%B0%E6%8D%AE%E5%BA%93%E5%88%86%E7%B1%BB/"/>
      <url>/2020/02/12/1-%E6%95%B0%E6%8D%AE%E5%BA%93%E5%88%86%E7%B1%BB/</url>
      
        <content type="html"><![CDATA[<p>我们可以从 <a href="https://db-engines.com/en/ranking" target="_blank" rel="noopener">https://db-engines.com/en/ranking</a>  这个网站查看数据库在互联网上的<code>流行程度</code>:<br><img src="http://mysql317.oss-cn-beijing.aliyuncs.com/database.png" alt="数据库流行程度"></p><h2 id="1-1-关系型数据库"><a href="#1-1-关系型数据库" class="headerlink" title="1.1 关系型数据库"></a>1.1 关系型数据库</h2><p>英文简称为RDMS,最常见的数据库,其核心思想是将复杂的数据结构归结成简单的二元关系<br>常见的关系型数据库为:Mysql,SqlServer,Oracle</p><h2 id="1-2-键值存储数据库"><a href="#1-2-键值存储数据库" class="headerlink" title="1.2  键值存储数据库"></a>1.2  键值存储数据库</h2><p>键值数据库是一种非关系数据库，它使用简单的键值方法来存储数据<br>键值数据库将数据存储为键值对集合，其中键作为唯一标识符<br>常见的键值存储数据库为：Redis和memcached</p><h2 id="1-3-列存储数据库"><a href="#1-3-列存储数据库" class="headerlink" title="1.3 列存储数据库"></a>1.3 列存储数据库</h2><p>列式存储(column-based)是相对于传统关系型数据库的行式存储(Row-basedstorage)来说的<br>简单来说两者的区别就是对表中数据的存储形式的差异<br>常见的列存储数据库为：HBase</p><h2 id="1-4-面向文档数据库"><a href="#1-4-面向文档数据库" class="headerlink" title="1.4 面向文档数据库"></a>1.4 面向文档数据库</h2><p>此类数据库可存放并获取文档，可以是XML、JSON、BSON等格式，这些文档具备可述性（self-describing），呈现分层的树状结构（hierarchical tree data structure），可以包含映射表、集合和纯量值。数据库中的文档彼此相似，但不必完全相同。文档数据库所存放的文档，就相当于键值数据库所存放的“值”。文档数据库可视为其值可查的键值数据库。<br>常见的面向文档数据库为：MongoDB</p><h2 id="1-5-图形数据库"><a href="#1-5-图形数据库" class="headerlink" title="1.5 图形数据库"></a>1.5 图形数据库</h2><p>故名思意就是存储图形关系的数据库,也是Nosql的一种<br>常见的图形数据库为:Neo4J、ArangoDB、OrientDB、FlockDB、GraphDB、InfiniteGraph、Titan和Cayley等</p><h2 id="1-6-搜索引擎存储"><a href="#1-6-搜索引擎存储" class="headerlink" title="1.6 搜索引擎存储"></a>1.6 搜索引擎存储</h2><p>搜索引擎数据库是应用在搜索引擎领域的数据存储形式，由于搜索引擎会爬取大量的数据，并以特定的格式进行存储，这样在检索的时候才能保证性能最优。<br>常见的搜索引擎存储为:Elasticsearch,solr</p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> Mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mysql </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
